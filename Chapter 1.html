<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Chapter 1: Foundations of Visual Perception – The Complete Guide to Bash Errors: From Beginner to Expert</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Chapter 2.html" rel="next">
<link href="./Chapter 0.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-27c261d06b905028a18691de25d09dde.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Chapter 1.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Chapter 1: Foundations of Visual Perception</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">The Complete Guide to Bash Errors: From Beginner to Expert</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Grammar of Figures: The Art &amp; Science of Visualizing Data for Publications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter 0.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title"><strong>Grammar of Figures: The Art and Science of Visualizing Data for Publication</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter 1.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Chapter 1: Foundations of Visual Perception</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter 2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Chapter 2: The Language of Color</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter 3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Chapter 3: Typography, Annotation &amp; Labels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter 4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Chapter 4: Data Encoding &amp; Graph Selection</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter 5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Chapter 5: Layout, Composition &amp; Figure Assembly</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter 6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Chapter 6: Technical Specifications &amp; Publication Requirements</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter 7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Chapter 7: Common Figure Types Deep Dive</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter 8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Chapter 8: Specialized Field Visualizations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter 9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chapter 9: Interactive and Dynamic Figures</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter 10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Chapter 10: Figure Troubleshooting Guide</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#how-we-see-graphical-perception-principles" id="toc-how-we-see-graphical-perception-principles" class="nav-link active" data-scroll-target="#how-we-see-graphical-perception-principles"><span class="header-section-number">3.1</span> 1.1 How We See: Graphical Perception Principles</a>
  <ul class="collapse">
  <li><a href="#the-science-behind-data-visualization" id="toc-the-science-behind-data-visualization" class="nav-link" data-scroll-target="#the-science-behind-data-visualization"><span class="header-section-number">3.1.1</span> The Science Behind Data Visualization</a></li>
  <li><a href="#pre-attentive-processing-what-we-see-without-thinking" id="toc-pre-attentive-processing-what-we-see-without-thinking" class="nav-link" data-scroll-target="#pre-attentive-processing-what-we-see-without-thinking"><span class="header-section-number">3.1.2</span> Pre-attentive Processing: What We See Without Thinking</a></li>
  <li><a href="#the-hierarchy-of-perceptual-accuracy-cleveland-mcgill" id="toc-the-hierarchy-of-perceptual-accuracy-cleveland-mcgill" class="nav-link" data-scroll-target="#the-hierarchy-of-perceptual-accuracy-cleveland-mcgill"><span class="header-section-number">3.1.3</span> The Hierarchy of Perceptual Accuracy: Cleveland &amp; McGill</a></li>
  <li><a href="#practical-application-choosing-plot-types" id="toc-practical-application-choosing-plot-types" class="nav-link" data-scroll-target="#practical-application-choosing-plot-types"><span class="header-section-number">3.1.4</span> Practical Application: Choosing Plot Types</a></li>
  <li><a href="#attention-and-visual-search" id="toc-attention-and-visual-search" class="nav-link" data-scroll-target="#attention-and-visual-search"><span class="header-section-number">3.1.5</span> Attention and Visual Search</a></li>
  <li><a href="#gestalt-principles-in-data-visualization" id="toc-gestalt-principles-in-data-visualization" class="nav-link" data-scroll-target="#gestalt-principles-in-data-visualization"><span class="header-section-number">3.1.6</span> Gestalt Principles in Data Visualization</a></li>
  <li><a href="#change-blindness-and-inattentional-blindness" id="toc-change-blindness-and-inattentional-blindness" class="nav-link" data-scroll-target="#change-blindness-and-inattentional-blindness"><span class="header-section-number">3.1.7</span> Change Blindness and Inattentional Blindness</a></li>
  <li><a href="#working-memory-constraints" id="toc-working-memory-constraints" class="nav-link" data-scroll-target="#working-memory-constraints"><span class="header-section-number">3.1.8</span> Working Memory Constraints</a></li>
  <li><a href="#perceptual-biases-we-cannot-avoid" id="toc-perceptual-biases-we-cannot-avoid" class="nav-link" data-scroll-target="#perceptual-biases-we-cannot-avoid"><span class="header-section-number">3.1.9</span> Perceptual Biases We Cannot Avoid</a></li>
  <li><a href="#temporal-perception-animation-and-change" id="toc-temporal-perception-animation-and-change" class="nav-link" data-scroll-target="#temporal-perception-animation-and-change"><span class="header-section-number">3.1.10</span> Temporal Perception: Animation and Change</a></li>
  <li><a href="#exercise-1.1.1-perceptual-hierarchy-experiment" id="toc-exercise-1.1.1-perceptual-hierarchy-experiment" class="nav-link" data-scroll-target="#exercise-1.1.1-perceptual-hierarchy-experiment"><span class="header-section-number">3.1.11</span> Exercise 1.1.1: Perceptual Hierarchy Experiment</a></li>
  <li><a href="#exercise-1.1.2-pre-attentive-feature-detection" id="toc-exercise-1.1.2-pre-attentive-feature-detection" class="nav-link" data-scroll-target="#exercise-1.1.2-pre-attentive-feature-detection"><span class="header-section-number">3.1.12</span> Exercise 1.1.2: Pre-attentive Feature Detection</a></li>
  <li><a href="#exercise-1.1.3-gestalt-principles-audit" id="toc-exercise-1.1.3-gestalt-principles-audit" class="nav-link" data-scroll-target="#exercise-1.1.3-gestalt-principles-audit"><span class="header-section-number">3.1.13</span> Exercise 1.1.3: Gestalt Principles Audit</a></li>
  </ul></li>
  <li><a href="#visual-channels-and-their-effectiveness" id="toc-visual-channels-and-their-effectiveness" class="nav-link" data-scroll-target="#visual-channels-and-their-effectiveness"><span class="header-section-number">3.2</span> 1.2 Visual Channels and Their Effectiveness</a>
  <ul class="collapse">
  <li><a href="#what-are-visual-channels" id="toc-what-are-visual-channels" class="nav-link" data-scroll-target="#what-are-visual-channels"><span class="header-section-number">3.2.1</span> What Are Visual Channels?</a></li>
  <li><a href="#the-complete-channel-inventory" id="toc-the-complete-channel-inventory" class="nav-link" data-scroll-target="#the-complete-channel-inventory"><span class="header-section-number">3.2.2</span> The Complete Channel Inventory</a></li>
  <li><a href="#matching-channels-to-data-types" id="toc-matching-channels-to-data-types" class="nav-link" data-scroll-target="#matching-channels-to-data-types"><span class="header-section-number">3.2.3</span> Matching Channels to Data Types</a></li>
  <li><a href="#channel-combination-rules" id="toc-channel-combination-rules" class="nav-link" data-scroll-target="#channel-combination-rules"><span class="header-section-number">3.2.4</span> Channel Combination Rules</a></li>
  <li><a href="#common-channel-mistakes" id="toc-common-channel-mistakes" class="nav-link" data-scroll-target="#common-channel-mistakes"><span class="header-section-number">3.2.5</span> Common Channel Mistakes</a></li>
  <li><a href="#exercise-1.2.1-channel-selection-practice" id="toc-exercise-1.2.1-channel-selection-practice" class="nav-link" data-scroll-target="#exercise-1.2.1-channel-selection-practice"><span class="header-section-number">3.2.6</span> Exercise 1.2.1: Channel Selection Practice</a></li>
  <li><a href="#exercise-1.2.2-channel-effectiveness-audit" id="toc-exercise-1.2.2-channel-effectiveness-audit" class="nav-link" data-scroll-target="#exercise-1.2.2-channel-effectiveness-audit"><span class="header-section-number">3.2.7</span> Exercise 1.2.2: Channel Effectiveness Audit</a></li>
  </ul></li>
  <li><a href="#gestalt-principles-in-figure-design-expanded" id="toc-gestalt-principles-in-figure-design-expanded" class="nav-link" data-scroll-target="#gestalt-principles-in-figure-design-expanded"><span class="header-section-number">3.3</span> 1.3 Gestalt Principles in Figure Design (Expanded)</a>
  <ul class="collapse">
  <li><a href="#the-law-of-prägnanz-simplicity" id="toc-the-law-of-prägnanz-simplicity" class="nav-link" data-scroll-target="#the-law-of-prägnanz-simplicity"><span class="header-section-number">3.3.1</span> The Law of Prägnanz (Simplicity)</a></li>
  <li><a href="#advanced-gestalt-applications" id="toc-advanced-gestalt-applications" class="nav-link" data-scroll-target="#advanced-gestalt-applications"><span class="header-section-number">3.3.2</span> Advanced Gestalt Applications</a></li>
  </ul></li>
  <li><a href="#visual-hierarchy-and-focus" id="toc-visual-hierarchy-and-focus" class="nav-link" data-scroll-target="#visual-hierarchy-and-focus"><span class="header-section-number">3.4</span> 1.4 Visual Hierarchy and Focus</a>
  <ul class="collapse">
  <li><a href="#creating-effective-visual-hierarchy" id="toc-creating-effective-visual-hierarchy" class="nav-link" data-scroll-target="#creating-effective-visual-hierarchy"><span class="header-section-number">3.4.1</span> Creating Effective Visual Hierarchy</a></li>
  <li><a href="#the-three-level-hierarchy" id="toc-the-three-level-hierarchy" class="nav-link" data-scroll-target="#the-three-level-hierarchy"><span class="header-section-number">3.4.2</span> The Three-Level Hierarchy</a></li>
  <li><a href="#contrast-as-the-primary-tool" id="toc-contrast-as-the-primary-tool" class="nav-link" data-scroll-target="#contrast-as-the-primary-tool"><span class="header-section-number">3.4.3</span> Contrast as the Primary Tool</a></li>
  <li><a href="#common-hierarchy-mistakes" id="toc-common-hierarchy-mistakes" class="nav-link" data-scroll-target="#common-hierarchy-mistakes"><span class="header-section-number">3.4.4</span> Common Hierarchy Mistakes</a></li>
  <li><a href="#exercise-1.4.1-visual-hierarchy-redesign" id="toc-exercise-1.4.1-visual-hierarchy-redesign" class="nav-link" data-scroll-target="#exercise-1.4.1-visual-hierarchy-redesign"><span class="header-section-number">3.4.5</span> Exercise 1.4.1: Visual Hierarchy Redesign</a></li>
  </ul></li>
  <li><a href="#common-perceptual-traps-and-how-to-avoid-them" id="toc-common-perceptual-traps-and-how-to-avoid-them" class="nav-link" data-scroll-target="#common-perceptual-traps-and-how-to-avoid-them"><span class="header-section-number">3.5</span> 1.5 Common Perceptual Traps and How to Avoid Them</a>
  <ul class="collapse">
  <li><a href="#trap-1-the-truncated-axis" id="toc-trap-1-the-truncated-axis" class="nav-link" data-scroll-target="#trap-1-the-truncated-axis"><span class="header-section-number">3.5.1</span> Trap 1: The Truncated Axis</a></li>
  <li><a href="#trap-2-the-dual-axis-deception" id="toc-trap-2-the-dual-axis-deception" class="nav-link" data-scroll-target="#trap-2-the-dual-axis-deception"><span class="header-section-number">3.5.2</span> Trap 2: The Dual Axis Deception</a></li>
  <li><a href="#trap-3-cherry-picked-axis-ranges" id="toc-trap-3-cherry-picked-axis-ranges" class="nav-link" data-scroll-target="#trap-3-cherry-picked-axis-ranges"><span class="header-section-number">3.5.3</span> Trap 3: Cherry-Picked Axis Ranges</a></li>
  <li><a href="#trap-4-logarithmic-scale-without-clear-indication" id="toc-trap-4-logarithmic-scale-without-clear-indication" class="nav-link" data-scroll-target="#trap-4-logarithmic-scale-without-clear-indication"><span class="header-section-number">3.5.4</span> Trap 4: Logarithmic Scale Without Clear Indication</a></li>
  <li><a href="#trap-5-the-3d-disaster" id="toc-trap-5-the-3d-disaster" class="nav-link" data-scroll-target="#trap-5-the-3d-disaster"><span class="header-section-number">3.5.5</span> Trap 5: The 3D Disaster</a></li>
  <li><a href="#exercise-1.5.1-perceptual-trap-detection" id="toc-exercise-1.5.1-perceptual-trap-detection" class="nav-link" data-scroll-target="#exercise-1.5.1-perceptual-trap-detection"><span class="header-section-number">3.5.6</span> Exercise 1.5.1: Perceptual Trap Detection</a></li>
  </ul></li>
  <li><a href="#chapter-1-summary" id="toc-chapter-1-summary" class="nav-link" data-scroll-target="#chapter-1-summary"><span class="header-section-number">3.6</span> Chapter 1 Summary</a>
  <ul class="collapse">
  <li><a href="#key-principles-from-visual-perception-science" id="toc-key-principles-from-visual-perception-science" class="nav-link" data-scroll-target="#key-principles-from-visual-perception-science"><span class="header-section-number">3.6.1</span> Key Principles from Visual Perception Science</a></li>
  <li><a href="#practical-application-checklist" id="toc-practical-application-checklist" class="nav-link" data-scroll-target="#practical-application-checklist"><span class="header-section-number">3.6.2</span> Practical Application Checklist</a></li>
  <li><a href="#transition-to-chapter-2" id="toc-transition-to-chapter-2" class="nav-link" data-scroll-target="#transition-to-chapter-2"><span class="header-section-number">3.6.3</span> Transition to Chapter 2</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Chapter 1: Foundations of Visual Perception</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="how-we-see-graphical-perception-principles" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="how-we-see-graphical-perception-principles"><span class="header-section-number">3.1</span> 1.1 How We See: Graphical Perception Principles</h2>
<section id="the-science-behind-data-visualization" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="the-science-behind-data-visualization"><span class="header-section-number">3.1.1</span> The Science Behind Data Visualization</h3>
<p>Before we can create effective scientific figures, we must understand the fundamental mechanisms of how humans perceive and interpret visual information. <strong>Graphical perception</strong> is the study of how people extract quantitative information from visual displays. Understanding these principles transforms figure design from an aesthetic exercise into a scientifically-grounded practice.</p>
</section>
<section id="pre-attentive-processing-what-we-see-without-thinking" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="pre-attentive-processing-what-we-see-without-thinking"><span class="header-section-number">3.1.2</span> Pre-attentive Processing: What We See Without Thinking</h3>
<p><strong>Pre-attentive processing</strong> refers to visual features that our brain processes automatically, before conscious attention. These features are detected in less than 200-250 milliseconds—essentially instantaneously.</p>
<p><strong>Pre-attentive Visual Features:</strong> - <strong>Color hue</strong> (red vs.&nbsp;blue) - <strong>Intensity/brightness</strong> (dark vs.&nbsp;light) - <strong>Orientation</strong> (vertical vs.&nbsp;horizontal lines) - <strong>Size</strong> (large vs.&nbsp;small) - <strong>Shape</strong> (circle vs.&nbsp;square) - <strong>Position</strong> (spatial location) - <strong>Motion</strong> (in dynamic displays)</p>
<p><strong>Example Demonstration:</strong></p>
<p>Imagine two scatter plots: - <strong>Plot A</strong>: 100 gray circles, with 1 red circle - <strong>Plot B</strong>: 100 gray circles in random positions, with 1 gray circle positioned differently</p>
<p>In Plot A, the red circle “pops out” immediately (pre-attentive color detection). In Plot B, you must consciously search for the differently positioned circle (attentive processing).</p>
<p><strong>Implication for Figure Design:</strong> Use pre-attentive features to direct attention to the most important data points or patterns. Don’t bury your key finding in visual complexity that requires effortful search.</p>
<p><strong>Good Example:</strong></p>
<pre><code>A volcano plot showing differential gene expression:
- Thousands of gray points (non-significant genes)
- Significant upregulated genes in red
- Significant downregulated genes in blue
→ The colored points immediately draw attention</code></pre>
<p><strong>Bad Example:</strong></p>
<pre><code>The same volcano plot where:
- All points are gray
- Significant genes marked only by slightly different symbols (triangle vs. circle)
→ Requires careful examination; key findings don't stand out</code></pre>
</section>
<section id="the-hierarchy-of-perceptual-accuracy-cleveland-mcgill" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="the-hierarchy-of-perceptual-accuracy-cleveland-mcgill"><span class="header-section-number">3.1.3</span> The Hierarchy of Perceptual Accuracy: Cleveland &amp; McGill</h3>
<p>In the 1980s, psychologists William Cleveland and Robert McGill conducted landmark experiments to determine how accurately people can judge different types of visual encodings. Their findings established a <strong>hierarchy of perceptual accuracy</strong>:</p>
<p><strong>Ranking from MOST to LEAST Accurate:</strong></p>
<ol type="1">
<li><strong>Position along a common scale</strong> (e.g., points on a scatter plot with shared axes)</li>
<li><strong>Position along non-aligned scales</strong> (e.g., separate panels with different scales)</li>
<li><strong>Length</strong> (e.g., bar heights)</li>
<li><strong>Direction/Angle</strong> (e.g., slopes of lines)</li>
<li><strong>Area</strong> (e.g., bubble sizes in bubble charts)</li>
<li><strong>Volume/Density</strong> (e.g., 3D shapes)</li>
<li><strong>Color saturation/intensity</strong> (e.g., heatmap gradients)</li>
<li><strong>Color hue</strong> (e.g., categorical colors)</li>
</ol>
<p><strong>What This Means for Practice:</strong></p>
<p><strong>Most Accurate Encoding (Position):</strong></p>
<pre><code>Comparing treatment effects across conditions:
✓ GOOD: Dot plot with groups on x-axis, values on y-axis
  → Direct position comparison along common y-axis scale
✗ AVOID: Pie charts comparing percentages
  → Requires angle/area judgments, much less accurate</code></pre>
<p><strong>Length vs.&nbsp;Area:</strong></p>
<pre><code>Showing relative quantities:
✓ GOOD: Bar chart (comparing bar heights/lengths)
✗ WORSE: Bubble chart (comparing circle areas)
  → People underestimate area differences

Mathematical reality:
- A circle with 2× the radius has 4× the area
- But viewers perceive only ~2× difference</code></pre>
<p><strong>Color Hue for Quantitative Data:</strong></p>
<pre><code>✗ BAD: Using rainbow colors (red → yellow → blue) for continuous data
  → No inherent ordering; perceptually non-uniform
✓ GOOD: Using sequential color scale (light blue → dark blue)
  → Clear ordering; leverages intensity perception</code></pre>
</section>
<section id="practical-application-choosing-plot-types" class="level3" data-number="3.1.4">
<h3 data-number="3.1.4" class="anchored" data-anchor-id="practical-application-choosing-plot-types"><span class="header-section-number">3.1.4</span> Practical Application: Choosing Plot Types</h3>
<p>Based on the Cleveland-McGill hierarchy, here’s how to select plot types:</p>
<p><strong>For Precise Quantitative Comparisons:</strong> 1. <strong>Scatter plots</strong> (position vs.&nbsp;position) 2. <strong>Line graphs</strong> (position over continuous variable like time) 3. <strong>Bar charts</strong> (length comparison) 4. <strong>Dot plots</strong> (position along scale)</p>
<p><strong>For Approximate Patterns/Trends:</strong> 5. <strong>Heatmaps</strong> (color intensity for patterns, not precise values) 6. <strong>Bubble charts</strong> (area for rough magnitude) 7. <strong>Pie charts</strong> (only for 2-3 very different proportions, if at all)</p>
<p><strong>For Categorical Relationships:</strong> 8. <strong>Box plots/Violin plots</strong> (distribution shapes) 9. <strong>Network diagrams</strong> (connectivity, not precise values)</p>
</section>
<section id="attention-and-visual-search" class="level3" data-number="3.1.5">
<h3 data-number="3.1.5" class="anchored" data-anchor-id="attention-and-visual-search"><span class="header-section-number">3.1.5</span> Attention and Visual Search</h3>
<p>Beyond pre-attentive processing, how we direct and sustain attention matters for complex figures.</p>
<p><strong>Limited Attention Resources:</strong> - We can only consciously attend to one thing at a time - Complex figures require serial processing (scanning element by element) - Each additional element increases cognitive load</p>
<p><strong>Implications:</strong> 1. <strong>Minimize visual clutter</strong>: Every element should serve a purpose 2. <strong>Create clear visual hierarchy</strong>: Most important elements should be most salient 3. <strong>Limit simultaneous comparisons</strong>: Human working memory holds ~4-7 items 4. <strong>Guide the viewer’s path</strong>: Use layout to create a reading order</p>
<p><strong>Example of Attention Management:</strong></p>
<p><strong>Bad: Cognitive Overload</strong></p>
<pre><code>A single figure trying to show:
- Time course of 8 treatments (8 overlapping lines)
- Individual data points (hundreds of dots)
- Error bars at each timepoint
- Statistical significance markers between all pairs
- Three different y-axis scales
→ Viewer doesn't know where to look first; analysis paralysis</code></pre>
<p><strong>Good: Staged Information</strong></p>
<pre><code>Multi-panel approach:
Panel A: Overview - mean trajectories only (3 key treatments)
Panel B: Detailed comparison - 2 treatments with error bars
Panel C: Summary - final endpoint comparison with statistics
→ Clear narrative progression; each panel has one message</code></pre>
</section>
<section id="gestalt-principles-in-data-visualization" class="level3" data-number="3.1.6">
<h3 data-number="3.1.6" class="anchored" data-anchor-id="gestalt-principles-in-data-visualization"><span class="header-section-number">3.1.6</span> Gestalt Principles in Data Visualization</h3>
<p>Gestalt psychology describes how humans organize visual elements into groups or unified wholes. These principles are fundamental to effective figure layout.</p>
<section id="proximity" class="level4" data-number="3.1.6.1">
<h4 data-number="3.1.6.1" class="anchored" data-anchor-id="proximity"><span class="header-section-number">3.1.6.1</span> 1. Proximity</h4>
<p><strong>Principle:</strong> Elements close together are perceived as belonging together.</p>
<p><strong>Application:</strong></p>
<pre><code>Multi-panel figures:
- Place related panels near each other
- Use white space to separate conceptually different sections
- Group legends near their corresponding data

Example:
Panel A (experiment 1) | Panel B (experiment 2)
[placed adjacently]
vs.
Panel C (control data)
[separated by white space]</code></pre>
</section>
<section id="similarity" class="level4" data-number="3.1.6.2">
<h4 data-number="3.1.6.2" class="anchored" data-anchor-id="similarity"><span class="header-section-number">3.1.6.2</span> 2. Similarity</h4>
<p><strong>Principle:</strong> Elements that share visual properties (color, shape, size) are perceived as related.</p>
<p><strong>Application:</strong></p>
<pre><code>Consistent encoding across figures:
- Same colors for same treatments throughout manuscript
- Same symbols for same data types
- Same line styles for same conditions

Example:
Figure 1: Control = blue circles, Treatment = red squares
Figure 2: Should maintain same scheme, not switch arbitrarily</code></pre>
</section>
<section id="continuity" class="level4" data-number="3.1.6.3">
<h4 data-number="3.1.6.3" class="anchored" data-anchor-id="continuity"><span class="header-section-number">3.1.6.3</span> 3. Continuity</h4>
<p><strong>Principle:</strong> The eye follows paths and lines naturally.</p>
<p><strong>Application:</strong></p>
<pre><code>Line graphs:
- Smooth lines guide eye through temporal progression
- Connecting related data points clarifies relationships
- Avoid unnecessary breaks in lines (unless data truly missing)

Example in multi-panel layout:
Arrange panels in reading order (left → right, top → bottom)
that matches narrative progression</code></pre>
</section>
<section id="closure" class="level4" data-number="3.1.6.4">
<h4 data-number="3.1.6.4" class="anchored" data-anchor-id="closure"><span class="header-section-number">3.1.6.4</span> 4. Closure</h4>
<p><strong>Principle:</strong> We perceive complete figures even when parts are missing.</p>
<p><strong>Application:</strong></p>
<pre><code>Axis design:
✓ Can omit top and right spines (brain completes the frame)
✗ Don't omit axis labels (brain cannot infer meaning)

Scatter plots:
- Can use partial grid lines (just at major ticks)
- Brain fills in the implicit grid structure</code></pre>
</section>
<section id="figure-ground-separation" class="level4" data-number="3.1.6.5">
<h4 data-number="3.1.6.5" class="anchored" data-anchor-id="figure-ground-separation"><span class="header-section-number">3.1.6.5</span> 5. Figure-Ground Separation</h4>
<p><strong>Principle:</strong> We distinguish foreground objects from background.</p>
<p><strong>Application:</strong></p>
<pre><code>Data vs. Context:
- Data elements (points, lines) should be visually prominent
- Supporting elements (grid, axis lines) should recede
- Use contrast: bold/bright for data, light/thin for context

Example:
✓ Black data points on light gray grid
✗ Gray data points on black grid (inverts natural hierarchy)</code></pre>
</section>
</section>
<section id="change-blindness-and-inattentional-blindness" class="level3" data-number="3.1.7">
<h3 data-number="3.1.7" class="anchored" data-anchor-id="change-blindness-and-inattentional-blindness"><span class="header-section-number">3.1.7</span> Change Blindness and Inattentional Blindness</h3>
<p><strong>Change Blindness:</strong> Failure to detect changes in visual scenes when they occur during brief interruptions.</p>
<p><strong>Relevance to Figures:</strong> - Readers may miss subtle differences between conditions if not highlighted - Before/after comparisons need clear side-by-side presentation - Don’t rely on readers remembering Figure 2 when viewing Figure 5</p>
<p><strong>Solutions:</strong></p>
<pre><code>✓ Direct comparisons within same panel or adjacent panels
✓ Use annotation arrows to highlight changes
✓ Repeat reference condition in multiple panels if needed</code></pre>
<p><strong>Inattentional Blindness:</strong> Failing to see unexpected objects when attention is focused elsewhere.</p>
<p><strong>Relevance to Figures:</strong> - Readers focused on one aspect may miss important secondary patterns - Critical findings need explicit visual emphasis - Cannot assume readers will notice everything you see</p>
<p><strong>Example:</strong></p>
<pre><code>Scatter plot showing correlation:
- Main focus: positive correlation in Treatment A
- Hidden insight: 3 extreme outliers that might be artifacts
→ If outliers aren't highlighted (different color/size),
   readers focused on the trend will miss them</code></pre>
</section>
<section id="working-memory-constraints" class="level3" data-number="3.1.8">
<h3 data-number="3.1.8" class="anchored" data-anchor-id="working-memory-constraints"><span class="header-section-number">3.1.8</span> Working Memory Constraints</h3>
<p><strong>Miller’s Law:</strong> Human working memory can hold approximately 7±2 items simultaneously.</p>
<p><strong>Implications for Figures:</strong></p>
<p><strong>Bad: Exceeding Memory Limits</strong></p>
<pre><code>Line graph with 15 different colored lines
→ Cannot keep track of which color means what
→ Constant back-and-forth reference to legend
→ Cognitive overload</code></pre>
<p><strong>Good: Respecting Memory Limits</strong></p>
<pre><code>Option 1: Show only 3-5 key lines, others in supplementary figure
Option 2: Use small multiples (separate panels for each line)
Option 3: Highlight 2-3 key comparisons, gray out others</code></pre>
<p><strong>Legend Design Consideration:</strong></p>
<pre><code>If legend requires &gt;7 items, consider:
- Is this really one figure, or should it be split?
- Can you use direct labeling instead of legend?
- Can you group items into fewer categories?</code></pre>
</section>
<section id="perceptual-biases-we-cannot-avoid" class="level3" data-number="3.1.9">
<h3 data-number="3.1.9" class="anchored" data-anchor-id="perceptual-biases-we-cannot-avoid"><span class="header-section-number">3.1.9</span> Perceptual Biases We Cannot Avoid</h3>
<section id="the-weber-fechner-law" class="level4" data-number="3.1.9.1">
<h4 data-number="3.1.9.1" class="anchored" data-anchor-id="the-weber-fechner-law"><span class="header-section-number">3.1.9.1</span> The Weber-Fechner Law</h4>
<p><strong>Principle:</strong> We perceive differences logarithmically, not linearly.</p>
<p><strong>Implications:</strong></p>
<pre><code>Comparing values:
- Difference between 1 and 2 feels bigger than between 10 and 11
  (both are +1, but 1→2 is 100% increase vs. 10→11 is 10% increase)

Solution for large ranges:
- Use log scales when data spans orders of magnitude
- This makes proportional differences perceptually equal</code></pre>
</section>
<section id="the-area-perception-bias" class="level4" data-number="3.1.9.2">
<h4 data-number="3.1.9.2" class="anchored" data-anchor-id="the-area-perception-bias"><span class="header-section-number">3.1.9.2</span> The Area Perception Bias</h4>
<p><strong>Principle:</strong> We systematically underestimate area differences.</p>
<p><strong>Example:</strong></p>
<pre><code>Circle A has diameter 10, Circle B has diameter 20
- Actual area ratio: (20/10)² = 4:1
- Perceived ratio: approximately 2:1

Implication:
✗ Bubble charts exaggerate small differences, hide large ones
✓ Use length/position encodings for accurate magnitude comparison</code></pre>
</section>
<section id="the-color-contrast-effect" class="level4" data-number="3.1.9.3">
<h4 data-number="3.1.9.3" class="anchored" data-anchor-id="the-color-contrast-effect"><span class="header-section-number">3.1.9.3</span> The Color Contrast Effect</h4>
<p><strong>Principle:</strong> Perceived color depends on surrounding colors.</p>
<p><strong>Example:</strong></p>
<pre><code>Same gray square appears:
- Darker when surrounded by white
- Lighter when surrounded by black

Implication for heatmaps:
- Use consistent backgrounds across figures
- Be aware that adjacent colors influence perception
- Test figures in both digital (white background) and print contexts</code></pre>
</section>
</section>
<section id="temporal-perception-animation-and-change" class="level3" data-number="3.1.10">
<h3 data-number="3.1.10" class="anchored" data-anchor-id="temporal-perception-animation-and-change"><span class="header-section-number">3.1.10</span> Temporal Perception: Animation and Change</h3>
<p>For dynamic displays (less common in static publications, but relevant for presentations and supplementary materials):</p>
<p><strong>Effective Use:</strong> - Showing temporal progression of processes - Revealing complex patterns in stages - Guiding attention through complex figures</p>
<p><strong>Caution:</strong> - Motion is highly pre-attentive (can be distracting) - Difficult to compare frames from memory - Not suitable for precise quantitative reading - Accessibility issues (motion sensitivity)</p>
<p><strong>Best Practice:</strong></p>
<pre><code>For presentations:
✓ Use animation to build up complexity gradually
✓ Pause on key frames for analysis
✓ Provide static "key frame" summary

For publications:
✓ Convert animations to multi-panel static figures
✓ Show representative timepoints</code></pre>
<hr>
</section>
<section id="exercise-1.1.1-perceptual-hierarchy-experiment" class="level3" data-number="3.1.11">
<h3 data-number="3.1.11" class="anchored" data-anchor-id="exercise-1.1.1-perceptual-hierarchy-experiment"><span class="header-section-number">3.1.11</span> Exercise 1.1.1: Perceptual Hierarchy Experiment</h3>
<p><strong>Objective:</strong> Experience the Cleveland-McGill hierarchy firsthand</p>
<p><strong>Materials needed:</strong> Graph paper or plotting software</p>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li><strong>Create three versions of the same data</strong> (5 categories, values: 20, 35, 45, 60, 75):
<ul>
<li>Version A: Bar chart (length encoding)</li>
<li>Version B: Pie chart (angle encoding)</li>
<li>Version C: Bubble chart (area encoding)</li>
</ul></li>
<li><strong>Test yourself:</strong>
<ul>
<li>Look at each for 3 seconds only</li>
<li>Without referring back, estimate:
<ul>
<li>Which category has the highest value?</li>
<li>What is the ratio of largest to smallest value?</li>
<li>Rank all categories from smallest to largest</li>
</ul></li>
</ul></li>
<li><strong>Reflection questions:</strong>
<ul>
<li>Which version made estimation easiest?</li>
<li>Where did you make errors?</li>
<li>Which version required the most “mental calculation”?</li>
<li>What does this tell you about encoding choice?</li>
</ul></li>
</ol>
<p><strong>Expected finding:</strong> Bar chart will be easiest and most accurate; pie chart most difficult.</p>
<hr>
</section>
<section id="exercise-1.1.2-pre-attentive-feature-detection" class="level3" data-number="3.1.12">
<h3 data-number="3.1.12" class="anchored" data-anchor-id="exercise-1.1.2-pre-attentive-feature-detection"><span class="header-section-number">3.1.12</span> Exercise 1.1.2: Pre-attentive Feature Detection</h3>
<p><strong>Objective:</strong> Identify what “pops out” in your figures</p>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li><p><strong>Take a figure you’re currently working on</strong></p></li>
<li><p><strong>The 3-second test:</strong></p>
<ul>
<li>Show figure to a colleague for exactly 3 seconds</li>
<li>Remove it</li>
<li>Ask: “What did you notice first?”</li>
</ul></li>
<li><p><strong>Analysis:</strong></p>
<ul>
<li>Was the first thing they noticed your intended main message?</li>
<li>If yes: What pre-attentive feature made it stand out? (color, size, position?)</li>
<li>If no: What competed for attention? How can you adjust?</li>
</ul></li>
<li><p><strong>Redesign:</strong></p>
<ul>
<li>Emphasize the main message using pre-attentive features</li>
<li>De-emphasize secondary elements</li>
<li>Retest with a different colleague</li>
</ul></li>
</ol>
<hr>
</section>
<section id="exercise-1.1.3-gestalt-principles-audit" class="level3" data-number="3.1.13">
<h3 data-number="3.1.13" class="anchored" data-anchor-id="exercise-1.1.3-gestalt-principles-audit"><span class="header-section-number">3.1.13</span> Exercise 1.1.3: Gestalt Principles Audit</h3>
<p><strong>Objective:</strong> Apply Gestalt principles to improve figure organization</p>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li><p><strong>Select a multi-panel figure</strong> (your own or from a published paper)</p></li>
<li><p><strong>Analyze each Gestalt principle:</strong></p>
<ul>
<li><p><strong>Proximity:</strong> Are related panels grouped together? Is white space used to separate conceptually different elements?</p></li>
<li><p><strong>Similarity:</strong> Do similar data types use consistent visual encoding? Are colors/shapes reused meaningfully?</p></li>
<li><p><strong>Continuity:</strong> Does the layout create a natural reading path? Does it match your narrative order?</p></li>
<li><p><strong>Closure:</strong> Are all frames necessary, or could you simplify by letting the brain “complete” structures?</p></li>
<li><p><strong>Figure-Ground:</strong> Do data elements stand out from supporting elements (axes, grids)?</p></li>
</ul></li>
<li><p><strong>Score each principle:</strong> 1 (poor) to 5 (excellent)</p></li>
<li><p><strong>Identify weakest area</strong> and sketch one specific improvement</p></li>
</ol>
<p><strong>Example improvement:</strong></p>
<pre><code>Original: Four panels scattered with inconsistent spacing
Problem: Violation of proximity principle
Solution: Group panels A-B (related experiments) close together,
          separate from panels C-D (control data) with more white space</code></pre>
<hr>
</section>
</section>
<section id="visual-channels-and-their-effectiveness" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="visual-channels-and-their-effectiveness"><span class="header-section-number">3.2</span> 1.2 Visual Channels and Their Effectiveness</h2>
<section id="what-are-visual-channels" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="what-are-visual-channels"><span class="header-section-number">3.2.1</span> What Are Visual Channels?</h3>
<p>A <strong>visual channel</strong> (or <strong>visual variable</strong>) is any controlled aspect of a graphical mark that can encode data. Understanding which channels are most effective for which data types is foundational to making good visualization choices.</p>
</section>
<section id="the-complete-channel-inventory" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="the-complete-channel-inventory"><span class="header-section-number">3.2.2</span> The Complete Channel Inventory</h3>
<p><strong>Spatial Channels (Most Effective):</strong> 1. <strong>Position (X, Y coordinates)</strong> - <em>Best for quantitative data</em> 2. <strong>Length</strong> - <em>Very good for quantitative data</em> 3. <strong>Angle</strong> - <em>Good for ordinal/limited quantitative</em> 4. <strong>Slope</strong> - <em>Good for trends and rates of change</em></p>
<p><strong>Appearance Channels (Moderate Effectiveness):</strong> 5. <strong>Area</strong> - <em>Moderate for quantitative, good for magnitude</em> 6. <strong>Volume</strong> - <em>Poor for quantitative, avoid if possible</em> 7. <strong>Color Hue</strong> - <em>Best for categorical/nominal data</em> 8. <strong>Color Saturation</strong> - <em>Good for ordinal/limited quantitative</em> 9. <strong>Color Luminance</strong> - <em>Good for quantitative (single hue)</em></p>
<p><strong>Texture Channels (Lower Effectiveness):</strong> 10. <strong>Shape</strong> - <em>Good for categorical (limited #)</em> 11. <strong>Texture/Pattern</strong> - <em>Moderate for categorical</em> 12. <strong>Orientation</strong> - <em>Moderate for categorical/ordinal</em></p>
</section>
<section id="matching-channels-to-data-types" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="matching-channels-to-data-types"><span class="header-section-number">3.2.3</span> Matching Channels to Data Types</h3>
<p>The type of data you have determines which channels are appropriate:</p>
<section id="quantitative-data-continuous-numbers" class="level4" data-number="3.2.3.1">
<h4 data-number="3.2.3.1" class="anchored" data-anchor-id="quantitative-data-continuous-numbers"><span class="header-section-number">3.2.3.1</span> 1. Quantitative Data (Continuous Numbers)</h4>
<p><strong>Best Channels (in order):</strong> - <strong>Position</strong> (scatter plots, line graphs) - <strong>Length</strong> (bar charts) - <strong>Color luminance</strong> (single-hue gradient heatmaps)</p>
<p><strong>Example:</strong></p>
<pre><code>Showing gene expression levels across samples:
✓ EXCELLENT: Position (dot plot with values on y-axis)
✓ GOOD: Length (bar chart)
✓ ACCEPTABLE: Color luminance (heatmap, light→dark)
✗ POOR: Color hue (rainbow heatmap)
✗ TERRIBLE: Area/volume (3D bar chart)</code></pre>
<p><strong>Why position is best:</strong> - Humans excel at judging positions along a common scale - Precise reading possible with gridlines - Direct comparison between elements - Minimal perceptual distortion</p>
<p><strong>Code Example (Python):</strong></p>
<pre><code>import matplotlib.pyplot as plt
import numpy as np

# Sample data: gene expression across 5 conditions
genes = ['GeneA', 'GeneB', 'GeneC', 'GeneD', 'GeneE']
expression = [2.3, 5.1, 3.7, 8.2, 4.9]

# BEST: Position encoding (dot plot)
fig, axes = plt.subplots(1, 3, figsize=(12, 3))

# Plot 1: Position (best)
axes[0].scatter(expression, genes, s=100, color='steelblue')
axes[0].set_xlabel('Expression Level')
axes[0].set_title('Position Channel (Best)')
axes[0].grid(axis='x', alpha=0.3)

# Plot 2: Length (good)
axes[1].barh(genes, expression, color='steelblue')
axes[1].set_xlabel('Expression Level')
axes[1].set_title('Length Channel (Good)')

# Plot 3: Area (poor - for comparison)
# Normalize for bubble sizing
sizes = (np.array(expression) ** 2) * 10
axes[2].scatter([1]*len(genes), genes, s=sizes,
                color='steelblue', alpha=0.6)
axes[2].set_xlim(0.5, 1.5)
axes[2].set_xticks([])
axes[2].set_title('Area Channel (Poor)')

plt.tight_layout()
plt.savefig('channel_comparison.png', dpi=300, bbox_inches='tight')</code></pre>
</section>
<section id="ordinal-data-rankedordered-categories" class="level4" data-number="3.2.3.2">
<h4 data-number="3.2.3.2" class="anchored" data-anchor-id="ordinal-data-rankedordered-categories"><span class="header-section-number">3.2.3.2</span> 2. Ordinal Data (Ranked/Ordered Categories)</h4>
<p><strong>Best Channels:</strong> - <strong>Position</strong> (along an ordered axis) - <strong>Color luminance</strong> (sequential palette) - <strong>Size</strong> (small to large) - <strong>Angle</strong> (for cyclic data like time of day)</p>
<p><strong>Example:</strong></p>
<pre><code>Showing disease severity (mild, moderate, severe):
✓ EXCELLENT: Position (ordered categories on x-axis)
✓ GOOD: Color (light → dark gradient)
✓ ACCEPTABLE: Size (small → medium → large markers)
✗ POOR: Color hue (red, blue, green - no inherent order)</code></pre>
<p><strong>Code Example (R):</strong></p>
<pre><code>library(ggplot2)
library(RColorBrewer)

# Sample data
data &lt;- data.frame(
  patient = 1:20,
  severity = factor(sample(c("Mild", "Moderate", "Severe"), 20, replace=TRUE),
                    levels = c("Mild", "Moderate", "Severe"),
                    ordered = TRUE),
  response = rnorm(20, 50, 10)
)

# GOOD: Position + sequential color for ordinal data
ggplot(data, aes(x = severity, y = response, color = severity)) +
  geom_jitter(size = 3, width = 0.2) +
  scale_color_brewer(palette = "YlOrRd") +  # Sequential palette
  labs(x = "Disease Severity", y = "Treatment Response",
       title = "Position + Sequential Color for Ordinal Data") +
  theme_minimal(base_size = 12) +
  theme(legend.position = "none")  # Legend redundant when x-axis labeled</code></pre>
</section>
<section id="categoricalnominal-data-unordered-groups" class="level4" data-number="3.2.3.3">
<h4 data-number="3.2.3.3" class="anchored" data-anchor-id="categoricalnominal-data-unordered-groups"><span class="header-section-number">3.2.3.3</span> 3. Categorical/Nominal Data (Unordered Groups)</h4>
<p><strong>Best Channels:</strong> - <strong>Color hue</strong> (distinct colors) - <strong>Shape</strong> (different symbols - limit to ~6) - <strong>Position</strong> (separate groups along axis) - <strong>Faceting</strong> (separate panels)</p>
<p><strong>Example:</strong></p>
<pre><code>Showing data from 4 different cell lines:
✓ EXCELLENT: Color hue (4 distinct colors)
✓ GOOD: Shape (4 different symbols: circle, square, triangle, diamond)
✓ ACCEPTABLE: Position (4 separate groups on x-axis)
✗ AVOID: Color luminance (implies ordering that doesn't exist)</code></pre>
<p><strong>Code Example (Python):</strong></p>
<pre><code>import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# Sample data
data = pd.DataFrame({
    'cell_line': np.repeat(['A', 'B', 'C', 'D'], 50),
    'time': np.tile(np.arange(50), 4),
    'growth': np.concatenate([
        np.cumsum(np.random.randn(50) + 0.5),
        np.cumsum(np.random.randn(50) + 0.3),
        np.cumsum(np.random.randn(50) + 0.7),
        np.cumsum(np.random.randn(50) + 0.4)
    ])
})

# GOOD: Color hue for categorical data
fig, ax = plt.subplots(figsize=(8, 5))

# Qualitative color palette
colors = ['#E64B35', '#4DBBD5', '#00A087', '#3C5488']

for i, cell_line in enumerate(['A', 'B', 'C', 'D']):
    subset = data[data['cell_line'] == cell_line]
    ax.plot(subset['time'], subset['growth'],
            color=colors[i], linewidth=2, label=f'Cell Line {cell_line}')

ax.set_xlabel('Time (hours)', fontsize=12)
ax.set_ylabel('Cell Growth (AU)', fontsize=12)
ax.set_title('Color Hue for Categorical Data', fontsize=14, fontweight='bold')
ax.legend(frameon=True, loc='upper left')
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

plt.tight_layout()
plt.savefig('categorical_channels.png', dpi=300, bbox_inches='tight')</code></pre>
</section>
</section>
<section id="channel-combination-rules" class="level3" data-number="3.2.4">
<h3 data-number="3.2.4" class="anchored" data-anchor-id="channel-combination-rules"><span class="header-section-number">3.2.4</span> Channel Combination Rules</h3>
<p>Often you need to encode multiple data dimensions simultaneously. Here’s how to combine channels effectively:</p>
<section id="rule-1-use-the-strongest-channel-for-the-most-important-variable" class="level4" data-number="3.2.4.1">
<h4 data-number="3.2.4.1" class="anchored" data-anchor-id="rule-1-use-the-strongest-channel-for-the-most-important-variable"><span class="header-section-number">3.2.4.1</span> Rule 1: Use the Strongest Channel for the Most Important Variable</h4>
<pre><code>Example: Scatter plot showing drug response

Primary variable (most important): Treatment outcome
Secondary variable: Patient age
Tertiary variable: Treatment group

Encoding:
✓ Position Y: Treatment outcome (strongest channel)
✓ Position X: Patient age (second strongest)
✓ Color: Treatment group (weaker channel, but effective for categories)</code></pre>
</section>
<section id="rule-2-avoid-channel-conflict" class="level4" data-number="3.2.4.2">
<h4 data-number="3.2.4.2" class="anchored" data-anchor-id="rule-2-avoid-channel-conflict"><span class="header-section-number">3.2.4.2</span> Rule 2: Avoid Channel Conflict</h4>
<p><strong>Conflict Example:</strong></p>
<pre><code>✗ BAD: Using both size AND color luminance to encode the same variable
  → Redundant and potentially contradictory
  → e.g., larger AND darker doesn't add information

✓ BETTER: Use size for one variable, color hue for another categorical variable</code></pre>
<p><strong>Non-Conflict Example:</strong></p>
<pre><code>Encoding three variables on a scatter plot:
- X-position: Time
- Y-position: Temperature
- Color: Location (categorical)
→ No conflict: each channel encodes different information</code></pre>
</section>
<section id="rule-3-leverage-redundancy-for-accessibility" class="level4" data-number="3.2.4.3">
<h4 data-number="3.2.4.3" class="anchored" data-anchor-id="rule-3-leverage-redundancy-for-accessibility"><span class="header-section-number">3.2.4.3</span> Rule 3: Leverage Redundancy for Accessibility</h4>
<p><strong>Strategic Redundancy:</strong></p>
<pre><code>✓ GOOD: Encoding the same categorical variable with BOTH color AND shape
  → Ensures colorblind accessibility
  → Shape alone works if color unavailable

Example:
Treatment A: Red circles
Treatment B: Blue squares
Treatment C: Green triangles

→ If colors indistinguishable, shapes still differentiate groups</code></pre>
</section>
<section id="rule-4-limit-channel-overload" class="level4" data-number="3.2.4.4">
<h4 data-number="3.2.4.4" class="anchored" data-anchor-id="rule-4-limit-channel-overload"><span class="header-section-number">3.2.4.4</span> Rule 4: Limit Channel Overload</h4>
<p><strong>Too Many Channels:</strong></p>
<pre><code>✗ BAD: Encoding 6 variables on one scatter plot:
  - X position
  - Y position
  - Color hue
  - Color saturation
  - Size
  - Shape

→ Cognitively overwhelming
→ Hard to decode

✓ BETTER: Use small multiples (faceting) to split some variables into panels</code></pre>
</section>
</section>
<section id="common-channel-mistakes" class="level3" data-number="3.2.5">
<h3 data-number="3.2.5" class="anchored" data-anchor-id="common-channel-mistakes"><span class="header-section-number">3.2.5</span> Common Channel Mistakes</h3>
<section id="mistake-1-using-area-for-quantitative-comparison" class="level4" data-number="3.2.5.1">
<h4 data-number="3.2.5.1" class="anchored" data-anchor-id="mistake-1-using-area-for-quantitative-comparison"><span class="header-section-number">3.2.5.1</span> Mistake 1: Using Area for Quantitative Comparison</h4>
<p><strong>The Problem:</strong></p>
<pre><code>Bubble chart where bubble size represents quantity:
- Data: values of 100, 200, 300
- Bubble areas: A₁, A₂, A₃
- Perceptual ratio: ~1.5:2:2.3
- Actual ratio: 1:2:3

→ Systematic underestimation of larger values</code></pre>
<p><strong>The Fix:</strong></p>
<pre><code>✓ Use length encoding instead (bar chart)
✗ If bubble chart necessary, scale radius (not area) linearly
  But still expect perceptual error</code></pre>
<p><strong>Code to Demonstrate:</strong></p>
<pre><code>import matplotlib.pyplot as plt
import numpy as np

values = np.array([100, 200, 300, 400])

fig, axes = plt.subplots(1, 2, figsize=(10, 4))

# WRONG: Area proportional to value (default behavior)
axes[0].scatter([1, 2, 3, 4], [1, 1, 1, 1], s=values, alpha=0.5)
axes[0].set_xlim(0, 5)
axes[0].set_ylim(0, 2)
axes[0].set_title('WRONG: Area ∝ Value\n(Perceptually misleading)')
axes[0].set_xticks([1, 2, 3, 4])
axes[0].set_xticklabels(values)

# BETTER: Length proportional to value
axes[1].bar([1, 2, 3, 4], values, width=0.6, alpha=0.7)
axes[1].set_title('BETTER: Length ∝ Value\n(Accurate perception)')
axes[1].set_xticks([1, 2, 3, 4])
axes[1].set_xticklabels(values)
axes[1].set_ylabel('Value')

plt.tight_layout()
plt.savefig('area_vs_length.png', dpi=300, bbox_inches='tight')</code></pre>
</section>
<section id="mistake-2-rainbow-color-maps-for-quantitative-data" class="level4" data-number="3.2.5.2">
<h4 data-number="3.2.5.2" class="anchored" data-anchor-id="mistake-2-rainbow-color-maps-for-quantitative-data"><span class="header-section-number">3.2.5.2</span> Mistake 2: Rainbow Color Maps for Quantitative Data</h4>
<p><strong>The Problem:</strong></p>
<pre><code>Using hue spectrum (rainbow: red→yellow→green→blue→violet) for continuous data:

Issues:
1. No perceptual ordering (is yellow &gt; green?)
2. Non-uniform perceptual steps (yellow is much brighter)
3. False boundaries (sharp transitions in smooth data)
4. Accessibility issues (colorblind viewers lose information)</code></pre>
<p><strong>The Fix:</strong></p>
<pre><code>✓ Use sequential colormaps (single hue, varying luminance)
  Examples: Blues, Greens, Greys

✓ Use diverging colormaps for data with meaningful midpoint
  Examples: Blue-White-Red for positive/negative values

✓ Use perceptually uniform colormaps
  Examples: viridis, plasma, cividis</code></pre>
<p><strong>Demonstration:</strong></p>
<pre><code>import matplotlib.pyplot as plt
import numpy as np

# Create sample heatmap data
data = np.random.randn(10, 10).cumsum(axis=1)

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

# BAD: Rainbow
im1 = axes[0].imshow(data, cmap='jet', aspect='auto')
axes[0].set_title('BAD: Rainbow (jet)\nNon-uniform, no order', fontsize=12)
plt.colorbar(im1, ax=axes[0])

# BETTER: Sequential
im2 = axes[1].imshow(data, cmap='Blues', aspect='auto')
axes[1].set_title('BETTER: Sequential\nClear low→high', fontsize=12)
plt.colorbar(im2, ax=axes[1])

# BEST: Perceptually uniform
im3 = axes[2].imshow(data, cmap='viridis', aspect='auto')
axes[2].set_title('BEST: Viridis\nPerceptually uniform', fontsize=12)
plt.colorbar(im3, ax=axes[2])

for ax in axes:
    ax.set_xticks([])
    ax.set_yticks([])

plt.tight_layout()
plt.savefig('colormap_comparison.png', dpi=300, bbox_inches='tight')</code></pre>
</section>
<section id="mistake-3-using-3d-for-2d-data" class="level4" data-number="3.2.5.3">
<h4 data-number="3.2.5.3" class="anchored" data-anchor-id="mistake-3-using-3d-for-2d-data"><span class="header-section-number">3.2.5.3</span> Mistake 3: Using 3D for 2D Data</h4>
<p><strong>The Problem:</strong></p>
<pre><code>3D bar charts, 3D pie charts, 3D scatter plots when z-axis adds no information:

Issues:
1. Perspective distortion (objects in back appear smaller)
2. Occlusion (bars hide each other)
3. Difficult to read exact values
4. Adds no information, only visual complexity</code></pre>
<p><strong>The Fix:</strong></p>
<pre><code>✓ Use 2D representations with position/length channels
✗ Only use 3D when you genuinely have 3 spatial dimensions of data
  (e.g., protein structure, geographic elevation)</code></pre>
<hr>
</section>
</section>
<section id="exercise-1.2.1-channel-selection-practice" class="level3" data-number="3.2.6">
<h3 data-number="3.2.6" class="anchored" data-anchor-id="exercise-1.2.1-channel-selection-practice"><span class="header-section-number">3.2.6</span> Exercise 1.2.1: Channel Selection Practice</h3>
<p><strong>Objective:</strong> Practice choosing appropriate channels for different data types</p>
<p><strong>Scenario:</strong> You have the following dataset from a clinical trial:</p>
<ul>
<li><strong>Patient ID</strong> (categorical, nominal)</li>
<li><strong>Treatment Group</strong> (categorical: A, B, C, Control)</li>
<li><strong>Age</strong> (quantitative, continuous: 20-80 years)</li>
<li><strong>Disease Severity</strong> (ordinal: Mild, Moderate, Severe)</li>
<li><strong>Treatment Outcome</strong> (quantitative, continuous: 0-100 scale)</li>
<li><strong>Time to Response</strong> (quantitative, continuous: days)</li>
</ul>
<p><strong>Task:</strong> Design visualizations for these questions, specifying which channels you’d use:</p>
<ol type="1">
<li><strong>Question:</strong> How does treatment outcome vary by treatment group?
<ul>
<li>Primary channel for outcome: _______</li>
<li>Channel for treatment group: _______</li>
<li>Justification: _______</li>
</ul></li>
<li><strong>Question:</strong> Is there a relationship between age and treatment outcome?
<ul>
<li>Channel for age: _______</li>
<li>Channel for outcome: _______</li>
<li>Optional third variable (disease severity): _______</li>
<li>Justification: _______</li>
</ul></li>
<li><strong>Question:</strong> How do the four treatment groups compare across disease severity levels?
<ul>
<li>Channel for treatment group: _______</li>
<li>Channel for severity: _______</li>
<li>Channel for outcome: _______</li>
<li>Plot type: _______</li>
</ul></li>
</ol>
<p><strong>Deliverable:</strong> Sketch rough layouts and write 2-3 sentences justifying each channel choice based on the Cleveland-McGill hierarchy.</p>
<hr>
</section>
<section id="exercise-1.2.2-channel-effectiveness-audit" class="level3" data-number="3.2.7">
<h3 data-number="3.2.7" class="anchored" data-anchor-id="exercise-1.2.2-channel-effectiveness-audit"><span class="header-section-number">3.2.7</span> Exercise 1.2.2: Channel Effectiveness Audit</h3>
<p><strong>Objective:</strong> Evaluate channel usage in existing figures</p>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li><p><strong>Find 3 published figures</strong> from your field (preferably recent high-impact papers)</p></li>
<li><p><strong>For each figure, document:</strong></p>
<ul>
<li>What channels are used? (position, length, color, size, shape, etc.)</li>
<li>What type of data is each channel encoding? (quantitative, ordinal, categorical)</li>
<li>Is this an effective match based on the hierarchy?</li>
</ul></li>
<li><p><strong>Identify at least one figure where:</strong></p>
<ul>
<li>A strong channel is wasted on less important data</li>
<li>A weak channel is used for critical quantitative data</li>
<li>Channel choice could be improved</li>
</ul></li>
<li><p><strong>Redesign:</strong> Sketch how you would reassign channels for better effectiveness</p></li>
</ol>
<p><strong>Example Analysis:</strong></p>
<pre><code>Figure: Scatter plot of gene expression

Current encoding:
- X-axis (position): Gene ID number (nominal) ❌
- Y-axis (position): Expression level (quantitative) ✓
- Color (hue): Experimental condition (categorical) ✓

Problem: X-axis position (strongest channel) wasted on arbitrary gene IDs

Improved encoding:
- X-axis (position): Time point
</code></pre>
</section>
</section>
<section id="gestalt-principles-in-figure-design-expanded" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="gestalt-principles-in-figure-design-expanded"><span class="header-section-number">3.3</span> 1.3 Gestalt Principles in Figure Design (Expanded)</h2>
<section id="the-law-of-prägnanz-simplicity" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="the-law-of-prägnanz-simplicity"><span class="header-section-number">3.3.1</span> The Law of Prägnanz (Simplicity)</h3>
<p>Beyond the basic Gestalt principles introduced in 1.1, the overarching <strong>Law of Prägnanz</strong> states that people perceive and interpret ambiguous or complex images in the simplest form possible. Our brains seek to impose order and structure on visual information.</p>
<p><strong>Implication for Scientific Figures:</strong> - Viewers will try to find patterns even in random data - Clear, simple structures are processed faster and remembered better - Unnecessary complexity causes cognitive strain</p>
</section>
<section id="advanced-gestalt-applications" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="advanced-gestalt-applications"><span class="header-section-number">3.3.2</span> Advanced Gestalt Applications</h3>
<section id="common-fate" class="level4" data-number="3.3.2.1">
<h4 data-number="3.3.2.1" class="anchored" data-anchor-id="common-fate"><span class="header-section-number">3.3.2.1</span> Common Fate</h4>
<p><strong>Principle:</strong> Elements moving in the same direction are perceived as a group.</p>
<p><strong>Static Figure Applications:</strong></p>
<pre><code>Line graphs with multiple time series:
✓ Lines following similar trajectories naturally group together
✓ Diverging lines signal important differences
✓ Use this to your advantage: arrange panels so similar patterns are adjacent

Example:
Panel A: All upward trends (treatment responders)
Panel B: All downward trends (treatment non-responders)
→ Visual coherence within each panel strengthens message</code></pre>
<p><strong>Code Example (Python):</strong></p>
<pre><code>import matplotlib.pyplot as plt
import numpy as np

# Demonstrate common fate grouping
time = np.linspace(0, 10, 50)

# Group 1: Similar upward trajectories (common fate)
group1 = [time * 0.8 + np.random.randn(50) * 0.5,
          time * 0.9 + np.random.randn(50) * 0.5,
          time * 0.85 + np.random.randn(50) * 0.5]

# Group 2: Similar flat trajectories (common fate)
group2 = [5 + np.random.randn(50) * 0.5,
          5.5 + np.random.randn(50) * 0.5,
          4.8 + np.random.randn(50) * 0.5]

fig, ax = plt.subplots(figsize=(8, 5))

# Plot group 1 in shades of red (responders)
for i, trajectory in enumerate(group1):
    ax.plot(time, trajectory, color=plt.cm.Reds(0.5 + i*0.15),
            linewidth=2, label=f'Responder {i+1}' if i &lt; 1 else '')

# Plot group 2 in shades of blue (non-responders)
for i, trajectory in enumerate(group2):
    ax.plot(time, trajectory, color=plt.cm.Blues(0.5 + i*0.15),
            linewidth=2, label=f'Non-responder {i+1}' if i &lt; 1 else '')

ax.set_xlabel('Time (hours)', fontsize=12)
ax.set_ylabel('Biomarker Level', fontsize=12)
ax.set_title('Common Fate: Trajectories Naturally Group', fontsize=14, fontweight='bold')
ax.legend(loc='upper left', frameon=True)
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

plt.tight_layout()
plt.savefig('common_fate_example.png', dpi=300, bbox_inches='tight')</code></pre>
</section>
<section id="symmetry-and-balance" class="level4" data-number="3.3.2.2">
<h4 data-number="3.3.2.2" class="anchored" data-anchor-id="symmetry-and-balance"><span class="header-section-number">3.3.2.2</span> Symmetry and Balance</h4>
<p><strong>Principle:</strong> Symmetric elements are perceived as belonging together and forming a coherent whole.</p>
<p><strong>Applications in Multi-Panel Figures:</strong></p>
<pre><code>✓ Symmetric grid layouts feel organized and professional
✓ Asymmetry draws attention (use deliberately for emphasis)

Example layouts:

Symmetric (balanced, harmonious):
[Panel A] [Panel B]
[Panel C] [Panel D]

Asymmetric for emphasis (main result gets more space):
[Panel A - large    ] [B]
[Panel C - large    ] [D]
→ Panels A &amp; C visually dominate</code></pre>
<p><strong>Code Example (R):</strong></p>
<pre><code>library(ggplot2)
library(patchwork)

# Create sample plots
p1 &lt;- ggplot(mtcars, aes(x = wt, y = mpg)) +
  geom_point() +
  labs(title = "Panel A: Main Result") +
  theme_classic()

p2 &lt;- ggplot(mtcars, aes(x = hp, y = mpg)) +
  geom_point() +
  labs(title = "Panel B: Control") +
  theme_classic()

p3 &lt;- ggplot(mtcars, aes(x = disp, y = mpg)) +
  geom_point() +
  labs(title = "Panel C: Supplementary") +
  theme_classic()

p4 &lt;- ggplot(mtcars, aes(x = qsec, y = mpg)) +
  geom_point() +
  labs(title = "Panel D: Supplementary") +
  theme_classic()

# Symmetric layout
symmetric &lt;- (p1 + p2) / (p3 + p4)

# Asymmetric layout (emphasize A and C)
asymmetric &lt;- (p1 + p2) / (p3 + p4) +
  plot_layout(heights = c(2, 1))

ggsave("symmetric_layout.png", symmetric, width = 8, height = 8, dpi = 300)
ggsave("asymmetric_layout.png", asymmetric, width = 8, height = 8, dpi = 300)</code></pre>
</section>
<section id="connectedness" class="level4" data-number="3.3.2.3">
<h4 data-number="3.3.2.3" class="anchored" data-anchor-id="connectedness"><span class="header-section-number">3.3.2.3</span> Connectedness</h4>
<p><strong>Principle:</strong> Elements connected by lines or enclosed in shapes are perceived as more strongly grouped than mere proximity.</p>
<p><strong>Applications:</strong></p>
<pre><code>✓ Use lines to connect related data points (time series)
✓ Use boxes/frames to group related panels
✓ Use arrows to show causal relationships

Example:
Before/After comparison:
[Before image] --arrow--&gt; [After image]
→ Arrow creates stronger association than just placement</code></pre>
<hr>
</section>
</section>
</section>
<section id="visual-hierarchy-and-focus" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="visual-hierarchy-and-focus"><span class="header-section-number">3.4</span> 1.4 Visual Hierarchy and Focus</h2>
<section id="creating-effective-visual-hierarchy" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="creating-effective-visual-hierarchy"><span class="header-section-number">3.4.1</span> Creating Effective Visual Hierarchy</h3>
<p><strong>Visual hierarchy</strong> is the arrangement of elements in order of importance, guiding the viewer’s attention through the figure in a deliberate sequence.</p>
</section>
<section id="the-three-level-hierarchy" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="the-three-level-hierarchy"><span class="header-section-number">3.4.2</span> The Three-Level Hierarchy</h3>
<p>Every effective figure has three levels:</p>
<section id="level-1-primary-focus-the-message" class="level4" data-number="3.4.2.1">
<h4 data-number="3.4.2.1" class="anchored" data-anchor-id="level-1-primary-focus-the-message"><span class="header-section-number">3.4.2.1</span> Level 1: Primary Focus (The Message)</h4>
<p><strong>This should be seen first, within 1-2 seconds.</strong></p>
<p><strong>Techniques to create primary focus:</strong> 1. <strong>High contrast</strong> - Make it darker, brighter, or more saturated than everything else 2. <strong>Larger size</strong> - Primary element should be visually dominant 3. <strong>Central position</strong> - Eye naturally goes to center first 4. <strong>Enclosure</strong> - Box, circle, or annotation around key element 5. <strong>Isolation</strong> - Surround with white space</p>
<p><strong>Example:</strong></p>
<pre><code>Scatter plot showing drug efficacy:
Primary focus: The significant outlier responders
→ Make them larger, brighter color, add annotation arrow

Secondary: All other data points
→ Smaller, gray, lower opacity

Tertiary: Grid, axes, legend
→ Lightest gray, thin lines</code></pre>
<p><strong>Code Example (Python):</strong></p>
<pre><code>import matplotlib.pyplot as plt
import numpy as np

np.random.seed(42)

# Generate data
x = np.random.randn(100)
y = 2*x + np.random.randn(100)

# Identify "significant" outliers
outlier_idx = np.where((y &gt; 4) | (y &lt; -4))[0]

# Create figure with visual hierarchy
fig, ax = plt.subplots(figsize=(8, 6))

# Level 3: Grid (most subtle)
ax.grid(True, alpha=0.2, linewidth=0.5, color='gray', zorder=0)

# Level 2: Regular data points (secondary)
regular_idx = np.setdiff1d(np.arange(len(x)), outlier_idx)
ax.scatter(x[regular_idx], y[regular_idx],
           s=30, color='lightgray', alpha=0.6, zorder=2, label='Regular')

# Level 1: Outliers (PRIMARY FOCUS)
ax.scatter(x[outlier_idx], y[outlier_idx],
           s=200, color='#E63946', alpha=0.9, zorder=3,
           edgecolors='darkred', linewidths=2, label='Outliers')

# Annotate one key outlier
if len(outlier_idx) &gt; 0:
    key_outlier = outlier_idx[0]
    ax.annotate('Key responder',
                xy=(x[key_outlier], y[key_outlier]),
                xytext=(x[key_outlier]-1, y[key_outlier]+1),
                fontsize=11, fontweight='bold', color='#E63946',
                arrowprops=dict(arrowstyle='-&gt;', color='#E63946', lw=2),
                zorder=4)

# Styling (de-emphasize axes - level 3)
ax.set_xlabel('Drug Concentration (μM)', fontsize=11)
ax.set_ylabel('Cell Response (AU)', fontsize=11)
ax.set_title('Visual Hierarchy: Outliers Stand Out', fontsize=14, fontweight='bold')
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['left'].set_color('gray')
ax.spines['bottom'].set_color('gray')
ax.legend(loc='lower right', frameon=True, fontsize=10)

plt.tight_layout()
plt.savefig('visual_hierarchy.png', dpi=300, bbox_inches='tight')
</code></pre>
</section>
<section id="level-2-supporting-context" class="level4" data-number="3.4.2.2">
<h4 data-number="3.4.2.2" class="anchored" data-anchor-id="level-2-supporting-context"><span class="header-section-number">3.4.2.2</span> Level 2: Supporting Context</h4>
<p><strong>Provides necessary information but doesn’t compete with primary focus.</strong></p>
<p><strong>Elements at this level:</strong> - Main data that isn’t the key finding - Axis labels and titles - Legend (if not redundant) - Reference lines or regions</p>
<p><strong>Techniques:</strong> - Medium contrast - Standard sizing - Neutral colors (blacks, grays, muted tones)</p>
</section>
<section id="level-3-infrastructure" class="level4" data-number="3.4.2.3">
<h4 data-number="3.4.2.3" class="anchored" data-anchor-id="level-3-infrastructure"><span class="header-section-number">3.4.2.3</span> Level 3: Infrastructure</h4>
<p><strong>Essential for interpretation but should fade into background.</strong></p>
<p><strong>Elements at this level:</strong> - Grid lines - Minor tick marks - Axis lines - Background shading</p>
<p><strong>Techniques:</strong> - Low contrast (light grays) - Thin line weights - Semi-transparency</p>
</section>
</section>
<section id="contrast-as-the-primary-tool" class="level3" data-number="3.4.3">
<h3 data-number="3.4.3" class="anchored" data-anchor-id="contrast-as-the-primary-tool"><span class="header-section-number">3.4.3</span> Contrast as the Primary Tool</h3>
<p><strong>Types of contrast for creating hierarchy:</strong></p>
<p><strong>1. Value Contrast (Light vs.&nbsp;Dark)</strong></p>
<pre><code>✓ Dark data on light background (most common)
✓ Light data on dark background (for presentations/posters)
✗ Medium gray data on medium gray background (no contrast)</code></pre>
<p><strong>2. Saturation Contrast</strong></p>
<pre><code>✓ Saturated color for key data, desaturated for context
Example: Bright red key points, pale pink supporting data</code></pre>
<p><strong>3. Size Contrast</strong></p>
<pre><code>✓ Larger primary elements, smaller supporting elements
Rule of thumb: 2:1 or 3:1 size ratio minimum</code></pre>
<p><strong>4. Weight Contrast</strong></p>
<pre><code>✓ Bold/thick for primary, light/thin for secondary
Applies to: lines, fonts, borders</code></pre>
</section>
<section id="common-hierarchy-mistakes" class="level3" data-number="3.4.4">
<h3 data-number="3.4.4" class="anchored" data-anchor-id="common-hierarchy-mistakes"><span class="header-section-number">3.4.4</span> Common Hierarchy Mistakes</h3>
<section id="mistake-1-everything-is-emphasized-nothing-stands-out" class="level4" data-number="3.4.4.1">
<h4 data-number="3.4.4.1" class="anchored" data-anchor-id="mistake-1-everything-is-emphasized-nothing-stands-out"><span class="header-section-number">3.4.4.1</span> Mistake 1: Everything is Emphasized (Nothing Stands Out)</h4>
<p><strong>Bad Example:</strong></p>
<pre><code>✗ All data points large and bright
✗ Bold axis labels
✗ Thick grid lines
✗ Multiple colors all saturated
→ Result: Visual chaos, no clear message</code></pre>
<p><strong>Fix:</strong></p>
<pre><code>✓ Choose ONE element as primary focus
✓ Make everything else subordinate
✓ Ask: "If viewer sees only one thing, what should it be?"</code></pre>
</section>
<section id="mistake-2-wrong-element-is-emphasized" class="level4" data-number="3.4.4.2">
<h4 data-number="3.4.4.2" class="anchored" data-anchor-id="mistake-2-wrong-element-is-emphasized"><span class="header-section-number">3.4.4.2</span> Mistake 2: Wrong Element is Emphasized</h4>
<p><strong>Bad Example:</strong></p>
<pre><code>✗ Huge, bold legend in bright colors
✗ Decorative border or logo prominently featured
✗ Actual data is small and gray
→ Result: Reader focuses on metadata, not results</code></pre>
<p><strong>Fix:</strong></p>
<pre><code>✓ Data ink &gt;&gt; non-data ink (Tufte's principle)
✓ Legend should be smallest readable size
✓ Branding/logos should be minimal or absent</code></pre>
</section>
<section id="mistake-3-competing-focal-points" class="level4" data-number="3.4.4.3">
<h4 data-number="3.4.4.3" class="anchored" data-anchor-id="mistake-3-competing-focal-points"><span class="header-section-number">3.4.4.3</span> Mistake 3: Competing Focal Points</h4>
<p><strong>Bad Example:</strong></p>
<pre><code>✗ Three different elements all trying to be #1:
  - Large red title
  - Bright blue highlighted region
  - Orange outlier points
→ Result: Eye doesn't know where to go first</code></pre>
<p><strong>Fix:</strong></p>
<pre><code>✓ Clear priority: One primary (e.g., outliers)
✓ Others as secondary (title standard weight, region subtle shading)
✓ Use color consistently, not for multiple purposes</code></pre>
<hr>
</section>
</section>
<section id="exercise-1.4.1-visual-hierarchy-redesign" class="level3" data-number="3.4.5">
<h3 data-number="3.4.5" class="anchored" data-anchor-id="exercise-1.4.1-visual-hierarchy-redesign"><span class="header-section-number">3.4.5</span> Exercise 1.4.1: Visual Hierarchy Redesign</h3>
<p><strong>Objective:</strong> Transform a flat figure into one with clear visual hierarchy</p>
<p><strong>Materials:</strong> - Take a figure you’ve created (or find one online) where everything has similar visual weight</p>
<p><strong>Task:</strong></p>
<ol type="1">
<li><strong>Audit current state:</strong>
<ul>
<li>List all visual elements in the figure</li>
<li>Rate each on “attention-grabbing” scale (1-10)</li>
<li>Identify if multiple elements score 8-10 (competing focus problem)</li>
</ul></li>
<li><strong>Define hierarchy:</strong>
<ul>
<li>What is THE main message? (This becomes Level 1)</li>
<li>What supports understanding? (Level 2)</li>
<li>What is infrastructure? (Level 3)</li>
</ul></li>
<li><strong>Redesign with tools:</strong>
<ul>
<li><strong>For Level 1:</strong> Increase size by 2x, use high-contrast color, add annotation</li>
<li><strong>For Level 2:</strong> Use medium gray or neutral colors, standard sizes</li>
<li><strong>For Level 3:</strong> Reduce to light gray (alpha=0.2-0.3), thin lines</li>
</ul></li>
<li><strong>Test:</strong>
<ul>
<li>Show both versions to a colleague for 3 seconds each</li>
<li>Ask: “What did you notice first?”</li>
<li>Did the redesign direct attention correctly?</li>
</ul></li>
</ol>
<p><strong>Example Transformation:</strong></p>
<p><em>Before:</em> - All scatter points same size (50 pixels) - All points same color (blue) - Grid lines same thickness as data trendline - Title and axis labels same font weight</p>
<p><em>After:</em> - Key points: 150 pixels, red - Other points: 30 pixels, light gray - Grid lines: alpha=0.2, thin - Trendline: Bold, black - Title: Bold, axis labels: regular weight</p>
<hr>
</section>
</section>
<section id="common-perceptual-traps-and-how-to-avoid-them" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="common-perceptual-traps-and-how-to-avoid-them"><span class="header-section-number">3.5</span> 1.5 Common Perceptual Traps and How to Avoid Them</h2>
<section id="trap-1-the-truncated-axis" class="level3" data-number="3.5.1">
<h3 data-number="3.5.1" class="anchored" data-anchor-id="trap-1-the-truncated-axis"><span class="header-section-number">3.5.1</span> Trap 1: The Truncated Axis</h3>
<p><strong>The Problem:</strong> When y-axis doesn’t start at zero for bar charts, small differences appear exaggerated.</p>
<p><strong>Example of Misuse:</strong></p>
<pre><code>Sales data:
Competitor A: 98 units
Our product: 100 units

✗ BAD: Y-axis from 95-100
→ Bar for our product appears 2.5x taller (visual difference 5 units out of 5)
→ Actual difference: 2% (100 vs 98)</code></pre>
<p><strong>When It’s Acceptable:</strong></p>
<pre><code>✓ Line graphs (emphasizing trend over absolute values)
✓ Scatter plots (focusing on relationship)
✓ When differences ARE meaningful relative to natural variation

Example: Temperature anomalies
- Baseline: 15.0°C
- Year 1: 15.1°C
- Year 2: 15.3°C
✓ OK to zoom to 14.8-15.5°C range
→ These small changes are scientifically significant</code></pre>
<p><strong>Code Example - Demonstrating the Effect:</strong></p>
<pre><code>import matplotlib.pyplot as plt
import numpy as np

categories = ['Competitor A', 'Our Product']
values = [98, 100]

fig, axes = plt.subplots(1, 2, figsize=(10, 4))

# MISLEADING: Truncated axis for bar chart
axes[0].bar(categories, values, color=['gray', 'steelblue'])
axes[0].set_ylim(95, 101)
axes[0].set_ylabel('Sales (units)')
axes[0].set_title('MISLEADING: Truncated Axis\n(Appears 5x difference)',
                   fontsize=11, color='red')
axes[0].axhline(0, color='black', linewidth=0.8)

# HONEST: Full axis from zero
axes[1].bar(categories, values, color=['gray', 'steelblue'])
axes[1].set_ylim(0, 110)
axes[1].set_ylabel('Sales (units)')
axes[1].set_title('HONEST: Full Axis\n(Shows 2% difference)',
                   fontsize=11, color='green')

plt.tight_layout()
plt.savefig('truncated_axis_trap.png', dpi=300, bbox_inches='tight')</code></pre>
<p><strong>Solution:</strong></p>
<pre><code>For bar charts:
✓ Always start at zero (or explicitly show break if necessary)
✓ Add context: "Values differ by 2% (98 vs 100)"

For line graphs:
✓ Truncation is OK but add reference line at zero
✓ Clearly label axis range
✓ Consider showing full range in inset panel</code></pre>
</section>
<section id="trap-2-the-dual-axis-deception" class="level3" data-number="3.5.2">
<h3 data-number="3.5.2" class="anchored" data-anchor-id="trap-2-the-dual-axis-deception"><span class="header-section-number">3.5.2</span> Trap 2: The Dual Axis Deception</h3>
<p><strong>The Problem:</strong> Dual y-axes allow arbitrary scaling that can manufacture correlations or hide them.</p>
<p><strong>Example of Misuse:</strong></p>
<pre><code>✗ Graph showing "Ice cream sales" and "Drowning deaths" over months
→ Both increase in summer
→ Dual axes scaled to make lines overlap perfectly
→ Implies causal relationship (which doesn't exist)</code></pre>
<p><strong>Why It’s Problematic:</strong></p>
<pre><code>1. No inherent relationship between the two scales
2. Can be manipulated to show any pattern desired
3. Viewer cannot judge relative magnitudes
4. Confuses correlation with causation</code></pre>
<p><strong>Better Alternatives:</strong></p>
<pre><code>✓ Option 1: Two separate plots stacked vertically
  → Allows visual comparison without misleading single axis

✓ Option 2: Normalize both variables (0-100% scale or z-scores)
  → Same scale, honest comparison

✓ Option 3: Scatter plot (X = variable 1, Y = variable 2)
  → Shows relationship directly

✓ Option 4: If truly related, use secondary axis BUT:
  - Use same scale factor (e.g., both per capita)
  - Make relationship explicit ("°F" vs "°C" - mathematically linked)</code></pre>
<p><strong>Code Example (R):</strong></p>
<pre><code>library(ggplot2)
library(patchwork)

# Sample data
months &lt;- 1:12
ice_cream &lt;- c(20, 25, 40, 55, 70, 85, 90, 85, 65, 45, 30, 22)
drownings &lt;- c(2, 3, 5, 8, 12, 15, 16, 14, 10, 6, 4, 2)

data &lt;- data.frame(month = months, ice_cream = ice_cream, drownings = drownings)

# BAD: Dual axis (manipulable)
p_bad &lt;- ggplot(data, aes(x = month)) +
  geom_line(aes(y = ice_cream), color = "orange", size = 1.5) +
  geom_line(aes(y = drownings * 6), color = "blue", size = 1.5) +  # Scaled to overlap
  scale_y_continuous(
    name = "Ice Cream Sales",
    sec.axis = sec_axis(~./6, name = "Drownings")
  ) +
  labs(title = "MISLEADING: Dual Axis (Scales Manipulated)") +
  theme_classic()

# BETTER: Separate panels
p1 &lt;- ggplot(data, aes(x = month, y = ice_cream)) +
  geom_line(color = "orange", size = 1.5) +
  labs(y = "Ice Cream Sales", title = "Ice Cream Sales") +
  theme_classic()

p2 &lt;- ggplot(data, aes(x = month, y = drownings)) +
  geom_line(color = "blue", size = 1.5) +
  labs(y = "Drownings", x = "Month", title = "Drowning Deaths") +
  theme_classic()

p_good &lt;- p1 / p2 + plot_annotation(title = "BETTER: Separate Panels (Honest Comparison)")

ggsave("dual_axis_bad.png", p_bad, width = 7, height = 4, dpi = 300)
ggsave("dual_axis_good.png", p_good, width = 7, height = 6, dpi = 300)
</code></pre>
</section>
<section id="trap-3-cherry-picked-axis-ranges" class="level3" data-number="3.5.3">
<h3 data-number="3.5.3" class="anchored" data-anchor-id="trap-3-cherry-picked-axis-ranges"><span class="header-section-number">3.5.3</span> Trap 3: Cherry-Picked Axis Ranges</h3>
<p><strong>The Problem:</strong> Selectively choosing axis ranges to emphasize or hide patterns.</p>
<p><strong>Example:</strong></p>
<pre><code>Clinical trial results:

Full timeline (0-24 months):
→ Drug effect appears temporary, returns to baseline

Cropped timeline (0-6 months):
→ Drug appears highly effective
→ Hides the fact that effect disappears

✗ Publishing only the 6-month view is misleading</code></pre>
<p><strong>Solution:</strong></p>
<pre><code>✓ Show complete temporal or spatial range relevant to the study
✓ If cropping for focus, include inset with full range
✓ State explicit rationale for range choice
✓ Provide supplementary figures with full data</code></pre>
</section>
<section id="trap-4-logarithmic-scale-without-clear-indication" class="level3" data-number="3.5.4">
<h3 data-number="3.5.4" class="anchored" data-anchor-id="trap-4-logarithmic-scale-without-clear-indication"><span class="header-section-number">3.5.4</span> Trap 4: Logarithmic Scale Without Clear Indication</h3>
<p><strong>The Problem:</strong> Log scales dramatically change visual perception but are easy to miss.</p>
<p><strong>Example:</strong></p>
<pre><code>Linear scale:
1, 2, 3, 4, 5, 10, 100, 1000
→ Visually: huge jump to 100

Log scale:
10⁰, 10¹, 10², 10³
→ Visually: even spacing
→ Can hide massive actual differences</code></pre>
<p><strong>When Logarithmic Scales are Appropriate:</strong></p>
<pre><code>✓ Data spanning multiple orders of magnitude
✓ Exponential growth/decay processes
✓ Multiplicative effects (fold-changes)
✓ When relative changes matter more than absolute

Examples:
- Gene expression (ranges from 0.01 to 10,000)
- Earthquake magnitudes (Richter scale)
- Sound intensity (decibels)
- Drug concentrations (dose-response curves)</code></pre>
<p><strong>How to Use Responsibly:</strong></p>
<pre><code>✓ Label axis clearly: "Log₁₀ Concentration"
✓ Show actual values on tick labels (1, 10, 100) not (0, 1, 2)
✓ Mention in caption: "Note logarithmic scale"
✓ Consider showing both linear and log versions</code></pre>
<p><strong>Code Example (Python):</strong></p>
<pre><code>import matplotlib.pyplot as plt
import numpy as np

# Exponential data
x = np.linspace(0, 10, 50)
y = np.exp(x/2)

fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# Linear scale
axes[0].plot(x, y, 'o-', color='steelblue', linewidth=2, markersize=4)
axes[0].set_xlabel('Time')
axes[0].set_ylabel('Cell Count')
axes[0].set_title('LINEAR Scale\n(Emphasizes recent growth)', fontsize=12)
axes[0].grid(alpha=0.3)

# Log scale
axes[1].plot(x, y, 'o-', color='coral', linewidth=2, markersize=4)
axes[1].set_yscale('log')
axes[1].set_xlabel('Time')
axes[1].set_ylabel('Cell Count (log scale)', fontweight='bold')
axes[1].set_title('LOGARITHMIC Scale\n(Shows exponential trend clearly)', fontsize=12)
axes[1].grid(alpha=0.3, which='both')

# Highlight log scale usage
axes[1].text(0.5, 0.95, 'NOTE: Log scale', transform=axes[1].transAxes,
             fontsize=11, ha='center', va='top',
             bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))

plt.tight_layout()
plt.savefig('log_scale_comparison.png', dpi=300, bbox_inches='tight')</code></pre>
</section>
<section id="trap-5-the-3d-disaster" class="level3" data-number="3.5.5">
<h3 data-number="3.5.5" class="anchored" data-anchor-id="trap-5-the-3d-disaster"><span class="header-section-number">3.5.5</span> Trap 5: The 3D Disaster</h3>
<p><strong>The Problem:</strong> 3D charts for 2D data introduce perspective distortion and occlusion without adding information.</p>
<p><strong>Common Offenders:</strong> - 3D pie charts - 3D bar charts - 3D scatter plots (when Z-axis is unused)</p>
<p><strong>Why They Fail:</strong></p>
<pre><code>1. Perspective makes closer elements appear larger
2. Back elements occluded by front elements
3. Difficult to read exact values
4. Chartjunk (unnecessary visual complexity)
5. "Cool factor" often motivates use, not data needs</code></pre>
<p><strong>Example:</strong></p>
<pre><code>✗ 3D pie chart:
→ Slice in foreground appears larger than identical slice in background
→ Pure perceptual distortion

✓ 2D pie chart (or better, bar chart):
→ Accurate representation
→ Easy comparison</code></pre>
<p><strong>When 3D is Justified:</strong></p>
<pre><code>✓ Genuine spatial data (protein structures, geographic terrain)
✓ Physical specimens (medical imaging)
✓ Three independent quantitative variables

Even then, consider:
- Providing multiple 2D views (orthogonal projections)
- Interactive 3D (can rotate) for digital supplements
- Color/size encoding on 2D projection as alternative</code></pre>
<hr>
</section>
<section id="exercise-1.5.1-perceptual-trap-detection" class="level3" data-number="3.5.6">
<h3 data-number="3.5.6" class="anchored" data-anchor-id="exercise-1.5.1-perceptual-trap-detection"><span class="header-section-number">3.5.6</span> Exercise 1.5.1: Perceptual Trap Detection</h3>
<p><strong>Objective:</strong> Develop critical eye for misleading visualizations</p>
<p><strong>Materials:</strong> News articles, advertisements, or scientific papers with quantitative graphics</p>
<p><strong>Task:</strong></p>
<ol type="1">
<li><p><strong>Find 5 figures</strong> from various sources (news media, research papers, company reports)</p></li>
<li><p><strong>For each, check for these traps:</strong></p>
<ul class="task-list">
<li><label><input type="checkbox">Truncated axis (bar chart not starting at zero)</label></li>
<li><label><input type="checkbox">Dual axes (with manipulated scaling)</label></li>
<li><label><input type="checkbox">Cherry-picked range (timeline suspiciously cropped)</label></li>
<li><label><input type="checkbox">Unlabeled log scale</label></li>
<li><label><input type="checkbox">Unnecessary 3D</label></li>
<li><label><input type="checkbox">Misleading aspect ratio (tall/skinny vs.&nbsp;wide/short changes perception of slope)</label></li>
</ul></li>
<li><p><strong>Analyze intent:</strong></p>
<ul>
<li>Is this an honest mistake or deliberate distortion?</li>
<li>What is the figure trying to emphasize?</li>
<li>How would fixing the issue change the message?</li>
</ul></li>
<li><p><strong>Redesign one:</strong></p>
<ul>
<li>Choose the most misleading figure</li>
<li>Create an honest version</li>
<li>Write 2-3 sentences on how perception changes</li>
</ul></li>
</ol>
<p><strong>Example Analysis:</strong></p>
<pre><code>Figure: Bar chart from Company X press release
Trap detected: Y-axis starts at 95%, goes to 100%
Effect: 96% → 98% improvement appears massive (fills whole chart)
Honest version: Y-axis 0-100% shows 2 percentage point change (barely visible)
Conclusion: Likely deliberate to exaggerate modest improvement</code></pre>
<hr>
</section>
</section>
<section id="chapter-1-summary" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="chapter-1-summary"><span class="header-section-number">3.6</span> Chapter 1 Summary</h2>
<section id="key-principles-from-visual-perception-science" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="key-principles-from-visual-perception-science"><span class="header-section-number">3.6.1</span> Key Principles from Visual Perception Science</h3>
<ol type="1">
<li><strong>Pre-attentive processing</strong> guides immediate attention
<ul>
<li>Use color, size, position strategically</li>
<li>Key findings should “pop out” without effort</li>
</ul></li>
<li><strong>Cleveland-McGill hierarchy</strong> informs encoding choices
<ul>
<li>Position &gt; Length &gt; Angle &gt; Area &gt; Color hue</li>
<li>Match strongest channels to most important data</li>
</ul></li>
<li><strong>Gestalt principles</strong> create coherent organization
<ul>
<li>Proximity, similarity, continuity, closure</li>
<li>Work with brain’s natural grouping tendencies</li>
</ul></li>
<li><strong>Visual hierarchy</strong> directs viewer’s eye
<ul>
<li>Three levels: Primary focus, supporting context, infrastructure</li>
<li>Use contrast (value, saturation, size, weight) to differentiate</li>
</ul></li>
<li><strong>Working memory limits</strong> constrain complexity
<ul>
<li>7±2 items maximum simultaneously</li>
<li>Simplify, chunk, or use small multiples</li>
</ul></li>
<li><strong>Perceptual biases</strong> require vigilance
<ul>
<li>We underestimate area differences</li>
<li>We perceive logarithmically</li>
<li>Dual axes and truncated ranges can mislead</li>
</ul></li>
</ol>
</section>
<section id="practical-application-checklist" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="practical-application-checklist"><span class="header-section-number">3.6.2</span> Practical Application Checklist</h3>
<p>Before finalizing any figure, ask:</p>
<ul class="task-list">
<li><label><input type="checkbox"><strong>Can a naive viewer identify the main message in 3 seconds?</strong></label></li>
<li><label><input type="checkbox"><strong>Are the strongest visual channels used for the most important data?</strong></label></li>
<li><label><input type="checkbox"><strong>Does the layout group related elements (Gestalt proximity/similarity)?</strong></label></li>
<li><label><input type="checkbox"><strong>Is there a clear visual hierarchy (one primary focus)?</strong></label></li>
<li><label><input type="checkbox"><strong>Are comparisons easy (common scales, aligned axes)?</strong></label></li>
<li><label><input type="checkbox"><strong>Is the figure free from perceptual traps (truncation, dual axes, unnecessary 3D)?</strong></label></li>
<li><label><input type="checkbox"><strong>Would this work in grayscale (redundant encoding for accessibility)?</strong></label></li>
<li><label><input type="checkbox"><strong>Does it require less than 7 simultaneous comparisons?</strong></label></li>
</ul>
</section>
<section id="transition-to-chapter-2" class="level3" data-number="3.6.3">
<h3 data-number="3.6.3" class="anchored" data-anchor-id="transition-to-chapter-2"><span class="header-section-number">3.6.3</span> Transition to Chapter 2</h3>
<p>Now that we understand <strong>how humans perceive visual information</strong>, we can make informed decisions about <strong>specific design elements</strong>.</p>
<p><strong>Chapter 2: The Language of Color</strong> will build on these perceptual foundations to explore: - Color theory and color spaces - Choosing palettes for different data types - Accessibility and color-blind friendly design - Avoiding common color mistakes</p>
<p>You now have the cognitive science framework; next we apply it to one of the most powerful (and most misused) visual channels: <strong>color</strong>.</p>
<hr>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Chapter 0.html" class="pagination-link" aria-label="**Grammar of Figures: The Art and Science of Visualizing Data for Publication**">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title"><strong>Grammar of Figures: The Art and Science of Visualizing Data for Publication</strong></span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Chapter 2.html" class="pagination-link" aria-label="Chapter 2: The Language of Color">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Chapter 2: The Language of Color</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>