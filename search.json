[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Complete Guide to Bash Errors: From Beginner to Expert",
    "section": "",
    "text": "Grammar of Figures: The Art & Science of Visualizing Data for Publications\nAuthor: Kai Guo • Contact: guokai8@gmail.com",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Grammar of Figures: The Art & Science of Visualizing Data for Publications</span>"
    ]
  },
  {
    "objectID": "index.html#about-this-book",
    "href": "index.html#about-this-book",
    "title": "The Complete Guide to Bash Errors: From Beginner to Expert",
    "section": "About this book",
    "text": "About this book\nA practical, code-first field guide to designing beautiful, rigorous figures for scientific publications using Python and R. It combines perceptual science, design principles, and journal requirements with reproducible workflows.\n\nAudience: researchers, data scientists, and visualization engineers targeting journals (e.g., Nature, Cell, Science) and preprints.\nPrereqs: basic Python/R, familiarity with matplotlib/ggplot2; comfort with command line for reproducible exports.\nGoal: help you decide what to show, how to encode it, and why—then ship print-ready, accessible figures.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Grammar of Figures: The Art & Science of Visualizing Data for Publications</span>"
    ]
  },
  {
    "objectID": "index.html#conventions",
    "href": "index.html#conventions",
    "title": "The Complete Guide to Bash Errors: From Beginner to Expert",
    "section": "Conventions",
    "text": "Conventions\n\nCode style: minimal, reproducible. Python uses matplotlib/seaborn/plotnine (when helpful); R uses ggplot2 + tidyverse. Saving: plt.savefig() / ggsave() with explicit DPI and dimensions.\nTypography: SI units, sentence case for axis titles, Title Case for figure titles (configurable).\nAccessibility: color-vision-deficiency-safe palettes; minimum contrast ratios; legends never convey meaning by color alone; redundant encodings (color + shape/line).\nTerminology: mark (point/line/area), channel (position, length, angle, area, hue, saturation, luminance, shape, texture, motion).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Grammar of Figures: The Art & Science of Visualizing Data for Publications</span>"
    ]
  },
  {
    "objectID": "index.html#how-to-cite",
    "href": "index.html#how-to-cite",
    "title": "The Complete Guide to Bash Errors: From Beginner to Expert",
    "section": "How to cite",
    "text": "How to cite\n\nKai Guo. Grammar of Figures: The Art & Science of Visualizing Data for Publications. Version X.Y.Z, YEAR. DOI/URL.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Grammar of Figures: The Art & Science of Visualizing Data for Publications</span>"
    ]
  },
  {
    "objectID": "Chapter 0.html",
    "href": "Chapter 0.html",
    "title": "Grammar of Figures: The Art and Science of Visualizing Data for Publication",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Grammar of Figures: The Art and Science of Visualizing Data for Publication**</span>"
    ]
  },
  {
    "objectID": "Chapter 0.html#why-figures-matter-communication-before-decoration",
    "href": "Chapter 0.html#why-figures-matter-communication-before-decoration",
    "title": "Grammar of Figures: The Art and Science of Visualizing Data for Publication",
    "section": "0.1 Why Figures Matter: Communication Before Decoration",
    "text": "0.1 Why Figures Matter: Communication Before Decoration\n\nThe Central Role of Figures in Scientific Communication\nIn modern scientific literature, figures have evolved from mere supplementary illustrations to primary communication vehicles. Research shows that readers typically engage with a paper by first scanning the abstract, then examining the figures, and only afterward reading the full text. This “figure-first” reading pattern reflects a fundamental truth: a well-designed figure can convey complex relationships, patterns, and evidence more efficiently than paragraphs of text.\nConsider this: a single scatter plot with error bars can simultaneously communicate: - The relationship between two variables - The distribution of data points - The uncertainty in measurements - The sample size - Outliers or unusual patterns - Statistical trends\nConveying the same information in text would require dense prose that few readers would parse with the same comprehension.\n\n\nThe Cost of Poor Figures\nConversely, poorly designed figures impose significant costs:\nBad Example Characteristics: - Cognitive overload: Too many colors, overlapping points, cluttered legends that force readers to decode rather than understand - Ambiguity: Missing units, unlabeled axes, or unclear symbols that leave readers guessing - Misleading representation: Truncated y-axes, inappropriate plot types, or manipulated scales that distort the data’s story - Inaccessibility: Color schemes that fail for colorblind readers, text too small after publication sizing, or unnecessarily complex visualizations\nConsequences: - Reviewers may reject your manuscript based on figure quality alone - Your findings may be misunderstood or ignored - Replication efforts may fail due to unclear methodology shown in figures - Your work may receive fewer citations if readers cannot quickly extract value\n\n\nGood Figures: What Sets Them Apart\nExcellent scientific figures share common attributes:\n\nClarity of message: The main point is immediately apparent\nAppropriate complexity: No simpler than necessary, no more complex than required\nSelf-sufficiency: Figure + caption can stand alone without main text\nVisual integrity: Honest representation without distortion\nAccessibility: Readable by diverse audiences including those with visual impairments\nProfessional polish: Consistent styling, appropriate resolution, clean execution\n\nExample of Excellence: Think of landmark papers in your field. Their figures likely: - Use consistent color schemes throughout - Have legible text at publication size - Employ white space effectively - Guide your eye through a logical visual flow - Make statistical comparisons obvious - Include all necessary information without clutter\n\n\nExercise 0.1.1\nFind three published figures in your field: 1. One you consider excellent – list three specific design choices that make it effective 2. One that confused you initially – identify what made it difficult to understand 3. One that could be improved – sketch how you would redesign it",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Grammar of Figures: The Art and Science of Visualizing Data for Publication**</span>"
    ]
  },
  {
    "objectID": "Chapter 0.html#define-before-you-design-message-audience-context",
    "href": "Chapter 0.html#define-before-you-design-message-audience-context",
    "title": "Grammar of Figures: The Art and Science of Visualizing Data for Publication",
    "section": "0.2 Define Before You Design: Message, Audience & Context",
    "text": "0.2 Define Before You Design: Message, Audience & Context\n\nThe Three Questions Framework\nBefore opening your plotting software, answer these three fundamental questions:\n\nQuestion 1: What is the ONE main message?\nEvery figure should have a primary message – a single key takeaway. Secondary details can exist, but must not compete with the main point.\nGood Example: - Main message: “Drug A reduces tumor growth more effectively than Drug B over 4 weeks” - Supporting details: Variability in response, dose-dependent effects, time-course dynamics\nBad Example (multiple competing messages): - Trying to show: treatment effects + dose response + time course + molecular mechanisms + patient demographics all in one figure - Result: Cognitive overload, unclear priorities, no clear conclusion\nExercise: The Elevator Test Write your figure’s message in one sentence. If you cannot, your figure probably tries to communicate too much. Consider splitting it into multiple panels or separate figures.\n\n\nQuestion 2: Who is your audience?\nDifferent audiences require different approaches:\n\n\n\n\n\n\n\n\nAudience Type\nCharacteristics\nFigure Strategy\n\n\n\n\nDomain Experts\nDeep knowledge of methods, terminology, conventions\nCan use specialized plot types, assume familiarity with standard representations, include technical details\n\n\nInterdisciplinary Scientists\nScientific literacy but not domain-specific expertise\nRequire more context, clearer labels, standard plot types, avoid jargon in labels\n\n\nEducated General Public\nBasic scientific understanding\nNeed simple visualizations, extensive annotation, intuitive color schemes, metaphorical representations\n\n\nStudents/Trainees\nLearning the field\nBenefit from pedagogical clarity, step-by-step visual logic, examples of what to look for\n\n\n\nExample Scenario: You have RNA sequencing data showing differential gene expression.\n\nFor specialists (molecular biology journal): Volcano plot with gene names, log2 fold change, adjusted p-values – standard representation\nFor interdisciplinary audience (Science/Nature): Side-by-side bar charts of top 10 upregulated/downregulated genes with fold-change values and clear labels like “Genes increased in treated cells”\nFor general public (university press release): Simple pictogram showing affected biological pathways with metaphorical illustrations\n\n\n\nQuestion 3: Where will this figure appear?\nContext shapes design decisions:\nPrint Journal (single column: ~85mm width) - Design at final size - 8-point minimum font size - Limited colors (cost considerations historically) - 300+ DPI for images - Consider grayscale printing\nPrint Journal (double column: ~180mm width) - More room for complexity - Multi-panel layouts work well - Can include more detail - Still need high resolution\nDigital/Screen Display - RGB color space (vs CMYK for print) - Can use interactive elements (in online versions) - Lower DPI acceptable (96-150) - Attention to screen contrast\nPoster Presentation - Viewed from 1-2 meters away - Larger fonts (minimum 18-24 point) - High contrast - Simplified design - More visual impact, less detail\nSlide Presentation - Minimal text - High contrast for projector visibility - One point per slide - Animation can help reveal complexity - Legible from back of room\n\n\n\nThe Context-Driven Design Process\nStep-by-step workflow:\n\nStart with the message: Write it out explicitly\nKnow your venue: Check journal/conference requirements before designing\nSketch first: Rough draft on paper or whiteboard\nConsider alternatives: Generate 2-3 different approaches\nGet feedback: Show sketches to a colleague (preferably from your target audience)\nCode/design: Only now open your software\nTest at size: View your figure at actual publication size\nIterate: Refine based on the test\n\n\n\nExercise 0.2.1\nTake a figure you’re currently working on (or plan to create):\n\nWrite out your message in one sentence\nDescribe your audience in 2-3 sentences\nSpecify the context (journal name, column width, or presentation venue)\nList 3 design constraints this context imposes\nSketch two different ways to visualize this message\nWhich approach better serves your message + audience + context? Why?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Grammar of Figures: The Art and Science of Visualizing Data for Publication**</span>"
    ]
  },
  {
    "objectID": "Chapter 0.html#the-iterative-design-process",
    "href": "Chapter 0.html#the-iterative-design-process",
    "title": "Grammar of Figures: The Art and Science of Visualizing Data for Publication",
    "section": "0.3 The Iterative Design Process",
    "text": "0.3 The Iterative Design Process\n\nWhy Iteration Matters\nNo one creates a perfect figure on the first try. Just as you revise your manuscript text multiple times, figures require iterative refinement. The difference is that figures fail in ways that are often invisible to their creators – we become blind to our own design choices.\n\n\nThe Five-Stage Iterative Workflow\n\nStage 1: Sketch & Conceptualize (Paper/Whiteboard)\nBefore touching code or software:\n\nSketch 3-5 rough layouts quickly (5 minutes each)\nDon’t worry about accuracy or beauty\nFocus on structure: what goes where?\nTry different arrangements of the same data\nAsk: What catches the eye first in each version?\n\nBenefits: - Fast exploration without technical constraints - Easy to share and discuss - Reveals conceptual problems early - Prevents tunnel vision on a single approach\nExample: For a time-series experiment with 3 treatment groups: - Sketch 1: Three separate line plots stacked vertically - Sketch 2: All three lines on one plot with different colors - Sketch 3: Small multiples showing each group + control in separate panels - Sketch 4: Combination plot: overview + detail insets\n\n\nStage 2: Draft & Prototype (Initial Code)\nCreate a functional but not polished version:\n# Python example - quick draft\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate sample data\nx = np.linspace(0, 10, 50)\ny1 = np.sin(x) + np.random.normal(0, 0.1, 50)\ny2 = np.cos(x) + np.random.normal(0, 0.1, 50)\n\n# Quick draft plot\nfig, ax = plt.subplots()\nax.plot(x, y1, label='Treatment A')\nax.plot(x, y2, label='Treatment B')\nax.legend()\nax.set_xlabel('Time')\nax.set_ylabel('Response')\nplt.tight_layout()\nplt.savefig('draft_v1.png', dpi=150)\nAt this stage: - Use default colors and styles - Focus on getting data correctly represented - Ensure all necessary elements are present - Check that the data tell the story you intend\nDon’t worry about: - Perfect aesthetics - Final color choices - Publication-quality resolution - Typography details\n\n\nStage 3: Review & Critique (External Feedback)\nThis is the most important stage and the one most researchers skip.\nWho to ask: - Colleague in your field: Can they extract the main message in 10 seconds? - Scientist from different field: Is it interpretable without domain knowledge? - Lab junior member: Does it make sense to someone learning?\nQuestions to ask reviewers: 1. “What is the main point of this figure?” (without telling them first) 2. “What draws your attention first?” 3. “What confuses you or requires explanation?” 4. “If you could change one thing, what would it be?” 5. “Is there anything you expected to see that’s missing?”\nHow to handle feedback: - Don’t defend your choices – listen - Take notes on first impressions (they’re most valuable) - Look for patterns if multiple reviewers mention the same issue - Not all feedback is equal – prioritize comments about clarity over aesthetics\nExample Feedback Session:\nYou: \"What's the main message?\"\nReviewer: \"Um... that the blue line is higher than the red line?\"\nYou: (thinking: Oh no, I wanted them to notice the divergence at week 3)\n→ ACTION: Need to add annotation highlighting week 3, or use panel layout emphasizing that timepoint\n\n\nStage 4: Refine & Polish (Implement Improvements)\nNow focus on quality and professionalism:\n# Python example - polished version\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Rectangle\n\n# Set professional style\nplt.style.use('seaborn-v0_8-darkgrid')\nplt.rcParams['font.family'] = 'Arial'\nplt.rcParams['font.size'] = 10\n\n# Data (same as before)\nx = np.linspace(0, 10, 50)\ny1 = np.sin(x) + np.random.normal(0, 0.1, 50)\ny2 = np.cos(x) + np.random.normal(0, 0.1, 50)\n\n# Create figure at publication size\nfig, ax = plt.subplots(figsize=(3.5, 2.5))  # Single column width\n\n# Plot with carefully chosen colors\ncolor1 = '#2E86AB'  # Blue - colorblind safe\ncolor2 = '#A23B72'  # Purple - colorblind safe\n\nax.plot(x, y1, color=color1, linewidth=2, label='Treatment A', zorder=3)\nax.plot(x, y2, color=color2, linewidth=2, label='Treatment B', zorder=3)\n\n# Highlight key region (week 3 equivalent)\nax.axvspan(5, 7, alpha=0.1, color='gray', zorder=1)\nax.text(6, 1.2, 'Critical\\nperiod', ha='center', fontsize=9,\n        style='italic', color='dimgray')\n\n# Clean up axes\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.set_xlabel('Time (weeks)', fontsize=10, fontweight='bold')\nax.set_ylabel('Response (arbitrary units)', fontsize=10, fontweight='bold')\n\n# Legend with good placement\nax.legend(frameon=True, loc='upper left', fontsize=9)\n\n# Adjust layout\nplt.tight_layout()\n\n# Save at publication quality\nplt.savefig('figure_final.pdf', dpi=300, bbox_inches='tight')\nplt.savefig('figure_final.png', dpi=300, bbox_inches='tight')\nRefinement checklist: - [ ] Colorblind-accessible palette - [ ] All text legible at publication size - [ ] Consistent font styles throughout - [ ] Clear axis labels with units - [ ] Legend positioned logically - [ ] Annotations guide attention to key points - [ ] White space used effectively - [ ] No chartjunk or unnecessary elements - [ ] Data-to-ink ratio optimized - [ ] File format and resolution appropriate\n\n\nStage 5: Test & Validate (Final Check)\nBefore submission, perform these tests:\n\nSize test: Print or view figure at actual publication size\n\nCan you read all text?\nAre differences visible?\nDoes it maintain impact when small?\n\nGrayscale test: Convert to grayscale\n\nAre different elements still distinguishable?\nSome journals still print in B&W\n\nColorblind test: Use simulator (Color Oracle, Coblis)\n\nCheck all common types of colorblindness\nEnsure information isn’t lost\n\nContext test: Place in manuscript\n\nDoes it fit the narrative?\nDoes caption + figure stand alone?\nIs it referenced clearly in text?\n\nFresh eyes test: Come back after 24 hours\n\nWhat’s your first impression?\nWhat would you change now?\n\n\n\n\n\nManaging Multiple Figures: Version Control\nFor complex projects with many figures:\nproject/\n├── figures/\n│   ├── drafts/\n│   │   ├── fig1_v1_2024-01-15.png\n│   │   ├── fig1_v2_2024-01-18.png\n│   │   └── fig1_v3_2024-01-22.png\n│   ├── final/\n│   │   ├── figure1.pdf\n│   │   └── figure1.png\n│   └── source_code/\n│       ├── generate_fig1.py\n│       └── generate_fig1.R\n├── data/\n│   └── processed_data_for_figs.csv\n└── README.md  # Documents what each figure shows\nGit for figure code:\n# Track changes to figure generation scripts\ngit add figures/source_code/generate_fig1.py\ngit commit -m \"Added annotation highlighting critical period in Fig 1\"\n\n# Tag final versions\ngit tag -a v1.0-manuscript-submission -m \"Figures for initial submission\"\n\n\nWhen to Stop Iterating\nBeware of endless perfectionism. Stop when: - The message is clear to naive viewers - All journal requirements are met - External reviewers have no major concerns - You’ve addressed accessibility requirements - Further changes are purely aesthetic preference\nRemember: A good figure submitted is better than a perfect figure that delays your publication for weeks.\n\n\nExercise 0.3.1\nTake one of your current figures through the full iteration cycle:\n\nSketch: Draw 3 alternative layouts by hand\nDraft: Code the most promising version\nReview: Show to 2 colleagues and note their feedback\nRefine: Implement at least 3 improvements based on feedback\nTest: Run all 5 validation tests\nDocument: Write a brief paragraph about what changed and why",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Grammar of Figures: The Art and Science of Visualizing Data for Publication**</span>"
    ]
  },
  {
    "objectID": "Chapter 0.html#tools-technologies",
    "href": "Chapter 0.html#tools-technologies",
    "title": "Grammar of Figures: The Art and Science of Visualizing Data for Publication",
    "section": "0.4 Tools & Technologies",
    "text": "0.4 Tools & Technologies\n\nPhilosophy: Choose the Right Tool for the Task\nThere is no single “best” tool for creating scientific figures. Your choice depends on: - Your programming proficiency - Reproducibility requirements - Complexity of the visualization - Collaboration needs - Time constraints - Journal requirements\n\n\nThe Tool Spectrum: Code vs. GUI\nCode-based approaches (Python, R): - Pros: Reproducible, automatable, version-controlled, handles large datasets, scriptable - Cons: Steeper learning curve, slower for quick edits, limited interactive exploration\nGUI-based approaches (Illustrator, GraphPad): - Pros: Immediate visual feedback, intuitive, fast for polish and arrangement - Cons: Not reproducible, manual process, difficult to update with new data, expensive software\nHybrid approach (Recommended): 1. Generate core visualization with code (data → plot) 2. Export to vector format (PDF, SVG) 3. Final polish in vector editor (labels, arrangement, annotations) 4. Keep both code and final file for reproducibility\n\n\n\nPython Ecosystem\nCore Libraries:\n\n1. Matplotlib – The Foundation\nimport matplotlib.pyplot as plt\n\n# Basic but flexible\nfig, ax = plt.subplots()\nax.plot(x, y)\nax.set_xlabel('X Label')\nax.set_ylabel('Y Label')\nWhen to use: - Maximum control over every element - Custom or unusual plot types - Publication-quality static figures - When you need precise positioning\nLimitations: - Verbose syntax - Default aesthetics need work - Steeper learning curve\n\n\n2. Seaborn – Statistical Visualization\nimport seaborn as sns\n\n# High-level interface with good defaults\nsns.set_style(\"whitegrid\")\nsns.boxplot(data=df, x='group', y='value', palette='Set2')\nWhen to use: - Statistical plots (distributions, relationships) - Quick exploratory analysis - Better default aesthetics than matplotlib - Integrates well with pandas dataframes\nLimitations: - Less control than matplotlib - Limited to statistical plot types - Customization requires matplotlib knowledge\n\n\n3. Plotly – Interactive Figures\nimport plotly.express as px\n\n# Interactive plots with hover information\nfig = px.scatter(df, x='var1', y='var2', color='group',\n                 hover_data=['sample_id'])\nfig.show()\nWhen to use: - Web-based presentations - Exploratory data analysis - Interactive dashboards - Supplementary online materials\nLimitations: - File sizes can be large - Not ideal for print journals - Requires JavaScript for full functionality\n\n\n4. Specialized Libraries\n\nNetworkX + matplotlib: Network graphs\nBiopython: Phylogenetic trees, sequence alignments\nCartopy: Geographic/map visualizations\nYellowbrick: Machine learning visualization\n\nExample: Complete Python Workflow\n# generate_figure1.py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configuration\nplt.rcParams.update({\n    'font.size': 10,\n    'font.family': 'Arial',\n    'axes.linewidth': 1.0,\n    'figure.dpi': 300\n})\n\n# Load data\ndata = pd.read_csv('../data/experiment_data.csv')\n\n# Create figure\nfig, axes = plt.subplots(1, 2, figsize=(7, 3))\n\n# Panel A: Time series\naxes[0].plot(data['time'], data['control'],\n             label='Control', color='#333333', linewidth=2)\naxes[0].plot(data['time'], data['treatment'],\n             label='Treatment', color='#E63946', linewidth=2)\naxes[0].set_xlabel('Time (hours)')\naxes[0].set_ylabel('Cell viability (%)')\naxes[0].legend(frameon=False)\naxes[0].text(-0.15, 1.05, 'A', transform=axes[0].transAxes,\n             fontsize=12, fontweight='bold')\n\n# Panel B: Bar chart with stats\nsns.barplot(data=data, x='condition', y='final_viability',\n            ax=axes[1], palette=['#333333', '#E63946'])\naxes[1].set_xlabel('Condition')\naxes[1].set_ylabel('Final viability (%)')\naxes[1].text(-0.15, 1.05, 'B', transform=axes[1].transAxes,\n             fontsize=12, fontweight='bold')\n\n# Save\nplt.tight_layout()\nplt.savefig('../figures/figure1.pdf', bbox_inches='tight')\nplt.savefig('../figures/figure1.png', dpi=300, bbox_inches='tight')\nprint(\"Figure saved successfully\")\n\n\n\n\nR Ecosystem\nCore Libraries:\n\n1. ggplot2 – Grammar of Graphics\nlibrary(ggplot2)\n\n# Layered approach\nggplot(data, aes(x = time, y = value, color = group)) +\n  geom_line(size = 1) +\n  geom_point(size = 2) +\n  theme_minimal() +\n  labs(x = \"Time (hours)\", y = \"Response\")\nWhen to use: - Elegant, consistent syntax - Excellent for publication figures - Strong statistical integration - Extensive ecosystem (ggplot extensions)\nStrengths: - More intuitive than matplotlib for many - Better default aesthetics - Consistent API across plot types - Huge community and resources\n\n\n2. Cowplot & Patchwork – Multi-panel Layouts\nlibrary(cowplot)\nlibrary(patchwork)\n\n# Combine multiple plots\np1 &lt;- ggplot(...) + ...\np2 &lt;- ggplot(...) + ...\n\n# Using patchwork\ncombined &lt;- p1 + p2 + plot_annotation(tag_levels = 'A')\n\n# Or cowplot\nplot_grid(p1, p2, labels = c('A', 'B'), ncol = 2)\nWhen to use: - Complex multi-panel figures - Combining different plot types - Adding annotations across panels - Publication-ready layouts\n\n\n3. Specialized R Packages\n\npheatmap, ComplexHeatmap: Heatmaps with clustering\nggtree: Phylogenetic trees\nggmap: Geographic visualization\nsurvminer: Survival curves\nggpubr: Publication-ready plots with stats\n\nExample: Complete R Workflow\n# generate_figure1.R\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(scales)\n\n# Set theme\ntheme_set(theme_classic(base_size = 10, base_family = \"Arial\"))\n\n# Load data\ndata &lt;- read_csv(\"../data/experiment_data.csv\")\n\n# Panel A: Time series\np1 &lt;- ggplot(data, aes(x = time, y = viability, color = condition)) +\n  geom_line(size = 1) +\n  geom_point(size = 2) +\n  scale_color_manual(values = c(\"Control\" = \"#333333\",\n                                  \"Treatment\" = \"#E63946\")) +\n  labs(x = \"Time (hours)\",\n       y = \"Cell viability (%)\",\n       color = NULL) +\n  theme(legend.position = c(0.8, 0.9),\n        legend.background = element_blank())\n\n# Panel B: Final values with stats\np2 &lt;- ggplot(data %&gt;% filter(time == max(time)),\n             aes(x = condition, y = viability, fill = condition)) +\n  geom_bar(stat = \"summary\", fun = \"mean\", width = 0.6) +\n  geom_errorbar(stat = \"summary\", fun.data = \"mean_se\", width = 0.2) +\n  scale_fill_manual(values = c(\"Control\" = \"#333333\",\n                                \"Treatment\" = \"#E63946\")) +\n  labs(x = \"Condition\", y = \"Final viability (%)\") +\n  theme(legend.position = \"none\")\n\n# Combine panels\nfig1 &lt;- plot_grid(p1, p2, labels = c('A', 'B'),\n                  ncol = 2, rel_widths = c(1.2, 1))\n\n# Save\nggsave(\"../figures/figure1.pdf\", fig1, width = 7, height = 3, units = \"in\")\nggsave(\"../figures/figure1.png\", fig1, width = 7, height = 3, units = \"in\", dpi = 300)\n\nmessage(\"Figure saved successfully\")\n\n\n\n\nVector Graphics Editors\nWhen code alone isn’t enough, use professional editing software:\n\nAdobe Illustrator (Industry Standard)\nPros: - Precise control over every element - Professional typography tools - Excellent for multi-panel assembly - Widely used in scientific publishing\nCons: - Expensive (20-50/month) - Steeper learning curve - Proprietary format - Overkill for simple edits\nWhen to use: - Complex multi-panel figures requiring careful alignment - Adding custom illustrations or diagrams - Fine-tuning typography and spacing - Preparing figures for high-impact journals\n\n\nInkscape (Free & Open-Source)\nPros: - Free and open-source - Cross-platform (Windows, Mac, Linux) - SVG native format - Most Illustrator features available\nCons: - Slightly less polished interface - Some advanced features missing - Smaller user community - Occasional compatibility issues with complex PDFs\nWhen to use: - Budget constraints - Open-source workflow preference - Basic to intermediate vector editing - Learning before investing in Illustrator\n\n\nAffinity Designer (One-Time Purchase)\nPros: - One-time purchase (~70) - Modern interface - Good Illustrator compatibility - Growing in scientific community\nCons: - Smaller community than Illustrator - Fewer tutorials and resources - Some niche features missing\nBest Practices for Vector Editing:\n\nAlways start from code: Generate the data visualization programmatically\nExport as vector: PDF or SVG (never PNG/JPEG for initial export)\nPreserve layers: Keep editable elements on separate layers\nUse guides: Align panels precisely using grid and guides\nOutline fonts: Convert text to paths before final export (prevents font issues)\nSave source files: Keep both .ai/.svg and final PDF\n\nExample Workflow: Code → Vector Editor 1. Python/R generates figure1_raw.pdf 2. Open in Illustrator/Inkscape 3. Edits: - Adjust panel spacing - Add panel labels (A, B, C) - Fine-tune legend position - Add connecting arrows or annotations - Ensure consistent font sizes 4. Save as figure1_working.ai (editable) 5. Export as figure1_final.pdf (for submission) 6. Keep both files in version control\n\n\n\n\nThe Reproducibility vs. Polish Trade-Off\nFully Code-Based (Maximum Reproducibility)\ndata → script.py → figure.pdf\n\nUpdates automatically if data changes\nFully documented in code\nEasy to reproduce\nLimited aesthetic control\n\nHybrid Approach (Recommended Balance)\ndata → script.py → figure_raw.pdf → [illustrator] → figure_final.pdf\n\nCore visualization reproducible\nManual polish for publication quality\nDocument manual steps in README\nKeep both versions\n\nFully Manual (Avoid If Possible)\ndata → Excel → [copy to Illustrator] → figure.pdf\n\nNot reproducible\nError-prone\nHard to update\nCommon in some fields but discouraged\n\n\n\nTool Recommendations by Career Stage\nGraduate Students / Early Career: - Learn: Python (matplotlib + seaborn) OR R (ggplot2) - Practice with: Free tools (Inkscape) - Invest time in: Understanding principles, not just tools\nPostdocs / Mid-Career: - Master: One ecosystem deeply (Python or R) - Add: Vector editor (Illustrator or Affinity) - Consider: Specialized tools for your field\nEstablished Researchers / Lab Heads: - Standardize: Lab-wide tools and templates - Delegate: Train students/postdocs - Invest in: Site licenses for software - Focus on: Consistency and reproducibility across lab\n\n\nExercise 0.4.1\nTool Assessment & Setup:\n\nEvaluate your current tools:\n\nWhat do you currently use for figures?\nWhat frustrates you about your current workflow?\nWhat do you wish you could do but can’t?\n\nChoose your primary platform:\n\nBased on this chapter, pick: Python ecosystem, R ecosystem, or mixed\nWrite 2-3 sentences justifying your choice\n\nSet up your environment:\n\nInstall your chosen tools\nCreate a template script/project structure\nGenerate one simple figure (scatter plot with your data)\n\nTest the workflow:\n\nCreate a figure with code\nExport to vector format\nMake one manual edit in a vector editor\nDocument the process in a README file",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Grammar of Figures: The Art and Science of Visualizing Data for Publication**</span>"
    ]
  },
  {
    "objectID": "Chapter 0.html#chapter-0-summary",
    "href": "Chapter 0.html#chapter-0-summary",
    "title": "Grammar of Figures: The Art and Science of Visualizing Data for Publication",
    "section": "Chapter 0 Summary",
    "text": "Chapter 0 Summary\n\nKey Takeaways\n\nFigures are primary communication vehicles – they’re not decorative but essential to scientific storytelling\nDefine before you design – clarify message, audience, and context before touching software\nIterate deliberately – sketch → draft → review → refine → test\nChoose tools strategically – balance reproducibility, control, and efficiency; hybrid approaches often work best\nEstablish workflow early – consistent processes save time and improve quality across projects\n\n\n\nBefore Moving to Chapter 1\nYou should now be able to: - [ ] Articulate why a figure matters in scientific communication - [ ] Define the message, audience, and context for any figure you create - [ ] Execute the five-stage iterative design process - [ ] Choose appropriate tools for your needs and skill level - [ ] Set up a reproducible workflow for figure generation\n\n\nLooking Ahead\nIn Chapter 1, we’ll dive into the foundational science of visual perception – understanding how and why humans process visual information. This will provide the cognitive framework for all subsequent design decisions.\nBefore continuing, ensure you’ve completed at least Exercise 0.3.1 (iterative refinement of one of your figures) and Exercise 0.4.1 (tool setup and workflow test).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Grammar of Figures: The Art and Science of Visualizing Data for Publication**</span>"
    ]
  },
  {
    "objectID": "Chapter 1.html",
    "href": "Chapter 1.html",
    "title": "Chapter 1: Foundations of Visual Perception",
    "section": "",
    "text": "1.1 How We See: Graphical Perception Principles",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 1: Foundations of Visual Perception</span>"
    ]
  },
  {
    "objectID": "Chapter 1.html#how-we-see-graphical-perception-principles",
    "href": "Chapter 1.html#how-we-see-graphical-perception-principles",
    "title": "Chapter 1: Foundations of Visual Perception",
    "section": "",
    "text": "The Science Behind Data Visualization\nBefore we can create effective scientific figures, we must understand the fundamental mechanisms of how humans perceive and interpret visual information. Graphical perception is the study of how people extract quantitative information from visual displays. Understanding these principles transforms figure design from an aesthetic exercise into a scientifically-grounded practice.\n\n\nPre-attentive Processing: What We See Without Thinking\nPre-attentive processing refers to visual features that our brain processes automatically, before conscious attention. These features are detected in less than 200-250 milliseconds—essentially instantaneously.\nPre-attentive Visual Features: - Color hue (red vs. blue) - Intensity/brightness (dark vs. light) - Orientation (vertical vs. horizontal lines) - Size (large vs. small) - Shape (circle vs. square) - Position (spatial location) - Motion (in dynamic displays)\nExample Demonstration:\nImagine two scatter plots: - Plot A: 100 gray circles, with 1 red circle - Plot B: 100 gray circles in random positions, with 1 gray circle positioned differently\nIn Plot A, the red circle “pops out” immediately (pre-attentive color detection). In Plot B, you must consciously search for the differently positioned circle (attentive processing).\nImplication for Figure Design: Use pre-attentive features to direct attention to the most important data points or patterns. Don’t bury your key finding in visual complexity that requires effortful search.\nGood Example:\nA volcano plot showing differential gene expression:\n- Thousands of gray points (non-significant genes)\n- Significant upregulated genes in red\n- Significant downregulated genes in blue\n→ The colored points immediately draw attention\nBad Example:\nThe same volcano plot where:\n- All points are gray\n- Significant genes marked only by slightly different symbols (triangle vs. circle)\n→ Requires careful examination; key findings don't stand out\n\n\nThe Hierarchy of Perceptual Accuracy: Cleveland & McGill\nIn the 1980s, psychologists William Cleveland and Robert McGill conducted landmark experiments to determine how accurately people can judge different types of visual encodings. Their findings established a hierarchy of perceptual accuracy:\nRanking from MOST to LEAST Accurate:\n\nPosition along a common scale (e.g., points on a scatter plot with shared axes)\nPosition along non-aligned scales (e.g., separate panels with different scales)\nLength (e.g., bar heights)\nDirection/Angle (e.g., slopes of lines)\nArea (e.g., bubble sizes in bubble charts)\nVolume/Density (e.g., 3D shapes)\nColor saturation/intensity (e.g., heatmap gradients)\nColor hue (e.g., categorical colors)\n\nWhat This Means for Practice:\nMost Accurate Encoding (Position):\nComparing treatment effects across conditions:\n✓ GOOD: Dot plot with groups on x-axis, values on y-axis\n  → Direct position comparison along common y-axis scale\n✗ AVOID: Pie charts comparing percentages\n  → Requires angle/area judgments, much less accurate\nLength vs. Area:\nShowing relative quantities:\n✓ GOOD: Bar chart (comparing bar heights/lengths)\n✗ WORSE: Bubble chart (comparing circle areas)\n  → People underestimate area differences\n\nMathematical reality:\n- A circle with 2× the radius has 4× the area\n- But viewers perceive only ~2× difference\nColor Hue for Quantitative Data:\n✗ BAD: Using rainbow colors (red → yellow → blue) for continuous data\n  → No inherent ordering; perceptually non-uniform\n✓ GOOD: Using sequential color scale (light blue → dark blue)\n  → Clear ordering; leverages intensity perception\n\n\nPractical Application: Choosing Plot Types\nBased on the Cleveland-McGill hierarchy, here’s how to select plot types:\nFor Precise Quantitative Comparisons: 1. Scatter plots (position vs. position) 2. Line graphs (position over continuous variable like time) 3. Bar charts (length comparison) 4. Dot plots (position along scale)\nFor Approximate Patterns/Trends: 5. Heatmaps (color intensity for patterns, not precise values) 6. Bubble charts (area for rough magnitude) 7. Pie charts (only for 2-3 very different proportions, if at all)\nFor Categorical Relationships: 8. Box plots/Violin plots (distribution shapes) 9. Network diagrams (connectivity, not precise values)\n\n\nAttention and Visual Search\nBeyond pre-attentive processing, how we direct and sustain attention matters for complex figures.\nLimited Attention Resources: - We can only consciously attend to one thing at a time - Complex figures require serial processing (scanning element by element) - Each additional element increases cognitive load\nImplications: 1. Minimize visual clutter: Every element should serve a purpose 2. Create clear visual hierarchy: Most important elements should be most salient 3. Limit simultaneous comparisons: Human working memory holds ~4-7 items 4. Guide the viewer’s path: Use layout to create a reading order\nExample of Attention Management:\nBad: Cognitive Overload\nA single figure trying to show:\n- Time course of 8 treatments (8 overlapping lines)\n- Individual data points (hundreds of dots)\n- Error bars at each timepoint\n- Statistical significance markers between all pairs\n- Three different y-axis scales\n→ Viewer doesn't know where to look first; analysis paralysis\nGood: Staged Information\nMulti-panel approach:\nPanel A: Overview - mean trajectories only (3 key treatments)\nPanel B: Detailed comparison - 2 treatments with error bars\nPanel C: Summary - final endpoint comparison with statistics\n→ Clear narrative progression; each panel has one message\n\n\nGestalt Principles in Data Visualization\nGestalt psychology describes how humans organize visual elements into groups or unified wholes. These principles are fundamental to effective figure layout.\n\n1. Proximity\nPrinciple: Elements close together are perceived as belonging together.\nApplication:\nMulti-panel figures:\n- Place related panels near each other\n- Use white space to separate conceptually different sections\n- Group legends near their corresponding data\n\nExample:\nPanel A (experiment 1) | Panel B (experiment 2)\n[placed adjacently]\nvs.\nPanel C (control data)\n[separated by white space]\n\n\n2. Similarity\nPrinciple: Elements that share visual properties (color, shape, size) are perceived as related.\nApplication:\nConsistent encoding across figures:\n- Same colors for same treatments throughout manuscript\n- Same symbols for same data types\n- Same line styles for same conditions\n\nExample:\nFigure 1: Control = blue circles, Treatment = red squares\nFigure 2: Should maintain same scheme, not switch arbitrarily\n\n\n3. Continuity\nPrinciple: The eye follows paths and lines naturally.\nApplication:\nLine graphs:\n- Smooth lines guide eye through temporal progression\n- Connecting related data points clarifies relationships\n- Avoid unnecessary breaks in lines (unless data truly missing)\n\nExample in multi-panel layout:\nArrange panels in reading order (left → right, top → bottom)\nthat matches narrative progression\n\n\n4. Closure\nPrinciple: We perceive complete figures even when parts are missing.\nApplication:\nAxis design:\n✓ Can omit top and right spines (brain completes the frame)\n✗ Don't omit axis labels (brain cannot infer meaning)\n\nScatter plots:\n- Can use partial grid lines (just at major ticks)\n- Brain fills in the implicit grid structure\n\n\n5. Figure-Ground Separation\nPrinciple: We distinguish foreground objects from background.\nApplication:\nData vs. Context:\n- Data elements (points, lines) should be visually prominent\n- Supporting elements (grid, axis lines) should recede\n- Use contrast: bold/bright for data, light/thin for context\n\nExample:\n✓ Black data points on light gray grid\n✗ Gray data points on black grid (inverts natural hierarchy)\n\n\n\nChange Blindness and Inattentional Blindness\nChange Blindness: Failure to detect changes in visual scenes when they occur during brief interruptions.\nRelevance to Figures: - Readers may miss subtle differences between conditions if not highlighted - Before/after comparisons need clear side-by-side presentation - Don’t rely on readers remembering Figure 2 when viewing Figure 5\nSolutions:\n✓ Direct comparisons within same panel or adjacent panels\n✓ Use annotation arrows to highlight changes\n✓ Repeat reference condition in multiple panels if needed\nInattentional Blindness: Failing to see unexpected objects when attention is focused elsewhere.\nRelevance to Figures: - Readers focused on one aspect may miss important secondary patterns - Critical findings need explicit visual emphasis - Cannot assume readers will notice everything you see\nExample:\nScatter plot showing correlation:\n- Main focus: positive correlation in Treatment A\n- Hidden insight: 3 extreme outliers that might be artifacts\n→ If outliers aren't highlighted (different color/size),\n   readers focused on the trend will miss them\n\n\nWorking Memory Constraints\nMiller’s Law: Human working memory can hold approximately 7±2 items simultaneously.\nImplications for Figures:\nBad: Exceeding Memory Limits\nLine graph with 15 different colored lines\n→ Cannot keep track of which color means what\n→ Constant back-and-forth reference to legend\n→ Cognitive overload\nGood: Respecting Memory Limits\nOption 1: Show only 3-5 key lines, others in supplementary figure\nOption 2: Use small multiples (separate panels for each line)\nOption 3: Highlight 2-3 key comparisons, gray out others\nLegend Design Consideration:\nIf legend requires &gt;7 items, consider:\n- Is this really one figure, or should it be split?\n- Can you use direct labeling instead of legend?\n- Can you group items into fewer categories?\n\n\nPerceptual Biases We Cannot Avoid\n\nThe Weber-Fechner Law\nPrinciple: We perceive differences logarithmically, not linearly.\nImplications:\nComparing values:\n- Difference between 1 and 2 feels bigger than between 10 and 11\n  (both are +1, but 1→2 is 100% increase vs. 10→11 is 10% increase)\n\nSolution for large ranges:\n- Use log scales when data spans orders of magnitude\n- This makes proportional differences perceptually equal\n\n\nThe Area Perception Bias\nPrinciple: We systematically underestimate area differences.\nExample:\nCircle A has diameter 10, Circle B has diameter 20\n- Actual area ratio: (20/10)² = 4:1\n- Perceived ratio: approximately 2:1\n\nImplication:\n✗ Bubble charts exaggerate small differences, hide large ones\n✓ Use length/position encodings for accurate magnitude comparison\n\n\nThe Color Contrast Effect\nPrinciple: Perceived color depends on surrounding colors.\nExample:\nSame gray square appears:\n- Darker when surrounded by white\n- Lighter when surrounded by black\n\nImplication for heatmaps:\n- Use consistent backgrounds across figures\n- Be aware that adjacent colors influence perception\n- Test figures in both digital (white background) and print contexts\n\n\n\nTemporal Perception: Animation and Change\nFor dynamic displays (less common in static publications, but relevant for presentations and supplementary materials):\nEffective Use: - Showing temporal progression of processes - Revealing complex patterns in stages - Guiding attention through complex figures\nCaution: - Motion is highly pre-attentive (can be distracting) - Difficult to compare frames from memory - Not suitable for precise quantitative reading - Accessibility issues (motion sensitivity)\nBest Practice:\nFor presentations:\n✓ Use animation to build up complexity gradually\n✓ Pause on key frames for analysis\n✓ Provide static \"key frame\" summary\n\nFor publications:\n✓ Convert animations to multi-panel static figures\n✓ Show representative timepoints\n\n\n\nExercise 1.1.1: Perceptual Hierarchy Experiment\nObjective: Experience the Cleveland-McGill hierarchy firsthand\nMaterials needed: Graph paper or plotting software\nInstructions:\n\nCreate three versions of the same data (5 categories, values: 20, 35, 45, 60, 75):\n\nVersion A: Bar chart (length encoding)\nVersion B: Pie chart (angle encoding)\nVersion C: Bubble chart (area encoding)\n\nTest yourself:\n\nLook at each for 3 seconds only\nWithout referring back, estimate:\n\nWhich category has the highest value?\nWhat is the ratio of largest to smallest value?\nRank all categories from smallest to largest\n\n\nReflection questions:\n\nWhich version made estimation easiest?\nWhere did you make errors?\nWhich version required the most “mental calculation”?\nWhat does this tell you about encoding choice?\n\n\nExpected finding: Bar chart will be easiest and most accurate; pie chart most difficult.\n\n\n\nExercise 1.1.2: Pre-attentive Feature Detection\nObjective: Identify what “pops out” in your figures\nInstructions:\n\nTake a figure you’re currently working on\nThe 3-second test:\n\nShow figure to a colleague for exactly 3 seconds\nRemove it\nAsk: “What did you notice first?”\n\nAnalysis:\n\nWas the first thing they noticed your intended main message?\nIf yes: What pre-attentive feature made it stand out? (color, size, position?)\nIf no: What competed for attention? How can you adjust?\n\nRedesign:\n\nEmphasize the main message using pre-attentive features\nDe-emphasize secondary elements\nRetest with a different colleague\n\n\n\n\n\nExercise 1.1.3: Gestalt Principles Audit\nObjective: Apply Gestalt principles to improve figure organization\nInstructions:\n\nSelect a multi-panel figure (your own or from a published paper)\nAnalyze each Gestalt principle:\n\nProximity: Are related panels grouped together? Is white space used to separate conceptually different elements?\nSimilarity: Do similar data types use consistent visual encoding? Are colors/shapes reused meaningfully?\nContinuity: Does the layout create a natural reading path? Does it match your narrative order?\nClosure: Are all frames necessary, or could you simplify by letting the brain “complete” structures?\nFigure-Ground: Do data elements stand out from supporting elements (axes, grids)?\n\nScore each principle: 1 (poor) to 5 (excellent)\nIdentify weakest area and sketch one specific improvement\n\nExample improvement:\nOriginal: Four panels scattered with inconsistent spacing\nProblem: Violation of proximity principle\nSolution: Group panels A-B (related experiments) close together,\n          separate from panels C-D (control data) with more white space",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 1: Foundations of Visual Perception</span>"
    ]
  },
  {
    "objectID": "Chapter 1.html#visual-channels-and-their-effectiveness",
    "href": "Chapter 1.html#visual-channels-and-their-effectiveness",
    "title": "Chapter 1: Foundations of Visual Perception",
    "section": "1.2 Visual Channels and Their Effectiveness",
    "text": "1.2 Visual Channels and Their Effectiveness\n\nWhat Are Visual Channels?\nA visual channel (or visual variable) is any controlled aspect of a graphical mark that can encode data. Understanding which channels are most effective for which data types is foundational to making good visualization choices.\n\n\nThe Complete Channel Inventory\nSpatial Channels (Most Effective): 1. Position (X, Y coordinates) - Best for quantitative data 2. Length - Very good for quantitative data 3. Angle - Good for ordinal/limited quantitative 4. Slope - Good for trends and rates of change\nAppearance Channels (Moderate Effectiveness): 5. Area - Moderate for quantitative, good for magnitude 6. Volume - Poor for quantitative, avoid if possible 7. Color Hue - Best for categorical/nominal data 8. Color Saturation - Good for ordinal/limited quantitative 9. Color Luminance - Good for quantitative (single hue)\nTexture Channels (Lower Effectiveness): 10. Shape - Good for categorical (limited #) 11. Texture/Pattern - Moderate for categorical 12. Orientation - Moderate for categorical/ordinal\n\n\nMatching Channels to Data Types\nThe type of data you have determines which channels are appropriate:\n\n1. Quantitative Data (Continuous Numbers)\nBest Channels (in order): - Position (scatter plots, line graphs) - Length (bar charts) - Color luminance (single-hue gradient heatmaps)\nExample:\nShowing gene expression levels across samples:\n✓ EXCELLENT: Position (dot plot with values on y-axis)\n✓ GOOD: Length (bar chart)\n✓ ACCEPTABLE: Color luminance (heatmap, light→dark)\n✗ POOR: Color hue (rainbow heatmap)\n✗ TERRIBLE: Area/volume (3D bar chart)\nWhy position is best: - Humans excel at judging positions along a common scale - Precise reading possible with gridlines - Direct comparison between elements - Minimal perceptual distortion\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Sample data: gene expression across 5 conditions\ngenes = ['GeneA', 'GeneB', 'GeneC', 'GeneD', 'GeneE']\nexpression = [2.3, 5.1, 3.7, 8.2, 4.9]\n\n# BEST: Position encoding (dot plot)\nfig, axes = plt.subplots(1, 3, figsize=(12, 3))\n\n# Plot 1: Position (best)\naxes[0].scatter(expression, genes, s=100, color='steelblue')\naxes[0].set_xlabel('Expression Level')\naxes[0].set_title('Position Channel (Best)')\naxes[0].grid(axis='x', alpha=0.3)\n\n# Plot 2: Length (good)\naxes[1].barh(genes, expression, color='steelblue')\naxes[1].set_xlabel('Expression Level')\naxes[1].set_title('Length Channel (Good)')\n\n# Plot 3: Area (poor - for comparison)\n# Normalize for bubble sizing\nsizes = (np.array(expression) ** 2) * 10\naxes[2].scatter([1]*len(genes), genes, s=sizes,\n                color='steelblue', alpha=0.6)\naxes[2].set_xlim(0.5, 1.5)\naxes[2].set_xticks([])\naxes[2].set_title('Area Channel (Poor)')\n\nplt.tight_layout()\nplt.savefig('channel_comparison.png', dpi=300, bbox_inches='tight')\n\n\n2. Ordinal Data (Ranked/Ordered Categories)\nBest Channels: - Position (along an ordered axis) - Color luminance (sequential palette) - Size (small to large) - Angle (for cyclic data like time of day)\nExample:\nShowing disease severity (mild, moderate, severe):\n✓ EXCELLENT: Position (ordered categories on x-axis)\n✓ GOOD: Color (light → dark gradient)\n✓ ACCEPTABLE: Size (small → medium → large markers)\n✗ POOR: Color hue (red, blue, green - no inherent order)\nCode Example (R):\nlibrary(ggplot2)\nlibrary(RColorBrewer)\n\n# Sample data\ndata &lt;- data.frame(\n  patient = 1:20,\n  severity = factor(sample(c(\"Mild\", \"Moderate\", \"Severe\"), 20, replace=TRUE),\n                    levels = c(\"Mild\", \"Moderate\", \"Severe\"),\n                    ordered = TRUE),\n  response = rnorm(20, 50, 10)\n)\n\n# GOOD: Position + sequential color for ordinal data\nggplot(data, aes(x = severity, y = response, color = severity)) +\n  geom_jitter(size = 3, width = 0.2) +\n  scale_color_brewer(palette = \"YlOrRd\") +  # Sequential palette\n  labs(x = \"Disease Severity\", y = \"Treatment Response\",\n       title = \"Position + Sequential Color for Ordinal Data\") +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"none\")  # Legend redundant when x-axis labeled\n\n\n3. Categorical/Nominal Data (Unordered Groups)\nBest Channels: - Color hue (distinct colors) - Shape (different symbols - limit to ~6) - Position (separate groups along axis) - Faceting (separate panels)\nExample:\nShowing data from 4 different cell lines:\n✓ EXCELLENT: Color hue (4 distinct colors)\n✓ GOOD: Shape (4 different symbols: circle, square, triangle, diamond)\n✓ ACCEPTABLE: Position (4 separate groups on x-axis)\n✗ AVOID: Color luminance (implies ordering that doesn't exist)\nCode Example (Python):\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Sample data\ndata = pd.DataFrame({\n    'cell_line': np.repeat(['A', 'B', 'C', 'D'], 50),\n    'time': np.tile(np.arange(50), 4),\n    'growth': np.concatenate([\n        np.cumsum(np.random.randn(50) + 0.5),\n        np.cumsum(np.random.randn(50) + 0.3),\n        np.cumsum(np.random.randn(50) + 0.7),\n        np.cumsum(np.random.randn(50) + 0.4)\n    ])\n})\n\n# GOOD: Color hue for categorical data\nfig, ax = plt.subplots(figsize=(8, 5))\n\n# Qualitative color palette\ncolors = ['#E64B35', '#4DBBD5', '#00A087', '#3C5488']\n\nfor i, cell_line in enumerate(['A', 'B', 'C', 'D']):\n    subset = data[data['cell_line'] == cell_line]\n    ax.plot(subset['time'], subset['growth'],\n            color=colors[i], linewidth=2, label=f'Cell Line {cell_line}')\n\nax.set_xlabel('Time (hours)', fontsize=12)\nax.set_ylabel('Cell Growth (AU)', fontsize=12)\nax.set_title('Color Hue for Categorical Data', fontsize=14, fontweight='bold')\nax.legend(frameon=True, loc='upper left')\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\nplt.tight_layout()\nplt.savefig('categorical_channels.png', dpi=300, bbox_inches='tight')\n\n\n\nChannel Combination Rules\nOften you need to encode multiple data dimensions simultaneously. Here’s how to combine channels effectively:\n\nRule 1: Use the Strongest Channel for the Most Important Variable\nExample: Scatter plot showing drug response\n\nPrimary variable (most important): Treatment outcome\nSecondary variable: Patient age\nTertiary variable: Treatment group\n\nEncoding:\n✓ Position Y: Treatment outcome (strongest channel)\n✓ Position X: Patient age (second strongest)\n✓ Color: Treatment group (weaker channel, but effective for categories)\n\n\nRule 2: Avoid Channel Conflict\nConflict Example:\n✗ BAD: Using both size AND color luminance to encode the same variable\n  → Redundant and potentially contradictory\n  → e.g., larger AND darker doesn't add information\n\n✓ BETTER: Use size for one variable, color hue for another categorical variable\nNon-Conflict Example:\nEncoding three variables on a scatter plot:\n- X-position: Time\n- Y-position: Temperature\n- Color: Location (categorical)\n→ No conflict: each channel encodes different information\n\n\nRule 3: Leverage Redundancy for Accessibility\nStrategic Redundancy:\n✓ GOOD: Encoding the same categorical variable with BOTH color AND shape\n  → Ensures colorblind accessibility\n  → Shape alone works if color unavailable\n\nExample:\nTreatment A: Red circles\nTreatment B: Blue squares\nTreatment C: Green triangles\n\n→ If colors indistinguishable, shapes still differentiate groups\n\n\nRule 4: Limit Channel Overload\nToo Many Channels:\n✗ BAD: Encoding 6 variables on one scatter plot:\n  - X position\n  - Y position\n  - Color hue\n  - Color saturation\n  - Size\n  - Shape\n\n→ Cognitively overwhelming\n→ Hard to decode\n\n✓ BETTER: Use small multiples (faceting) to split some variables into panels\n\n\n\nCommon Channel Mistakes\n\nMistake 1: Using Area for Quantitative Comparison\nThe Problem:\nBubble chart where bubble size represents quantity:\n- Data: values of 100, 200, 300\n- Bubble areas: A₁, A₂, A₃\n- Perceptual ratio: ~1.5:2:2.3\n- Actual ratio: 1:2:3\n\n→ Systematic underestimation of larger values\nThe Fix:\n✓ Use length encoding instead (bar chart)\n✗ If bubble chart necessary, scale radius (not area) linearly\n  But still expect perceptual error\nCode to Demonstrate:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nvalues = np.array([100, 200, 300, 400])\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 4))\n\n# WRONG: Area proportional to value (default behavior)\naxes[0].scatter([1, 2, 3, 4], [1, 1, 1, 1], s=values, alpha=0.5)\naxes[0].set_xlim(0, 5)\naxes[0].set_ylim(0, 2)\naxes[0].set_title('WRONG: Area ∝ Value\\n(Perceptually misleading)')\naxes[0].set_xticks([1, 2, 3, 4])\naxes[0].set_xticklabels(values)\n\n# BETTER: Length proportional to value\naxes[1].bar([1, 2, 3, 4], values, width=0.6, alpha=0.7)\naxes[1].set_title('BETTER: Length ∝ Value\\n(Accurate perception)')\naxes[1].set_xticks([1, 2, 3, 4])\naxes[1].set_xticklabels(values)\naxes[1].set_ylabel('Value')\n\nplt.tight_layout()\nplt.savefig('area_vs_length.png', dpi=300, bbox_inches='tight')\n\n\nMistake 2: Rainbow Color Maps for Quantitative Data\nThe Problem:\nUsing hue spectrum (rainbow: red→yellow→green→blue→violet) for continuous data:\n\nIssues:\n1. No perceptual ordering (is yellow &gt; green?)\n2. Non-uniform perceptual steps (yellow is much brighter)\n3. False boundaries (sharp transitions in smooth data)\n4. Accessibility issues (colorblind viewers lose information)\nThe Fix:\n✓ Use sequential colormaps (single hue, varying luminance)\n  Examples: Blues, Greens, Greys\n\n✓ Use diverging colormaps for data with meaningful midpoint\n  Examples: Blue-White-Red for positive/negative values\n\n✓ Use perceptually uniform colormaps\n  Examples: viridis, plasma, cividis\nDemonstration:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Create sample heatmap data\ndata = np.random.randn(10, 10).cumsum(axis=1)\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\n# BAD: Rainbow\nim1 = axes[0].imshow(data, cmap='jet', aspect='auto')\naxes[0].set_title('BAD: Rainbow (jet)\\nNon-uniform, no order', fontsize=12)\nplt.colorbar(im1, ax=axes[0])\n\n# BETTER: Sequential\nim2 = axes[1].imshow(data, cmap='Blues', aspect='auto')\naxes[1].set_title('BETTER: Sequential\\nClear low→high', fontsize=12)\nplt.colorbar(im2, ax=axes[1])\n\n# BEST: Perceptually uniform\nim3 = axes[2].imshow(data, cmap='viridis', aspect='auto')\naxes[2].set_title('BEST: Viridis\\nPerceptually uniform', fontsize=12)\nplt.colorbar(im3, ax=axes[2])\n\nfor ax in axes:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.savefig('colormap_comparison.png', dpi=300, bbox_inches='tight')\n\n\nMistake 3: Using 3D for 2D Data\nThe Problem:\n3D bar charts, 3D pie charts, 3D scatter plots when z-axis adds no information:\n\nIssues:\n1. Perspective distortion (objects in back appear smaller)\n2. Occlusion (bars hide each other)\n3. Difficult to read exact values\n4. Adds no information, only visual complexity\nThe Fix:\n✓ Use 2D representations with position/length channels\n✗ Only use 3D when you genuinely have 3 spatial dimensions of data\n  (e.g., protein structure, geographic elevation)\n\n\n\n\nExercise 1.2.1: Channel Selection Practice\nObjective: Practice choosing appropriate channels for different data types\nScenario: You have the following dataset from a clinical trial:\n\nPatient ID (categorical, nominal)\nTreatment Group (categorical: A, B, C, Control)\nAge (quantitative, continuous: 20-80 years)\nDisease Severity (ordinal: Mild, Moderate, Severe)\nTreatment Outcome (quantitative, continuous: 0-100 scale)\nTime to Response (quantitative, continuous: days)\n\nTask: Design visualizations for these questions, specifying which channels you’d use:\n\nQuestion: How does treatment outcome vary by treatment group?\n\nPrimary channel for outcome: _______\nChannel for treatment group: _______\nJustification: _______\n\nQuestion: Is there a relationship between age and treatment outcome?\n\nChannel for age: _______\nChannel for outcome: _______\nOptional third variable (disease severity): _______\nJustification: _______\n\nQuestion: How do the four treatment groups compare across disease severity levels?\n\nChannel for treatment group: _______\nChannel for severity: _______\nChannel for outcome: _______\nPlot type: _______\n\n\nDeliverable: Sketch rough layouts and write 2-3 sentences justifying each channel choice based on the Cleveland-McGill hierarchy.\n\n\n\nExercise 1.2.2: Channel Effectiveness Audit\nObjective: Evaluate channel usage in existing figures\nInstructions:\n\nFind 3 published figures from your field (preferably recent high-impact papers)\nFor each figure, document:\n\nWhat channels are used? (position, length, color, size, shape, etc.)\nWhat type of data is each channel encoding? (quantitative, ordinal, categorical)\nIs this an effective match based on the hierarchy?\n\nIdentify at least one figure where:\n\nA strong channel is wasted on less important data\nA weak channel is used for critical quantitative data\nChannel choice could be improved\n\nRedesign: Sketch how you would reassign channels for better effectiveness\n\nExample Analysis:\nFigure: Scatter plot of gene expression\n\nCurrent encoding:\n- X-axis (position): Gene ID number (nominal) ❌\n- Y-axis (position): Expression level (quantitative) ✓\n- Color (hue): Experimental condition (categorical) ✓\n\nProblem: X-axis position (strongest channel) wasted on arbitrary gene IDs\n\nImproved encoding:\n- X-axis (position): Time point",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 1: Foundations of Visual Perception</span>"
    ]
  },
  {
    "objectID": "Chapter 1.html#gestalt-principles-in-figure-design-expanded",
    "href": "Chapter 1.html#gestalt-principles-in-figure-design-expanded",
    "title": "Chapter 1: Foundations of Visual Perception",
    "section": "1.3 Gestalt Principles in Figure Design (Expanded)",
    "text": "1.3 Gestalt Principles in Figure Design (Expanded)\n\nThe Law of Prägnanz (Simplicity)\nBeyond the basic Gestalt principles introduced in 1.1, the overarching Law of Prägnanz states that people perceive and interpret ambiguous or complex images in the simplest form possible. Our brains seek to impose order and structure on visual information.\nImplication for Scientific Figures: - Viewers will try to find patterns even in random data - Clear, simple structures are processed faster and remembered better - Unnecessary complexity causes cognitive strain\n\n\nAdvanced Gestalt Applications\n\nCommon Fate\nPrinciple: Elements moving in the same direction are perceived as a group.\nStatic Figure Applications:\nLine graphs with multiple time series:\n✓ Lines following similar trajectories naturally group together\n✓ Diverging lines signal important differences\n✓ Use this to your advantage: arrange panels so similar patterns are adjacent\n\nExample:\nPanel A: All upward trends (treatment responders)\nPanel B: All downward trends (treatment non-responders)\n→ Visual coherence within each panel strengthens message\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Demonstrate common fate grouping\ntime = np.linspace(0, 10, 50)\n\n# Group 1: Similar upward trajectories (common fate)\ngroup1 = [time * 0.8 + np.random.randn(50) * 0.5,\n          time * 0.9 + np.random.randn(50) * 0.5,\n          time * 0.85 + np.random.randn(50) * 0.5]\n\n# Group 2: Similar flat trajectories (common fate)\ngroup2 = [5 + np.random.randn(50) * 0.5,\n          5.5 + np.random.randn(50) * 0.5,\n          4.8 + np.random.randn(50) * 0.5]\n\nfig, ax = plt.subplots(figsize=(8, 5))\n\n# Plot group 1 in shades of red (responders)\nfor i, trajectory in enumerate(group1):\n    ax.plot(time, trajectory, color=plt.cm.Reds(0.5 + i*0.15),\n            linewidth=2, label=f'Responder {i+1}' if i &lt; 1 else '')\n\n# Plot group 2 in shades of blue (non-responders)\nfor i, trajectory in enumerate(group2):\n    ax.plot(time, trajectory, color=plt.cm.Blues(0.5 + i*0.15),\n            linewidth=2, label=f'Non-responder {i+1}' if i &lt; 1 else '')\n\nax.set_xlabel('Time (hours)', fontsize=12)\nax.set_ylabel('Biomarker Level', fontsize=12)\nax.set_title('Common Fate: Trajectories Naturally Group', fontsize=14, fontweight='bold')\nax.legend(loc='upper left', frameon=True)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\nplt.tight_layout()\nplt.savefig('common_fate_example.png', dpi=300, bbox_inches='tight')\n\n\nSymmetry and Balance\nPrinciple: Symmetric elements are perceived as belonging together and forming a coherent whole.\nApplications in Multi-Panel Figures:\n✓ Symmetric grid layouts feel organized and professional\n✓ Asymmetry draws attention (use deliberately for emphasis)\n\nExample layouts:\n\nSymmetric (balanced, harmonious):\n[Panel A] [Panel B]\n[Panel C] [Panel D]\n\nAsymmetric for emphasis (main result gets more space):\n[Panel A - large    ] [B]\n[Panel C - large    ] [D]\n→ Panels A & C visually dominate\nCode Example (R):\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Create sample plots\np1 &lt;- ggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  labs(title = \"Panel A: Main Result\") +\n  theme_classic()\n\np2 &lt;- ggplot(mtcars, aes(x = hp, y = mpg)) +\n  geom_point() +\n  labs(title = \"Panel B: Control\") +\n  theme_classic()\n\np3 &lt;- ggplot(mtcars, aes(x = disp, y = mpg)) +\n  geom_point() +\n  labs(title = \"Panel C: Supplementary\") +\n  theme_classic()\n\np4 &lt;- ggplot(mtcars, aes(x = qsec, y = mpg)) +\n  geom_point() +\n  labs(title = \"Panel D: Supplementary\") +\n  theme_classic()\n\n# Symmetric layout\nsymmetric &lt;- (p1 + p2) / (p3 + p4)\n\n# Asymmetric layout (emphasize A and C)\nasymmetric &lt;- (p1 + p2) / (p3 + p4) +\n  plot_layout(heights = c(2, 1))\n\nggsave(\"symmetric_layout.png\", symmetric, width = 8, height = 8, dpi = 300)\nggsave(\"asymmetric_layout.png\", asymmetric, width = 8, height = 8, dpi = 300)\n\n\nConnectedness\nPrinciple: Elements connected by lines or enclosed in shapes are perceived as more strongly grouped than mere proximity.\nApplications:\n✓ Use lines to connect related data points (time series)\n✓ Use boxes/frames to group related panels\n✓ Use arrows to show causal relationships\n\nExample:\nBefore/After comparison:\n[Before image] --arrow--&gt; [After image]\n→ Arrow creates stronger association than just placement",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 1: Foundations of Visual Perception</span>"
    ]
  },
  {
    "objectID": "Chapter 1.html#visual-hierarchy-and-focus",
    "href": "Chapter 1.html#visual-hierarchy-and-focus",
    "title": "Chapter 1: Foundations of Visual Perception",
    "section": "1.4 Visual Hierarchy and Focus",
    "text": "1.4 Visual Hierarchy and Focus\n\nCreating Effective Visual Hierarchy\nVisual hierarchy is the arrangement of elements in order of importance, guiding the viewer’s attention through the figure in a deliberate sequence.\n\n\nThe Three-Level Hierarchy\nEvery effective figure has three levels:\n\nLevel 1: Primary Focus (The Message)\nThis should be seen first, within 1-2 seconds.\nTechniques to create primary focus: 1. High contrast - Make it darker, brighter, or more saturated than everything else 2. Larger size - Primary element should be visually dominant 3. Central position - Eye naturally goes to center first 4. Enclosure - Box, circle, or annotation around key element 5. Isolation - Surround with white space\nExample:\nScatter plot showing drug efficacy:\nPrimary focus: The significant outlier responders\n→ Make them larger, brighter color, add annotation arrow\n\nSecondary: All other data points\n→ Smaller, gray, lower opacity\n\nTertiary: Grid, axes, legend\n→ Lightest gray, thin lines\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Generate data\nx = np.random.randn(100)\ny = 2*x + np.random.randn(100)\n\n# Identify \"significant\" outliers\noutlier_idx = np.where((y &gt; 4) | (y &lt; -4))[0]\n\n# Create figure with visual hierarchy\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Level 3: Grid (most subtle)\nax.grid(True, alpha=0.2, linewidth=0.5, color='gray', zorder=0)\n\n# Level 2: Regular data points (secondary)\nregular_idx = np.setdiff1d(np.arange(len(x)), outlier_idx)\nax.scatter(x[regular_idx], y[regular_idx],\n           s=30, color='lightgray', alpha=0.6, zorder=2, label='Regular')\n\n# Level 1: Outliers (PRIMARY FOCUS)\nax.scatter(x[outlier_idx], y[outlier_idx],\n           s=200, color='#E63946', alpha=0.9, zorder=3,\n           edgecolors='darkred', linewidths=2, label='Outliers')\n\n# Annotate one key outlier\nif len(outlier_idx) &gt; 0:\n    key_outlier = outlier_idx[0]\n    ax.annotate('Key responder',\n                xy=(x[key_outlier], y[key_outlier]),\n                xytext=(x[key_outlier]-1, y[key_outlier]+1),\n                fontsize=11, fontweight='bold', color='#E63946',\n                arrowprops=dict(arrowstyle='-&gt;', color='#E63946', lw=2),\n                zorder=4)\n\n# Styling (de-emphasize axes - level 3)\nax.set_xlabel('Drug Concentration (μM)', fontsize=11)\nax.set_ylabel('Cell Response (AU)', fontsize=11)\nax.set_title('Visual Hierarchy: Outliers Stand Out', fontsize=14, fontweight='bold')\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_color('gray')\nax.spines['bottom'].set_color('gray')\nax.legend(loc='lower right', frameon=True, fontsize=10)\n\nplt.tight_layout()\nplt.savefig('visual_hierarchy.png', dpi=300, bbox_inches='tight')\n\n\n\nLevel 2: Supporting Context\nProvides necessary information but doesn’t compete with primary focus.\nElements at this level: - Main data that isn’t the key finding - Axis labels and titles - Legend (if not redundant) - Reference lines or regions\nTechniques: - Medium contrast - Standard sizing - Neutral colors (blacks, grays, muted tones)\n\n\nLevel 3: Infrastructure\nEssential for interpretation but should fade into background.\nElements at this level: - Grid lines - Minor tick marks - Axis lines - Background shading\nTechniques: - Low contrast (light grays) - Thin line weights - Semi-transparency\n\n\n\nContrast as the Primary Tool\nTypes of contrast for creating hierarchy:\n1. Value Contrast (Light vs. Dark)\n✓ Dark data on light background (most common)\n✓ Light data on dark background (for presentations/posters)\n✗ Medium gray data on medium gray background (no contrast)\n2. Saturation Contrast\n✓ Saturated color for key data, desaturated for context\nExample: Bright red key points, pale pink supporting data\n3. Size Contrast\n✓ Larger primary elements, smaller supporting elements\nRule of thumb: 2:1 or 3:1 size ratio minimum\n4. Weight Contrast\n✓ Bold/thick for primary, light/thin for secondary\nApplies to: lines, fonts, borders\n\n\nCommon Hierarchy Mistakes\n\nMistake 1: Everything is Emphasized (Nothing Stands Out)\nBad Example:\n✗ All data points large and bright\n✗ Bold axis labels\n✗ Thick grid lines\n✗ Multiple colors all saturated\n→ Result: Visual chaos, no clear message\nFix:\n✓ Choose ONE element as primary focus\n✓ Make everything else subordinate\n✓ Ask: \"If viewer sees only one thing, what should it be?\"\n\n\nMistake 2: Wrong Element is Emphasized\nBad Example:\n✗ Huge, bold legend in bright colors\n✗ Decorative border or logo prominently featured\n✗ Actual data is small and gray\n→ Result: Reader focuses on metadata, not results\nFix:\n✓ Data ink &gt;&gt; non-data ink (Tufte's principle)\n✓ Legend should be smallest readable size\n✓ Branding/logos should be minimal or absent\n\n\nMistake 3: Competing Focal Points\nBad Example:\n✗ Three different elements all trying to be #1:\n  - Large red title\n  - Bright blue highlighted region\n  - Orange outlier points\n→ Result: Eye doesn't know where to go first\nFix:\n✓ Clear priority: One primary (e.g., outliers)\n✓ Others as secondary (title standard weight, region subtle shading)\n✓ Use color consistently, not for multiple purposes\n\n\n\n\nExercise 1.4.1: Visual Hierarchy Redesign\nObjective: Transform a flat figure into one with clear visual hierarchy\nMaterials: - Take a figure you’ve created (or find one online) where everything has similar visual weight\nTask:\n\nAudit current state:\n\nList all visual elements in the figure\nRate each on “attention-grabbing” scale (1-10)\nIdentify if multiple elements score 8-10 (competing focus problem)\n\nDefine hierarchy:\n\nWhat is THE main message? (This becomes Level 1)\nWhat supports understanding? (Level 2)\nWhat is infrastructure? (Level 3)\n\nRedesign with tools:\n\nFor Level 1: Increase size by 2x, use high-contrast color, add annotation\nFor Level 2: Use medium gray or neutral colors, standard sizes\nFor Level 3: Reduce to light gray (alpha=0.2-0.3), thin lines\n\nTest:\n\nShow both versions to a colleague for 3 seconds each\nAsk: “What did you notice first?”\nDid the redesign direct attention correctly?\n\n\nExample Transformation:\nBefore: - All scatter points same size (50 pixels) - All points same color (blue) - Grid lines same thickness as data trendline - Title and axis labels same font weight\nAfter: - Key points: 150 pixels, red - Other points: 30 pixels, light gray - Grid lines: alpha=0.2, thin - Trendline: Bold, black - Title: Bold, axis labels: regular weight\n\n\n\n1.5 Theme Base Size and Font Scaling\nPrinciple: Set appropriate base font sizes that account for potential figure reduction.\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Font size calculation for figure reduction\n\n\"\"\"\nFONT SIZE PLANNING:\n\nJournals often reduce figures to fit column width:\n- 50% reduction common (7\" → 3.5\")\n- Font sizes reduce proportionally\n\nMinimum readable size: 6-7 points after reduction\n\nCalculation:\nIf figure reduced 50%, you need DOUBLE the font size:\n- Want 8pt final → Use 16pt in original\n- Want 10pt final → Use 20pt in original\n\nSafe starting sizes (for 50% reduction):\n- Title: 24-28pt → becomes 12-14pt ✓\n- Axis labels: 20-22pt → becomes 10-11pt ✓\n- Tick labels: 16-18pt → becomes 8-9pt ✓\n- Legend: 16-18pt → becomes 8-9pt ✓\n\"\"\"\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n# Panel A: TOO SMALL - Will be unreadable after reduction\nax1 = axes[0, 0]\nx = np.linspace(0, 10, 50)\ny = 2*x + np.random.randn(50)*2\n\nax1.scatter(x, y, s=30, color='#3498DB', alpha=0.7)\nax1.set_xlabel('Variable X (units)', fontsize=8)  # TOO SMALL\nax1.set_ylabel('Variable Y (units)', fontsize=8)  # TOO SMALL\nax1.set_title('Too Small Fonts', fontsize=10)  # TOO SMALL\nax1.tick_params(labelsize=7)  # TOO SMALL\nax1.grid(alpha=0.3)\n\nax1.text(0.5, 1.15, '❌ BAD: After 50% reduction\\nTitle→5pt, Labels→4pt (UNREADABLE)',\n        transform=ax1.transAxes, ha='center', fontsize=10,\n        color='red', fontweight='bold',\n        bbox=dict(boxstyle='round', facecolor='#FFCCCC', alpha=0.8))\n\n# Panel B: CORRECT - Accounts for reduction\nax2 = axes[0, 1]\nax2.scatter(x, y, s=50, color='#27AE60', alpha=0.7, edgecolors='black', linewidths=0.5)\nax2.set_xlabel('Variable X (units)', fontsize=14, fontweight='bold')  # GOOD\nax2.set_ylabel('Variable Y (units)', fontsize=14, fontweight='bold')  # GOOD\nax2.set_title('Correct Font Sizes', fontsize=16, fontweight='bold')  # GOOD\nax2.tick_params(labelsize=12)  # GOOD\nax2.grid(alpha=0.3)\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\n\nax2.text(0.5, 1.15, '✓ GOOD: After 50% reduction\\nTitle→8pt, Labels→7pt (READABLE)',\n        transform=ax2.transAxes, ha='center', fontsize=10,\n        color='green', fontweight='bold',\n        bbox=dict(boxstyle='round', facecolor='#CCFFCC', alpha=0.8))\n\n# Panel C: Theme base_size comparison\nax3 = axes[1, 0]\n\n# Matplotlib rcParams approach\nplt.rcParams.update({\n    'font.size': 18,  # Base size accounting for reduction\n    'axes.labelsize': 20,\n    'axes.titlesize': 22,\n    'xtick.labelsize': 16,\n    'ytick.labelsize': 16,\n    'legend.fontsize': 16\n})\n\nax3.scatter(x, y, s=50, color='#3498DB', alpha=0.7)\nax3.set_xlabel('Variable X (units)', fontweight='bold')\nax3.set_ylabel('Variable Y (units)', fontweight='bold')\nax3.set_title('Using rcParams Base Size', fontweight='bold')\nax3.grid(alpha=0.3)\n\ncode_example = \"\"\"\n# Set once at script start:\nplt.rcParams['font.size'] = 18\nplt.rcParams['axes.labelsize'] = 20\nplt.rcParams['axes.titlesize'] = 22\n\n# All subsequent plots inherit these sizes\n\"\"\"\nax3.text(0.5, -0.25, code_example, transform=ax3.transAxes,\n        ha='center', fontsize=9, family='monospace',\n        bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))\n\n# Panel D: Test print guide\nax4 = axes[1, 1]\nax4.axis('off')\n\ntest_guide = \"\"\"\nFONT SIZE TEST PROCEDURE:\n\n1. Create figure at FINAL SIZE\n   fig, ax = plt.subplots(figsize=(3.5, 2.5))\n   # Not (7, 5) if it will be reduced to (3.5, 2.5)!\n\n2. Set fonts for FINAL SIZE\n   ax.set_xlabel('Label', fontsize=11)\n   # Not 22 if figure already at final size\n\n3. Save and PRINT at 100% scale\n   plt.savefig('test.pdf', dpi=300)\n   # Print without \"fit to page\"\n\n4. Check readability:\n   • Can you read smallest text from 1 foot away?\n   • Are subscripts/superscripts clear?\n   • Is legend distinguishable?\n\n5. If NO to any → Increase font sizes\n\nALTERNATIVE: Scale test\n• Create at large size (7×5)\n• Print and physically reduce by 50%\n• Check readability\n\"\"\"\n\nax4.text(0.05, 0.95, test_guide, transform=ax4.transAxes,\n        verticalalignment='top', fontsize=10, family='monospace',\n        bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n\nax4.set_title('Font Size Testing Guide',\n              fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('font_size_reduction_planning.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\n\n# Reset rcParams\nplt.rcParams.update(plt.rcParamsDefault)\nR equivalent:\nlibrary(ggplot2)\n\n# Base size in ggplot2 theme\n# Will scale all text proportionally\n\n# TOO SMALL (will be unreadable after reduction)\np_bad &lt;- ggplot(data, aes(x, y)) +\n  geom_point(size = 2, color = '#3498DB', alpha = 0.7) +\n  labs(x = 'Variable X (units)',\n       y = 'Variable Y (units)',\n       title = 'Too Small Fonts') +\n  theme_classic(base_size = 8) +  # TOO SMALL!\n  theme(plot.title = element_text(face = 'bold'))\n\n# GOOD (accounts for 50% reduction)\np_good &lt;- ggplot(data, aes(x, y)) +\n  geom_point(size = 3, color = '#27AE60', alpha = 0.7) +\n  labs(x = 'Variable X (units)',\n       y = 'Variable Y (units)',\n       title = 'Correct Font Sizes') +\n  theme_classic(base_size = 16) +  # GOOD!\n  theme(\n    plot.title = element_text(face = 'bold', size = 20),\n    axis.title = element_text(face = 'bold', size = 18),\n    axis.text = element_text(size = 14)\n  )\n\n# Save at final intended size\nggsave('figure_correct_size.png', p_good,\n       width = 3.5, height = 2.5,  # Final size, not pre-reduction\n       dpi = 300)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 1: Foundations of Visual Perception</span>"
    ]
  },
  {
    "objectID": "Chapter 1.html#common-perceptual-traps-and-how-to-avoid-them",
    "href": "Chapter 1.html#common-perceptual-traps-and-how-to-avoid-them",
    "title": "Chapter 1: Foundations of Visual Perception",
    "section": "1.6 Common Perceptual Traps and How to Avoid Them",
    "text": "1.6 Common Perceptual Traps and How to Avoid Them\n\nTrap 1: The Truncated Axis\nThe Problem: When y-axis doesn’t start at zero for bar charts, small differences appear exaggerated.\nExample of Misuse:\nSales data:\nCompetitor A: 98 units\nOur product: 100 units\n\n✗ BAD: Y-axis from 95-100\n→ Bar for our product appears 2.5x taller (visual difference 5 units out of 5)\n→ Actual difference: 2% (100 vs 98)\nWhen It’s Acceptable:\n✓ Line graphs (emphasizing trend over absolute values)\n✓ Scatter plots (focusing on relationship)\n✓ When differences ARE meaningful relative to natural variation\n\nExample: Temperature anomalies\n- Baseline: 15.0°C\n- Year 1: 15.1°C\n- Year 2: 15.3°C\n✓ OK to zoom to 14.8-15.5°C range\n→ These small changes are scientifically significant\nCode Example - Demonstrating the Effect:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ncategories = ['Competitor A', 'Our Product']\nvalues = [98, 100]\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 4))\n\n# MISLEADING: Truncated axis for bar chart\naxes[0].bar(categories, values, color=['gray', 'steelblue'])\naxes[0].set_ylim(95, 101)\naxes[0].set_ylabel('Sales (units)')\naxes[0].set_title('MISLEADING: Truncated Axis\\n(Appears 5x difference)',\n                   fontsize=11, color='red')\naxes[0].axhline(0, color='black', linewidth=0.8)\n\n# HONEST: Full axis from zero\naxes[1].bar(categories, values, color=['gray', 'steelblue'])\naxes[1].set_ylim(0, 110)\naxes[1].set_ylabel('Sales (units)')\naxes[1].set_title('HONEST: Full Axis\\n(Shows 2% difference)',\n                   fontsize=11, color='green')\n\nplt.tight_layout()\nplt.savefig('truncated_axis_trap.png', dpi=300, bbox_inches='tight')\nSolution:\nFor bar charts:\n✓ Always start at zero (or explicitly show break if necessary)\n✓ Add context: \"Values differ by 2% (98 vs 100)\"\n\nFor line graphs:\n✓ Truncation is OK but add reference line at zero\n✓ Clearly label axis range\n✓ Consider showing full range in inset panel\n\n\nTrap 2: The Dual Axis Deception\nThe Problem: Dual y-axes allow arbitrary scaling that can manufacture correlations or hide them.\nExample of Misuse:\n✗ Graph showing \"Ice cream sales\" and \"Drowning deaths\" over months\n→ Both increase in summer\n→ Dual axes scaled to make lines overlap perfectly\n→ Implies causal relationship (which doesn't exist)\nWhy It’s Problematic:\n1. No inherent relationship between the two scales\n2. Can be manipulated to show any pattern desired\n3. Viewer cannot judge relative magnitudes\n4. Confuses correlation with causation\nBetter Alternatives:\n✓ Option 1: Two separate plots stacked vertically\n  → Allows visual comparison without misleading single axis\n\n✓ Option 2: Normalize both variables (0-100% scale or z-scores)\n  → Same scale, honest comparison\n\n✓ Option 3: Scatter plot (X = variable 1, Y = variable 2)\n  → Shows relationship directly\n\n✓ Option 4: If truly related, use secondary axis BUT:\n  - Use same scale factor (e.g., both per capita)\n  - Make relationship explicit (\"°F\" vs \"°C\" - mathematically linked)\nCode Example (R):\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Sample data\nmonths &lt;- 1:12\nice_cream &lt;- c(20, 25, 40, 55, 70, 85, 90, 85, 65, 45, 30, 22)\ndrownings &lt;- c(2, 3, 5, 8, 12, 15, 16, 14, 10, 6, 4, 2)\n\ndata &lt;- data.frame(month = months, ice_cream = ice_cream, drownings = drownings)\n\n# BAD: Dual axis (manipulable)\np_bad &lt;- ggplot(data, aes(x = month)) +\n  geom_line(aes(y = ice_cream), color = \"orange\", size = 1.5) +\n  geom_line(aes(y = drownings * 6), color = \"blue\", size = 1.5) +  # Scaled to overlap\n  scale_y_continuous(\n    name = \"Ice Cream Sales\",\n    sec.axis = sec_axis(~./6, name = \"Drownings\")\n  ) +\n  labs(title = \"MISLEADING: Dual Axis (Scales Manipulated)\") +\n  theme_classic()\n\n# BETTER: Separate panels\np1 &lt;- ggplot(data, aes(x = month, y = ice_cream)) +\n  geom_line(color = \"orange\", size = 1.5) +\n  labs(y = \"Ice Cream Sales\", title = \"Ice Cream Sales\") +\n  theme_classic()\n\np2 &lt;- ggplot(data, aes(x = month, y = drownings)) +\n  geom_line(color = \"blue\", size = 1.5) +\n  labs(y = \"Drownings\", x = \"Month\", title = \"Drowning Deaths\") +\n  theme_classic()\n\np_good &lt;- p1 / p2 + plot_annotation(title = \"BETTER: Separate Panels (Honest Comparison)\")\n\nggsave(\"dual_axis_bad.png\", p_bad, width = 7, height = 4, dpi = 300)\nggsave(\"dual_axis_good.png\", p_good, width = 7, height = 6, dpi = 300)\n\n\n\nTrap 3: Cherry-Picked Axis Ranges\nThe Problem:\nSelectively choosing axis ranges to emphasize or hide patterns.\nExample:\nClinical trial results:\n\nFull timeline (0-24 months):\n→ Drug effect appears temporary, returns to baseline\n\nCropped timeline (0-6 months):\n→ Drug appears highly effective\n→ Hides the fact that effect disappears\n\n✗ Publishing only the 6-month view is misleading\nSolution:\n✓ Show complete temporal or spatial range relevant to the study\n✓ If cropping for focus, include inset with full range\n✓ State explicit rationale for range choice\n✓ Provide supplementary figures with full data\n\n\nTrap 4: Logarithmic Scale Without Clear Indication\nThe Problem: Log scales dramatically change visual perception but are easy to miss.\nExample:\nLinear scale:\n1, 2, 3, 4, 5, 10, 100, 1000\n→ Visually: huge jump to 100\n\nLog scale:\n10⁰, 10¹, 10², 10³\n→ Visually: even spacing\n→ Can hide massive actual differences\nWhen Logarithmic Scales are Appropriate:\n✓ Data spanning multiple orders of magnitude\n✓ Exponential growth/decay processes\n✓ Multiplicative effects (fold-changes)\n✓ When relative changes matter more than absolute\n\nExamples:\n- Gene expression (ranges from 0.01 to 10,000)\n- Earthquake magnitudes (Richter scale)\n- Sound intensity (decibels)\n- Drug concentrations (dose-response curves)\nHow to Use Responsibly:\n✓ Label axis clearly: \"Log₁₀ Concentration\"\n✓ Show actual values on tick labels (1, 10, 100) not (0, 1, 2)\n✓ Mention in caption: \"Note logarithmic scale\"\n✓ Consider showing both linear and log versions\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Exponential data\nx = np.linspace(0, 10, 50)\ny = np.exp(x/2)\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Linear scale\naxes[0].plot(x, y, 'o-', color='steelblue', linewidth=2, markersize=4)\naxes[0].set_xlabel('Time')\naxes[0].set_ylabel('Cell Count')\naxes[0].set_title('LINEAR Scale\\n(Emphasizes recent growth)', fontsize=12)\naxes[0].grid(alpha=0.3)\n\n# Log scale\naxes[1].plot(x, y, 'o-', color='coral', linewidth=2, markersize=4)\naxes[1].set_yscale('log')\naxes[1].set_xlabel('Time')\naxes[1].set_ylabel('Cell Count (log scale)', fontweight='bold')\naxes[1].set_title('LOGARITHMIC Scale\\n(Shows exponential trend clearly)', fontsize=12)\naxes[1].grid(alpha=0.3, which='both')\n\n# Highlight log scale usage\naxes[1].text(0.5, 0.95, 'NOTE: Log scale', transform=axes[1].transAxes,\n             fontsize=11, ha='center', va='top',\n             bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n\nplt.tight_layout()\nplt.savefig('log_scale_comparison.png', dpi=300, bbox_inches='tight')\n\n\nTrap 5: The 3D Disaster\nThe Problem: 3D charts for 2D data introduce perspective distortion and occlusion without adding information.\nCommon Offenders: - 3D pie charts - 3D bar charts - 3D scatter plots (when Z-axis is unused)\nWhy They Fail:\n1. Perspective makes closer elements appear larger\n2. Back elements occluded by front elements\n3. Difficult to read exact values\n4. Chartjunk (unnecessary visual complexity)\n5. \"Cool factor\" often motivates use, not data needs\nExample:\n✗ 3D pie chart:\n→ Slice in foreground appears larger than identical slice in background\n→ Pure perceptual distortion\n\n✓ 2D pie chart (or better, bar chart):\n→ Accurate representation\n→ Easy comparison\nWhen 3D is Justified:\n✓ Genuine spatial data (protein structures, geographic terrain)\n✓ Physical specimens (medical imaging)\n✓ Three independent quantitative variables\n\nEven then, consider:\n- Providing multiple 2D views (orthogonal projections)\n- Interactive 3D (can rotate) for digital supplements\n- Color/size encoding on 2D projection as alternative\n\n\n\nExercise 1.6.1: Perceptual Trap Detection\nObjective: Develop critical eye for misleading visualizations\nMaterials: News articles, advertisements, or scientific papers with quantitative graphics\nTask:\n\nFind 5 figures from various sources (news media, research papers, company reports)\nFor each, check for these traps:\n\nTruncated axis (bar chart not starting at zero)\nDual axes (with manipulated scaling)\nCherry-picked range (timeline suspiciously cropped)\nUnlabeled log scale\nUnnecessary 3D\nMisleading aspect ratio (tall/skinny vs. wide/short changes perception of slope)\n\nAnalyze intent:\n\nIs this an honest mistake or deliberate distortion?\nWhat is the figure trying to emphasize?\nHow would fixing the issue change the message?\n\nRedesign one:\n\nChoose the most misleading figure\nCreate an honest version\nWrite 2-3 sentences on how perception changes\n\n\nExample Analysis:\nFigure: Bar chart from Company X press release\nTrap detected: Y-axis starts at 95%, goes to 100%\nEffect: 96% → 98% improvement appears massive (fills whole chart)\nHonest version: Y-axis 0-100% shows 2 percentage point change (barely visible)\nConclusion: Likely deliberate to exaggerate modest improvement",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 1: Foundations of Visual Perception</span>"
    ]
  },
  {
    "objectID": "Chapter 1.html#chapter-1-summary",
    "href": "Chapter 1.html#chapter-1-summary",
    "title": "Chapter 1: Foundations of Visual Perception",
    "section": "Chapter 1 Summary",
    "text": "Chapter 1 Summary\n\nKey Principles from Visual Perception Science\n\nPre-attentive processing guides immediate attention\n\nUse color, size, position strategically\nKey findings should “pop out” without effort\n\nCleveland-McGill hierarchy informs encoding choices\n\nPosition &gt; Length &gt; Angle &gt; Area &gt; Color hue\nMatch strongest channels to most important data\n\nGestalt principles create coherent organization\n\nProximity, similarity, continuity, closure\nWork with brain’s natural grouping tendencies\n\nVisual hierarchy directs viewer’s eye\n\nThree levels: Primary focus, supporting context, infrastructure\nUse contrast (value, saturation, size, weight) to differentiate\n\nWorking memory limits constrain complexity\n\n7±2 items maximum simultaneously\nSimplify, chunk, or use small multiples\n\nPerceptual biases require vigilance\n\nWe underestimate area differences\nWe perceive logarithmically\nDual axes and truncated ranges can mislead\n\n\n\n\nPractical Application Checklist\nBefore finalizing any figure, ask:\n\nCan a naive viewer identify the main message in 3 seconds?\nAre the strongest visual channels used for the most important data?\nDoes the layout group related elements (Gestalt proximity/similarity)?\nIs there a clear visual hierarchy (one primary focus)?\nAre comparisons easy (common scales, aligned axes)?\nIs the figure free from perceptual traps (truncation, dual axes, unnecessary 3D)?\nWould this work in grayscale (redundant encoding for accessibility)?\nDoes it require less than 7 simultaneous comparisons?\n\n\n\nTransition to Chapter 2\nNow that we understand how humans perceive visual information, we can make informed decisions about specific design elements.\nChapter 2: The Language of Color will build on these perceptual foundations to explore: - Color theory and color spaces - Choosing palettes for different data types - Accessibility and color-blind friendly design - Avoiding common color mistakes\nYou now have the cognitive science framework; next we apply it to one of the most powerful (and most misused) visual channels: color.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 1: Foundations of Visual Perception</span>"
    ]
  },
  {
    "objectID": "Chapter 2.html",
    "href": "Chapter 2.html",
    "title": "Chapter 2: The Language of Color",
    "section": "",
    "text": "2.1 Color Theory Foundations",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2: The Language of Color</span>"
    ]
  },
  {
    "objectID": "Chapter 2.html#color-theory-foundations",
    "href": "Chapter 2.html#color-theory-foundations",
    "title": "Chapter 2: The Language of Color",
    "section": "",
    "text": "Why Color Matters in Scientific Visualization\nColor is one of the most powerful visual channels available, yet it’s also one of the most misused. Unlike position or length, which have inherent quantitative meaning, color’s interpretation is:\n\nCulturally dependent (red means “danger” in some contexts, “celebration” in others)\nContext-dependent (same color looks different on different backgrounds)\nPerceptually non-uniform (equal numeric differences ≠ equal perceptual differences)\nBiologically variable (8% of males, 0.5% of females have color vision deficiency)\n\nThe Goal of This Chapter: Teach you to use color scientifically — as a precise encoding tool, not decoration.\n\n\n\nColor Models and Color Spaces\nTo use color effectively, we must understand how to specify and manipulate it. Different color models serve different purposes.\n\nRGB: The Additive Model (Screens)\nDefinition: Colors created by mixing Red, Green, and Blue light.\nRange: Each channel: 0-255 (8-bit) or 0.0-1.0 (normalized)\nExamples:\nPure Red:    RGB(255, 0, 0)   or RGB(1.0, 0.0, 0.0)\nPure Green:  RGB(0, 255, 0)   or RGB(0.0, 1.0, 0.0)\nPure Blue:   RGB(0, 0, 255)   or RGB(0.0, 0.0, 1.0)\nWhite:       RGB(255, 255, 255)\nBlack:       RGB(0, 0, 0)\nGray:        RGB(128, 128, 128)\nStrengths: - Native to digital displays - Direct hardware mapping - Simple for programming\nWeaknesses: - Not perceptually uniform: Equal RGB steps don’t produce equal visual differences - Hard to reason about: “What’s halfway between red and blue?” → Purple? Magenta? - Doesn’t separate color dimensions: Hue and brightness are entangled\nWhen to Use: - Specifying colors for screen display - Digital-only figures - When starting from hex codes (e.g., #FF5733)\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport numpy as np\n\n# Demonstrate RGB color space\nfig, ax = plt.subplots(figsize=(10, 4))\n\n# Create color samples\ncolors_rgb = [\n    (1.0, 0.0, 0.0, 'Red\\nRGB(255,0,0)'),\n    (0.0, 1.0, 0.0, 'Green\\nRGB(0,255,0)'),\n    (0.0, 0.0, 1.0, 'Blue\\nRGB(0,0,255)'),\n    (1.0, 1.0, 0.0, 'Yellow\\nRGB(255,255,0)'),\n    (1.0, 0.0, 1.0, 'Magenta\\nRGB(255,0,255)'),\n    (0.0, 1.0, 1.0, 'Cyan\\nRGB(0,255,255)'),\n]\n\nfor i, (r, g, b, label) in enumerate(colors_rgb):\n    rect = mpatches.Rectangle((i, 0), 1, 1, facecolor=(r, g, b))\n    ax.add_patch(rect)\n    ax.text(i+0.5, 0.5, label, ha='center', va='center',\n            fontsize=9, color='white' if (r+g+b) &lt; 1.5 else 'black')\n\nax.set_xlim(0, len(colors_rgb))\nax.set_ylim(0, 1)\nax.set_aspect('equal')\nax.axis('off')\nax.set_title('RGB Color Model: Additive Primaries', fontsize=14, fontweight='bold', pad=20)\n\nplt.tight_layout()\nplt.savefig('rgb_color_model.png', dpi=300, bbox_inches='tight')\nplt.close()\nCode Example (R):\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Create RGB color samples\nrgb_colors &lt;- data.frame(\n  x = 1:6,\n  color = c('red', 'green', 'blue', 'yellow', 'magenta', 'cyan'),\n  rgb_code = c('RGB(255,0,0)', 'RGB(0,255,0)', 'RGB(0,0,255)',\n               'RGB(255,255,0)', 'RGB(255,0,255)', 'RGB(0,255,255)'),\n  hex = c('#FF0000', '#00FF00', '#0000FF', '#FFFF00', '#FF00FF', '#00FFFF')\n)\n\nggplot(rgb_colors, aes(x = x, y = 1)) +\n  geom_tile(aes(fill = hex), color = 'black', size = 1, width = 0.9, height = 0.8) +\n  geom_text(aes(label = paste(color, rgb_code, sep='\\n')),\n            color = 'white', fontface = 'bold', size = 3.5) +\n  scale_fill_identity() +\n  labs(title = 'RGB Color Model: Additive Primaries') +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, size = 14, face = 'bold'))\n\nggsave('rgb_color_model.png', width = 10, height = 3, dpi = 300)\n\n\n\nCMYK: The Subtractive Model (Print)\nDefinition: Colors created by mixing Cyan, Magenta, Yellow, and Black (K) inks.\nRange: Each channel: 0-100%\nWhy It Exists: - Ink on paper absorbs light (subtractive) - Different from light emission (additive RGB) - Professional printing uses CMYK\nExample:\nPure Red:     CMYK(0%, 100%, 100%, 0%)   [No cyan, full magenta+yellow]\nPure Green:   CMYK(100%, 0%, 100%, 0%)   [Full cyan+yellow, no magenta]\nPure Blue:    CMYK(100%, 100%, 0%, 0%)   [Full cyan+magenta]\nBlack:        CMYK(0%, 0%, 0%, 100%)     [Pure black ink]\nWhen to Use: - Preparing figures for print publication - Journal requires CMYK submission - Proofing how colors will appear in print\nImportant Note: - RGB → CMYK conversion can shift colors (especially bright blues, greens) - Always preview in target color space - Some RGB colors have no CMYK equivalent (out of gamut)\nCode Example (Python):\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Note: Matplotlib doesn't natively support CMYK, but we can demonstrate conversion\n\n# Create RGB image\nfig, axes = plt.subplots(1, 2, figsize=(10, 4))\n\n# RGB version\nrgb_colors = ['red', 'green', 'blue', 'cyan', 'magenta', 'yellow']\nfor i, color in enumerate(rgb_colors):\n    rect = plt.Rectangle((i, 0), 1, 1, facecolor=color)\n    axes[0].add_patch(rect)\n\naxes[0].set_xlim(0, len(rgb_colors))\naxes[0].set_ylim(0, 1)\naxes[0].set_title('RGB (Screen Display)', fontsize=12, fontweight='bold')\naxes[0].axis('off')\n\n# Simulated \"CMYK\" appearance (with gamut limitations)\n# In reality, you'd convert via color management\ncmyk_note = \"\"\"CMYK (Print):\n- Some colors shift\n- Gamut smaller than RGB\n- Preview before submission\"\"\"\n\naxes[1].text(0.5, 0.5, cmyk_note, ha='center', va='center',\n             fontsize=11, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\naxes[1].set_xlim(0, 1)\naxes[1].set_ylim(0, 1)\naxes[1].axis('off')\naxes[1].set_title('CMYK Considerations', fontsize=12, fontweight='bold')\n\nplt.suptitle('RGB vs CMYK Color Spaces', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig('rgb_vs_cmyk.png', dpi=300, bbox_inches='tight')\nplt.close()\nCode Example (R):\nlibrary(ggplot2)\n\n# RGB to CMYK conversion approximation\nrgb_to_cmyk &lt;- function(r, g, b) {\n  # Normalize RGB to 0-1\n  r &lt;- r/255; g &lt;- g/255; b &lt;- b/255\n\n  # Calculate K (black)\n  k &lt;- 1 - max(c(r, g, b))\n\n  if (k == 1) {\n    return(c(C=0, M=0, Y=0, K=100))\n  }\n\n  # Calculate CMY\n  c &lt;- (1 - r - k) / (1 - k)\n  m &lt;- (1 - g - k) / (1 - k)\n  y &lt;- (1 - b - k) / (1 - k)\n\n  return(c(C=round(c*100), M=round(m*100), Y=round(y*100), K=round(k*100)))\n}\n\n# Example colors\ncolors_demo &lt;- data.frame(\n  name = c('Red', 'Green', 'Blue', 'Cyan', 'Magenta', 'Yellow'),\n  rgb = c('#FF0000', '#00FF00', '#0000FF', '#00FFFF', '#FF00FF', '#FFFF00'),\n  r = c(255, 0, 0, 0, 255, 255),\n  g = c(0, 255, 0, 255, 0, 255),\n  b = c(0, 0, 255, 255, 255, 0)\n)\n\n# Add CMYK values\ncolors_demo$cmyk &lt;- apply(colors_demo[, c('r', 'g', 'b')], 1,\n                          function(x) paste(rgb_to_cmyk(x[1], x[2], x[3]), collapse=','))\n\n# Plot\nggplot(colors_demo, aes(x = name, y = 1)) +\n  geom_tile(aes(fill = rgb), color = 'black', width = 0.8, height = 0.6) +\n  geom_text(aes(label = paste0('RGB: ', rgb, '\\nCMYK: ', cmyk)),\n            size = 2.5, color = 'white', fontface = 'bold') +\n  scale_fill_identity() +\n  labs(title = 'RGB to CMYK Conversion',\n       subtitle = 'Note: Actual print colors may differ') +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, size = 14, face = 'bold'),\n        plot.subtitle = element_text(hjust = 0.5, size = 10, face = 'italic'))\n\nggsave('rgb_to_cmyk_conversion.png', width = 10, height = 4, dpi = 300)\n\n\n\nHSV/HSB: Hue, Saturation, Value (Brightness)\nDefinition: A more intuitive color model based on human perception.\nComponents: - Hue (H): The “pure” color (0-360°) - 0° = Red, 120° = Green, 240° = Blue - Circular: 360° wraps back to red\n\nSaturation (S): Color intensity (0-100%)\n\n0% = Gray (no color)\n100% = Pure, vivid color\n\nValue/Brightness (V): Lightness (0-100%)\n\n0% = Black\n100% = Brightest version of that hue\n\n\nAdvantages: - Intuitive: “I want a light, desaturated blue” → easy to specify - Easy manipulation: Adjust brightness without changing hue - Good for color picking: Natural way humans think about color\nDisadvantages: - Still not perceptually uniform - Brightness perception varies with hue (yellow appears brighter than blue at same V)\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nfrom matplotlib.colors import hsv_to_rgb\nimport numpy as np\n\nfig, axes = plt.subplots(2, 1, figsize=(12, 6))\n\n# Demonstrate Hue variation (S=1, V=1)\nhues = np.linspace(0, 1, 12, endpoint=False)\nfor i, hue in enumerate(hues):\n    color = hsv_to_rgb([hue, 1.0, 1.0])\n    rect = mpatches.Rectangle((i, 0), 1, 1, facecolor=color)\n    axes[0].add_patch(rect)\n    axes[0].text(i+0.5, 0.5, f'{int(hue*360)}°', ha='center', va='center',\n                fontsize=9, color='white', fontweight='bold')\n\naxes[0].set_xlim(0, 12)\naxes[0].set_ylim(0, 1)\naxes[0].set_title('Hue Variation (Saturation=100%, Value=100%)',\n                  fontsize=12, fontweight='bold')\naxes[0].axis('off')\n\n# Demonstrate Saturation variation (H=0.6 [blue], V=1)\nsaturations = np.linspace(0, 1, 10)\nfor i, sat in enumerate(saturations):\n    color = hsv_to_rgb([0.6, sat, 1.0])\n    rect = mpatches.Rectangle((i, 0), 1, 1, facecolor=color)\n    axes[1].add_patch(rect)\n    axes[1].text(i+0.5, 0.5, f'{int(sat*100)}%', ha='center', va='center',\n                fontsize=9, color='black' if sat &lt; 0.5 else 'white', fontweight='bold')\n\naxes[1].set_xlim(0, 10)\naxes[1].set_ylim(0, 1)\naxes[1].set_title('Saturation Variation (Hue=216°, Value=100%)',\n                  fontsize=12, fontweight='bold')\naxes[1].axis('off')\n\nplt.suptitle('HSV Color Model', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig('hsv_color_model.png', dpi=300, bbox_inches='tight')\nplt.close()\nCode Example (R):\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Hue variation\nhue_demo &lt;- data.frame(\n  x = 1:12,\n  hue = seq(0, 330, by = 30),\n  saturation = 1,\n  value = 1\n)\n\nhue_demo$color &lt;- hsv(hue_demo$hue/360, hue_demo$saturation, hue_demo$value)\n\np1 &lt;- ggplot(hue_demo, aes(x = x, y = 1)) +\n  geom_tile(aes(fill = color), color = 'black', width = 0.9, height = 0.8) +\n  geom_text(aes(label = paste0(hue, '°')), color = 'white',\n            fontface = 'bold', size = 3.5) +\n  scale_fill_identity() +\n  labs(title = 'Hue Variation (Saturation=100%, Value=100%)') +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, size = 12, face = 'bold'))\n\n# Saturation variation\nsat_demo &lt;- data.frame(\n  x = 1:10,\n  hue = 0.6,  # Blue\n  saturation = seq(0, 1, length.out = 10),\n  value = 1\n)\n\nsat_demo$color &lt;- hsv(sat_demo$hue, sat_demo$saturation, sat_demo$value)\nsat_demo$label &lt;- paste0(round(sat_demo$saturation*100), '%')\n\np2 &lt;- ggplot(sat_demo, aes(x = x, y = 1)) +\n  geom_tile(aes(fill = color), color = 'black', width = 0.9, height = 0.8) +\n  geom_text(aes(label = label),\n            color = ifelse(sat_demo$saturation &lt; 0.5, 'black', 'white'),\n            fontface = 'bold', size = 3.5) +\n  scale_fill_identity() +\n  labs(title = 'Saturation Variation (Hue=216°, Value=100%)') +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, size = 12, face = 'bold'))\n\n# Combine plots\nlibrary(patchwork)\ncombined &lt;- p1 / p2 + plot_annotation(\n  title = 'HSV Color Model',\n  theme = theme(plot.title = element_text(hjust = 0.5, size = 14, face = 'bold'))\n)\n\nggsave('hsv_color_model.png', combined, width = 12, height = 6, dpi = 300)\n\n\n\nCIELAB (L*a*b*): Perceptually Uniform\nDefinition: A color space designed to be perceptually uniform — equal distances in the space correspond to equal perceived color differences.\nComponents: - L* (Lightness): 0 (black) to 100 (white) - a*: Green (-) to Red (+) axis - b*: Blue (-) to Yellow (+) axis\nWhy It Matters:\nProblem with RGB/HSV:\n- RGB(100, 0, 0) → RGB(110, 0, 0): small perceptual change\n- RGB(200, 0, 0) → RGB(210, 0, 0): even smaller perceptual change\n→ Not uniform!\n\nSolution with CIELAB:\n- Moving 10 units in any direction produces approximately equal perceptual change\n→ Uniform!\nApplications: - Designing perceptually uniform colormaps (e.g., viridis) - Measuring color similarity (Delta E metric) - Quality control in printing - Accessible color palette design\nWhen to Use: - Creating custom sequential colormaps - Ensuring smooth gradients - Comparing colors quantitatively - Accessibility testing\nCode Example (Python) - Perceptual Uniformity:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage import color\n\n# Generate gradients in RGB and LAB\nn_steps = 50\n\n# RGB gradient (red to blue)\nrgb_gradient = np.zeros((1, n_steps, 3))\nrgb_gradient[0, :, 0] = np.linspace(1, 0, n_steps)  # Red decreases\nrgb_gradient[0, :, 2] = np.linspace(0, 1, n_steps)  # Blue increases\n\n# Convert to LAB\nlab_gradient = color.rgb2lab(rgb_gradient[0])\n\n# Calculate perceptual differences\nrgb_diffs = np.diff(rgb_gradient[0], axis=0)\nrgb_distances = np.linalg.norm(rgb_diffs, axis=1)\n\nlab_diffs = np.diff(lab_gradient, axis=0)\nlab_distances = np.linalg.norm(lab_diffs, axis=1)\n\n# Plot\nfig, axes = plt.subplots(3, 1, figsize=(12, 8))\n\n# Show gradient\naxes[0].imshow(rgb_gradient, aspect='auto')\naxes[0].set_title('Red to Blue Gradient', fontsize=12, fontweight='bold')\naxes[0].axis('off')\n\n# RGB distances (non-uniform)\naxes[1].plot(rgb_distances, 'o-', color='steelblue', linewidth=2)\naxes[1].set_ylabel('Step Size (RGB)', fontsize=10)\naxes[1].set_title('RGB: Non-Uniform Perceptual Steps', fontsize=12, fontweight='bold')\naxes[1].grid(alpha=0.3)\naxes[1].axhline(rgb_distances.mean(), color='red', linestyle='--',\n                label=f'Mean={rgb_distances.mean():.3f}')\naxes[1].legend()\n\n# LAB distances (more uniform)\naxes[2].plot(lab_distances, 'o-', color='coral', linewidth=2)\naxes[2].set_xlabel('Gradient Step', fontsize=10)\naxes[2].set_ylabel('Step Size (LAB)', fontsize=10)\naxes[2].set_title('LAB: More Uniform Perceptual Steps', fontsize=12, fontweight='bold')\naxes[2].grid(alpha=0.3)\naxes[2].axhline(lab_distances.mean(), color='red', linestyle='--',\n                label=f'Mean={lab_distances.mean():.3f}')\naxes[2].legend()\n\nplt.tight_layout()\nplt.savefig('perceptual_uniformity.png', dpi=300, bbox_inches='tight')\nplt.close()\nCode Example (R):\nlibrary(ggplot2)\nlibrary(colorspace)\nlibrary(patchwork)\n\n# Create gradients\nn_steps &lt;- 50\n\n# RGB gradient (red to blue)\nred_vals &lt;- seq(1, 0, length.out = n_steps)\nblue_vals &lt;- seq(0, 1, length.out = n_steps)\nrgb_colors &lt;- rgb(red_vals, 0, blue_vals)\n\n# Convert to LAB\nrgb_mat &lt;- col2rgb(rgb_colors)/255\nlab_colors &lt;- t(apply(rgb_mat, 2, function(x) {\n  as(RGB(x[1], x[2], x[3]), \"LAB\")@coords\n}))\n\n# Calculate perceptual distances\nrgb_distances &lt;- sqrt(diff(red_vals)^2 + diff(blue_vals)^2)\nlab_distances &lt;- sqrt(rowSums(diff(lab_colors)^2))\n\n# Plot gradient\ngrad_data &lt;- data.frame(\n  x = 1:n_steps,\n  y = 1,\n  color = rgb_colors\n)\n\np1 &lt;- ggplot(grad_data, aes(x = x, y = y, fill = color)) +\n  geom_tile() +\n  scale_fill_identity() +\n  labs(title = 'Red to Blue Gradient') +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, face = 'bold'))\n\n# RGB distances\nrgb_df &lt;- data.frame(\n  step = 1:(n_steps-1),\n  distance = rgb_distances\n)\n\np2 &lt;- ggplot(rgb_df, aes(x = step, y = distance)) +\n  geom_line(color = 'steelblue', size = 1) +\n  geom_point(color = 'steelblue', size = 2) +\n  geom_hline(yintercept = mean(rgb_distances), color = 'red',\n             linetype = 'dashed', size = 1) +\n  annotate('text', x = n_steps/2, y = mean(rgb_distances)*1.1,\n           label = paste0('Mean = ', round(mean(rgb_distances), 3)),\n           color = 'red', fontface = 'bold') +\n  labs(title = 'RGB: Non-Uniform Perceptual Steps',\n       y = 'Step Size (RGB)') +\n  theme_classic() +\n  theme(plot.title = element_text(face = 'bold'))\n\n# LAB distances\nlab_df &lt;- data.frame(\n  step = 1:(n_steps-1),\n  distance = lab_distances\n)\n\np3 &lt;- ggplot(lab_df, aes(x = step, y = distance)) +\n  geom_line(color = 'coral', size = 1) +\n  geom_point(color = 'coral', size = 2) +\n  geom_hline(yintercept = mean(lab_distances), color = 'red',\n             linestyle = 'dashed', size = 1) +\n  annotate('text', x = n_steps/2, y = mean(lab_distances)*1.1,\n           label = paste0('Mean = ', round(mean(lab_distances), 1)),\n           color = 'red', fontface = 'bold') +\n  labs(title = 'LAB: More Uniform Perceptual Steps',\n       x = 'Gradient Step', y = 'Step Size (LAB)') +\n  theme_classic() +\n  theme(plot.title = element_text(face = 'bold'))\n\n# Combine\ncombined &lt;- p1 / p2 / p3 + plot_annotation(\n  title = 'Perceptual Uniformity: RGB vs CIELAB',\n  theme = theme(plot.title = element_text(hjust = 0.5, size = 14, face = 'bold'))\n)\n\nggsave('perceptual_uniformity.png', combined, width = 12, height = 10, dpi = 300)\n\n\n\n\nSummary: Which Color Space to Use?\n\n\n\nTask\nBest Color Space\nWhy\n\n\n\n\nDigital display\nRGB\nNative to screens\n\n\nPrint publication\nCMYK\nRequired by printers\n\n\nColor picking/adjustment\nHSV\nIntuitive manipulation\n\n\nDesigning gradients\nCIELAB\nPerceptually uniform\n\n\nAccessibility testing\nCIELAB\nQuantify perceptual differences\n\n\nGeneral programming\nRGB or Hex\nSimplest, most compatible\n\n\n\nBest Practice Workflow:\n1. Think in HSV (intuitive)\n2. Implement in RGB (compatible)\n3. Validate in CIELAB (uniform)\n4. Convert to CMYK if printing (required)\n\n\n\nExercise 2.1.1: Color Space Exploration\nObjective: Experience how different color spaces represent the same color\nTask:\n\nPick a color from a published figure you admire\nConvert it across spaces:\n\nUse a color picker to get RGB values\nConvert to HSV: https://www.rapidtables.com/convert/color/rgb-to-hsv.html\nConvert to CIELAB: https://colormine.org/convert/rgb-to-lab\nConvert to CMYK: https://www.rapidtables.com/convert/color/rgb-to-cmyk.html\n\nDocument:\n\nReflection:\n\nWhich representation is most intuitive to you?\nIf you wanted a “lighter version” of this color, which space makes that easiest?\nHow much does CMYK shift from RGB? (Compare visually)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2: The Language of Color</span>"
    ]
  },
  {
    "objectID": "Chapter 2.html#choosing-color-palettes",
    "href": "Chapter 2.html#choosing-color-palettes",
    "title": "Chapter 2: The Language of Color",
    "section": "2.2 Choosing Color Palettes",
    "text": "2.2 Choosing Color Palettes\nNow that we understand color spaces, let’s apply them to the most critical decision: choosing appropriate color palettes for different types of data.\n\nThe Three Palette Types\nEvery color palette falls into one of three categories, each suited to different data types:\n\n1. Sequential Palettes (Quantitative, Ordered Data)\nUse for: - Continuous numerical data - Ordered categories (mild → moderate → severe) - Any data with a natural progression\nCharacteristics: - Single hue varying in lightness/saturation - Clear directionality (low → high) - Perceptually ordered (darker = more)\nExamples:\nGood Sequential Palettes:\n✓ Light Blue → Dark Blue\n✓ White → Red\n✓ Light Gray → Black\n✓ Viridis (yellow → blue, perceptually uniform)\nBad Sequential Palettes:\n✗ Rainbow (red → orange → yellow → green → blue → purple)\n  → No inherent ordering\n  → Perceptual non-uniformity\n\n✗ Random hues (blue → pink → orange)\n  → Implies categorical data, not continuous\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate sample data (heatmap)\nnp.random.seed(42)\ndata = np.random.randn(10, 10).cumsum(axis=1)\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 8))\n\n# Good sequential palettes\npalettes = [\n    ('Blues', 'Good: Single Hue (Blue)'),\n    ('YlOrRd', 'Good: Yellow-Orange-Red'),\n    ('viridis', 'Good: Viridis (Perceptually Uniform)'),\n    ('jet', 'BAD: Rainbow (No Order)'),\n    ('Set3', 'BAD: Qualitative (Wrong Type)'),\n    ('RdYlGn', 'ACCEPTABLE: Diverging (If Zero is Meaningful)')\n]\n\nfor ax, (cmap, title) in zip(axes.flat, palettes):\n    im = ax.imshow(data, cmap=cmap, aspect='auto')\n    ax.set_title(title, fontsize=11, fontweight='bold',\n                color='green' if 'Good' in title else 'red')\n    ax.axis('off')\n    plt.colorbar(im, ax=ax, fraction=0.046)\n\nplt.suptitle('Sequential Palettes: Good vs Bad', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig('sequential_palettes.png', dpi=300, bbox_inches='tight')\nplt.close()\nCode Example (R):\nlibrary(ggplot2)\nlibrary(viridis)\nlibrary(RColorBrewer)\nlibrary(patchwork)\n\n# Generate sample data\nset.seed(42)\ndata_matrix &lt;- matrix(cumsum(rnorm(100)), nrow=10, ncol=10)\ndata_long &lt;- expand.grid(x=1:10, y=1:10)\ndata_long$value &lt;- as.vector(data_matrix)\n\n# Helper function to create heatmap\ncreate_heatmap &lt;- function(data, palette, title, quality) {\n  ggplot(data, aes(x=x, y=y, fill=value)) +\n    geom_tile() +\n    scale_fill_gradientn(colors=palette) +\n    labs(title=title) +\n    theme_void() +\n    theme(plot.title=element_text(hjust=0.5, face='bold', size=10,\n                                   color=ifelse(quality=='good', 'darkgreen', 'red')),\n          legend.position='bottom',\n          legend.key.width=unit(1, 'cm'),\n          legend.key.height=unit(0.3, 'cm'))\n}\n\n# Create plots\n\n# Good sequential palettes\np1 &lt;- create_heatmap(data_long, brewer.pal(9, 'Blues'),\n                     'Good: Single Hue (Blue)', 'good')\np2 &lt;- create_heatmap(data_long, brewer.pal(9, 'YlOrRd'),\n                     'Good: Yellow-Orange-Red', 'good')\np3 &lt;- create_heatmap(data_long, viridis(100),\n                     'Good: Viridis (Perceptually Uniform)', 'good')\n\n# Bad sequential palettes\np4 &lt;- create_heatmap(data_long, rainbow(100),\n                     'BAD: Rainbow (No Order)', 'bad')\np5 &lt;- create_heatmap(data_long, brewer.pal(8, 'Set3'),\n                     'BAD: Qualitative (Wrong Type)', 'bad')\np6 &lt;- create_heatmap(data_long, brewer.pal(11, 'RdYlGn'),\n                     'ACCEPTABLE: Diverging (If Zero Meaningful)', 'acceptable')\n\n# Combine\ncombined &lt;- (p1 | p2 | p3) / (p4 | p5 | p6) +\n  plot_annotation(\n    title = 'Sequential Palettes: Good vs Bad',\n    theme = theme(plot.title = element_text(hjust = 0.5, size = 14, face = 'bold'))\n  )\n\nggsave('sequential_palettes.png', combined, width = 15, height = 8, dpi = 300)\n\n\n\n2. Diverging Palettes (Data with Meaningful Midpoint)\nUse for: - Data with a critical central value (zero, neutral, baseline) - Deviations in two directions (positive/negative, above/below average) - Comparisons showing increase vs. decrease\nCharacteristics: - Two contrasting hues at extremes - Neutral color (white, gray, beige) at center - Symmetric intensity increasing toward both ends\nExamples:\nGood Diverging Palettes:\n✓ Blue ← White → Red (cold/hot, negative/positive)\n✓ Green ← Beige → Purple (gene downregulation/upregulation)\n✓ RdBu (Red-Blue, colorblind-safe)\nWhen NOT to Use:\n✗ Data without a meaningful center point\n  Example: Temperature in Kelvin (0K is absolute, not \"neutral\")\n\n✗ Data that's inherently one-directional\n  Example: Age (0-100, no negative ages)\nReal-World Example:\nGene expression fold-change:\n- Values: -5 to +5\n- Center: 0 (no change)\n- Negative: Downregulated (blue)\n- Positive: Upregulated (red)\n→ Perfect for diverging palette\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\n# Generate diverging data (centered at zero)\nnp.random.seed(42)\ndata_diverging = np.random.randn(10, 10) * 2  # Mean=0, symmetric\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\n# Good diverging palettes\npalettes_div = [\n    ('RdBu_r', 'Good: Red-Blue (Symmetric)'),\n    ('PiYG', 'Good: Pink-Green (Colorblind-Safe)'),\n    ('coolwarm', 'Good: Cool-Warm')\n]\n\nfor ax, (cmap, title) in zip(axes.flat, palettes_div):\n    # Set symmetric limits around zero\n    vmax = np.abs(data_diverging).max()\n    im = ax.imshow(data_diverging, cmap=cmap, aspect='auto',\n                   vmin=-vmax, vmax=vmax)  # Critical: symmetric limits\n    ax.set_title(title, fontsize=11, fontweight='bold')\n    ax.axis('off')\n\n    # Colorbar with zero highlighted\n    cbar = plt.colorbar(im, ax=ax, fraction=0.046)\n    cbar.ax.axhline(0, color='black', linewidth=2)  # Highlight zero\n\nplt.suptitle('Diverging Palettes: Critical Zero Point',\n             fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig('diverging_palettes.png', dpi=300, bbox_inches='tight')\nplt.close()\nCode Example (R):\nlibrary(ggplot2)\nlibrary(RColorBrewer)\nlibrary(patchwork)\n\n# Generate diverging data\nset.seed(42)\ndata_div &lt;- matrix(rnorm(100) * 2, nrow=10, ncol=10)\ndata_long_div &lt;- expand.grid(x=1:10, y=1:10)\ndata_long_div$value &lt;- as.vector(data_div)\n\n# Helper function for diverging heatmap\ncreate_div_heatmap &lt;- function(data, palette_name, title) {\n  # Get symmetric limits\n  max_abs &lt;- max(abs(data$value))\n\n  ggplot(data, aes(x=x, y=y, fill=value)) +\n    geom_tile() +\n    scale_fill_gradientn(colors=brewer.pal(11, palette_name),\n                         limits=c(-max_abs, max_abs)) +  # Symmetric limits\n    labs(title=title) +\n    theme_void() +\n    theme(plot.title=element_text(hjust=0.5, face='bold', size=10),\n          legend.position='bottom',\n          legend.key.width=unit(1.5, 'cm'),\n          legend.key.height=unit(0.3, 'cm')) +\n    # Highlight zero in legend\n    geom_hline(yintercept=0, color='black', size=1)\n}\n\n# Create plots\np1 &lt;- create_div_heatmap(data_long_div, 'RdBu', 'Good: Red-Blue (Symmetric)')\np2 &lt;- create_div_heatmap(data_long_div, 'PiYG', 'Good: Pink-Green (Colorblind-Safe)')\np3 &lt;- create_div_heatmap(data_long_div, 'BrBG', 'Good: Brown-Blue-Green')\n\ncombined &lt;- p1 | p2 | p3\ncombined &lt;- combined + plot_annotation(\n  title = 'Diverging Palettes: Critical Zero Point',\n  theme = theme(plot.title = element_text(hjust = 0.5, size = 14, face = 'bold'))\n)\n\nggsave('diverging_palettes.png', combined, width = 15, height = 5, dpi = 300)\n\n\n\n3. Qualitative Palettes (Categorical Data)\nUse for: - Unordered categories (species, treatments, locations) - Nominal data (no inherent ordering) - Group comparisons (control vs. experimental groups)\nCharacteristics: - Distinct hues (maximally different colors) - Similar lightness (no implied hierarchy) - Visually balanced (no one color dominates)\nRules:\n✓ Limit to 6-8 categories maximum\n  → Beyond this, colors become too similar\n\n✓ Use colorblind-safe combinations\n  → Avoid red-green only distinctions\n\n✓ Consider adding shape/line style redundancy\n  → Ensures accessibility\nGood Qualitative Palettes:\n✓ ColorBrewer 'Set2' (8 colors, colorblind-friendly)\n✓ ColorBrewer 'Dark2' (8 colors, good contrast)\n✓ Okabe-Ito palette (8 colors, designed for colorblindness)\n✓ Custom palettes from your field's conventions\nBad Qualitative Palettes:\n✗ Rainbow (implies ordering that doesn't exist)\n✗ Sequential palette (Blues) for categories (implies hierarchy)\n✗ Too many similar colors (light blue, medium blue, cyan, teal...)\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\n# Sample categorical data\nnp.random.seed(42)\ncategories = ['Group A', 'Group B', 'Group C', 'Group D', 'Group E']\nx = np.repeat(np.arange(50), len(categories))\ny = np.tile(np.arange(len(categories)), 50) + np.random.randn(len(categories)*50)*0.3\ncategory = np.tile(categories, 50)\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Good qualitative palette (Okabe-Ito, colorblind-safe)\nokabe_ito = ['#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2',\n             '#D55E00', '#CC79A7', '#000000']\n\naxes[0, 0].scatter(x, y, c=[okabe_ito[i%8] for i, _ in enumerate(category)],\n                   alpha=0.6, s=50)\naxes[0, 0].set_title('GOOD: Okabe-Ito Palette\\n(Colorblind-Safe, Distinct Hues)',\n                     fontsize=11, fontweight='bold', color='green')\naxes[0, 0].set_xlabel('X Variable')\naxes[0, 0].set_ylabel('Y Variable')\n\n# Good: ColorBrewer Set2\nset2_colors = sns.color_palette('Set2', len(categories))\nfor i, cat in enumerate(categories):\n    mask = np.array(category) == cat\n    axes[0, 1].scatter(x[mask], y[mask], color=set2_colors[i],\n                       label=cat, alpha=0.6, s=50)\naxes[0, 1].set_title('GOOD: ColorBrewer Set2\\n(Balanced, Distinct)',\n                     fontsize=11, fontweight='bold', color='green')\naxes[0, 1].legend(loc='upper right', frameon=True)\naxes[0, 1].set_xlabel('X Variable')\naxes[0, 1].set_ylabel('Y Variable')\n\n# Bad: Rainbow (implies false ordering)\nrainbow_colors = plt.cm.rainbow(np.linspace(0, 1, len(categories)))\nfor i, cat in enumerate(categories):\n    mask = np.array(category) == cat\n    axes[1, 0].scatter(x[mask], y[mask], color=rainbow_colors[i],\n                       label=cat, alpha=0.6, s=50)\naxes[1, 0].set_title('BAD: Rainbow\\n(Implies Ordering, Not Colorblind-Safe)',\n                     fontsize=11, fontweight='bold', color='red')\naxes[1, 0].legend(loc='upper right', frameon=True)\naxes[1, 0].set_xlabel('X Variable')\naxes[1, 0].set_ylabel('Y Variable')\n\n# Bad: Too similar colors (all blues)\nblues_colors = plt.cm.Blues(np.linspace(0.3, 0.9, len(categories)))\nfor i, cat in enumerate(categories):\n    mask = np.array(category) == cat\n    axes[1, 1].scatter(x[mask], y[mask], color=blues_colors[i],\n                       label=cat, alpha=0.6, s=50)\naxes[1, 1].set_title('BAD: Sequential for Categorical\\n(Similar Colors, Implies Hierarchy)',\n                     fontsize=11, fontweight='bold', color='red')\naxes[1, 1].legend(loc='upper right', frameon=True)\naxes[1, 1].set_xlabel('X Variable')\naxes[1, 1].set_ylabel('Y Variable')\n\nplt.suptitle('Qualitative Palettes: Good vs Bad', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig('qualitative_palettes.png', dpi=300, bbox_inches='tight')\nplt.close()\nCode Example (R):\nlibrary(ggplot2)\nlibrary(RColorBrewer)\nlibrary(patchwork)\n\n# Sample categorical data\nset.seed(42)\nn_per_group &lt;- 50\ncategories &lt;- c('Group A', 'Group B', 'Group C', 'Group D', 'Group E')\n\ndata_cat &lt;- data.frame(\n  x = rep(1:n_per_group, each=length(categories)),\n  y = rep(1:length(categories), n_per_group) + rnorm(n_per_group*length(categories), 0, 0.3),\n  category = rep(categories, n_per_group)\n)\n\n# Okabe-Ito colorblind-safe palette\nokabe_ito &lt;- c('#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2',\n               '#D55E00', '#CC79A7', '#000000')\n\n# Good: Okabe-Ito\np1 &lt;- ggplot(data_cat, aes(x=x, y=y, color=category)) +\n  geom_point(alpha=0.6, size=2) +\n  scale_color_manual(values=okabe_ito[1:length(categories)]) +\n  labs(title='GOOD: Okabe-Ito Palette\\n(Colorblind-Safe, Distinct Hues)',\n       x='X Variable', y='Y Variable') +\n  theme_classic() +\n  theme(plot.title=element_text(hjust=0.5, face='bold', color='darkgreen', size=10),\n        legend.position='right')\n\n# Good: ColorBrewer Set2\np2 &lt;- ggplot(data_cat, aes(x=x, y=y, color=category)) +\n  geom_point(alpha=0.6, size=2) +\n  scale_color_brewer(palette='Set2') +\n  labs(title='GOOD: ColorBrewer Set2\\n(Balanced, Distinct)',\n       x='X Variable', y='Y Variable') +\n  theme_classic() +\n  theme(plot.title=element_text(hjust=0.5, face='bold', color='darkgreen', size=10),\n        legend.position='right')\n\n# Bad: Rainbow\np3 &lt;- ggplot(data_cat, aes(x=x, y=y, color=category)) +\n  geom_point(alpha=0.6, size=2) +\n  scale_color_manual(values=rainbow(length(categories))) +\n  labs(title='BAD: Rainbow\\n(Implies Ordering, Not Colorblind-Safe)',\n       x='X Variable', y='Y Variable') +\n  theme_classic() +\n  theme(plot.title=element_text(hjust=0.5, face='bold', color='red', size=10),\n        legend.position='right')\n\n# Bad: Sequential (Blues) for categorical\np4 &lt;- ggplot(data_cat, aes(x=x, y=y, color=category)) +\n  geom_point(alpha=0.6, size=2) +\n  scale_color_brewer(palette='Blues') +\n  labs(title='BAD: Sequential for Categorical\\n(Similar Colors, Implies Hierarchy)',\n       x='X Variable', y='Y Variable') +\n  theme_classic() +\n  theme(plot.title=element_text(hjust=0.5, face='bold', color='red', size=10),\n        legend.position='right')\n\n# Combine\ncombined &lt;- (p1 | p2) / (p3 | p4) + plot_annotation(\n  title = 'Qualitative Palettes: Good vs Bad',\n  theme = theme(plot.title = element_text(hjust = 0.5, size = 14, face = 'bold'))\n)\n\nggsave('qualitative_palettes.png', combined, width = 14, height = 10, dpi = 300)\n\n\n\n\nPalette Selection Decision Tree\nSTART: What type of data do I have?\n\n├─ QUANTITATIVE/CONTINUOUS\n│   ├─ Has meaningful midpoint (zero, baseline)?\n│   │   └─ YES → DIVERGING PALETTE\n│   │       Examples: RdBu, PiYG, BrBG\n│   │\n│   └─ NO → SEQUENTIAL PALETTE\n│       Examples: Blues, Viridis, YlOrRd\n│\n└─ CATEGORICAL/NOMINAL\n    ├─ Ordered categories (mild/moderate/severe)?\n    │   └─ YES → SEQUENTIAL PALETTE\n    │       (Treat as ordinal data)\n    │\n    └─ NO → QUALITATIVE PALETTE\n        Examples: Set2, Dark2, Okabe-Ito\n\n        Special consideration:\n        - If &gt;8 categories → Consider splitting figure\n        - Always check colorblind simulation\n        - Add shape/line redundancy\n\n\n\nExercise 2.2.1: Palette Type Classification\nObjective: Practice identifying appropriate palette types\nInstructions:\nFor each dataset below, identify: 1. Data type (quantitative continuous, ordinal, nominal) 2. Appropriate palette type (sequential, diverging, qualitative) 3. Specific palette recommendation 4. Why alternatives would be wrong\nDatasets:\nA. Temperature anomaly (deviation from 20th century average) - Values: -2°C to +2°C - Represents: Climate change warming/cooling\nB. Species distribution across 5 habitat types - Categories: Forest, Grassland, Desert, Wetland, Tundra - No inherent ordering\nC. Disease progression stages - Categories: Healthy, At-risk, Early disease, Advanced disease - Clear progression\nD. Population density (people per km²) - Values: 0 to 10,000 - All positive, no meaningful center\nE. Stock price change (% change from yesterday) - Values: -15% to +15% - Zero = no change\nYour answers should look like:\nDataset A:\n- Data type: Quantitative continuous with meaningful zero\n- Palette type: Diverging\n- Recommendation: RdBu_r (blue=cooling, red=warming)\n- Why not sequential: Would lose critical distinction between warming/cooling\n- Why not qualitative: Data is continuous, not categorical",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2: The Language of Color</span>"
    ]
  },
  {
    "objectID": "Chapter 2.html#light-vs.-dark-background",
    "href": "Chapter 2.html#light-vs.-dark-background",
    "title": "Chapter 2: The Language of Color",
    "section": "2.3 Light vs. Dark Background",
    "text": "2.3 Light vs. Dark Background\n\nThe Context-Driven Choice\nThe choice between light and dark themes isn’t about personal preference—it’s about medium, venue, and function. Scientific publications have specific requirements, and understanding when each theme is appropriate is crucial for effective communication.\n\n\nPublication Standard: Light Backgrounds (Default)\nWhy light themes dominate scientific literature:\n\nPrint legacy: Scientific journals evolved from print media where:\n\nBlack ink on white paper is most economical\nHigh contrast ensures legibility\nGrayscale reproduction is reliable\n\nReading comprehension: Studies show:\n\nDark text on light backgrounds reduces eye strain for extended reading\nBetter for detailed analysis and data interpretation\nMaintains performance across various lighting conditions\n\nJournal requirements: Most high-impact journals explicitly require:\n\nWhite or light gray backgrounds\nBlack text and axis lines\nConservative, professional appearance\n\n\nStandard Scientific Figure Format:\n✓ White background\n✓ Black or dark gray text\n✓ Colored data elements (but limited palette)\n✓ Light gray gridlines (if used)\n✓ Clean, minimal aesthetic\n\n\n\nWhen Dark Themes Are Appropriate\nAcceptable Use Cases:\n1. Presentations and Posters\nWhy it works:\n- Projected in dark/dim rooms\n- High contrast improves visibility from distance\n- More dramatic visual impact\n- Reduces screen glare\n\nRequirements:\n- Still maintain high contrast\n- Use lighter text colors\n- Test in actual presentation conditions\n2. Supplementary Digital Materials\nWhy it works:\n- Interactive web-based figures\n- Video presentations\n- Screen-based analysis tools\n\nRequirements:\n- Provide light theme alternative\n- Ensure all elements remain visible\n- Test on multiple devices\n3. Specific Data Visualization Contexts\nAstronomical imaging: Stars on black sky (natural representation)\nFluorescence microscopy: Bright signals on dark background (matches actual imaging)\nNetwork visualizations: Sometimes clearer on dark backgrounds\n\nBut even here: Consider converting to light theme for publication\n\n\n\nThe Color Restraint Principle for Publications\nCritical Rule: Use color sparingly and purposefully\nIn scientific publications, every color must have a functional reason, not merely aesthetic appeal. This principle stems from:\n\nCognitive load: Too many colors overwhelm readers\nReproducibility: Simpler color schemes are easier to recreate\nAccessibility: Fewer colors reduce colorblind accessibility issues\nProfessional standards: Conservative color use signals scientific rigor\nPrint costs: Historically, color pages cost more (legacy influence)\n\n\n\n\nThe “3-Color Rule” for Scientific Figures\nGuideline: Aim for 3 colors maximum per figure (excluding grayscale)\nWhy this works:\nExample: Treatment Comparison Figure\n✓ GOOD (3 colors):\n  - Control group: Gray (#808080)\n  - Treatment A: Blue (#2E86AB)\n  - Treatment B: Red (#A23B72)\n  - Background: White\n  - Text/axes: Black\n  - Gridlines: Light gray (#D3D3D3)\n\n→ Clear, distinct, professional\n→ Easy to distinguish in legend\n→ Works in grayscale (shades differ)\nBad Example: Color Overload\n✗ BAD (8+ colors):\n  - 8 different treatment groups in rainbow colors\n  - Multiple colored gridlines\n  - Colored background\n  - Multicolored title\n\n→ Visually chaotic\n→ Hard to match legend to data\n→ Loses impact of individual colors\n\n\n\nLogical Color Schemes: Semantic Consistency\nColors should carry semantic meaning consistently across your entire manuscript\nPrinciple: Same concept = Same color throughout all figures\nExample Consistency Rules:\nTemperature-related data:\n✓ Consistent across all figures:\n  - Cold/low temperature: Blue (#3498DB)\n  - Hot/high temperature: Red (#E74C3C)\n  - Neutral: Gray (#95A5A6)\n\n✗ Inconsistent (confusing):\n  - Figure 1: Cold=Blue, Hot=Red\n  - Figure 2: Cold=Green, Hot=Orange\n  - Figure 3: Cold=Purple, Hot=Yellow\n→ Reader must relearn color meaning each time\nBiological example:\nConsistent color scheme for cell types across all figures:\n  - Neurons: Purple (#9B59B6)\n  - Astrocytes: Green (#27AE60)\n  - Microglia: Orange (#E67E22)\n\nApplied to:\n  - Figure 1: Immunohistochemistry images\n  - Figure 2: Flow cytometry plots\n  - Figure 3: Gene expression heatmaps\n  - Figure 4: Quantification bar charts\n\n→ Immediate recognition, reduced cognitive load\n\n\n\nField-Specific Color Conventions\nMany scientific fields have established color conventions—follow them unless you have strong justification\nMolecular Biology:\n- DNA: Blue\n- RNA: Red\n- Protein: Green or purple\n- Upregulated genes: Red\n- Downregulated genes: Blue/green\nNeuroscience:\n- Excitatory neurons: Red\n- Inhibitory neurons: Blue\n- Dendrites: Green\n- Axons: Red or blue\nClimate Science:\n- Warming: Red/orange\n- Cooling: Blue\n- Land: Brown/green\n- Water: Blue\nMedical Imaging:\n- PET scans: Rainbow (hot) scale\n- MRI: Grayscale\n- Functional activation: Hot colors on grayscale\nRespecting conventions:\n✓ Advantages:\n  - Immediate interpretation by experts\n  - Consistent with literature\n  - Reduces confusion\n\n✗ Breaking conventions:\n  - Only if you have strong perceptual/accessibility reason\n  - Must explain explicitly in caption\n  - Risk confusing your audience\n\n\n\nCode Examples: Light Theme with Minimal Color\nPython Example: Publication-Ready Light Theme\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Set publication-ready style\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.rcParams.update({\n    'font.family': 'Arial',\n    'font.size': 10,\n    'axes.labelsize': 11,\n    'axes.titlesize': 12,\n    'axes.labelweight': 'bold',\n    'xtick.labelsize': 9,\n    'ytick.labelsize': 9,\n    'legend.fontsize': 9,\n    'figure.titlesize': 14,\n    'figure.facecolor': 'white',\n    'axes.facecolor': 'white',\n    'axes.edgecolor': '#333333',\n    'axes.linewidth': 1.2,\n    'grid.color': '#D3D3D3',\n    'grid.linewidth': 0.8,\n    'grid.alpha': 0.5\n})\n\n# Sample data (treatment comparison)\nnp.random.seed(42)\ntime = np.arange(0, 24, 1)\ncontrol = 100 + np.cumsum(np.random.randn(len(time)) * 2)\ntreatment_a = 100 + np.cumsum(np.random.randn(len(time)) * 2 + 0.5)\ntreatment_b = 100 + np.cumsum(np.random.randn(len(time)) * 2 + 1.0)\n\n# Define consistent color palette (3 colors only)\nCOLOR_CONTROL = '#808080'      # Gray\nCOLOR_TREATMENT_A = '#2E86AB'  # Blue\nCOLOR_TREATMENT_B = '#A23B72'  # Purple-red\n\nfig, ax = plt.subplots(figsize=(7, 4.5))\n\n# Plot data with ONLY 3 colors\nax.plot(time, control, color=COLOR_CONTROL, linewidth=2.5,\n        label='Control', marker='o', markersize=4, markevery=3)\nax.plot(time, treatment_a, color=COLOR_TREATMENT_A, linewidth=2.5,\n        label='Treatment A', marker='s', markersize=4, markevery=3)\nax.plot(time, treatment_b, color=COLOR_TREATMENT_B, linewidth=2.5,\n        label='Treatment B', marker='^', markersize=4, markevery=3)\n\n# Minimal, functional styling\nax.set_xlabel('Time (hours)', fontweight='bold')\nax.set_ylabel('Cell Viability (%)', fontweight='bold')\nax.set_title('Effect of Treatments on Cell Viability', fontweight='bold', pad=15)\n\n# Legend: simple, unobtrusive\nax.legend(loc='upper left', frameon=True, facecolor='white',\n          edgecolor='#333333', framealpha=1.0)\n\n# Remove top and right spines (cleaner look)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n# Subtle gridlines (not distracting)\nax.grid(True, alpha=0.3, linewidth=0.7, linestyle='--')\n\nplt.tight_layout()\nplt.savefig('light_theme_minimal_color.png', dpi=300,\n            bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"Figure saved with:\")\nprint(f\"  - Background: White\")\nprint(f\"  - Colors used: 3 (Gray, Blue, Purple-red)\")\nprint(f\"  - Text: Black\")\nprint(f\"  - Grid: Light gray, subtle\")\n\nR Example: Publication-Ready Light Theme\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Sample data\nset.seed(42)\ntime &lt;- 0:23\ndata &lt;- data.frame(\n  time = rep(time, 3),\n  viability = c(\n    100 + cumsum(rnorm(length(time), 0, 2)),           # Control\n    100 + cumsum(rnorm(length(time), 0.5, 2)),         # Treatment A\n    100 + cumsum(rnorm(length(time), 1.0, 2))          # Treatment B\n  ),\n  group = rep(c('Control', 'Treatment A', 'Treatment B'), each=length(time))\n)\n\n# Consistent color palette (3 colors only)\nCOLOR_CONTROL &lt;- '#808080'      # Gray\nCOLOR_TREATMENT_A &lt;- '#2E86AB'  # Blue\nCOLOR_TREATMENT_B &lt;- '#A23B72'  # Purple-red\n\ncolors_palette &lt;- c('Control' = COLOR_CONTROL,\n                    'Treatment A' = COLOR_TREATMENT_A,\n                    'Treatment B' = COLOR_TREATMENT_B)\n\n# Create publication-ready plot\np &lt;- ggplot(data, aes(x = time, y = viability, color = group, shape = group)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2.5, data = data %&gt;% filter(time %% 3 == 0)) +  # Every 3rd point\n\n  # Apply color palette\n  scale_color_manual(values = colors_palette) +\n  scale_shape_manual(values = c(16, 15, 17)) +  # Circle, square, triangle\n\n  # Labels\n  labs(\n    x = 'Time (hours)',\n    y = 'Cell Viability (%)',\n    title = 'Effect of Treatments on Cell Viability',\n    color = NULL,\n    shape = NULL\n  ) +\n\n  # Theme: clean, light background\n  theme_classic(base_size = 11, base_family = 'Arial') +\n  theme(\n    # White background (publication standard)\n    plot.background = element_rect(fill = 'white', color = NA),\n    panel.background = element_rect(fill = 'white', color = NA),\n\n    # Subtle grid\n    panel.grid.major = element_line(color = '#D3D3D3', size = 0.3, linetype = 'dashed'),\n    panel.grid.minor = element_blank(),\n\n    # Bold axis labels\n    axis.title = element_text(face = 'bold', size = 11),\n    axis.text = element_text(size = 9, color = '#333333'),\n\n    # Title\n    plot.title = element_text(face = 'bold', size = 12, hjust = 0, margin = margin(b = 10)),\n\n    # Legend: simple, unobtrusive\n    legend.position = c(0.15, 0.85),\n    legend.background = element_rect(fill = 'white', color = '#333333', size = 0.5),\n    legend.key = element_rect(fill = 'white'),\n    legend.text = element_text(size = 9),\n    legend.margin = margin(t = 5, r = 5, b = 5, l = 5),\n\n    # Remove top/right borders\n    axis.line = element_line(color = '#333333', size = 0.7),\n    panel.border = element_blank()\n  )\n\n# Save\nggsave('light_theme_minimal_color.png', p, width = 7, height = 4.5,\n       dpi = 300, bg = 'white')\n\ncat(\"Figure saved with:\\n\")\ncat(\"  - Background: White\\n\")\ncat(\"  - Colors used: 3 (Gray, Blue, Purple-red)\\n\")\ncat(\"  - Text: Black\\n\")\ncat(\"  - Grid: Light gray, subtle\\n\")\n\n\n\nDark Theme: When and How (Presentations Only)\nPython Example: Dark Theme for Presentation\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Dark theme settings (for presentations ONLY)\nplt.style.use('dark_background')\nplt.rcParams.update({\n    'font.family': 'Arial',\n    'font.size': 12,  # Larger for visibility\n    'figure.facecolor': '#1E1E1E',\n    'axes.facecolor': '#1E1E1E',\n    'axes.edgecolor': '#CCCCCC',\n    'text.color': 'white',\n    'axes.labelcolor': 'white',\n    'xtick.color': 'white',\n    'ytick.color': 'white',\n    'grid.color': '#444444',\n    'grid.alpha': 0.5\n})\n\n# Same data as before\nnp.random.seed(42)\ntime = np.arange(0, 24, 1)\ncontrol = 100 + np.cumsum(np.random.randn(len(time)) * 2)\ntreatment_a = 100 + np.cumsum(np.random.randn(len(time)) * 2 + 0.5)\ntreatment_b = 100 + np.cumsum(np.random.randn(len(time)) * 2 + 1.0)\n\n# LIGHTER colors for dark background (higher saturation/brightness)\nCOLOR_CONTROL_DARK = '#B0B0B0'      # Light gray\nCOLOR_TREATMENT_A_DARK = '#5DADE2'  # Light blue\nCOLOR_TREATMENT_B_DARK = '#EC7063'  # Light red\n\nfig, ax = plt.subplots(figsize=(10, 6))  # Larger for presentations\n\nax.plot(time, control, color=COLOR_CONTROL_DARK, linewidth=3,\n        label='Control', marker='o', markersize=6, markevery=3)\nax.plot(time, treatment_a, color=COLOR_TREATMENT_A_DARK, linewidth=3,\n        label='Treatment A', marker='s', markersize=6, markevery=3)\nax.plot(time, treatment_b, color=COLOR_TREATMENT_B_DARK, linewidth=3,\n        label='Treatment B', marker='^', markersize=6, markevery=3)\n\nax.set_xlabel('Time (hours)', fontweight='bold', fontsize=14)\nax.set_ylabel('Cell Viability (%)', fontweight='bold', fontsize=14)\nax.set_title('Effect of Treatments on Cell Viability\\n(Presentation Version)',\n             fontweight='bold', fontsize=16, color='white', pad=20)\n\nax.legend(loc='upper left', fontsize=12, frameon=True,\n          facecolor='#2C2C2C', edgecolor='#CCCCCC')\n\nax.grid(True, alpha=0.3, linewidth=0.8)\n\nplt.tight_layout()\nplt.savefig('dark_theme_presentation.png', dpi=150,\n            bbox_inches='tight', facecolor='#1E1E1E')\nplt.close()\n\nprint(\"Dark theme figure (PRESENTATION ONLY) saved\")\nprint(\"Note: Convert to light theme for publication submission\")\n\nR Example: Dark Theme for Presentation\nlibrary(ggplot2)\n\n# Same data\nset.seed(42)\ntime &lt;- 0:23\ndata &lt;- data.frame(\n  time = rep(time, 3),\n  viability = c(\n    100 + cumsum(rnorm(length(time), 0, 2)),\n    100 + cumsum(rnorm(length(time), 0.5, 2)),\n    100 + cumsum(rnorm(length(time), 1.0, 2))\n  ),\n  group = rep(c('Control', 'Treatment A', 'Treatment B'), each=length(time))\n)\n\n# Lighter colors for dark background\nCOLOR_CONTROL_DARK &lt;- '#B0B0B0'      # Light gray\nCOLOR_TREATMENT_A_DARK &lt;- '#5DADE2'  # Light blue\nCOLOR_TREATMENT_B_DARK &lt;- '#EC7063'  # Light red\n\ncolors_dark &lt;- c('Control' = COLOR_CONTROL_DARK,\n                 'Treatment A' = COLOR_TREATMENT_A_DARK,\n                 'Treatment B' = COLOR_TREATMENT_B_DARK)\n\n# Dark theme plot\np_dark &lt;- ggplot(data, aes(x = time, y = viability, color = group, shape = group)) +\n  geom_line(size = 1.5) +\n  geom_point(size = 3.5, data = data %&gt;% filter(time %% 3 == 0)) +\n\n  scale_color_manual(values = colors_dark) +\n  scale_shape_manual(values = c(16, 15, 17)) +\n\n  labs(\n    x = 'Time (hours)',\n    y = 'Cell Viability (%)',\n    title = 'Effect of Treatments on Cell Viability\\n(Presentation Version)',\n    color = NULL,\n    shape = NULL\n  ) +\n\n  # Dark theme\n  theme_minimal(base_size = 14, base_family = 'Arial') +\n  theme(\n    # Dark background\n    plot.background = element_rect(fill = '#1E1E1E', color = NA),\n    panel.background = element_rect(fill = '#1E1E1E', color = NA),\n\n    # Light text\n    text = element_text(color = 'white'),\n    axis.text = element_text(color = 'white', size = 12),\n    axis.title = element_text(color = 'white', face = 'bold', size = 14),\n    plot.title = element_text(color = 'white', face = 'bold', size = 16, hjust = 0.5),\n\n    # Subtle grid\n    panel.grid.major = element_line(color = '#444444', size = 0.4),\n    panel.grid.minor = element_blank(),\n\n    # Legend\n    legend.position = c(0.15, 0.85),\n    legend.background = element_rect(fill = '#2C2C2C', color = '#CCCCCC', size = 0.5),\n    legend.text = element_text(color = 'white', size = 12),\n    legend.key = element_rect(fill = '#2C2C2C')\n  )\n\nggsave('dark_theme_presentation.png', p_dark, width = 10, height = 6,\n       dpi = 150, bg = '#1E1E1E')\n\ncat(\"Dark theme figure (PRESENTATION ONLY) saved\\n\")\ncat(\"Note: Convert to light theme for publication submission\\n\")\n\n\n\nPublication Submission Checklist: Color & Theme\nBefore submitting your manuscript, verify:\n\nBackground is white or light gray (not dark)\nMaximum 3-4 distinct colors per figure (excluding grayscale)\nColor consistency across all figures (same concept = same color)\nSemantic logic (colors match intuitive meanings)\nField conventions respected (unless explicitly justified)\nText is black or very dark gray (#333333)\nGridlines are subtle (light gray, thin, low opacity)\nNo decorative colors (every color has functional purpose)\nWorks in grayscale (test by converting to black & white)\nColorblind accessible (test with simulation tools)\n\n\n\n\nExercise 2.3.1: Color Restraint Practice\nObjective: Practice creating publication-ready figures with minimal, logical color use\nTask:\n\nFind a figure from your own work or literature that uses &gt;5 colors\nRedesign it following these constraints:\n\nMaximum 3 distinct colors (plus grayscale)\nLight background (white)\nConsistent color logic (explain your color choices)\nNo decorative color\n\nDocument your choices:\nOriginal figure: [description, number of colors used]\nRedesign:\n\nColor 1: [Hex code] - Used for: [data/concept] - Reason: [explain]\nColor 2: [Hex code] - Used for: [data/concept] - Reason: [explain]\nColor 3: [Hex code] - Used for: [data/concept] - Reason: [explain]\nGrayscale: Used for: [supporting elements]\n\nLogic: [Explain the semantic consistency of your color choices]\nImprovements: [What became clearer with fewer colors]\nTest accessibility:\n\nConvert to grayscale: Do distinctions remain clear?\nUse colorblind simulator: Is information preserved?\n\n\n\nEnd of Section 2.3\nKey Takeaways: - Default to light themes for all publications - Dark themes only for presentations/posters - 3-color maximum (excluding grayscale) for clarity - Every color must have semantic meaning - Consistency across manuscript is mandatory - Respect field conventions unless you have strong justification —",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2: The Language of Color</span>"
    ]
  },
  {
    "objectID": "Chapter 2.html#light-vs.-deep-colors-saturation-and-intensity",
    "href": "Chapter 2.html#light-vs.-deep-colors-saturation-and-intensity",
    "title": "Chapter 2: The Language of Color",
    "section": "2.4 Light vs. Deep Colors: Saturation and Intensity",
    "text": "2.4 Light vs. Deep Colors: Saturation and Intensity\n\nUnderstanding Color Intensity in Scientific Figures\nIn scientific visualization, the choice between light (desaturated) and deep (saturated) colors isn’t about aesthetics—it’s about visual hierarchy, emphasis, and cognitive processing. This section addresses when to use vivid, saturated colors versus pale, muted tones.\n\n\nThe Saturation Spectrum\nColor saturation refers to the intensity or purity of a color:\n\nHigh saturation (deep colors): Vivid, pure, intense (e.g., pure red #FF0000)\nLow saturation (light colors): Pale, muted, washed-out (e.g., light pink #FFB3BA)\nZero saturation: Grayscale only\n\nIn HSV/HSB color model:\nSaturation = 0%: Pure gray (no color)\nSaturation = 50%: Muted, pastel-like\nSaturation = 100%: Maximum vividness\n\n\n\nThe Visual Hierarchy Principle: Deep Colors for Focus\nRule: Use deep, saturated colors sparingly for PRIMARY focus only\nWhy this matters: 1. Pre-attentive attention: Saturated colors grab attention immediately 2. Visual weight: Deep colors appear “heavier” and more important 3. Cognitive load: Too many saturated colors cause visual fatigue 4. Professional standards: Scientific figures should be clear, not garish\nThe Hierarchy Strategy:\nLEVEL 1 (Primary focus): Deep, saturated colors\n└─ The key finding, most important data\n└─ Examples: Significant results, highlighted treatment group\n\nLEVEL 2 (Supporting context): Medium saturation\n└─ Important but secondary data\n└─ Examples: Reference groups, all experimental conditions\n\nLEVEL 3 (Background/infrastructure): Light, desaturated colors\n└─ Supporting elements that shouldn't distract\n└─ Examples: Gridlines, reference regions, non-significant data\n\n\n\nPractical Application Examples\n\nExample 1: Highlighting Significant Results\nScenario: Clinical trial with 8 treatment groups, only 2 show significant improvement\nBad Approach (Equal saturation):\n✗ All 8 groups in equally bright, saturated colors\n  → No visual priority\n  → Reader must read legend and statistics to find key results\n  → Cognitive overload from too many bright colors\nGood Approach (Saturation hierarchy):\n✓ 2 significant groups: Deep, saturated colors (e.g., #E63946 red, #2E86AB blue)\n✓ 6 non-significant groups: Light, desaturated gray (#CCCCCC)\n  → Immediate visual focus on significant findings\n  → Clean, uncluttered appearance\n  → Professional and publication-ready\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Sample data: 8 treatment groups\nnp.random.seed(42)\ngroups = [f'Group {i+1}' for i in range(8)]\nvalues = [15, 12, 28, 10, 14, 25, 11, 13]  # Groups 3 and 6 are significant\nerrors = [2, 2.5, 3, 2, 2.5, 3.5, 2, 2.5]\n\n# Identify significant groups\nsignificant = [2, 5]  # Indices of Group 3 and Group 6\n\n# GOOD: Deep colors for significant, light for non-significant\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# BAD approach: All equally saturated\ncolors_bad = ['#E63946', '#F77F00', '#FCBF49', '#06A77D',\n              '#4ECDC4', '#2E86AB', '#8338EC', '#A23B72']\n\naxes[0].bar(groups, values, color=colors_bad, edgecolor='black', linewidth=1.2)\naxes[0].errorbar(groups, values, yerr=errors, fmt='none', ecolor='black', capsize=5)\naxes[0].set_ylabel('Response (arbitrary units)', fontsize=11, fontweight='bold')\naxes[0].set_title('BAD: All Colors Equally Saturated\\n(No visual priority)',\n                  fontsize=12, fontweight='bold', color='red')\naxes[0].tick_params(axis='x', rotation=45)\naxes[0].grid(axis='y', alpha=0.3)\naxes[0].spines['top'].set_visible(False)\naxes[0].spines['right'].set_visible(False)\n\n# GOOD approach: Deep colors only for significant\ncolors_good = ['#D3D3D3'] * 8  # All light gray by default\ncolors_good[2] = '#E63946'     # Group 3: Deep red\ncolors_good[5] = '#2E86AB'     # Group 6: Deep blue\n\naxes[1].bar(groups, values, color=colors_good, edgecolor='black', linewidth=1.2)\naxes[1].errorbar(groups, values, yerr=errors, fmt='none', ecolor='black', capsize=5)\naxes[1].set_ylabel('Response (arbitrary units)', fontsize=11, fontweight='bold')\naxes[1].set_title('GOOD: Deep Colors for Significant Only\\n(Clear visual hierarchy)',\n                  fontsize=12, fontweight='bold', color='green')\naxes[1].tick_params(axis='x', rotation=45)\naxes[1].grid(axis='y', alpha=0.3)\naxes[1].spines['top'].set_visible(False)\naxes[1].spines['right'].set_visible(False)\n\n# Add significance markers\nfor idx in significant:\n    axes[1].text(idx, values[idx] + errors[idx] + 2, '***',\n                ha='center', fontsize=16, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('saturation_hierarchy.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R):\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Sample data\ngroups &lt;- paste0('Group ', 1:8)\nvalues &lt;- c(15, 12, 28, 10, 14, 25, 11, 13)\nerrors &lt;- c(2, 2.5, 3, 2, 2.5, 3.5, 2, 2.5)\nsignificant &lt;- c(3, 6)  # Group 3 and 6 are significant\n\ndata &lt;- data.frame(\n  group = factor(groups, levels = groups),\n  value = values,\n  error = errors,\n  is_significant = 1:8 %in% significant\n)\n\n# BAD: All equally saturated\ncolors_bad &lt;- c('#E63946', '#F77F00', '#FCBF49', '#06A77D',\n                '#4ECDC4', '#2E86AB', '#8338EC', '#A23B72')\n\np_bad &lt;- ggplot(data, aes(x = group, y = value)) +\n  geom_bar(stat = 'identity', aes(fill = group), color = 'black', size = 0.8) +\n  geom_errorbar(aes(ymin = value - error, ymax = value + error),\n                width = 0.3, size = 0.7) +\n  scale_fill_manual(values = colors_bad) +\n  labs(y = 'Response (arbitrary units)',\n       title = 'BAD: All Colors Equally Saturated\\n(No visual priority)') +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 12),\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(face = 'bold'),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = 'none',\n    panel.grid.major.y = element_line(color = 'gray90')\n  )\n\n# GOOD: Deep colors only for significant\ndata$color &lt;- ifelse(data$is_significant,\n                     ifelse(data$group == 'Group 3', '#E63946', '#2E86AB'),\n                     '#D3D3D3')\n\np_good &lt;- ggplot(data, aes(x = group, y = value)) +\n  geom_bar(stat = 'identity', aes(fill = color), color = 'black', size = 0.8) +\n  geom_errorbar(aes(ymin = value - error, ymax = value + error),\n                width = 0.3, size = 0.7) +\n  scale_fill_identity() +\n  labs(y = 'Response (arbitrary units)',\n       title = 'GOOD: Deep Colors for Significant Only\\n(Clear visual hierarchy)') +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 12),\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(face = 'bold'),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid.major.y = element_line(color = 'gray90')\n  ) +\n  # Add significance markers\n  geom_text(data = data %&gt;% filter(is_significant),\n            aes(label = '***', y = value + error + 2),\n            size = 6, fontface = 'bold')\n\n# Combine plots\nlibrary(patchwork)\ncombined &lt;- p_bad | p_good\nggsave('saturation_hierarchy.png', combined, width = 14, height = 5,\n       dpi = 300, bg = 'white')\n\n\n\nExample 2: Correlation Strength Visualization\nScenario: Showing multiple correlations, want to emphasize strongest relationships\nPrinciple: Deep colors = Strong/significant, Light colors = Weak/non-significant\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Rectangle\n\n# Correlation matrix data\nnp.random.seed(42)\nvariables = ['Gene A', 'Gene B', 'Gene C', 'Gene D', 'Gene E']\nn_vars = len(variables)\n\n# Generate correlation matrix with some strong correlations\ncorr_matrix = np.random.rand(n_vars, n_vars) * 0.5\ncorr_matrix = (corr_matrix + corr_matrix.T) / 2  # Symmetrize\nnp.fill_diagonal(corr_matrix, 1.0)\n\n# Add some strong correlations\ncorr_matrix[0, 2] = corr_matrix[2, 0] = 0.85  # Strong positive\ncorr_matrix[1, 4] = corr_matrix[4, 1] = -0.78  # Strong negative\ncorr_matrix[3, 4] = corr_matrix[4, 3] = 0.72  # Moderate-strong\n\n# Significance (p-values) - for demonstration\np_values = np.random.rand(n_vars, n_vars) * 0.1\np_values[0, 2] = p_values[2, 0] = 0.001  # Highly significant\np_values[1, 4] = p_values[4, 1] = 0.002  # Highly significant\np_values[3, 4] = p_values[4, 3] = 0.01   # Significant\nnp.fill_diagonal(p_values, 0)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# BAD: Uniform saturation regardless of significance\nim1 = axes[0].imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1, aspect='auto')\naxes[0].set_xticks(range(n_vars))\naxes[0].set_yticks(range(n_vars))\naxes[0].set_xticklabels(variables, rotation=45, ha='right')\naxes[0].set_yticklabels(variables)\naxes[0].set_title('BAD: All Correlations Equal Saturation\\n(Significant and non-significant look same)',\n                  fontsize=12, fontweight='bold', color='red')\n\n# Add correlation values\nfor i in range(n_vars):\n    for j in range(n_vars):\n        axes[0].text(j, i, f'{corr_matrix[i, j]:.2f}',\n                    ha='center', va='center', fontsize=9,\n                    color='white' if abs(corr_matrix[i, j]) &gt; 0.5 else 'black')\n\nplt.colorbar(im1, ax=axes[0], label='Correlation coefficient')\n\n# GOOD: Deep colors for significant, desaturated for non-significant\n# Create custom colormap with saturation based on significance\ncorr_colored = np.zeros((n_vars, n_vars, 3))\n\nfor i in range(n_vars):\n    for j in range(n_vars):\n        r = corr_matrix[i, j]\n        p = p_values[i, j]\n\n        if p &lt; 0.05:  # Significant: deep colors\n            if r &gt; 0:\n                # Deep red for significant positive\n                saturation = min(abs(r), 1.0)\n                corr_colored[i, j] = [0.9, 0.2, 0.2]  # Deep red\n            else:\n                # Deep blue for significant negative\n                saturation = min(abs(r), 1.0)\n                corr_colored[i, j] = [0.2, 0.3, 0.7]  # Deep blue\n        else:  # Non-significant: light colors\n            if r &gt; 0:\n                # Light pink for non-significant positive\n                corr_colored[i, j] = [1.0, 0.85, 0.85]  # Light pink\n            else:\n                # Light blue for non-significant negative\n                corr_colored[i, j] = [0.85, 0.9, 1.0]  # Light blue\n\naxes[1].imshow(corr_colored, aspect='auto')\naxes[1].set_xticks(range(n_vars))\naxes[1].set_yticks(range(n_vars))\naxes[1].set_xticklabels(variables, rotation=45, ha='right')\naxes[1].set_yticklabels(variables)\naxes[1].set_title('GOOD: Deep Colors for Significant Only\\n(p &lt; 0.05 with deep colors, others desaturated)',\n                  fontsize=12, fontweight='bold', color='green')\n\n# Add correlation values with significance markers\nfor i in range(n_vars):\n    for j in range(n_vars):\n        sig_marker = '***' if p_values[i, j] &lt; 0.01 else ('*' if p_values[i, j] &lt; 0.05 else '')\n        axes[1].text(j, i, f'{corr_matrix[i, j]:.2f}\\n{sig_marker}',\n                    ha='center', va='center', fontsize=8,\n                    color='white' if p_values[i, j] &lt; 0.05 and abs(corr_matrix[i, j]) &gt; 0.5 else 'black',\n                    fontweight='bold' if sig_marker else 'normal')\n\nplt.tight_layout()\nplt.savefig('correlation_saturation_logic.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R):\nlibrary(ggplot2)\nlibrary(reshape2)\nlibrary(dplyr)\n\n# Generate correlation data\nset.seed(42)\nvariables &lt;- c('Gene A', 'Gene B', 'Gene C', 'Gene D', 'Gene E')\nn_vars &lt;- length(variables)\n\n# Correlation matrix\ncorr_matrix &lt;- matrix(runif(n_vars^2, -0.5, 0.5), n_vars, n_vars)\ncorr_matrix &lt;- (corr_matrix + t(corr_matrix)) / 2  # Symmetrize\ndiag(corr_matrix) &lt;- 1.0\n\n# Add strong correlations\ncorr_matrix[1, 3] &lt;- corr_matrix[3, 1] &lt;- 0.85   # Strong positive\ncorr_matrix[2, 5] &lt;- corr_matrix[5, 2] &lt;- -0.78  # Strong negative\ncorr_matrix[4, 5] &lt;- corr_matrix[5, 4] &lt;- 0.72   # Moderate-strong\n\n# P-values\np_values &lt;- matrix(runif(n_vars^2, 0, 0.1), n_vars, n_vars)\np_values[1, 3] &lt;- p_values[3, 1] &lt;- 0.001\np_values[2, 5] &lt;- p_values[5, 2] &lt;- 0.002\np_values[4, 5] &lt;- p_values[5, 4] &lt;- 0.01\ndiag(p_values) &lt;- 0\n\n# Convert to long format\nrownames(corr_matrix) &lt;- colnames(corr_matrix) &lt;- variables\nrownames(p_values) &lt;- colnames(p_values) &lt;- variables\n\ncorr_long &lt;- melt(corr_matrix, varnames = c('Var1', 'Var2'), value.name = 'correlation')\np_long &lt;- melt(p_values, varnames = c('Var1', 'Var2'), value.name = 'p_value')\n\ndata_combined &lt;- corr_long %&gt;%\n  left_join(p_long, by = c('Var1', 'Var2')) %&gt;%\n  mutate(\n    significant = p_value &lt; 0.05,\n    sig_marker = case_when(\n      p_value &lt; 0.01 ~ '***',\n      p_value &lt; 0.05 ~ '*',\n      TRUE ~ ''\n    ),\n    # Color logic: deep colors for significant, light for non-significant\n    color_category = case_when(\n      significant & correlation &gt; 0 ~ 'Significant Positive',\n      significant & correlation &lt; 0 ~ 'Significant Negative',\n      !significant & correlation &gt; 0 ~ 'Non-sig Positive',\n      !significant & correlation &lt; 0 ~ 'Non-sig Negative',\n      TRUE ~ 'Neutral'\n    )\n  )\n\n# Define colors\ncolor_mapping &lt;- c(\n  'Significant Positive' = '#E63946',    # Deep red\n  'Significant Negative' = '#2E86AB',    # Deep blue\n  'Non-sig Positive' = '#FFD6D6',        # Light pink\n  'Non-sig Negative' = '#D6E5F2',        # Light blue\n  'Neutral' = '#FFFFFF'\n)\n\n# GOOD plot: Saturation based on significance\np_good &lt;- ggplot(data_combined, aes(x = Var2, y = Var1, fill = color_category)) +\n  geom_tile(color = 'white', size = 1) +\n  geom_text(aes(label = paste0(sprintf('%.2f', correlation), '\\n', sig_marker)),\n            size = 3.5, fontface = ifelse(data_combined$significant, 'bold', 'plain')) +\n  scale_fill_manual(values = color_mapping, name = 'Correlation Type') +\n  labs(title = 'GOOD: Deep Colors for Significant Correlations\\n(p &lt; 0.05 with deep colors, others desaturated)',\n       x = NULL, y = NULL) +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 12),\n    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),\n    panel.grid = element_blank(),\n    legend.position = 'bottom'\n  ) +\n  coord_fixed()\n\nggsave('correlation_saturation_logic.png', p_good, width = 8, height = 7,\n       dpi = 300, bg = 'white')\n\n\n\n\nGuidelines for Saturation Use\nDO use deep, saturated colors for: - Statistically significant results (p &lt; 0.05) - Primary experimental condition (treatment vs. all controls) - Key finding you want to emphasize - Strong effects (large effect sizes, high correlations) - Highlighting outliers or exceptional cases\nDO use light, desaturated colors for: - Non-significant results (p ≥ 0.05) - Reference/control groups (when not the focus) - Background data (context, not main finding) - Weak effects (low correlations, small differences) - Supporting information (supplementary analyses)\nColor Saturation Decision Matrix:\n\n\n\n\n\n\n\n\nData Type\nPrimary/Significant\nSecondary/Non-significant\n\n\n\n\nPositive correlation\nDeep red (#E63946)\nLight pink (#FFD6D6)\n\n\nNegative correlation\nDeep blue (#2E86AB)\nLight blue (#D6E5F2)\n\n\nTreatment group\nDeep color (#9B59B6)\nLight gray (#D3D3D3)\n\n\nControl group\nMedium gray (#808080)\nLight gray (#ECECEC)\n\n\nUpregulated genes\nDeep red (#C0392B)\nLight red (#F5B7B1)\n\n\nDownregulated genes\nDeep blue (#2874A6)\nLight blue (#AED6F1)\n\n\n\n\n\n\nThe “3-Color + Saturation” Strategy\nMost effective publication approach: 3 base colors, varied saturation\nExample: Gene Expression Study\nBase Palette (3 colors):\n1. Red family: For upregulation\n2. Blue family: For downregulation\n3. Gray: For no change/control\n\nSaturation levels:\n- Deep (S=100%): Significant changes (p &lt; 0.05, |fold-change| &gt; 2)\n- Medium (S=60%): Moderate changes (p &lt; 0.05, |fold-change| 1-2)\n- Light (S=30%): Non-significant changes (p ≥ 0.05)\nCode Example (Python) - Gene Expression Volcano Plot:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Simulate gene expression data\nnp.random.seed(42)\nn_genes = 1000\n\n# Log2 fold change\nlog2fc = np.random.randn(n_genes) * 2\n\n# -log10 p-values\nneg_log10_p = -np.log10(np.random.uniform(0.0001, 0.5, n_genes))\n\n# Add some significant genes\nsig_up_idx = np.random.choice(n_genes, 50, replace=False)\nsig_down_idx = np.random.choice(np.setdiff1d(range(n_genes), sig_up_idx), 50, replace=False)\n\nlog2fc[sig_up_idx] = np.random.uniform(2, 4, 50)\nlog2fc[sig_down_idx] = np.random.uniform(-4, -2, 50)\nneg_log10_p[sig_up_idx] = np.random.uniform(3, 6, 50)\nneg_log10_p[sig_down_idx] = np.random.uniform(3, 6, 50)\n\n# Categorize genes by significance and magnitude\ndef categorize_gene(fc, p_val):\n    significant = p_val &gt; -np.log10(0.05)  # p &lt; 0.05\n    strong_change = abs(fc) &gt; 2\n\n    if significant and strong_change:\n        if fc &gt; 0:\n            return 'sig_up_strong', '#C0392B', 100  # Deep red\n        else:\n            return 'sig_down_strong', '#2874A6', 100  # Deep blue\n    elif significant:\n        if fc &gt; 0:\n            return 'sig_up_mod', '#E74C3C', 60  # Medium red\n        else:\n            return 'sig_down_mod', '#3498DB', 60  # Medium blue\n    else:\n        return 'not_sig', '#D5D8DC', 30  # Light gray\n\ncategories = [categorize_gene(fc, p) for fc, p in zip(log2fc, neg_log10_p)]\ncat_names, colors, sizes = zip(*categories)\n\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot with saturation hierarchy\nax.scatter(log2fc, neg_log10_p, c=colors, s=15, alpha=0.6, edgecolors='none')\n\n# Add thresholds\nax.axhline(-np.log10(0.05), color='black', linestyle='--', linewidth=1,\n           label='p = 0.05', alpha=0.5)\nax.axvline(-2, color='gray', linestyle='--', linewidth=1, alpha=0.5)\nax.axvline(2, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n\n# Labels and styling\nax.set_xlabel('Log₂ Fold Change', fontsize=12, fontweight='bold')\nax.set_ylabel('-Log₁₀ P-value', fontsize=12, fontweight='bold')\nax.set_title('Volcano Plot: Saturation Shows Significance & Magnitude',\n             fontsize=13, fontweight='bold')\n\n# Custom legend\nfrom matplotlib.patches import Patch\nlegend_elements = [\n    Patch(facecolor='#C0392B', label='Sig. upregulated (|FC| &gt; 2)'),\n    Patch(facecolor='#E74C3C', label='Sig. upregulated (|FC| &lt; 2)'),\n    Patch(facecolor='#2874A6', label='Sig. downregulated (|FC| &gt; 2)'),\n    Patch(facecolor='#3498DB', label='Sig. downregulated (|FC| &lt; 2)'),\n    Patch(facecolor='#D5D8DC', label='Not significant')\n]\nax.legend(handles=legend_elements, loc='upper left', frameon=True, fontsize=9)\n\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.grid(alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('volcano_saturation_logic.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R):\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Simulate gene expression data\nset.seed(42)\nn_genes &lt;- 1000\n\ndata &lt;- data.frame(\n  log2fc = rnorm(n_genes, 0, 2),\n  neg_log10_p = -log10(runif(n_genes, 0.0001, 0.5))\n)\n\n# Add significant genes\nsig_up_idx &lt;- sample(n_genes, 50)\nsig_down_idx &lt;- sample(setdiff(1:n_genes, sig_up_idx), 50)\n\ndata$log2fc[sig_up_idx] &lt;- runif(50, 2, 4)\ndata$log2fc[sig_down_idx] &lt;- runif(50, -4, -2)\ndata$neg_log10_p[sig_up_idx] &lt;- runif(50, 3, 6)\ndata$neg_log10_p[sig_down_idx] &lt;- runif(50, 3, 6)\n\n# Categorize\ndata &lt;- data %&gt;%\n  mutate(\n    significant = neg_log10_p &gt; -log10(0.05),\n    strong_change = abs(log2fc) &gt; 2,\n    category = case_when(\n      significant & strong_change & log2fc &gt; 0 ~ 'Sig. Up (strong)',\n      significant & strong_change & log2fc &lt; 0 ~ 'Sig. Down (strong)',\n      significant & log2fc &gt; 0 ~ 'Sig. Up (moderate)',\n      significant & log2fc &lt; 0 ~ 'Sig. Down (moderate)',\n      TRUE ~ 'Not significant'\n    ),\n    color = case_when(\n      category == 'Sig. Up (strong)' ~ '#C0392B',      # Deep red\n      category == 'Sig. Up (moderate)' ~ '#E74C3C',    # Medium red\n      category == 'Sig. Down (strong)' ~ '#2874A6',    # Deep blue\n      category == 'Sig. Down (moderate)' ~ '#3498DB',  # Medium blue\n      TRUE ~ '#D5D8DC'                                  # Light gray\n    )\n  )\n\n# Set factor levels for legend order\ndata$category &lt;- factor(data$category, levels = c(\n  'Sig. Up (strong)', 'Sig. Up (moderate)',\n  'Sig. Down (strong)', 'Sig. Down (moderate)',\n  'Not significant'\n))\n\n# Plot\np &lt;- ggplot(data, aes(x = log2fc, y = neg_log10_p, color = category)) +\n  geom_point(size = 1.5, alpha = 0.6) +\n\n  # Thresholds\n  geom_hline(yintercept = -log10(0.05), linetype = 'dashed',\n             color = 'black', size = 0.7, alpha = 0.5) +\n  geom_vline(xintercept = c(-2, 2), linetype = 'dashed',\n             color = 'gray50', size = 0.7, alpha = 0.5) +\n\n  # Colors\n  scale_color_manual(values = c(\n    'Sig. Up (strong)' = '#C0392B',\n    'Sig. Up (moderate)' = '#E74C3C',\n    'Sig. Down (strong)' = '#2874A6',\n    'Sig. Down (moderate)' = '#3498DB',\n    'Not significant' = '#D5D8DC'\n  )) +\n\n  # Labels\n  labs(\n    x = 'Log₂ Fold Change',\n    y = '-Log₁₀ P-value',\n    title = 'Volcano Plot: Saturation Shows Significance & Magnitude',\n    color = 'Gene Category'\n  ) +\n\n  # Theme\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 13),\n    axis.title = element_text(face = 'bold'),\n    legend.position = c(0.15, 0.85),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\nggsave('volcano_saturation_logic.png', p, width = 8, height = 6,\n       dpi = 300, bg = 'white')\n\n\n\nPublication Checklist: Color Saturation\nBefore finalizing figures, verify:\n\nDeep colors reserved for significant results (p &lt; 0.05 or key findings)\nLight colors for non-significant or background data\nSaturation hierarchy matches data importance\nMaximum 3 base colors (not counting saturation variants)\nLogical semantic meaning (e.g., red=up, blue=down; maintained across all figures)\nWorks in grayscale (test by converting)\nColorblind accessible (test with simulator)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2: The Language of Color</span>"
    ]
  },
  {
    "objectID": "Chapter 2.html#continuous-vs.-discrete-color-scales",
    "href": "Chapter 2.html#continuous-vs.-discrete-color-scales",
    "title": "Chapter 2: The Language of Color",
    "section": "2.5 Continuous vs. Discrete Color Scales",
    "text": "2.5 Continuous vs. Discrete Color Scales\n\nUnderstanding the Distinction\nThe choice between continuous and discrete color scales is not aesthetic—it’s determined by your data type. Using the wrong scale type can fundamentally misrepresent your data and mislead readers.\n\n\n\nContinuous Color Scales (Sequential/Diverging Gradients)\nUse for: Truly continuous numerical data\nData types: - Temperature measurements (15.3°C, 15.4°C, 15.5°C…) - Gene expression levels (FPKM: 0.1, 2.3, 45.8, 123.4…) - Concentration gradients (0.01 μM to 100 μM) - Correlation coefficients (-1.0 to +1.0) - Probability values (0.0 to 1.0) - Any measurement on a continuous scale\nKey characteristic: Values can take any point along a spectrum, including intermediate values.\nVisual representation: Smooth gradient with no discrete boundaries\n\n\n\nWhen Continuous Scales Make Sense\n\nExample 1: Correlation Matrices\nLogical Application:\nCorrelation coefficient r ranges from -1.0 to +1.0\n- Any value in between is possible: -0.87, -0.23, 0.0, 0.45, 0.91\n- Smooth gradient shows strength naturally\n- Diverging palette: Blue (negative) ← White (zero) → Red (positive)\nWhy it’s logical: - Proportional interpretation: Darker red = stronger positive correlation - Continuous nature: Correlation is genuinely continuous - Intuitive reading: Color intensity matches correlation strength\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\n# Generate correlation matrix\nnp.random.seed(42)\nn_vars = 8\nvariables = [f'Var{i+1}' for i in range(n_vars)]\n\n# Create realistic correlation structure\nbase_corr = np.random.randn(n_vars, n_vars) * 0.3\ncorr_matrix = base_corr @ base_corr.T\ncorr_matrix = corr_matrix / np.outer(np.sqrt(np.diag(corr_matrix)),\n                                      np.sqrt(np.diag(corr_matrix)))\nnp.fill_diagonal(corr_matrix, 1.0)\n\n# Continuous scale with logical meaning\nfig, ax = plt.subplots(figsize=(8, 7))\n\n# Use diverging colormap: negative=blue, zero=white, positive=red\nim = ax.imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1, aspect='auto')\n\n# Styling\nax.set_xticks(range(n_vars))\nax.set_yticks(range(n_vars))\nax.set_xticklabels(variables, rotation=45, ha='right', fontsize=10)\nax.set_yticklabels(variables, fontsize=10)\n\n# Add correlation values\nfor i in range(n_vars):\n    for j in range(n_vars):\n        text_color = 'white' if abs(corr_matrix[i, j]) &gt; 0.5 else 'black'\n        ax.text(j, i, f'{corr_matrix[i, j]:.2f}',\n                ha='center', va='center', fontsize=9,\n                color=text_color, fontweight='bold' if abs(corr_matrix[i, j]) &gt; 0.7 else 'normal')\n\n# Colorbar with clear interpretation\ncbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\ncbar.set_label('Correlation Coefficient (r)', fontsize=11, fontweight='bold')\ncbar.ax.axhline(0, color='black', linewidth=2, linestyle='-')  # Highlight zero\n\nax.set_title('CONTINUOUS SCALE: Correlation Matrix\\n(Smooth gradient shows continuous relationship)',\n             fontsize=12, fontweight='bold', pad=15)\n\nplt.tight_layout()\nplt.savefig('continuous_correlation.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R):\nlibrary(ggplot2)\nlibrary(reshape2)\nlibrary(dplyr)\n\n# Generate correlation matrix\nset.seed(42)\nn_vars &lt;- 8\nvariables &lt;- paste0('Var', 1:n_vars)\n\nbase_corr &lt;- matrix(rnorm(n_vars^2, 0, 0.3), n_vars, n_vars)\ncorr_matrix &lt;- base_corr %*% t(base_corr)\ncorr_matrix &lt;- corr_matrix / outer(sqrt(diag(corr_matrix)), sqrt(diag(corr_matrix)))\ndiag(corr_matrix) &lt;- 1.0\n\n# Convert to long format\nrownames(corr_matrix) &lt;- colnames(corr_matrix) &lt;- variables\ncorr_long &lt;- melt(corr_matrix, varnames = c('Var1', 'Var2'), value.name = 'correlation')\n\n# Plot with continuous scale\np &lt;- ggplot(corr_long, aes(x = Var2, y = Var1, fill = correlation)) +\n  geom_tile(color = 'white', size = 0.5) +\n\n  # Continuous diverging scale\n  scale_fill_gradient2(\n    low = '#2166AC',      # Blue (negative)\n    mid = 'white',        # White (zero)\n    high = '#B2182B',     # Red (positive)\n    midpoint = 0,\n    limits = c(-1, 1),\n    name = 'Correlation\\nCoefficient (r)'\n  ) +\n\n  # Add text labels\n  geom_text(aes(label = sprintf('%.2f', correlation)),\n            size = 3,\n            color = ifelse(abs(corr_long$correlation) &gt; 0.5, 'white', 'black'),\n            fontface = ifelse(abs(corr_long$correlation) &gt; 0.7, 'bold', 'plain')) +\n\n  labs(title = 'CONTINUOUS SCALE: Correlation Matrix\\n(Smooth gradient shows continuous relationship)') +\n\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 12),\n    axis.title = element_blank(),\n    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),\n    panel.grid = element_blank(),\n    legend.position = 'right'\n  ) +\n  coord_fixed()\n\nggsave('continuous_correlation.png', p, width = 9, height = 7,\n       dpi = 300, bg = 'white')\n\n\n\nExample 2: Gene Expression Heatmaps\nLogical Application:\nExpression level (FPKM/TPM) is genuinely continuous\n- Values: 0.1, 1.3, 5.7, 23.4, 156.8...\n- Often log-transformed for visualization (log2 or log10)\n- Sequential gradient shows intensity naturally\nWhy continuous scale is appropriate: - Expression can take any positive value - Smooth transitions reflect biological reality - Color intensity proportional to expression level\nImportant: Add significance layer with saturation (from 2.3)\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\n# Simulate gene expression data\nnp.random.seed(42)\nn_genes = 30\nn_samples = 8\n\n# Log2-transformed expression values (continuous)\nexpression = np.random.lognormal(mean=2, sigma=1.5, size=(n_genes, n_samples))\nlog2_expr = np.log2(expression + 1)\n\n# Simulate p-values for differential expression\np_values = np.random.uniform(0, 0.15, n_genes)\nsignificant = p_values &lt; 0.05\n\n# Gene and sample names\ngenes = [f'Gene{i+1}' for i in range(n_genes)]\nsamples = [f'S{i+1}' for i in range(n_samples)]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 8))\n\n# Panel A: Standard continuous heatmap (all genes equal visual weight)\nax1 = axes[0]\nim1 = ax1.imshow(log2_expr, cmap='YlOrRd', aspect='auto')\nax1.set_xticks(range(n_samples))\nax1.set_yticks(range(n_genes))\nax1.set_xticklabels(samples, fontsize=8)\nax1.set_yticklabels(genes, fontsize=7)\nax1.set_xlabel('Samples', fontsize=10, fontweight='bold')\nax1.set_ylabel('Genes', fontsize=10, fontweight='bold')\nax1.set_title('CONTINUOUS: Standard Heatmap\\n(All genes equal visual weight)',\n              fontsize=11, fontweight='bold')\n\ncbar1 = plt.colorbar(im1, ax=ax1, fraction=0.046)\ncbar1.set_label('Log₂ Expression', fontsize=10, fontweight='bold')\n\n# Panel B: Enhanced with significance (deep colors for significant only)\nax2 = axes[1]\n\n# Create custom colormap: deep colors for significant, light for non-significant\nexpression_colored = np.zeros((n_genes, n_samples, 3))\n\n# Normalize expression for color mapping\nexpr_norm = (log2_expr - log2_expr.min()) / (log2_expr.max() - log2_expr.min())\n\nfor i in range(n_genes):\n    for j in range(n_samples):\n        intensity = expr_norm[i, j]\n\n        if significant[i]:  # Significant: deep red gradient\n            # Deep red scale\n            expression_colored[i, j] = [\n                0.2 + intensity * 0.6,  # R: 0.2 to 0.8\n                0.1 * (1 - intensity),  # G: decrease with intensity\n                0.1 * (1 - intensity)   # B: decrease with intensity\n            ]\n        else:  # Non-significant: light pink gradient\n            # Light pink scale\n            expression_colored[i, j] = [\n                0.95,                    # R: always high (pink)\n                0.7 + intensity * 0.25,  # G: light\n                0.7 + intensity * 0.25   # B: light\n            ]\n\nax2.imshow(expression_colored, aspect='auto')\nax2.set_xticks(range(n_samples))\nax2.set_yticks(range(n_genes))\nax2.set_xticklabels(samples, fontsize=8)\nax2.set_yticklabels(genes, fontsize=7)\nax2.set_xlabel('Samples', fontsize=10, fontweight='bold')\nax2.set_ylabel('Genes', fontsize=10, fontweight='bold')\nax2.set_title('CONTINUOUS + SIGNIFICANCE:\\n(Deep colors = p&lt;0.05, Light = non-sig)',\n              fontsize=11, fontweight='bold', color='green')\n\n# Add significance markers\nfor i in range(n_genes):\n    if significant[i]:\n        ax2.text(-1.5, i, '***', fontsize=10, fontweight='bold',\n                ha='center', va='center', color='red')\n\nplt.tight_layout()\nplt.savefig('continuous_expression_heatmap.png', dpi=300,\n            bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R):\nlibrary(ggplot2)\nlibrary(reshape2)\nlibrary(dplyr)\nlibrary(patchwork)\n\n# Simulate gene expression data\nset.seed(42)\nn_genes &lt;- 30\nn_samples &lt;- 8\n\nexpression &lt;- matrix(rlnorm(n_genes * n_samples, meanlog=2, sdlog=1.5),\n                     nrow=n_genes, ncol=n_samples)\nlog2_expr &lt;- log2(expression + 1)\n\n# P-values\np_values &lt;- runif(n_genes, 0, 0.15)\nsignificant &lt;- p_values &lt; 0.05\n\n# Names\ngenes &lt;- paste0('Gene', 1:n_genes)\nsamples &lt;- paste0('S', 1:n_samples)\n\n# Convert to long format\ncolnames(log2_expr) &lt;- samples\nrownames(log2_expr) &lt;- genes\n\nexpr_long &lt;- log2_expr %&gt;%\n  as.data.frame() %&gt;%\n  tibble::rownames_to_column('Gene') %&gt;%\n  melt(id.vars = 'Gene', variable.name = 'Sample', value.name = 'Expression') %&gt;%\n  mutate(Gene = factor(Gene, levels = genes))\n\n# Add significance\nexpr_long &lt;- expr_long %&gt;%\n  left_join(\n    data.frame(Gene = genes, p_value = p_values, significant = significant),\n    by = 'Gene'\n  )\n\n# Panel A: Standard continuous heatmap\np1 &lt;- ggplot(expr_long, aes(x = Sample, y = Gene, fill = Expression)) +\n  geom_tile(color = 'white', size = 0.5) +\n  scale_fill_gradientn(\n    colors = c('#FFFFCC', '#FFEDA0', '#FED976', '#FEB24C', '#FD8D3C', '#FC4E2A', '#E31A1C', '#B10026'),\n    name = 'Log₂\\nExpression'\n  ) +\n  labs(title = 'CONTINUOUS: Standard Heatmap\\n(All genes equal visual weight)') +\n  theme_minimal(base_size = 10) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 11),\n    axis.title = element_text(face = 'bold', size = 10),\n    axis.text.y = element_text(size = 7),\n    axis.text.x = element_text(size = 8),\n    panel.grid = element_blank()\n  )\n\n# Panel B: With significance (deep vs light colors)\nexpr_long &lt;- expr_long %&gt;%\n  mutate(\n    # Scale expression 0-1\n    expr_norm = (Expression - min(Expression)) / (max(Expression) - min(Expression)),\n    # Color based on significance\n    color = case_when(\n      significant ~ rgb(0.2 + expr_norm * 0.6, 0.1 * (1 - expr_norm), 0.1 * (1 - expr_norm)),\n      TRUE ~ rgb(0.95, 0.7 + expr_norm * 0.25, 0.7 + expr_norm * 0.25)\n    )\n  )\n\np2 &lt;- ggplot(expr_long, aes(x = Sample, y = Gene)) +\n  geom_tile(aes(fill = color), color = 'white', size = 0.5) +\n  scale_fill_identity() +\n  labs(title = 'CONTINUOUS + SIGNIFICANCE\\n(Deep colors = p&lt;0.05, Light = non-sig)') +\n  theme_minimal(base_size = 10) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 11, color = 'darkgreen'),\n    axis.title = element_text(face = 'bold', size = 10),\n    axis.text.y = element_text(size = 7),\n    axis.text.x = element_text(size = 8),\n    panel.grid = element_blank()\n  )\n\n# Add significance markers\nsig_genes &lt;- expr_long %&gt;%\n  filter(significant) %&gt;%\n  distinct(Gene)\n\np2 &lt;- p2 +\n  geom_text(data = sig_genes, aes(x = 0, y = Gene, label = '***'),\n            size = 3.5, fontface = 'bold', color = 'red', hjust = 1)\n\n# Combine\ncombined &lt;- p1 | p2\nggsave('continuous_expression_heatmap.png', combined, width = 14, height = 8,\n       dpi = 300, bg = 'white')\n\n\n\n\nDiscrete Color Scales (Categorical Palettes)\nUse for: Truly categorical data with distinct, unordered groups\nData types: - Species names (Homo sapiens, Mus musculus, Drosophila…) - Treatment groups (Control, Drug A, Drug B, Placebo) - Cell types (Neurons, Astrocytes, Microglia, Endothelial) - Geographic regions (North, South, East, West) - Genotypes (Wild-type, Heterozygous, Homozygous mutant)\nKey characteristic: Values are distinct categories with no inherent ordering or intermediate states.\nVisual representation: Distinct, non-gradient colors\n\n\n\nWhen Discrete Scales Make Sense\n\nExample 1: Cell Type Identification\nLogical Application:\nCell types are categorical:\n- A cell is a neuron OR an astrocyte, not \"half-neuron, half-astrocyte\"\n- No intermediate states or smooth transitions\n- Each type needs a distinct, recognizable color\nWhy discrete scale is logical: - Categories are mutually exclusive - No quantitative relationship between categories - Distinct colors prevent false impression of ordering\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Simulate spatial cell type data (e.g., from microscopy or spatial transcriptomics)\nnp.random.seed(42)\nn_cells = 500\n\n# Spatial coordinates\nx = np.random.rand(n_cells) * 100\ny = np.random.rand(n_cells) * 100\n\n# Cell types (categorical - mutually exclusive)\ncell_types = np.random.choice(['Neuron', 'Astrocyte', 'Microglia', 'Oligodendrocyte', 'Endothelial'],\n                              size=n_cells, p=[0.35, 0.25, 0.15, 0.15, 0.10])\n\n# DISCRETE colors for categorical data (Okabe-Ito colorblind-safe palette)\ncolor_map = {\n    'Neuron': '#E69F00',         # Orange\n    'Astrocyte': '#56B4E9',      # Sky blue\n    'Microglia': '#009E73',      # Green\n    'Oligodendrocyte': '#F0E442', # Yellow\n    'Endothelial': '#CC79A7'     # Pink\n}\n\ncolors = [color_map[ct] for ct in cell_types]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# BAD: Continuous colormap for categorical data\nax1 = axes[0]\ncell_type_numeric = np.array([list(color_map.keys()).index(ct) for ct in cell_types])\nscatter1 = ax1.scatter(x, y, c=cell_type_numeric, cmap='viridis', s=50, alpha=0.7)\nax1.set_xlabel('X Position (μm)', fontsize=11, fontweight='bold')\nax1.set_ylabel('Y Position (μm)', fontsize=11, fontweight='bold')\nax1.set_title('BAD: Continuous Scale for Categories\\n(Implies false ordering/gradient)',\n              fontsize=12, fontweight='bold', color='red')\ncbar1 = plt.colorbar(scatter1, ax=ax1)\ncbar1.set_label('Cell Type (?)', fontsize=10)\nax1.set_aspect('equal')\n\n# GOOD: Discrete colors for categorical data\nax2 = axes[1]\nfor cell_type, color in color_map.items():\n    mask = cell_types == cell_type\n    ax2.scatter(x[mask], y[mask], c=color, s=50, alpha=0.7,\n               label=cell_type, edgecolors='black', linewidths=0.5)\n\nax2.set_xlabel('X Position (μm)', fontsize=11, fontweight='bold')\nax2.set_ylabel('Y Position (μm)', fontsize=11, fontweight='bold')\nax2.set_title('GOOD: Discrete Colors for Categories\\n(Each type distinct and recognizable)',\n              fontsize=12, fontweight='bold', color='green')\nax2.legend(loc='upper right', frameon=True, fontsize=9, title='Cell Type',\n          title_fontsize=10, edgecolor='black')\nax2.set_aspect('equal')\n\nplt.tight_layout()\nplt.savefig('discrete_cell_types.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R):\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n\n# Simulate spatial cell type data\nset.seed(42)\nn_cells &lt;- 500\n\ndata &lt;- data.frame(\n  x = runif(n_cells, 0, 100),\n  y = runif(n_cells, 0, 100),\n  cell_type = sample(c('Neuron', 'Astrocyte', 'Microglia', 'Oligodendrocyte', 'Endothelial'),\n                     size = n_cells, replace = TRUE,\n                     prob = c(0.35, 0.25, 0.15, 0.15, 0.10))\n)\n\n# Discrete colors (Okabe-Ito palette)\ncolor_map &lt;- c(\n  'Neuron' = '#E69F00',\n  'Astrocyte' = '#56B4E9',\n  'Microglia' = '#009E73',\n  'Oligodendrocyte' = '#F0E442',\n  'Endothelial' = '#CC79A7'\n)\n\n# BAD: Treating categorical as continuous\ndata$cell_type_numeric &lt;- as.numeric(factor(data$cell_type))\n\np1 &lt;- ggplot(data, aes(x = x, y = y, color = cell_type_numeric)) +\n  geom_point(size = 2.5, alpha = 0.7) +\n  scale_color_viridis_c(name = 'Cell Type (?)') +\n  labs(x = 'X Position (μm)', y = 'Y Position (μm)',\n       title = 'BAD: Continuous Scale for Categories\\n(Implies false ordering/gradient)') +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 12),\n    axis.title = element_text(face = 'bold'),\n    aspect.ratio = 1\n  )\n\n# GOOD: Discrete colors\np2 &lt;- ggplot(data, aes(x = x, y = y, color = cell_type)) +\n  geom_point(size = 2.5, alpha = 0.7) +\n  scale_color_manual(values = color_map, name = 'Cell Type') +\n  labs(x = 'X Position (μm)', y = 'Y Position (μm)',\n       title = 'GOOD: Discrete Colors for Categories\\n(Each type distinct and recognizable)') +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 12),\n    axis.title = element_text(face = 'bold'),\n    legend.position = c(0.85, 0.85),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    aspect.ratio = 1\n  )\n\n# Combine\ncombined &lt;- p1 | p2\nggsave('discrete_cell_types.png', combined, width = 14, height = 6,\n       dpi = 300, bg = 'white')\n\n\n\n\nCommon Mistakes: Mixing Continuous and Discrete\nMistake 1: Using continuous scale for categories\n❌ BAD EXAMPLE:\nTreatment groups (A, B, C, D) colored with rainbow gradient\n→ Implies ordering: \"B is between A and C\"\n→ Misleading when no such relationship exists\n\n✓ FIX:\nUse distinct colors from qualitative palette (Set2, Dark2, Okabe-Ito)\nMistake 2: Using discrete colors for continuous data\n❌ BAD EXAMPLE:\nTemperature data (15°C, 16°C, 17°C...) with 3 discrete colors (blue, yellow, red)\n→ Creates false boundaries: \"Below 20°=blue, 20-25°=yellow, above 25°=red\"\n→ Loses precision of continuous measurement\n\n✓ FIX:\nUse continuous gradient (sequential colormap: light blue → dark blue)\n\n\n\nDecision Matrix: Continuous vs. Discrete\n\n\n\n\n\n\n\n\n\nQuestion\nAnswer\nScale Type\nExample\n\n\n\n\nCan data take intermediate values?\nYes\nContinuous\nTemperature: 25.7°C\n\n\nAre categories mutually exclusive?\nYes\nDiscrete\nSpecies: Human OR Mouse\n\n\nIs there natural ordering?\nYes (quantitative)\nContinuous\nConcentration: 0-100 μM\n\n\nIs there natural ordering?\nYes (categorical)\nDiscrete Sequential\nDisease: Mild/Moderate/Severe\n\n\nIs zero/midpoint meaningful?\nYes\nContinuous Diverging\nFold change: -2x to +2x\n\n\nDo you need exact value reading?\nYes\nContinuous\nGene expression levels\n\n\nDo you need category identification?\nYes\nDiscrete\nTreatment groups\n\n\n\n\n\n\nExercise 2.5.1: Scale Type Classification\nObjective: Practice identifying appropriate scale types and justifying choices\nInstructions:\nFor each dataset, determine: 1. Is data continuous or categorical? 2. If continuous: sequential or diverging? 3. If categorical: qualitative or ordinal? 4. What colormap would you use? 5. What would happen if you used the wrong scale type?\nDatasets:\nA. Soil pH measurements across a field - Values: 4.2, 5.8, 6.1, 6.9, 7.3, 8.1 - Range: 0-14\nB. Voting preference in an election - Categories: Candidate A, Candidate B, Candidate C, Undecided\nC. Protein abundance change after treatment - Values: -3.2x, -1.5x, +0.2x, +2.1x, +4.8x fold-change - Reference: 1x (no change)\nD. Animal species observed in a habitat - Categories: Deer, Rabbit, Fox, Squirrel, Bird\nE. Pain scale reported by patients - Categories: None, Mild, Moderate, Severe, Extreme\nFormat your answer like this:\nDataset A: Soil pH\n- Data type: Continuous numerical\n- Scale type: Sequential continuous\n- Colormap: Single-hue gradient (e.g., Yellow-Green-Blue for pH)\n- Justification: pH is genuinely continuous; any intermediate value possible\n- Wrong scale consequences: If discrete → false boundaries (e.g., \"acidic\" vs \"neutral\")\n  where transition is actually gradual\n\nDataset E: Pain scale\n- Data type: Ordinal categorical\n- Scale type: Discrete sequential (ordered categories)\n- Colormap: Light → Dark single hue (e.g., light yellow → deep red)\n- Justification: Clear ordering but categories are discrete (no \"2.5\" pain level)\n- Wrong scale consequences: If continuous gradient → implies precision that doesn't exist\n\nEnd of Section 2.5\nKey Takeaways: - Continuous scales for data that can take any value in a range - Discrete scales for mutually exclusive categories - Never mix types: Using continuous for categorical (or vice versa) misrepresents data - Significance matters: Layer saturation hierarchy onto continuous scales - Semantic logic: Color choices must match data meaning (correlation: blue-white-red, categories: distinct hues)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2: The Language of Color</span>"
    ]
  },
  {
    "objectID": "Chapter 2.html#color-in-context-scientific-taste-and-discipline-conventions",
    "href": "Chapter 2.html#color-in-context-scientific-taste-and-discipline-conventions",
    "title": "Chapter 2: The Language of Color",
    "section": "2.6 Color in Context: Scientific Taste and Discipline Conventions",
    "text": "2.6 Color in Context: Scientific Taste and Discipline Conventions\n\nThe Unwritten Rules of Scientific Color Use\nWhile color theory provides the technical foundation, successful scientific figures must also navigate field-specific conventions and aesthetic expectations that signal professionalism and credibility. This isn’t about arbitrary preferences—these conventions have evolved to facilitate rapid interpretation within specialized communities.\n\n\n\nWhat is “Scientific Taste” in Color?\nScientific taste refers to the collectively accepted color practices that:\n\nSignal competence: Proper use shows you understand your field\nFacilitate communication: Readers interpret colors according to learned conventions\nConvey rigor: Conservative, purposeful color use suggests careful analysis\nEnable comparison: Consistent schemes across literature allow mental cross-referencing\n\nNot scientific taste: - Personal aesthetic preferences - Trendy design styles - Decorative color choices - Maximum visual impact regardless of clarity\n\n\n\nCore Principles of Scientific Color Taste\n\nPrinciple 1: Conservation (Restraint Over Abundance)\nThe Rule: Use the minimum number of colors necessary to convey information.\nWhy it signals quality:\nToo many colors suggests:\n- Lack of focus (unclear message)\n- Inexperience (not understanding conventions)\n- Trying to impress rather than inform\n\nRestrained color use suggests:\n- Clear thinking (one message, one figure)\n- Confidence (don't need flashiness)\n- Respect for reader's cognitive load\nQuantitative Guidelines:\n\n\n\n\n\n\n\n\nFigure Type\nRecommended Max Colors\nRationale\n\n\n\n\nSingle plot\n3-4 distinct hues\nBeyond this, legend becomes confusing\n\n\nMulti-panel (related)\n3-4 across all panels\nConsistency aids interpretation\n\n\nMulti-panel (diverse)\n2-3 per panel\nEach panel can have its own scheme if data types differ\n\n\nHeatmap\n1 gradient (sequential or diverging)\nContinuous data needs smooth scale\n\n\n\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\ntime = np.arange(0, 24, 2)\n\n# Simulate experimental data\nn_groups = 3  # Restrained: only 3 groups shown\n\ndata = {\n    'Control': 100 + np.cumsum(np.random.randn(len(time)) * 3),\n    'Treatment A': 100 + np.cumsum(np.random.randn(len(time)) * 3 + 0.8),\n    'Treatment B': 100 + np.cumsum(np.random.randn(len(time)) * 3 + 1.5)\n}\n\n# GOOD: Restrained palette (3 colors max, grayscale for non-essential)\nCOLORS_GOOD = {\n    'Control': '#7F8C8D',      # Gray (reference)\n    'Treatment A': '#3498DB',  # Blue\n    'Treatment B': '#E74C3C'   # Red\n}\n\n# BAD: Excessive colors (trying to show too much at once)\ndata_bad = {**data, **{\n    'Treatment C': 100 + np.cumsum(np.random.randn(len(time)) * 3 + 0.5),\n    'Treatment D': 100 + np.cumsum(np.random.randn(len(time)) * 3 + 0.3),\n    'Treatment E': 100 + np.cumsum(np.random.randn(len(time)) * 3 + 1.0),\n    'Treatment F': 100 + np.cumsum(np.random.randn(len(time)) * 3 + 0.7)\n}}\n\nCOLORS_BAD = {\n    'Control': '#7F8C8D',\n    'Treatment A': '#3498DB',\n    'Treatment B': '#E74C3C',\n    'Treatment C': '#F39C12',\n    'Treatment D': '#8E44AD',\n    'Treatment E': '#16A085',\n    'Treatment F': '#D35400'\n}\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# BAD: Too many groups/colors\nax1 = axes[0]\nfor group, values in data_bad.items():\n    ax1.plot(time, values, marker='o', linewidth=2, markersize=5,\n            color=COLORS_BAD[group], label=group)\n\nax1.set_xlabel('Time (hours)', fontsize=11, fontweight='bold')\nax1.set_ylabel('Response (%)', fontsize=11, fontweight='bold')\nax1.set_title('BAD: Too Many Colors\\n(Cognitive overload, unclear message)',\n             fontsize=12, fontweight='bold', color='red')\nax1.legend(loc='upper left', fontsize=8, ncol=2, frameon=True)\nax1.grid(alpha=0.3)\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# GOOD: Restrained (3 colors)\nax2 = axes[1]\nfor group, values in data.items():\n    ax2.plot(time, values, marker='o', linewidth=2.5, markersize=6,\n            color=COLORS_GOOD[group], label=group)\n\nax2.set_xlabel('Time (hours)', fontsize=11, fontweight='bold')\nax2.set_ylabel('Response (%)', fontsize=11, fontweight='bold')\nax2.set_title('GOOD: Restrained Color Use\\n(Clear, focused message)',\n             fontsize=12, fontweight='bold', color='green')\nax2.legend(loc='upper left', fontsize=9, frameon=True)\nax2.grid(alpha=0.3)\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\n\nplt.tight_layout()\nplt.savefig('color_restraint_principle.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R):\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(patchwork)\n\nset.seed(42)\ntime &lt;- seq(0, 24, by = 2)\n\n# GOOD: 3 groups only\ndata_good &lt;- data.frame(\n  time = rep(time, 3),\n  response = c(\n    100 + cumsum(rnorm(length(time), 0, 3)),\n    100 + cumsum(rnorm(length(time), 0.8, 3)),\n    100 + cumsum(rnorm(length(time), 1.5, 3))\n  ),\n  group = rep(c('Control', 'Treatment A', 'Treatment B'), each = length(time))\n)\n\nCOLORS_GOOD &lt;- c(\n  'Control' = '#7F8C8D',\n  'Treatment A' = '#3498DB',\n  'Treatment B' = '#E74C3C'\n)\n\n# BAD: 7 groups (too many)\ndata_bad &lt;- data.frame(\n  time = rep(time, 7),\n  response = c(\n    100 + cumsum(rnorm(length(time), 0, 3)),\n    100 + cumsum(rnorm(length(time), 0.8, 3)),\n    100 + cumsum(rnorm(length(time), 1.5, 3)),\n    100 + cumsum(rnorm(length(time), 0.5, 3)),\n    100 + cumsum(rnorm(length(time), 0.3, 3)),\n    100 + cumsum(rnorm(length(time), 1.0, 3)),\n    100 + cumsum(rnorm(length(time), 0.7, 3))\n  ),\n  group = rep(c('Control', 'Treatment A', 'Treatment B', 'Treatment C',\n                'Treatment D', 'Treatment E', 'Treatment F'), each = length(time))\n)\n\nCOLORS_BAD &lt;- c(\n  'Control' = '#7F8C8D',\n  'Treatment A' = '#3498DB',\n  'Treatment B' = '#E74C3C',\n  'Treatment C' = '#F39C12',\n  'Treatment D' = '#8E44AD',\n  'Treatment E' = '#16A085',\n  'Treatment F' = '#D35400'\n)\n\n# BAD plot\np1 &lt;- ggplot(data_bad, aes(x = time, y = response, color = group)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 3) +\n  scale_color_manual(values = COLORS_BAD) +\n  labs(x = 'Time (hours)', y = 'Response (%)',\n       title = 'BAD: Too Many Colors\\n(Cognitive overload, unclear message)',\n       color = NULL) +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 12),\n    axis.title = element_text(face = 'bold'),\n    legend.position = c(0.15, 0.85),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\n# GOOD plot\np2 &lt;- ggplot(data_good, aes(x = time, y = response, color = group)) +\n  geom_line(size = 1.5) +\n  geom_point(size = 4) +\n  scale_color_manual(values = COLORS_GOOD) +\n  labs(x = 'Time (hours)', y = 'Response (%)',\n       title = 'GOOD: Restrained Color Use\\n(Clear, focused message)',\n       color = NULL) +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 12),\n    axis.title = element_text(face = 'bold'),\n    legend.position = c(0.15, 0.85),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\ncombined &lt;- p1 | p2\nggsave('color_restraint_principle.png', combined, width = 14, height = 5,\n       dpi = 300, bg = 'white')\n\n\n\nPrinciple 2: Semantic Consistency (Color = Meaning)\nThe Rule: Establish color-concept associations and maintain them throughout your entire manuscript.\nWhy it matters:\nReader mental model:\nFigure 1: \"Blue = Treatment A\"\n[Reads text, looks at Figure 2]\nFigure 2: \"Blue = Treatment A\" (same)\n→ Instant recognition, no re-learning\n\nInconsistent approach:\nFigure 1: \"Blue = Treatment A\"\nFigure 2: \"Red = Treatment A\" (changed!)\n→ Confusion, constant cross-referencing, error-prone\nSemantic Logic Examples:\nTemperature-related:\n✓ Blue = Cold/Low\n✓ Red = Hot/High\n✗ Never reverse this (culturally ingrained)\nBiological expression:\n✓ Red = Upregulated/Increased\n✓ Blue/Green = Downregulated/Decreased\n✓ Gray = No change/Control\nClinical outcomes:\n✓ Green = Healthy/Improved\n✓ Red = Disease/Worsened\n✓ Gray = Baseline\nStatistical significance:\n✓ Deep/saturated = Significant (p&lt;0.05)\n✓ Light/desaturated = Non-significant\n✓ Consistent across all figures\nCode Example (Python) - Manuscript-Wide Consistency:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# ============================================\n# DEFINE COLORS ONCE - USE THROUGHOUT MANUSCRIPT\n# ============================================\n\n# Global color scheme for entire paper\nMANUSCRIPT_COLORS = {\n    # Treatment groups (consistent across ALL figures)\n    'Control': '#95A5A6',        # Gray\n    'Drug_A': '#3498DB',         # Blue\n    'Drug_B': '#E74C3C',         # Red\n\n    # Expression levels\n    'Upregulated': '#C0392B',    # Deep red\n    'Downregulated': '#2874A6',  # Deep blue\n    'Unchanged': '#D5D8DC',      # Light gray\n\n    # Significance\n    'Significant': '#E67E22',    # Orange (highlights)\n    'NonSignificant': '#ECF0F1'  # Very light gray\n}\n\n# ============================================\n# FIGURE 1: Time Course\n# ============================================\n\nnp.random.seed(42)\ntime = np.arange(0, 24, 2)\n\ndata_fig1 = {\n    'Control': 100 + np.cumsum(np.random.randn(len(time)) * 2),\n    'Drug_A': 100 + np.cumsum(np.random.randn(len(time)) * 2 + 0.5),\n    'Drug_B': 100 + np.cumsum(np.random.randn(len(time)) * 2 + 1.0)\n}\n\nfig1, ax1 = plt.subplots(figsize=(7, 5))\n\nfor group, values in data_fig1.items():\n    ax1.plot(time, values, marker='o', linewidth=2.5, markersize=6,\n            color=MANUSCRIPT_COLORS[group], label=group)\n\nax1.set_xlabel('Time (hours)', fontsize=11, fontweight='bold')\nax1.set_ylabel('Cell Viability (%)', fontsize=11, fontweight='bold')\nax1.set_title('Figure 1: Time Course Analysis\\n(Colors: Control=Gray, Drug A=Blue, Drug B=Red)',\n             fontsize=12, fontweight='bold')\nax1.legend(loc='upper left', fontsize=10, frameon=True)\nax1.grid(alpha=0.3)\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\nplt.tight_layout()\nplt.savefig('manuscript_fig1_consistent_colors.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\n\n# ============================================\n# FIGURE 2: Endpoint Comparison (SAME COLORS)\n# ============================================\n\nfig2, ax2 = plt.subplots(figsize=(6, 5))\n\ngroups = ['Control', 'Drug_A', 'Drug_B']\nendpoint_values = [85, 92, 78]\nerrors = [5, 4, 6]\n\n# Use SAME colors from MANUSCRIPT_COLORS\nbar_colors = [MANUSCRIPT_COLORS[g] for g in groups]\n\nbars = ax2.bar(groups, endpoint_values, color=bar_colors,\n              edgecolor='black', linewidth=1.5, width=0.6)\nax2.errorbar(groups, endpoint_values, yerr=errors, fmt='none',\n            ecolor='black', capsize=8, linewidth=2)\n\nax2.set_ylabel('Final Viability (%)', fontsize=11, fontweight='bold')\nax2.set_title('Figure 2: Endpoint Comparison\\n(SAME colors as Figure 1 for consistency)',\n             fontsize=12, fontweight='bold')\nax2.set_ylim(0, 110)\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\nax2.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('manuscript_fig2_consistent_colors.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Colors consistent across Figures 1 and 2\")\nprint(\"✓ Control always Gray, Drug_A always Blue, Drug_B always Red\")\nCode Example (R) - Manuscript-Wide Consistency:\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n\n# ============================================\n# DEFINE COLORS ONCE - USE THROUGHOUT MANUSCRIPT\n# ============================================\n\nMANUSCRIPT_COLORS &lt;- list(\n  # Treatment groups\n  Control = '#95A5A6',\n  Drug_A = '#3498DB',\n  Drug_B = '#E74C3C',\n\n  # Expression\n  Upregulated = '#C0392B',\n  Downregulated = '#2874A6',\n  Unchanged = '#D5D8DC',\n\n  # Significance\n  Significant = '#E67E22',\n  NonSignificant = '#ECF0F1'\n)\n\n# ============================================\n# FIGURE 1: Time Course\n# ============================================\n\nset.seed(42)\ntime &lt;- seq(0, 24, by = 2)\n\ndata_fig1 &lt;- data.frame(\n  time = rep(time, 3),\n  viability = c(\n    100 + cumsum(rnorm(length(time), 0, 2)),\n    100 + cumsum(rnorm(length(time), 0.5, 2)),\n    100 + cumsum(rnorm(length(time), 1.0, 2))\n  ),\n  group = rep(c('Control', 'Drug_A', 'Drug_B'), each = length(time))\n)\n\np1 &lt;- ggplot(data_fig1, aes(x = time, y = viability, color = group)) +\n  geom_line(size = 1.5) +\n  geom_point(size = 4) +\n  scale_color_manual(values = unlist(MANUSCRIPT_COLORS[c('Control', 'Drug_A', 'Drug_B')])) +\n  labs(x = 'Time (hours)', y = 'Cell Viability (%)',\n       title = 'Figure 1: Time Course Analysis\\n(Colors: Control=Gray, Drug A=Blue, Drug B=Red)',\n       color = NULL) +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 12),\n    axis.title = element_text(face = 'bold'),\n    legend.position = c(0.15, 0.85),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\nggsave('manuscript_fig1_consistent_colors.png', p1, width = 7, height = 5,\n       dpi = 300, bg = 'white')\n\n# ============================================\n# FIGURE 2: Endpoint Comparison (SAME COLORS)\n# ============================================\n\ndata_fig2 &lt;- data.frame(\n  group = factor(c('Control', 'Drug_A', 'Drug_B'),\n                levels = c('Control', 'Drug_A', 'Drug_B')),\n  viability = c(85, 92, 78),\n  error = c(5, 4, 6)\n)\n\np2 &lt;- ggplot(data_fig2, aes(x = group, y = viability, fill = group)) +\n  geom_bar(stat = 'identity', color = 'black', size = 1, width = 0.6) +\n  geom_errorbar(aes(ymin = viability - error, ymax = viability + error),\n               width = 0.25, size = 1) +\n  scale_fill_manual(values = unlist(MANUSCRIPT_COLORS[c('Control', 'Drug_A', 'Drug_B')])) +\n  labs(y = 'Final Viability (%)',\n       title = 'Figure 2: Endpoint Comparison\\n(SAME colors as Figure 1 for consistency)') +\n  ylim(0, 110) +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 12),\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(face = 'bold'),\n    legend.position = 'none',\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\nggsave('manuscript_fig2_consistent_colors.png', p2, width = 6, height = 5,\n       dpi = 300, bg = 'white')\n\ncat(\"✓ Colors consistent across Figures 1 and 2\\n\")\ncat(\"✓ Control always Gray, Drug_A always Blue, Drug_B always Red\\n\")\n\n\n\n\nField-Specific Color Conventions\nDifferent scientific disciplines have evolved distinct color conventions. Knowing and following these signals domain expertise.\n\nMolecular Biology & Genomics\nStandard Conventions:\nDNA/RNA/Protein:\n✓ DNA: Blue\n✓ RNA: Red\n✓ Protein: Green or Purple\n\nGene Expression:\n✓ Upregulated: Red spectrum\n✓ Downregulated: Blue/Green spectrum\n✓ No change: Gray/White\n\nWestern Blots:\n✓ Grayscale (mimics X-ray film)\n✓ Or: Single color gradient (e.g., green for fluorescence)\nWhy these conventions: - Historical: DNA gels visualized with UV (blue), RNA with different dyes - Red/green originally from microarray technology (Cy3/Cy5 dyes) - Community agreement for rapid cross-study interpretation\n\n\nNeuroscience\nStandard Conventions:\nCell Types:\n✓ Neurons: Often red or orange\n✓ Astrocytes: Green or cyan\n✓ Microglia: Blue or purple\n\nActivity/Calcium Imaging:\n✓ Low activity: Blue/Purple\n✓ High activity: Yellow/Red (fire scale)\n\n\nClimate Science\nStandard Conventions:\nTemperature Anomalies:\n✓ Cooling: Blue\n✓ Neutral: White/Beige\n✓ Warming: Red/Orange\n(Never reverse this!)\n\nPrecipitation:\n✓ Drought: Brown/Yellow\n✓ Normal: Green\n✓ Excess: Blue\n\nElevation:\n✓ Low: Green/Blue\n✓ Mid: Yellow/Brown\n✓ High: White (snow-capped)\nCode Example - Climate Convention (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Simulate temperature anomaly data\nnp.random.seed(42)\nyears = np.arange(1900, 2024)\ntemp_anomaly = np.cumsum(np.random.randn(len(years)) * 0.1) - 0.5\n\nfig, ax = plt.subplots(figsize=(10, 5))\n\n# Use climate science convention: blue=cooling, red=warming\ncolors = ['#2166AC' if t &lt; 0 else '#B2182B' for t in temp_anomaly]\n\nax.bar(years, temp_anomaly, color=colors, width=1, edgecolor='none')\nax.axhline(0, color='black', linewidth=2, linestyle='-')\n\nax.set_xlabel('Year', fontsize=12, fontweight='bold')\nax.set_ylabel('Temperature Anomaly (°C)', fontsize=12, fontweight='bold')\nax.set_title('Climate Science Convention: Blue=Cooling, Red=Warming\\n(Never reverse this!)',\n             fontsize=13, fontweight='bold')\n\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.grid(axis='y', alpha=0.3)\n\n# Add legend\nfrom matplotlib.patches import Patch\nlegend_elements = [\n    Patch(facecolor='#2166AC', label='Below average (cooling)'),\n    Patch(facecolor='#B2182B', label='Above average (warming)')\n]\nax.legend(handles=legend_elements, loc='upper left', frameon=True, fontsize=10)\n\nplt.tight_layout()\nplt.savefig('climate_convention_colors.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example - Climate Convention (R):\nlibrary(ggplot2)\n\nset.seed(42)\nyears &lt;- 1900:2023\ntemp_anomaly &lt;- cumsum(rnorm(length(years), 0, 0.1)) - 0.5\n\ndata &lt;- data.frame(\n  year = years,\n  anomaly = temp_anomaly,\n  direction = ifelse(temp_anomaly &lt; 0, 'Below average (cooling)', 'Above average (warming)')\n)\n\np &lt;- ggplot(data, aes(x = year, y = anomaly, fill = direction)) +\n  geom_bar(stat = 'identity', width = 1) +\n  geom_hline(yintercept = 0, color = 'black', size = 1.5) +\n  scale_fill_manual(values = c('Below average (cooling)' = '#2166AC',\n                                'Above average (warming)' = '#B2182B')) +\n  labs(x = 'Year', y = 'Temperature Anomaly (°C)',\n       title = 'Climate Science Convention: Blue=Cooling, Red=Warming\\n(Never reverse this!)',\n       fill = NULL) +\n  theme_classic(base_size = 12) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 13),\n    axis.title = element_text(face = 'bold'),\n    legend.position = c(0.2, 0.9),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\nggsave('climate_convention_colors.png', p, width = 10, height = 5,\n       dpi = 300, bg = 'white')\n\n\n\n\nWhen to Break Conventions (Rarely)\nAcceptable reasons to deviate:\n\nAccessibility requirement: Convention uses red-green (colorblind problematic)\n\nSolution: Use blue-orange instead, note change in caption\n\nTechnical constraint: Equipment outputs specific colors\n\nExample: Microscope fluorophores are fixed\nSolution: State actual fluorophore colors in methods, use convention in schematic\n\nConflicting conventions: Interdisciplinary work where fields disagree\n\nSolution: Choose one, state explicitly in caption, be consistent\n\n\nUnacceptable reasons:\n\n“I like purple better than blue”\n“This looks cooler/more modern”\n“To make my figure stand out”\n\nHow to break conventions properly:\n✓ State explicitly in figure caption:\n  \"Note: We use blue for upregulation and red for downregulation\n   (reverse of typical convention) to match the color scheme\n   established in our previous work (Smith et al., 2022)\"\n\n✓ Provide justification in methods section\n\n✓ Ensure internal consistency remains absolute\n\n\n\nExercise 2.6.1: Convention Recognition and Application\nObjective: Identify field conventions and apply them correctly\nPart A: Convention Identification\nFor your field, research and document:\n\nStandard color schemes for common data types (check recent high-impact papers)\nForbidden combinations (colors that would confuse readers)\nHistorical reasons for these conventions (if discoverable)\n\nFormat:\nField: [Your discipline]\n\nConvention 1:\n- Data type: [e.g., Cell viability]\n- Standard colors: [e.g., Green=live, Red=dead]\n- Source: [e.g., Flow cytometry dye convention]\n- Strength: [Strong/Moderate/Weak] (how universal is this?)\n\nForbidden combination:\n- Never use: [e.g., Red for control group in my field]\n- Reason: [e.g., Red always means \"treatment\" or \"diseased\"]\nPart B: Cross-Field Comparison\nFind a paper from a different discipline and analyze:\n\nWhat color conventions differ from yours?\nWhich are universal (e.g., hot=red, cold=blue)?\nIf you had to present your data to that community, what would you change?\n\n\n\n\nSummary: Color Taste Checklist\nBefore finalizing your manuscript’s figures:\n\nMaximum 3-4 distinct hues per figure (excluding grayscale)\nSemantic consistency across all figures (same concept = same color)\nField conventions respected (or explicitly justified if broken)\nColor assignments documented (create a style guide for co-authors)\nNo decorative color (every color has functional meaning)\nWorks in context (looks professional compared to recent papers in target journal)\n\n\nEnd of Section 2.6",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2: The Language of Color</span>"
    ]
  },
  {
    "objectID": "Chapter 2.html#accessibility-and-integrity-in-color",
    "href": "Chapter 2.html#accessibility-and-integrity-in-color",
    "title": "Chapter 2: The Language of Color",
    "section": "2.7 Accessibility and Integrity in Color",
    "text": "2.7 Accessibility and Integrity in Color\n\nThe Ethical Imperative\nColor accessibility isn’t a “nice-to-have” feature—it’s an ethical requirement and increasingly a publication mandate. Approximately 8% of males and 0.5% of females have some form of color vision deficiency (CVD), meaning 1 in 12 men and 1 in 200 women in your audience may struggle with your figures if you don’t design for accessibility.\nWhy this matters for scientific communication:\n\nInclusivity: Exclude 8% of potential readers by default is unacceptable\nInformation integrity: Critical findings should be accessible to all\nJournal requirements: Many journals now mandate colorblind-safe figures\nReproducibility: Accessible figures are clearer for everyone, not just CVD readers\nProfessional standards: Signals rigor and attention to detail\n\n\n\n\nTypes of Color Vision Deficiency\nUnderstanding the types helps you design effectively:\n\n1. Deuteranopia (Green-Blind, ~5% of males)\nWhat’s affected: - Cannot distinguish between red and green - Perceive them as variations of yellow/brown\nProblematic combinations:\n✗ Red vs. Green (appears as yellow vs. yellow)\n✗ Red-green traffic light analogy (both look similar)\nSafe alternatives:\n✓ Blue vs. Orange\n✓ Blue vs. Red (distinguishable by brightness difference)\n✓ Purple vs. Yellow\n\n\n2. Protanopia (Red-Blind, ~2.5% of males)\nWhat’s affected: - Cannot distinguish between red and green - Red appears darker/brownish - Similar confusion to deuteranopia but with brightness shifts\nProblematic combinations:\n✗ Red vs. Green\n✗ Red vs. Orange (both appear similar)\n\n\n3. Tritanopia (Blue-Blind, &lt;1% of population, rare)\nWhat’s affected: - Cannot distinguish between blue and yellow - Blue appears greenish, yellow appears pinkish\nProblematic combinations:\n✗ Blue vs. Yellow\n✗ Blue vs. Green\nNote: Most colorblind-safe palettes focus on deuteranopia/protanopia (most common).\n\n\n\n\nDesigning for Color Accessibility\n\nStrategy 1: Use Colorblind-Safe Palettes\nPre-vetted palettes that work for all CVD types:\nOkabe-Ito Palette (Recommended):\nDesigned specifically for universal accessibility\n8 colors, distinguishable by all CVD types\n\nColors:\n#E69F00  Orange\n#56B4E9  Sky Blue\n#009E73  Bluish Green\n#F0E442  Yellow\n#0072B2  Blue\n#D55E00  Vermilion (red-orange)\n#CC79A7  Reddish Purple\n#000000  Black\nColorBrewer Palettes:\nMany ColorBrewer schemes are CVD-friendly\n- \"Set2\" (qualitative, 8 colors)\n- \"Dark2\" (qualitative, 8 colors)\n- \"RdYlBu\" (diverging, if used correctly)\n\nCheck: colorbrewer2.org has CVD-safe filter\n\nCode Example (Python) - Okabe-Ito Implementation:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Okabe-Ito colorblind-safe palette\nOKABE_ITO = {\n    'orange': '#E69F00',\n    'sky_blue': '#56B4E9',\n    'bluish_green': '#009E73',\n    'yellow': '#F0E442',\n    'blue': '#0072B2',\n    'vermilion': '#D55E00',\n    'reddish_purple': '#CC79A7',\n    'black': '#000000'\n}\n\n# Simulate grouped data\nnp.random.seed(42)\ngroups = ['Control', 'Treatment A', 'Treatment B', 'Treatment C']\nvalues = [25, 32, 28, 35]\nerrors = [3, 4, 3.5, 4.5]\n\n# Assign Okabe-Ito colors\ngroup_colors = [\n    OKABE_ITO['black'],          # Control: Black\n    OKABE_ITO['sky_blue'],       # Treatment A: Sky Blue\n    OKABE_ITO['vermilion'],      # Treatment B: Vermilion\n    OKABE_ITO['bluish_green']    # Treatment C: Bluish Green\n]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Standard view\nax1 = axes[0]\nbars1 = ax1.bar(groups, values, color=group_colors, edgecolor='black', linewidth=1.5)\nax1.errorbar(groups, values, yerr=errors, fmt='none', ecolor='black',\n            capsize=8, linewidth=2)\nax1.set_ylabel('Response (arbitrary units)', fontsize=11, fontweight='bold')\nax1.set_title('Okabe-Ito Palette: Standard View\\n(Colorblind-safe)',\n             fontsize=12, fontweight='bold', color='green')\nax1.set_ylim(0, 45)\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\nax1.grid(axis='y', alpha=0.3)\n\n# Simulated deuteranopia view (approximation)\n# Convert to grayscale perception weights for deuteranopia\ndef simulate_deuteranopia(hex_color):\n    \"\"\"Rough approximation of deuteranopia perception\"\"\"\n    # Convert hex to RGB\n    rgb = tuple(int(hex_color[i:i+2], 16)/255 for i in (1, 3, 5))\n    # Deuteranopia: red and green channels affected\n    # Simplified transformation (not exact)\n    gray = 0.3 * rgb[0] + 0.4 * rgb[1] + 0.3 * rgb[2]\n    adjusted = (rgb[2], gray, rgb[1])  # Shift perception\n    return tuple(min(1, max(0, c)) for c in adjusted)\n\ncvd_colors = [simulate_deuteranopia(c) for c in group_colors]\n\nax2 = axes[1]\nbars2 = ax2.bar(groups, values, color=cvd_colors, edgecolor='black', linewidth=1.5)\nax2.errorbar(groups, values, yerr=errors, fmt='none', ecolor='black',\n            capsize=8, linewidth=2)\nax2.set_ylabel('Response (arbitrary units)', fontsize=11, fontweight='bold')\nax2.set_title('Simulated Deuteranopia View\\n(Colors still distinguishable)',\n             fontsize=12, fontweight='bold', color='green')\nax2.set_ylim(0, 45)\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\nax2.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('okabe_ito_accessibility.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Okabe-Ito palette used\")\nprint(\"✓ Distinguishable by all color vision types\")\nCode Example (R) - Okabe-Ito Implementation:\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Okabe-Ito colorblind-safe palette\nOKABE_ITO &lt;- c(\n  orange = '#E69F00',\n  sky_blue = '#56B4E9',\n  bluish_green = '#009E73',\n  yellow = '#F0E442',\n  blue = '#0072B2',\n  vermilion = '#D55E00',\n  reddish_purple = '#CC79A7',\n  black = '#000000'\n)\n\n# Data\ndata &lt;- data.frame(\n  group = factor(c('Control', 'Treatment A', 'Treatment B', 'Treatment C'),\n                levels = c('Control', 'Treatment A', 'Treatment B', 'Treatment C')),\n  value = c(25, 32, 28, 35),\n  error = c(3, 4, 3.5, 4.5)\n)\n\n# Assign colors\ngroup_colors &lt;- c(\n  'Control' = OKABE_ITO['black'],\n  'Treatment A' = OKABE_ITO['sky_blue'],\n  'Treatment B' = OKABE_ITO['vermilion'],\n  'Treatment C' = OKABE_ITO['bluish_green']\n)\n\n# Plot\np &lt;- ggplot(data, aes(x = group, y = value, fill = group)) +\n  geom_bar(stat = 'identity', color = 'black', size = 1, width = 0.7) +\n  geom_errorbar(aes(ymin = value - error, ymax = value + error),\n               width = 0.3, size = 1) +\n  scale_fill_manual(values = group_colors) +\n  labs(y = 'Response (arbitrary units)',\n       title = 'Okabe-Ito Palette: Colorblind-Safe\\n(Distinguishable by all color vision types)') +\n  ylim(0, 45) +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 12),\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(face = 'bold'),\n    legend.position = 'none',\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\nggsave('okabe_ito_accessibility.png', p, width = 7, height = 5,\n       dpi = 300, bg = 'white')\n\ncat(\"✓ Okabe-Ito palette used\\n\")\ncat(\"✓ Distinguishable by all color vision types\\n\")\n\n\n\nStrategy 2: Redundant Encoding (Color + Something Else)\nThe most robust approach: Never rely on color alone\nRedundant channels: - Color + Shape (circles vs. squares vs. triangles) - Color + Line style (solid vs. dashed vs. dotted) - Color + Pattern/Texture (for bar charts: solid, striped, dotted) - Color + Position (separate panels/facets) - Color + Text labels (direct labeling on plot)\nCode Example (Python) - Redundant Encoding:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\nx = np.linspace(0, 10, 50)\n\n# Three treatment groups\ndata = {\n    'Control': (x, 5 + 0.5*x + np.random.randn(50)*0.5),\n    'Treatment A': (x, 5 + 1.2*x + np.random.randn(50)*0.5),\n    'Treatment B': (x, 5 + 0.8*x + np.random.randn(50)*0.5)\n}\n\n# Okabe-Ito colors\ncolors = {\n    'Control': '#000000',      # Black\n    'Treatment A': '#56B4E9',  # Sky Blue\n    'Treatment B': '#D55E00'   # Vermilion\n}\n\n# Different markers (redundant encoding with shape)\nmarkers = {\n    'Control': 'o',        # Circle\n    'Treatment A': 's',    # Square\n    'Treatment B': '^'     # Triangle\n}\n\n# Different line styles (additional redundancy)\nlinestyles = {\n    'Control': '-',         # Solid\n    'Treatment A': '--',    # Dashed\n    'Treatment B': '-.'     # Dash-dot\n}\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Color only (vulnerable to CVD)\nax1 = axes[0]\nfor group, (x_data, y_data) in data.items():\n    ax1.plot(x_data, y_data, color=colors[group], linewidth=2.5, label=group)\n\nax1.set_xlabel('Time (hours)', fontsize=11, fontweight='bold')\nax1.set_ylabel('Response', fontsize=11, fontweight='bold')\nax1.set_title('COLOR ONLY\\n(Vulnerable if colors indistinguishable)',\n             fontsize=12, fontweight='bold', color='red')\nax1.legend(loc='upper left', frameon=True, fontsize=10)\nax1.grid(alpha=0.3)\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# Color + Shape + Line style (robust, redundant)\nax2 = axes[1]\nfor group, (x_data, y_data) in data.items():\n    ax2.plot(x_data, y_data,\n            color=colors[group],\n            linestyle=linestyles[group],\n            linewidth=2.5,\n            marker=markers[group],\n            markersize=6,\n            markevery=5,  # Show marker every 5th point\n            label=group)\n\nax2.set_xlabel('Time (hours)', fontsize=11, fontweight='bold')\nax2.set_ylabel('Response', fontsize=11, fontweight='bold')\nax2.set_title('COLOR + SHAPE + LINE STYLE\\n(Accessible: multiple redundant cues)',\n             fontsize=12, fontweight='bold', color='green')\nax2.legend(loc='upper left', frameon=True, fontsize=10)\nax2.grid(alpha=0.3)\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\n\nplt.tight_layout()\nplt.savefig('redundant_encoding_accessibility.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Redundant encoding: Color + Shape + Line style\")\nprint(\"✓ Information preserved even if color is lost\")\nCode Example (R) - Redundant Encoding:\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n\nset.seed(42)\nx &lt;- seq(0, 10, length.out = 50)\n\n# Data\ndata &lt;- data.frame(\n  x = rep(x, 3),\n  y = c(\n    5 + 0.5*x + rnorm(50, 0, 0.5),\n    5 + 1.2*x + rnorm(50, 0, 0.5),\n    5 + 0.8*x + rnorm(50, 0, 0.5)\n  ),\n  group = rep(c('Control', 'Treatment A', 'Treatment B'), each = 50)\n)\n\n# Okabe-Ito colors\ncolors &lt;- c(\n  'Control' = '#000000',\n  'Treatment A' = '#56B4E9',\n  'Treatment B' = '#D55E00'\n)\n\n# Color only\np1 &lt;- ggplot(data, aes(x = x, y = y, color = group)) +\n  geom_line(size = 1.5) +\n  scale_color_manual(values = colors) +\n  labs(x = 'Time (hours)', y = 'Response',\n       title = 'COLOR ONLY\\n(Vulnerable if colors indistinguishable)',\n       color = NULL) +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 12),\n    axis.title = element_text(face = 'bold'),\n    legend.position = c(0.2, 0.85),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Color + Shape + Line style (redundant)\np2 &lt;- ggplot(data, aes(x = x, y = y, color = group, linetype = group, shape = group)) +\n  geom_line(size = 1.5) +\n  geom_point(data = data %&gt;% filter(row_number() %% 5 == 0), size = 3) +\n  scale_color_manual(values = colors) +\n  scale_linetype_manual(values = c('Control' = 'solid',\n                                    'Treatment A' = 'dashed',\n                                    'Treatment B' = 'dotdash')) +\n  scale_shape_manual(values = c('Control' = 16, 'Treatment A' = 15, 'Treatment B' = 17)) +\n  labs(x = 'Time (hours)', y = 'Response',\n       title = 'COLOR + SHAPE + LINE STYLE\\n(Accessible: multiple redundant cues)',\n       color = NULL, linetype = NULL, shape = NULL) +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 12),\n    axis.title = element_text(face = 'bold'),\n    legend.position = c(0.2, 0.85),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Combine\ncombined &lt;- p1 | p2\nggsave('redundant_encoding_accessibility.png', combined, width = 14, height = 5,\n       dpi = 300, bg = 'white')\n\ncat(\"✓ Redundant encoding: Color + Shape + Line style\\n\")\ncat(\"✓ Information preserved even if color is lost\\n\")\n\n\n\nStrategy 3: Test Your Figures\nDon’t guess—simulate how your figures appear to CVD readers\nTools for testing:\n1. Color Oracle (Free, Desktop App)\n- Windows, Mac, Linux\n- Real-time simulation overlay\n- Shows Deuteranopia, Protanopia, Tritanopia views\n- Download: colororacle.org\n2. Coblis (Web-based)\n- Upload image, see CVD simulations\n- coblis.blogspot.com\n3. R Package: colorblindcheck\nlibrary(colorblindcheck)\n\n# Test your palette\npalette_check(colors, plot = TRUE)\n4. Python: colorspacious\nfrom colorspacious import cspace_converter\n\n# Test color pairs for distinguishability\nTesting workflow:\n1. Create figure with your colors\n2. Export as PNG/PDF\n3. Open in Color Oracle → Toggle CVD simulation\n4. Check: Can you still distinguish all elements?\n5. If not: Revise colors or add redundant encoding\n6. Repeat until all CVD types are accessible\n\n\n\n\nColor Integrity: Ethical Use of Color\nBeyond accessibility, color integrity means using color honestly—not to mislead or manipulate interpretation.\n\nIntegrity Principle 1: No Manipulation of Color Scales\nCommon manipulations (unethical):\nMisleading Technique 1: Non-linear color scales\n❌ DISHONEST:\nHeatmap where:\n- 0-50: Gentle blue gradient (subtle)\n- 50-51: Sudden jump to deep red (dramatic)\n→ Exaggerates small difference near threshold\n\n✓ HONEST:\nLinear or perceptually uniform scale\n- Each color step = equal data step\nMisleading Technique 2: Asymmetric diverging scales\n❌ DISHONEST:\nFold-change heatmap:\n- Downregulation: -10x to 0 (wide blue range)\n- Upregulation: 0 to +2x (narrow red range)\n→ Visually minimizes upregulation\n\n✓ HONEST:\nSymmetric scale: -10x to +10x\nOR log-transform to make symmetric: log2(-10 to +10)\nCode Example (Python) - Honest vs. Dishonest Scales:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Simulate gene expression data with range -3 to +3 log2 fold change\nnp.random.seed(42)\ndata = np.random.randn(10, 10) * 1.5  # Symmetric around zero\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# DISHONEST: Asymmetric scale (manipulated to emphasize positive)\nax1 = axes[0]\nim1 = ax1.imshow(data, cmap='RdBu_r', vmin=-3, vmax=1)  # Asymmetric!\nax1.set_title('DISHONEST: Asymmetric Scale\\n(vmin=-3, vmax=1: exaggerates positives)',\n             fontsize=12, fontweight='bold', color='red')\nax1.set_xticks([])\nax1.set_yticks([])\ncbar1 = plt.colorbar(im1, ax=ax1)\ncbar1.set_label('Log2 Fold Change', fontsize=10, fontweight='bold')\ncbar1.ax.axhline(0, color='black', linewidth=2)\n\n# HONEST: Symmetric scale\nax2 = axes[1]\nvmax = np.abs(data).max()  # Symmetric limit\nim2 = ax2.imshow(data, cmap='RdBu_r', vmin=-vmax, vmax=vmax)  # Symmetric\nax2.set_title('HONEST: Symmetric Scale\\n(Equal range for up/down regulation)',\n             fontsize=12, fontweight='bold', color='green')\nax2.set_xticks([])\nax2.set_yticks([])\ncbar2 = plt.colorbar(im2, ax=ax2)\ncbar2.set_label('Log2 Fold Change', fontsize=10, fontweight='bold')\ncbar2.ax.axhline(0, color='black', linewidth=2)\n\nplt.tight_layout()\nplt.savefig('color_scale_integrity.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R) - Honest vs. Dishonest Scales:\nlibrary(ggplot2)\nlibrary(reshape2)\nlibrary(patchwork)\n\n# Simulate data\nset.seed(42)\ndata_matrix &lt;- matrix(rnorm(100, 0, 1.5), 10, 10)\ndata_long &lt;- melt(data_matrix)\nnames(data_long) &lt;- c('Row', 'Col', 'FoldChange')\n\n# DISHONEST: Asymmetric\np1 &lt;- ggplot(data_long, aes(x = Col, y = Row, fill = FoldChange)) +\n  geom_tile() +\n  scale_fill_gradient2(low = '#2166AC', mid = 'white', high = '#B2182B',\n                       midpoint = 0,\n                       limits = c(-3, 1),  # Asymmetric!\n                       name = 'Log2\\nFold Change') +\n  labs(title = 'DISHONEST: Asymmetric Scale\\n(vmin=-3, vmax=1: exaggerates positives)') +\n  theme_void() +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 12),\n    legend.position = 'right'\n  )\n\n# HONEST: Symmetric\nvmax &lt;- max(abs(data_long$FoldChange))\n\np2 &lt;- ggplot(data_long, aes(x = Col, y = Row, fill = FoldChange)) +\n  geom_tile() +\n  scale_fill_gradient2(low = '#2166AC', mid = 'white', high = '#B2182B',\n                       midpoint = 0,\n                       limits = c(-vmax, vmax),  # Symmetric\n                       name = 'Log2\\nFold Change') +\n  labs(title = 'HONEST: Symmetric Scale\\n(Equal range for up/down regulation)') +\n  theme_void() +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 12),\n    legend.position = 'right'\n  )\n\ncombined &lt;- p1 | p2\nggsave('color_scale_integrity.png', combined, width = 14, height = 6,\n       dpi = 300, bg = 'white')\n\n\n\nIntegrity Principle 2: Consistent Processing Across Groups\nThe rule: If you adjust color/contrast/brightness for one image, apply identical adjustments to ALL comparison images.\nCommon violation in microscopy:\n❌ DISHONEST:\nControl image: Default exposure\nTreated image: Increased brightness + contrast → looks more impressive\n\nThis is IMAGE MANIPULATION and grounds for retraction\n\n✓ HONEST:\nSame exposure settings for all images\nSame post-processing (if any) applied uniformly\nDocument all adjustments in methods\nJournal requirements (e.g., Nature, Science, Cell):\n\nNo manipulation that obscures, eliminates, or misrepresents information\nAdjustments (brightness, contrast) must be linear and applied to entire image\nMust apply identically to controls and experimental groups\nMust disclose all adjustments in methods section\nMust provide original, unprocessed images if requested\n\n\n\n\nIntegrity Principle 3: Report Colormap Choices\nTransparency requirement: State your colormap explicitly, especially if non-standard.\nIn figure caption:\n\"Heatmap colors represent correlation coefficients (blue = negative,\nwhite = zero, red = positive) using the RdBu diverging colormap.\"\nIn methods section:\n\"All heatmaps were generated using the 'viridis' perceptually uniform\ncolormap to ensure accessibility for colorblind readers.\"\n\n\n\n\nComplete Accessibility Checklist\nBefore submitting your manuscript:\n\nColorblind-safe palette used (Okabe-Ito, ColorBrewer CVD-safe, or tested)\nRedundant encoding employed (color + shape/line/texture for categories)\nTested with CVD simulator (Color Oracle, Coblis, or similar)\nWorks in grayscale (print figure in black & white—still interpretable?)\nSymmetric scales for diverging data (no manipulation)\nConsistent processing across comparison groups (microscopy, gels, etc.)\nColormap documented in caption or methods\nHigh contrast (sufficient for low-vision readers)\nNo color-only legends (combine with labels or patterns)\nField conventions respected (unless accessibility requires deviation—state explicitly)\n\n\n\n\nExercise 2.7.1: Accessibility Audit\nObjective: Evaluate and improve accessibility of existing figures\nPart A: CVD Testing\n\nFind 3 figures from your recent work or literature\nRun each through Color Oracle (or Coblis)\nFor each CVD type (Deuteranopia, Protanopia, Tritanopia), document:\n\nWhich elements become indistinguishable?\nIs critical information lost?\nHow would you fix it?\n\n\nFormat:\nFigure: [Description]\nOriginal colors: [List]\n\nDeuteranopia simulation:\n- Problem: \"Red and green bars look identical\"\n- Information lost: \"Cannot distinguish Treatment A vs B\"\n- Fix: \"Use blue vs. orange instead\" OR \"Add patterns to bars\"\n\nAccessibility score: [1-5, 5=perfect]\nRecommended changes: [List specific actions]\nPart B: Redundant Encoding Practice\nTake one figure that relies solely on color distinction and redesign it with redundant encoding:\n\nOriginal: Color only\nRedesign: Color + Shape/Line/Pattern\nTest: Works in grayscale?\nCompare: Side-by-side screenshots\n\n\n\n\nSummary: Accessibility & Integrity Principles\nAccessibility: - Use colorblind-safe palettes (Okabe-Ito recommended) - Employ redundant encoding (never color alone) - Test with CVD simulators before submission - Ensure grayscale compatibility\nIntegrity: - No manipulated color scales (symmetric for diverging data) - Consistent processing across comparison groups - Transparent reporting of colormap choices - Adherence to journal guidelines for image processing\nThese are not optional—they are ethical requirements for responsible scientific communication.\n\nThe Language of Color\nKey Takeaways: - Color theory provides technical foundation (RGB, CIELAB, perceptual uniformity) - Palette types match data types (sequential, diverging, qualitative) - Saturation hierarchy directs attention (deep=significant, light=background) - Restraint and consistency signal professionalism (3-color max, semantic meaning) - Field conventions facilitate interpretation (know and follow or justify deviations) - Accessibility is mandatory (CVD-safe palettes, redundant encoding, testing) - Integrity is ethical (no manipulation, symmetric scales, transparency)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2: The Language of Color</span>"
    ]
  },
  {
    "objectID": "Chapter 2.html#logical-color-mapping-special-cases-and-edge-scenarios",
    "href": "Chapter 2.html#logical-color-mapping-special-cases-and-edge-scenarios",
    "title": "Chapter 2: The Language of Color",
    "section": "2.8 Logical Color Mapping: Special Cases and Edge Scenarios",
    "text": "2.8 Logical Color Mapping: Special Cases and Edge Scenarios\n\nThe Critical Principle: Color Logic Must Match Data Reality\nA common error in scientific figures is applying color schemes that create false distinctions or hide meaningful patterns. This section addresses edge cases where standard color choices fail logical tests.\n\n\n\nScenario 1: All Values Are Significant\nThe Problem: When every data point meets your significance threshold, using a two-color saturation scheme (deep=significant, light=non-significant) becomes meaningless and misleading.\n\nCase Study: Genome-Wide Significance\nRNA-seq experiment:\n- 500 genes tested\n- All 500 show p &lt; 0.05 (all significant)\n- Fold changes range from +1.2x to +8.5x\n\n❌ WRONG approach:\nUse deep red for all genes (because all are \"significant\")\n→ Loses information about magnitude differences\n→ Visually monotonous, no hierarchy\n\n✓ CORRECT approach:\nUse continuous gradient based on effect size (fold change)\n- Light red: Small but significant changes (+1.2x to +2x)\n- Medium red: Moderate changes (+2x to +4x)\n- Deep red: Large changes (+4x to +8.5x)\n→ Color now represents biological importance, not statistical threshold\nLogical Reasoning:\nWhen the binary distinction (significant vs. non-significant) provides no information (all are significant), you must shift to encoding the continuous quantitative variable (effect size, correlation strength, etc.).\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Simulate gene expression: ALL significant, varying magnitudes\nnp.random.seed(42)\nn_genes = 50\nn_samples = 8\n\n# All genes have significant fold changes (1.2x to 8.5x)\nfold_changes = np.random.uniform(1.2, 8.5, (n_genes, n_samples))\nlog2_fc = np.log2(fold_changes)\n\n# All p-values &lt; 0.05 (all significant)\np_values = np.random.uniform(0.0001, 0.049, n_genes)\n\ngenes = [f'Gene{i+1}' for i in range(n_genes)]\nsamples = [f'S{i+1}' for i in range(n_samples)]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 8))\n\n# WRONG: Binary coloring (all one color because all significant)\nax1 = axes[0]\n# All get same deep red (useless)\nim1 = ax1.imshow(log2_fc, cmap='Reds', vmin=0, vmax=3.1, aspect='auto')\nax1.set_title('❌ WRONG: All Significant → All Same Deep Color\\n(Loses magnitude information)',\n              fontsize=12, fontweight='bold', color='red')\nax1.set_xlabel('Samples', fontsize=10, fontweight='bold')\nax1.set_ylabel('Genes', fontsize=10, fontweight='bold')\nax1.set_xticks(range(n_samples))\nax1.set_xticklabels(samples, fontsize=8)\nax1.set_yticks(range(0, n_genes, 10))\nax1.set_yticklabels([genes[i] for i in range(0, n_genes, 10)], fontsize=7)\n\n# Add misleading note\nax1.text(0.5, 1.05, 'All genes p &lt; 0.05 → All deep red (uninformative)',\n         transform=ax1.transAxes, ha='center', fontsize=9,\n         style='italic', color='red', weight='bold')\n\ncbar1 = plt.colorbar(im1, ax=ax1, fraction=0.046)\ncbar1.set_label('Log₂ Fold Change\\n(binary: all \"significant\")', fontsize=9)\n\n# CORRECT: Continuous gradient based on magnitude\nax2 = axes[1]\nim2 = ax2.imshow(log2_fc, cmap='YlOrRd', vmin=np.log2(1.2), vmax=np.log2(8.5), aspect='auto')\nax2.set_title('✓ CORRECT: Continuous Gradient by Magnitude\\n(Shows biological importance)',\n              fontsize=12, fontweight='bold', color='green')\nax2.set_xlabel('Samples', fontsize=10, fontweight='bold')\nax2.set_ylabel('Genes', fontsize=10, fontweight='bold')\nax2.set_xticks(range(n_samples))\nax2.set_xticklabels(samples, fontsize=8)\nax2.set_yticks(range(0, n_genes, 10))\nax2.set_yticklabels([genes[i] for i in range(0, n_genes, 10)], fontsize=7)\n\n# Add explanatory note\nax2.text(0.5, 1.05, 'All genes p &lt; 0.05 → Color = effect size (informative)',\n         transform=ax2.transAxes, ha='center', fontsize=9,\n         style='italic', color='green', weight='bold')\n\ncbar2 = plt.colorbar(im2, ax=ax2, fraction=0.046)\ncbar2.set_label('Log₂ Fold Change\\n(continuous magnitude)', fontsize=9, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('all_significant_color_logic.png', dpi=300,\n            bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ When all values significant: encode magnitude, not binary threshold\")\nCode Example (R):\nlibrary(ggplot2)\nlibrary(reshape2)\nlibrary(patchwork)\n\n# Simulate data: ALL significant\nset.seed(42)\nn_genes &lt;- 50\nn_samples &lt;- 8\n\nfold_changes &lt;- matrix(runif(n_genes * n_samples, 1.2, 8.5), n_genes, n_samples)\nlog2_fc &lt;- log2(fold_changes)\n\n# All p &lt; 0.05\np_values &lt;- runif(n_genes, 0.0001, 0.049)\n\ngenes &lt;- paste0('Gene', 1:n_genes)\nsamples &lt;- paste0('S', 1:n_samples)\n\ncolnames(log2_fc) &lt;- samples\nrownames(log2_fc) &lt;- genes\n\n# Convert to long format\ndata_long &lt;- melt(log2_fc, varnames = c('Gene', 'Sample'), value.name = 'Log2FC')\n\n# WRONG: All same deep color (uninformative)\np1 &lt;- ggplot(data_long, aes(x = Sample, y = Gene, fill = Log2FC)) +\n  geom_tile() +\n  scale_fill_gradient(low = '#FEE5D9', high = '#A50F15',  # Fixed deep red for \"all significant\"\n                      limits = c(0, 3.1),\n                      name = 'Log₂ FC\\n(binary)') +\n  labs(title = '❌ WRONG: All Significant → All Same Deep Color\\n(Loses magnitude information)',\n       x = 'Samples', y = 'Genes') +\n  theme_minimal(base_size = 10) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 11),\n    axis.title = element_text(face = 'bold', size = 10),\n    axis.text.y = element_text(size = 6),\n    axis.text.x = element_text(size = 8),\n    panel.grid = element_blank(),\n    legend.position = 'right'\n  ) +\n  annotate('text', x = 4.5, y = 52, label = 'All genes p &lt; 0.05 → All deep red (uninformative)',\n           size = 3, fontface = 'italic', color = 'red')\n\n# CORRECT: Continuous gradient\np2 &lt;- ggplot(data_long, aes(x = Sample, y = Gene, fill = Log2FC)) +\n  geom_tile() +\n  scale_fill_gradientn(colors = c('#FFFFCC', '#FFEDA0', '#FED976', '#FEB24C',\n                                   '#FD8D3C', '#FC4E2A', '#E31A1C', '#BD0026'),\n                       limits = c(log2(1.2), log2(8.5)),\n                       name = 'Log₂ FC\\n(magnitude)') +\n  labs(title = '✓ CORRECT: Continuous Gradient by Magnitude\\n(Shows biological importance)',\n       x = 'Samples', y = 'Genes') +\n  theme_minimal(base_size = 10) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 11),\n    axis.title = element_text(face = 'bold', size = 10),\n    axis.text.y = element_text(size = 6),\n    axis.text.x = element_text(size = 8),\n    panel.grid = element_blank(),\n    legend.position = 'right'\n  ) +\n  annotate('text', x = 4.5, y = 52, label = 'All genes p &lt; 0.05 → Color = effect size (informative)',\n           size = 3, fontface = 'italic', color = 'darkgreen')\n\n# Combine\ncombined &lt;- p1 / p2\nggsave('all_significant_color_logic.png', combined, width = 10, height = 12,\n       dpi = 300, bg = 'white')\n\ncat(\"✓ When all values significant: encode magnitude, not binary threshold\\n\")\n\n\n\n\nScenario 2: Missing Data in Heatmaps\nThe Problem: Missing values (NA, not measured, failed QC) require a distinct visual treatment that doesn’t interfere with your continuous colormap.\n\nThe Logical Rules:\n\nNever use a color from your gradient for missing data\n\nIf gradient is blue-white-red, don’t use gray (looks like “low value”)\nMissing ≠ Zero ≠ Low value\n\nUse a visually distinct, non-data color\n\nBest: Crosshatch/pattern (universally understood as “no data”)\nGood: Distinct color outside gradient (e.g., black, white with border)\nAcceptable: Very light gray with clear border (if pattern not possible)\n\nLabel explicitly in legend\n\n“Missing/Not measured” with example patch\n\n\n\n\nCommon Mistakes:\n❌ MISTAKE 1: Using gradient color for NA\nGradient: Light blue → Dark blue\nMissing data: Light blue or white\n→ Looks like \"low value\" not \"absent\"\n\n❌ MISTAKE 2: Using zero for NA\nSubstituting NA with 0 in data\n→ Falsely implies measurement of zero\n\n❌ MISTAKE 3: No visual distinction\nLeaving cells blank (white) when background is white\n→ Invisible, looks like data omission error\nCode Example (Python) - Missing Data:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Rectangle\nimport matplotlib.patches as mpatches\n\n# Simulate expression data with missing values\nnp.random.seed(42)\nn_genes = 20\nn_samples = 10\n\ndata = np.random.randn(n_genes, n_samples) * 2 + 5  # Mean ~5\n\n# Introduce random missing values (20%)\nmissing_mask = np.random.rand(n_genes, n_samples) &lt; 0.2\ndata_with_na = data.copy()\ndata_with_na[missing_mask] = np.nan\n\ngenes = [f'Gene{i+1}' for i in range(n_genes)]\nsamples = [f'S{i+1}' for i in range(n_samples)]\n\nfig, axes = plt.subplots(1, 3, figsize=(16, 7))\n\n# BAD 1: Missing data shown in gradient color (looks like low value)\nax1 = axes[0]\ndata_bad1 = np.nan_to_num(data_with_na, nan=0)  # Replace NA with 0\nim1 = ax1.imshow(data_bad1, cmap='YlOrRd', vmin=0, vmax=10, aspect='auto')\nax1.set_title('❌ BAD: NA → 0 (Looks like real low value)',\n              fontsize=11, fontweight='bold', color='red')\nax1.set_xlabel('Samples', fontsize=9, fontweight='bold')\nax1.set_ylabel('Genes', fontsize=9, fontweight='bold')\nax1.set_xticks(range(n_samples))\nax1.set_xticklabels(samples, fontsize=7)\nax1.set_yticks(range(0, n_genes, 5))\nax1.set_yticklabels([genes[i] for i in range(0, n_genes, 5)], fontsize=7)\ncbar1 = plt.colorbar(im1, ax=ax1, fraction=0.046)\ncbar1.set_label('Expression', fontsize=9)\n\n# BAD 2: Missing data in white (invisible on white background)\nax2 = axes[1]\nim2 = ax2.imshow(data_with_na, cmap='YlOrRd', vmin=0, vmax=10, aspect='auto')\nax2.set_title('❌ BAD: NA → White (Invisible/ambiguous)',\n              fontsize=11, fontweight='bold', color='red')\nax2.set_xlabel('Samples', fontsize=9, fontweight='bold')\nax2.set_ylabel('Genes', fontsize=9, fontweight='bold')\nax2.set_xticks(range(n_samples))\nax2.set_xticklabels(samples, fontsize=7)\nax2.set_yticks(range(0, n_genes, 5))\nax2.set_yticklabels([genes[i] for i in range(0, n_genes, 5)], fontsize=7)\ncbar2 = plt.colorbar(im2, ax=ax2, fraction=0.046)\ncbar2.set_label('Expression', fontsize=9)\n\n# GOOD: Missing data with distinct visual (gray + border)\nax3 = axes[2]\n# Plot data normally\nim3 = ax3.imshow(data_with_na, cmap='YlOrRd', vmin=0, vmax=10, aspect='auto')\n\n# Overlay missing data with distinct color + pattern\nfor i in range(n_genes):\n    for j in range(n_samples):\n        if missing_mask[i, j]:\n            # Draw rectangle with distinct color (gray) and thick black border\n            rect = Rectangle((j-0.5, i-0.5), 1, 1,\n                            facecolor='#CCCCCC',\n                            edgecolor='black',\n                            linewidth=2,\n                            hatch='///')  # Crosshatch pattern\n            ax3.add_patch(rect)\n\nax3.set_title('✓ GOOD: NA → Distinct Color + Pattern',\n              fontsize=11, fontweight='bold', color='green')\nax3.set_xlabel('Samples', fontsize=9, fontweight='bold')\nax3.set_ylabel('Genes', fontsize=9, fontweight='bold')\nax3.set_xticks(range(n_samples))\nax3.set_xticklabels(samples, fontsize=7)\nax3.set_yticks(range(0, n_genes, 5))\nax3.set_yticklabels([genes[i] for i in range(0, n_genes, 5)], fontsize=7)\n\n# Custom colorbar with NA indicator\ncbar3 = plt.colorbar(im3, ax=ax3, fraction=0.046)\ncbar3.set_label('Expression', fontsize=9, fontweight='bold')\n\n# Add legend for missing data\nmissing_patch = mpatches.Patch(facecolor='#CCCCCC', edgecolor='black',\n                               hatch='///', linewidth=2, label='Missing/NA')\nax3.legend(handles=[missing_patch], loc='upper right', fontsize=8, frameon=True)\n\nplt.tight_layout()\nplt.savefig('missing_data_color_logic.png', dpi=300,\n            bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Missing data requires distinct visual treatment\")\nprint(\"✓ Never use gradient colors for NA values\")\nCode Example (R) - Missing Data:\nlibrary(ggplot2)\nlibrary(reshape2)\nlibrary(dplyr)\nlibrary(patchwork)\n\n# Simulate data with missing values\nset.seed(42)\nn_genes &lt;- 20\nn_samples &lt;- 10\n\ndata_matrix &lt;- matrix(rnorm(n_genes * n_samples, 5, 2), n_genes, n_samples)\n\n# Introduce missing values\nmissing_mask &lt;- matrix(runif(n_genes * n_samples) &lt; 0.2, n_genes, n_samples)\ndata_with_na &lt;- data_matrix\ndata_with_na[missing_mask] &lt;- NA\n\ngenes &lt;- paste0('Gene', 1:n_genes)\nsamples &lt;- paste0('S', 1:n_samples)\n\ncolnames(data_with_na) &lt;- samples\nrownames(data_with_na) &lt;- genes\n\n# Convert to long format\ndata_long &lt;- melt(data_with_na, varnames = c('Gene', 'Sample'), value.name = 'Expression')\ndata_long$is_missing &lt;- is.na(data_long$Expression)\n\n# BAD 1: Replace NA with 0 (misleading)\ndata_bad1 &lt;- data_long\ndata_bad1$Expression[is.na(data_bad1$Expression)] &lt;- 0\n\np1 &lt;- ggplot(data_bad1, aes(x = Sample, y = Gene, fill = Expression)) +\n  geom_tile(color = 'white', size = 0.5) +\n  scale_fill_gradientn(colors = c('#FFFFCC', '#FED976', '#FD8D3C', '#E31A1C'),\n                       limits = c(0, 10),\n                       name = 'Expression') +\n  labs(title = '❌ BAD: NA → 0 (Looks like real low value)') +\n  theme_minimal(base_size = 10) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 11),\n    axis.text.y = element_text(size = 7),\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n    panel.grid = element_blank()\n  )\n\n# BAD 2: Missing data invisible (white on white)\np2 &lt;- ggplot(data_long, aes(x = Sample, y = Gene, fill = Expression)) +\n  geom_tile(color = 'white', size = 0.5) +\n  scale_fill_gradientn(colors = c('#FFFFCC', '#FED976', '#FD8D3C', '#E31A1C'),\n                       limits = c(0, 10),\n                       name = 'Expression',\n                       na.value = 'white') +  # NA = white (invisible)\n  labs(title = '❌ BAD: NA → White (Invisible/ambiguous)') +\n  theme_minimal(base_size = 10) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 11),\n    axis.text.y = element_text(size = 7),\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n    panel.grid = element_blank()\n  )\n\n# GOOD: Distinct color + pattern for NA\np3 &lt;- ggplot(data_long, aes(x = Sample, y = Gene, fill = Expression)) +\n  geom_tile(color = 'white', size = 0.5) +\n  scale_fill_gradientn(colors = c('#FFFFCC', '#FED976', '#FD8D3C', '#E31A1C'),\n                       limits = c(0, 10),\n                       name = 'Expression',\n                       na.value = '#CCCCCC') +  # NA = distinct gray\n  # Add border for missing cells\n  geom_tile(data = data_long %&gt;% filter(is_missing),\n            aes(x = Sample, y = Gene),\n            fill = '#CCCCCC', color = 'black', size = 1.5, alpha = 0.7) +\n  labs(title = '✓ GOOD: NA → Distinct Color + Border',\n       caption = 'Gray cells with black border = Missing/Not measured') +\n  theme_minimal(base_size = 10) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 11),\n    plot.caption = element_text(hjust = 0.5, face = 'italic', size = 9),\n    axis.text.y = element_text(size = 7),\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n    panel.grid = element_blank()\n  )\n\n# Combine\ncombined &lt;- (p1 | p2) / p3\nggsave('missing_data_color_logic.png', combined, width = 14, height = 12,\n       dpi = 300, bg = 'white')\n\ncat(\"✓ Missing data requires distinct visual treatment\\n\")\ncat(\"✓ Never use gradient colors for NA values\\n\")\n\n\n\n\nScenario 3: Zero is Meaningful vs. Zero is Arbitrary\nThe Logical Distinction:\nSome datasets have a meaningful zero point (requires diverging colormap), while others have arbitrary zero (requires sequential colormap).\n\nCase A: Meaningful Zero (Use Diverging)\nExamples where zero has special meaning:\n- Fold change: 0 = no change (negative = decrease, positive = increase)\n- Temperature anomaly: 0 = average (negative = below, positive = above)\n- Financial profit/loss: 0 = break-even\n- pH: 7 = neutral (&lt; 7 acidic, &gt; 7 basic)\n- Correlation: 0 = no relationship\n\n✓ CORRECT: Diverging colormap (Blue ← White (zero) → Red)\n\n\nCase B: Arbitrary Zero (Use Sequential)\nExamples where zero is just lower bound:\n- Gene expression (FPKM): 0 = not expressed, but not \"negative expression\"\n- Temperature in Kelvin: 0K is absolute zero, but no \"negative temp\"\n- Count data: 0 = none detected, but no \"negative counts\"\n- Distance: 0 = here, but no \"negative distance\"\n\n✓ CORRECT: Sequential colormap (Light → Dark single hue)\n❌ WRONG: Diverging colormap (implies negative values exist)\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Case A: Fold change (meaningful zero)\nfold_change_data = np.random.randn(10, 10) * 2  # Centered at 0\n\n# Case B: Gene expression counts (arbitrary zero, all positive)\nexpression_data = np.abs(np.random.randn(10, 10) * 2) + 1  # All positive\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# CASE A - WRONG: Sequential for data with meaningful zero\nax1 = axes[0, 0]\nim1 = ax1.imshow(fold_change_data, cmap='Reds', vmin=-4, vmax=4, aspect='auto')\nax1.set_title('❌ WRONG: Sequential for Fold Change\\n(Zero is meaningful midpoint!)',\n              fontsize=11, fontweight='bold', color='red')\nplt.colorbar(im1, ax=ax1, label='Fold Change')\nax1.set_xticks([])\nax1.set_yticks([])\n\n# CASE A - CORRECT: Diverging for data with meaningful zero\nax2 = axes[0, 1]\nim2 = ax2.imshow(fold_change_data, cmap='RdBu_r', vmin=-4, vmax=4, aspect='auto')\nax2.set_title('✓ CORRECT: Diverging for Fold Change\\n(White = no change)',\n              fontsize=11, fontweight='bold', color='green')\ncbar2 = plt.colorbar(im2, ax=ax2, label='Fold Change')\ncbar2.ax.axhline(0, color='black', linewidth=2)\nax2.set_xticks([])\nax2.set_yticks([])\n\n# CASE B - WRONG: Diverging for all-positive data\nax3 = axes[1, 0]\nim3 = ax3.imshow(expression_data, cmap='RdBu_r', vmin=0, vmax=6, aspect='auto')\nax3.set_title('❌ WRONG: Diverging for Expression\\n(Implies negative values exist)',\n              fontsize=11, fontweight='bold', color='red')\nplt.colorbar(im3, ax=ax3, label='Expression (FPKM)')\nax3.set_xticks([])\nax3.set_yticks([])\n\n# CASE B - CORRECT: Sequential for all-positive data\nax4 = axes[1, 1]\nim4 = ax4.imshow(expression_data, cmap='YlOrRd', vmin=0, vmax=6, aspect='auto')\nax4.set_title('✓ CORRECT: Sequential for Expression\\n(Zero = lower bound)',\n              fontsize=11, fontweight='bold', color='green')\nplt.colorbar(im4, ax=ax4, label='Expression (FPKM)')\nax4.set_xticks([])\nax4.set_yticks([])\n\nplt.tight_layout()\nplt.savefig('meaningful_zero_logic.png', dpi=300,\n            bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Meaningful zero → Diverging colormap\")\nprint(\"✓ Arbitrary zero → Sequential colormap\")\nCode Example (R):\nlibrary(ggplot2)\nlibrary(reshape2)\nlibrary(patchwork)\n\nset.seed(42)\n\n# Case A: Fold change (meaningful zero)\nfold_change &lt;- matrix(rnorm(100, 0, 2), 10, 10)\n\n# Case B: Expression (arbitrary zero, all positive)\nexpression &lt;- matrix(abs(rnorm(100, 0, 2)) + 1, 10, 10)\n\n# Convert to long\nfc_long &lt;- melt(fold_change)\nnames(fc_long) &lt;- c('Row', 'Col', 'FoldChange')\n\nexpr_long &lt;- melt(expression)\nnames(expr_long) &lt;- c('Row', 'Col', 'Expression')\n\n# CASE A - WRONG\np1 &lt;- ggplot(fc_long, aes(x = Col, y = Row, fill = FoldChange)) +\n  geom_tile() +\n  scale_fill_gradient(low = 'white', high = 'red',\n                      limits = c(-4, 4),\n                      name = 'Fold\\nChange') +\n  labs(title = '❌ WRONG: Sequential for Fold Change\\n(Zero is meaningful midpoint!)') +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 10))\n\n# CASE A - CORRECT\np2 &lt;- ggplot(fc_long, aes(x = Col, y = Row, fill = FoldChange)) +\n  geom_tile() +\n  scale_fill_gradient2(low = '#2166AC', mid = 'white', high = '#B2182B',\n                       midpoint = 0,\n                       limits = c(-4, 4),\n                       name = 'Fold\\nChange') +\n  labs(title = '✓ CORRECT: Diverging for Fold Change\\n(White = no change)') +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 10))\n\n# CASE B - WRONG\np3 &lt;- ggplot(expr_long, aes(x = Col, y = Row, fill = Expression)) +\n  geom_tile() +\n  scale_fill_gradient2(low = 'blue', mid = 'white', high = 'red',\n                       midpoint = 3,\n                       limits = c(0, 6),\n                       name = 'Expression\\n(FPKM)') +\n  labs(title = '❌ WRONG: Diverging for Expression\\n(Implies negative values exist)') +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 10))\n\n# CASE B - CORRECT\np4 &lt;- ggplot(expr_long, aes(x = Col, y = Row, fill = Expression)) +\n  geom_tile() +\n  scale_fill_gradientn(colors = c('#FFFFCC', '#FED976', '#FD8D3C', '#E31A1C'),\n                       limits = c(0, 6),\n                       name = 'Expression\\n(FPKM)') +\n  labs(title = '✓ CORRECT: Sequential for Expression\\n(Zero = lower bound)') +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 10))\n\ncombined &lt;- (p1 | p2) / (p3 | p4)\nggsave('meaningful_zero_logic.png', combined, width = 12, height = 10,\n       dpi = 300, bg = 'white')\n\ncat(\"✓ Meaningful zero → Diverging colormap\\n\")\ncat(\"✓ Arbitrary zero → Sequential colormap\\n\")\n\n\n\n\nSummary: Logical Color Mapping Rules\nRule 1: When significance is universal\nIf ALL values meet threshold (all p &lt; 0.05):\n→ Encode magnitude/effect size with continuous gradient\n→ Binary distinction provides no information\nRule 2: Missing data treatment\nMissing values require:\n→ Color OUTSIDE your gradient (not gray if gradient uses gray)\n→ Visual distinction (pattern, border, or unique color)\n→ Explicit legend entry: \"Missing/Not measured\"\nRule 3: Zero point semantics\nMeaningful zero (fold change, anomaly):\n→ Diverging colormap (blue ← white (zero) → red)\n\nArbitrary zero (counts, absolute scale):\n→ Sequential colormap (light → dark single hue)\n\n\n\nExercise 2.8.1: Logical Color Mapping Audit\nObjective: Identify and fix logical color mapping errors\nInstructions:\nFor each scenario, determine: 1. What is wrong with the current color scheme? 2. What does the data actually represent? 3. What colormap would be logically correct? 4. Why does the logical choice matter for interpretation?\nScenarios:\nA. RNA-seq heatmap - Data: All 1000 genes have p &lt; 0.01 (all highly significant) - Current coloring: Deep red for all (because all significant) - Fold changes: Range from +1.5x to +12x\nB. Spatial temperature map - Data: Average January temperatures across cities (range: -15°C to +25°C) - Current coloring: Diverging blue-white-red with white at 0°C - Question: Is 0°C meaningful here?\nC. Correlation heatmap with missing data - Data: Pearson correlations (-1 to +1), 15% cells have insufficient data - Current coloring: RdBu diverging, missing cells shown as light blue - Question: What’s the problem?\nD. Western blot quantification - Data: Protein band intensities (arbitrary units, 0-255) - Current coloring: Diverging colormap centered at 128 - Question: Does 128 have special biological meaning?\nE. Clinical trial with mixed significance - Data: 20 endpoints measured, 3 show p&lt;0.05, 17 show p&gt;0.05 - Current coloring: All bars in shades of blue gradient - Question: How should significance be encoded?\nYour answers should include:\nScenario [Letter]:\n\nCurrent approach:\n[Describe what they're doing wrong]\n\nData reality:\n[What the numbers actually represent]\n\nLogical issue:\n[Why current approach is misleading/uninformative]\n\nCorrect solution:\n[Specific colormap + justification]\n\nExample:\nScenario A: All significant genes\n\nCurrent: Deep red for all (binary: significant=red)\nData reality: All p&lt;0.01, fold changes vary 1.5x-12x\nLogical issue: Binary coloring loses magnitude information\nCorrect solution: Continuous yellow-orange-red gradient encoding fold change\n  → Light yellow: +1.5x, Deep red: +12x\n  → Reader sees biological importance, not just statistical threshold\n\n\n\nScenario 4: Cyclic Data (Time of Day, Angles, Compass Directions)\nThe Special Case: Some data is cyclic—the end wraps back to the beginning (e.g., 23:59 wraps to 00:00).\n\nLogical Requirement: Cyclic Colormap\nData types needing cyclic colormaps: - Time of day (24-hour clock) - Day of year (Dec 31 → Jan 1) - Compass directions (359° → 0°) - Phase angles (2π → 0) - Seasonal patterns\nStandard colormap FAILS:\n❌ Sequential colormap (light blue → dark blue):\n  - 23:00 appears dark blue (high value)\n  - 00:00 appears light blue (low value)\n  → False discontinuity! These times are adjacent\n\n✓ Cyclic colormap (e.g., 'twilight', 'hsv'):\n  - Start and end colors are perceptually similar\n  - Smooth transition across wraparound point\nCode Example (Python) - Cyclic Data:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Simulate circadian gene expression (24-hour cycle)\nnp.random.seed(42)\nhours = np.arange(0, 24, 0.5)  # Every 30 min\nexpression = 5 + 3 * np.sin(2 * np.pi * (hours - 6) / 24) + np.random.randn(len(hours)) * 0.5\n\n# Create circular heatmap data (genes x time)\nn_genes = 15\ncircular_data = np.array([\n    5 + 3 * np.sin(2 * np.pi * (hours - np.random.randint(0, 24)) / 24) +\n    np.random.randn(len(hours)) * 0.5\n    for _ in range(n_genes)\n])\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# WRONG: Sequential colormap (creates false discontinuity)\nax1 = axes[0]\nim1 = ax1.imshow(circular_data, cmap='viridis', aspect='auto',\n                 extent=[0, 24, 0, n_genes])\nax1.set_xlabel('Time of Day (hours)', fontsize=11, fontweight='bold')\nax1.set_ylabel('Gene', fontsize=11, fontweight='bold')\nax1.set_title('❌ WRONG: Sequential for Cyclic Data\\n(23:00 and 00:00 look unrelated)',\n              fontsize=12, fontweight='bold', color='red')\nax1.axvline(0, color='white', linestyle='--', linewidth=2, alpha=0.7)\nax1.axvline(24, color='white', linestyle='--', linewidth=2, alpha=0.7)\nax1.text(12, n_genes + 0.5, 'False boundary at midnight',\n         ha='center', fontsize=9, color='red', fontweight='bold')\ncbar1 = plt.colorbar(im1, ax=ax1)\ncbar1.set_label('Expression', fontsize=10)\n\n# CORRECT: Cyclic colormap (twilight - perceptually uniform cyclic)\nax2 = axes[1]\nim2 = ax2.imshow(circular_data, cmap='twilight', aspect='auto',\n                 extent=[0, 24, 0, n_genes])\nax2.set_xlabel('Time of Day (hours)', fontsize=11, fontweight='bold')\nax2.set_ylabel('Gene', fontsize=11, fontweight='bold')\nax2.set_title('✓ CORRECT: Cyclic Colormap\\n(Smooth across midnight)',\n              fontsize=12, fontweight='bold', color='green')\nax2.axvline(0, color='white', linestyle='--', linewidth=2, alpha=0.7)\nax2.axvline(24, color='white', linestyle='--', linewidth=2, alpha=0.7)\nax2.text(12, n_genes + 0.5, 'Continuous across midnight',\n         ha='center', fontsize=9, color='green', fontweight='bold')\ncbar2 = plt.colorbar(im2, ax=ax2)\ncbar2.set_label('Expression', fontsize=10)\n\nplt.tight_layout()\nplt.savefig('cyclic_data_colormap.png', dpi=300,\n            bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Cyclic data requires cyclic colormap (twilight, hsv)\")\nprint(\"✓ Start and end colors must be perceptually similar\")\nCode Example (R) - Cyclic Data:\nlibrary(ggplot2)\nlibrary(reshape2)\nlibrary(patchwork)\n\n# Simulate circadian data\nset.seed(42)\nhours &lt;- seq(0, 24, by = 0.5)\nn_genes &lt;- 15\n\ncircular_data &lt;- sapply(1:n_genes, function(i) {\n  phase &lt;- runif(1, 0, 24)\n  5 + 3 * sin(2 * pi * (hours - phase) / 24) + rnorm(length(hours), 0, 0.5)\n})\n\n# Convert to long format\ndata_long &lt;- melt(circular_data)\nnames(data_long) &lt;- c('Time', 'Gene', 'Expression')\ndata_long$Time &lt;- hours[data_long$Time]\n\n# WRONG: Sequential colormap\np1 &lt;- ggplot(data_long, aes(x = Time, y = Gene, fill = Expression)) +\n  geom_tile() +\n  scale_fill_viridis_c(option = 'viridis', name = 'Expression') +\n  geom_vline(xintercept = c(0, 24), color = 'white', linetype = 'dashed', size = 1) +\n  labs(x = 'Time of Day (hours)', y = 'Gene',\n       title = '❌ WRONG: Sequential for Cyclic Data\\n(23:00 and 00:00 look unrelated)',\n       caption = 'False boundary at midnight') +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 12),\n    plot.caption = element_text(hjust = 0.5, color = 'red', face = 'italic'),\n    axis.title = element_text(face = 'bold'),\n    panel.grid = element_blank()\n  )\n\n# CORRECT: Create cyclic palette manually (R doesn't have built-in twilight)\n# Using HSV color space for cyclic effect\ncyclic_colors &lt;- hsv(seq(0, 1, length.out = 100), s = 0.7, v = 0.8)\n\np2 &lt;- ggplot(data_long, aes(x = Time, y = Gene, fill = Expression)) +\n  geom_tile() +\n  scale_fill_gradientn(colors = cyclic_colors, name = 'Expression') +\n  geom_vline(xintercept = c(0, 24), color = 'white', linetype = 'dashed', size = 1) +\n  labs(x = 'Time of Day (hours)', y = 'Gene',\n       title = '✓ CORRECT: Cyclic Colormap\\n(Smooth across midnight)',\n       caption = 'Continuous across midnight') +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 12),\n    plot.caption = element_text(hjust = 0.5, color = 'darkgreen', face = 'italic'),\n    axis.title = element_text(face = 'bold'),\n    panel.grid = element_blank()\n  )\n\ncombined &lt;- p1 / p2\nggsave('cyclic_data_colormap.png', combined, width = 10, height = 10,\n       dpi = 300, bg = 'white')\n\ncat(\"✓ Cyclic data requires cyclic colormap\\n\")\ncat(\"✓ Start and end colors must be perceptually similar\\n\")\n\n\n\n\nScenario 5: Multiple Scales in One Figure\nThe Problem: When showing multiple datasets with different value ranges in the same figure, color scales must be handled carefully.\n\nCase A: Shared Scale (When Appropriate)\nUse when: - Data types are directly comparable (same units, same meaning) - Relative magnitudes matter - Example: Same gene measured across conditions\n✓ CORRECT: Shared color scale\nGene expression (FPKM) in 3 tissues\n- All use same scale: 0-100 FPKM\n- Direct visual comparison valid\n\n\nCase B: Independent Scales (When Necessary)\nUse when: - Different data types (e.g., temperature vs. precipitation) - Vastly different ranges would obscure one dataset - Example: Gene A (range 1-10) vs. Gene B (range 100-1000)\n✓ CORRECT: Independent scales, clearly labeled\n- Gene A: 0-10 scale\n- Gene B: 0-1000 scale\n- State explicitly in caption or on colorbars\nCritical Rule: Never use same colormap for different scales without explicit labeling\nCode Example (Python):\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Two genes with very different expression ranges\ngene_low = np.random.uniform(1, 10, (10, 10))  # Low expression\ngene_high = np.random.uniform(100, 1000, (10, 10))  # High expression\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# MISLEADING: Same colormap, not labeled properly\nax1 = axes[0, 0]\nim1 = ax1.imshow(gene_low, cmap='Reds', vmin=0, vmax=1000, aspect='auto')\nax1.set_title('Gene A (Low Range)', fontsize=11, fontweight='bold')\nplt.colorbar(im1, ax=ax1, label='Expression')\n\nax2 = axes[0, 1]\nim2 = ax2.imshow(gene_high, cmap='Reds', vmin=0, vmax=1000, aspect='auto')\nax2.set_title('Gene B (High Range)', fontsize=11, fontweight='bold')\nplt.colorbar(im2, ax=ax2, label='Expression')\n\naxes[0, 0].text(0.5, -0.15, '❌ MISLEADING: Same scale (Gene A looks uniformly low)',\n                transform=axes[0, 0].transAxes, ha='center', fontsize=10,\n                color='red', fontweight='bold')\n\n# CORRECT: Independent scales, clearly labeled\nax3 = axes[1, 0]\nim3 = ax3.imshow(gene_low, cmap='Reds', vmin=1, vmax=10, aspect='auto')\nax3.set_title('Gene A (Independent Scale)', fontsize=11, fontweight='bold')\ncbar3 = plt.colorbar(im3, ax=ax3)\ncbar3.set_label('Expression\\n(1-10 FPKM)', fontsize=9, fontweight='bold')\n\nax4 = axes[1, 1]\nim4 = ax4.imshow(gene_high, cmap='Reds', vmin=100, vmax=1000, aspect='auto')\nax4.set_title('Gene B (Independent Scale)', fontsize=11, fontweight='bold')\ncbar4 = plt.colorbar(im4, ax=ax4)\ncbar4.set_label('Expression\\n(100-1000 FPKM)', fontsize=9, fontweight='bold')\n\naxes[1, 0].text(0.5, -0.15, '✓ CORRECT: Independent scales, clearly labeled',\n                transform=axes[1, 0].transAxes, ha='center', fontsize=10,\n                color='green', fontweight='bold')\n\nfor ax in axes.flat:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.savefig('multiple_scales_logic.png', dpi=300,\n            bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Multiple scales require explicit labeling\")\nprint(\"✓ State ranges clearly in captions and colorbars\")\nCode Example (R):\nlibrary(ggplot2)\nlibrary(reshape2)\nlibrary(patchwork)\n\nset.seed(42)\n\n# Two genes with different ranges\ngene_low &lt;- matrix(runif(100, 1, 10), 10, 10)\ngene_high &lt;- matrix(runif(100, 100, 1000), 10, 10)\n\n# Convert to long\nlow_long &lt;- melt(gene_low)\nnames(low_long) &lt;- c('Row', 'Col', 'Expression')\nlow_long$Gene &lt;- 'Gene A'\n\nhigh_long &lt;- melt(gene_high)\nnames(high_long) &lt;- c('Row', 'Col', 'Expression')\nhigh_long$Gene &lt;- 'Gene B'\n\n# MISLEADING: Same scale\np1_low &lt;- ggplot(low_long, aes(x = Col, y = Row, fill = Expression)) +\n  geom_tile() +\n  scale_fill_gradient(low = 'white', high = 'red',\n                      limits = c(0, 1000),\n                      name = 'Expression') +\n  labs(title = 'Gene A (Low Range)',\n       subtitle = '❌ MISLEADING: Same scale') +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, face = 'bold', size = 11),\n        plot.subtitle = element_text(hjust = 0.5, color = 'red', size = 9))\n\np2_high &lt;- ggplot(high_long, aes(x = Col, y = Row, fill = Expression)) +\n  geom_tile() +\n  scale_fill_gradient(low = 'white', high = 'red',\n                      limits = c(0, 1000),\n                      name = 'Expression') +\n  labs(title = 'Gene B (High Range)',\n       subtitle = '(Gene A looks uniformly low)') +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, face = 'bold', size = 11),\n        plot.subtitle = element_text(hjust = 0.5, color = 'red', size = 9, face = 'italic'))\n\n# CORRECT: Independent scales\np3_low &lt;- ggplot(low_long, aes(x = Col, y = Row, fill = Expression)) +\n  geom_tile() +\n  scale_fill_gradient(low = 'white', high = 'red',\n                      limits = c(1, 10),\n                      name = 'Expression\\n(1-10 FPKM)') +\n  labs(title = 'Gene A (Independent Scale)',\n       subtitle = '✓ CORRECT: Scale optimized') +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, face = 'bold', size = 11),\n        plot.subtitle = element_text(hjust = 0.5, color = 'darkgreen', size = 9))\n\np4_high &lt;- ggplot(high_long, aes(x = Col, y = Row, fill = Expression)) +\n  geom_tile() +\n  scale_fill_gradient(low = 'white', high = 'red',\n                      limits = c(100, 1000),\n                      name = 'Expression\\n(100-1000 FPKM)') +\n  labs(title = 'Gene B (Independent Scale)',\n       subtitle = '(Clearly labeled)') +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, face = 'bold', size = 11),\n        plot.subtitle = element_text(hjust = 0.5, color = 'darkgreen', size = 9, face = 'italic'))\n\ncombined &lt;- (p1_low | p2_high) / (p3_low | p4_high)\nggsave('multiple_scales_logic.png', combined, width = 12, height = 10,\n       dpi = 300, bg = 'white')\n\ncat(\"✓ Multiple scales require explicit labeling\\n\")\ncat(\"✓ State ranges clearly in captions and colorbars\\n\")\n\n\n\n\nComplete Logical Color Mapping Checklist\nBefore finalizing figures with complex color schemes:\n\nIf all values meet threshold (e.g., all significant): Encode magnitude, not binary\nMissing data uses color OUTSIDE gradient + clear visual distinction\nZero point checked: Meaningful zero → Diverging; Arbitrary zero → Sequential\nCyclic data (time, angles): Use cyclic colormap (twilight, hsv)\nMultiple scales: Each clearly labeled or use shared scale if appropriate\nAsymmetric scales avoided (unless data truly asymmetric)\nLegend explicitly states what each color represents\nFigure caption documents colormap choice and scale ranges\n\n\n\n\nSummary: Advanced Color Logic\nThe Core Principle: Color mapping must reflect data structure, not override it\nCommon Violations: 1. Binary coloring when all values are in same category 2. Using gradient colors for missing data 3. Diverging colormap for data without meaningful center 4. Sequential colormap for cyclic data 5. Identical colormaps for vastly different scales without labeling\nThe Solution: - Match colormap type to data structure - Explicitly handle edge cases (NA, all significant, etc.) - Label everything clearly - Test interpretation: Can reader understand without reading caption?\n\n\n\n2.8 Color Palette Design Principles\nCore Principle: One figure page should contain 3 colors ideally, maximum 5 colors (excluding specialized plots like UMAPs where categorical distinctions require more).\n\n\nRule 1: The 3-5 Color Maximum\nScientific Principle: Human working memory effectively tracks 3-5 distinct categories simultaneously. Beyond this, cognitive load increases exponentially.\nApplication:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# CORRECT: 3-color palette (ideal)\nIDEAL_PALETTE = {\n    'WT': '#7F8C8D',        # Wild-type: neutral gray\n    'KO': '#E74C3C',        # Knockout: red (problem/loss)\n    'Rescue': '#3498DB'     # Rescue: blue (restoration)\n}\n\n# Example: Gene expression comparison\nnp.random.seed(42)\nconditions = ['WT', 'KO', 'Rescue']\nvalues = [100, 45, 92]  # Relative expression\nerrors = [8, 6, 9]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Panel A: Good example (3 colors)\nax1 = axes[0]\ncolors_good = [IDEAL_PALETTE[c] for c in conditions]\nbars1 = ax1.bar(conditions, values, yerr=errors, capsize=8,\n                color=colors_good, edgecolor='black', linewidth=2, width=0.6)\nax1.set_ylabel('Relative Expression (%)', fontsize=12, fontweight='bold')\nax1.set_ylim(0, 120)\nax1.set_title('✓ GOOD: 3 Colors\\n(Clear, memorable)',\n              fontsize=13, fontweight='bold', color='green')\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\nax1.grid(axis='y', alpha=0.3)\n\n# Add interpretation annotations\nax1.annotate('', xy=(0, values[0]), xytext=(1, values[1]),\n            arrowprops=dict(arrowstyle='&lt;-&gt;', color='black', lw=2))\nax1.text(0.5, (values[0]+values[1])/2 - 10, 'Loss of\\nfunction',\n        ha='center', fontsize=9, style='italic')\n\n# Panel B: Too many colors example\nax2 = axes[1]\nconditions_bad = ['WT', 'KO1', 'KO2', 'Rescue1', 'Rescue2',\n                  'Treatment A', 'Treatment B', 'Combination']\nvalues_bad = np.random.randint(40, 100, len(conditions_bad))\ncolors_bad = plt.cm.tab10(np.linspace(0, 1, len(conditions_bad)))\n\nbars2 = ax2.bar(range(len(conditions_bad)), values_bad,\n                color=colors_bad, edgecolor='black', linewidth=1, width=0.7)\nax2.set_xticks(range(len(conditions_bad)))\nax2.set_xticklabels(conditions_bad, rotation=45, ha='right', fontsize=8)\nax2.set_ylabel('Relative Expression (%)', fontsize=12, fontweight='bold')\nax2.set_ylim(0, 120)\nax2.set_title('❌ BAD: 8 Colors\\n(Overwhelming, hard to distinguish)',\n              fontsize=13, fontweight='bold', color='red')\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\n\nplt.tight_layout()\nplt.savefig('color_rule_3to5.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ 3-5 color rule demonstrated\")\nWhen you MUST use &gt;5 colors (e.g., UMAP clustering):\n# Solution: Use numbers/labels instead of relying solely on color\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Circle\nimport numpy as np\n\nnp.random.seed(42)\n\n# Simulate UMAP with 15 clusters\nn_cells = 1000\numap1 = np.random.randn(n_cells) * 3\numap2 = np.random.randn(n_cells) * 3\nclusters = np.random.randint(0, 15, n_cells)\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 7))\n\n# Panel A: Color only (hard to distinguish)\nax1 = axes[0]\nscatter1 = ax1.scatter(umap1, umap2, c=clusters, cmap='tab20',\n                       s=20, alpha=0.6, edgecolors='none')\nax1.set_xlabel('UMAP 1', fontsize=12, fontweight='bold')\nax1.set_ylabel('UMAP 2', fontsize=12, fontweight='bold')\nax1.set_title('❌ 15 Clusters: Color Only\\n(Hard to match legend)',\n              fontsize=13, fontweight='bold', color='red')\ncbar1 = plt.colorbar(scatter1, ax=ax1)\ncbar1.set_label('Cluster ID', fontsize=11, fontweight='bold')\n\n# Panel B: Color + numbered labels (clear)\nax2 = axes[1]\nscatter2 = ax2.scatter(umap1, umap2, c=clusters, cmap='tab20',\n                       s=20, alpha=0.6, edgecolors='none')\n\n# Add cluster number labels at centroids\nfor cluster_id in range(15):\n    mask = clusters == cluster_id\n    if np.sum(mask) &gt; 0:\n        centroid_x = umap1[mask].mean()\n        centroid_y = umap2[mask].mean()\n\n        # White circle background for visibility\n        circle = Circle((centroid_x, centroid_y), radius=0.5,\n                       facecolor='white', edgecolor='black',\n                       linewidth=2, zorder=10)\n        ax2.add_patch(circle)\n\n        # Cluster number\n        ax2.text(centroid_x, centroid_y, str(cluster_id),\n                ha='center', va='center', fontsize=10,\n                fontweight='bold', zorder=11)\n\nax2.set_xlabel('UMAP 1', fontsize=12, fontweight='bold')\nax2.set_ylabel('UMAP 2', fontsize=12, fontweight='bold')\nax2.set_title('✓ BETTER: Color + Numbers\\n(Easy to reference)',\n              fontsize=13, fontweight='bold', color='green')\n\nplt.tight_layout()\nplt.savefig('many_clusters_solution.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\n\n\nRule 2: Color Harmony - Avoid Deep + Light Mixing\nPrinciple: Mixing very dark and very light colors creates harsh, unbalanced contrast that looks unprofessional.\nSolution: Keep colors within similar lightness ranges, or balance proportions intentionally.\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nfrom matplotlib import colors as mcolors\nimport numpy as np\n\nfig, axes = plt.subplots(3, 1, figsize=(12, 10))\n\n# BAD Example: Deep + Light mixing (unbalanced)\nax1 = axes[0]\nbad_colors = ['#1A1A1A', '#EFEFEF', '#2C3E50', '#ECF0F1']  # Very dark + very light\nbad_labels = ['Very Dark', 'Very Light', 'Dark', 'Light']\n\nfor i, (c, label) in enumerate(zip(bad_colors, bad_labels)):\n    rect = mpatches.Rectangle((i*2.5, 0), 2, 1, facecolor=c,\n                             edgecolor='black', linewidth=2)\n    ax1.add_patch(rect)\n\n    # Calculate lightness\n    rgb = mcolors.hex2color(c)\n    lightness = 0.299*rgb[0] + 0.587*rgb[1] + 0.114*rgb[2]\n\n    ax1.text(i*2.5 + 1, 0.5, f'{label}\\nL={lightness:.2f}',\n            ha='center', va='center', fontsize=10, fontweight='bold',\n            color='white' if lightness &lt; 0.5 else 'black')\n\nax1.set_xlim(0, 10)\nax1.set_ylim(0, 1)\nax1.set_title('❌ BAD: Deep + Light Mixing (Harsh Contrast, L range: 0.07-0.94)',\n              fontsize=13, fontweight='bold', color='red', pad=15)\nax1.axis('off')\n\n# GOOD Example: Balanced lightness\nax2 = axes[1]\ngood_colors = ['#7F8C8D', '#3498DB', '#E74C3C', '#27AE60']  # Balanced\ngood_labels = ['Gray', 'Blue', 'Red', 'Green']\n\nfor i, (c, label) in enumerate(zip(good_colors, good_labels)):\n    rect = mpatches.Rectangle((i*2.5, 0), 2, 1, facecolor=c,\n                             edgecolor='black', linewidth=2)\n    ax2.add_patch(rect)\n\n    rgb = mcolors.hex2color(c)\n    lightness = 0.299*rgb[0] + 0.587*rgb[1] + 0.114*rgb[2]\n\n    ax2.text(i*2.5 + 1, 0.5, f'{label}\\nL={lightness:.2f}',\n            ha='center', va='center', fontsize=10, fontweight='bold',\n            color='white')\n\nax2.set_xlim(0, 10)\nax2.set_ylim(0, 1)\nax2.set_title('✓ GOOD: Balanced Lightness (L range: 0.35-0.55)',\n              fontsize=13, fontweight='bold', color='green', pad=15)\nax2.axis('off')\n\n# ACCEPTABLE: Intentional gradient (if needed)\nax3 = axes[2]\ngradient_colors = ['#D6EAF8', '#85C1E9', '#3498DB', '#21618C', '#1B4F72']  # Blue gradient\ngradient_labels = ['Very Light', 'Light', 'Medium', 'Dark', 'Very Dark']\n\nfor i, (c, label) in enumerate(zip(gradient_colors, gradient_labels)):\n    rect = mpatches.Rectangle((i*2, 0), 1.8, 1, facecolor=c,\n                             edgecolor='black', linewidth=2)\n    ax3.add_patch(rect)\n\n    rgb = mcolors.hex2color(c)\n    lightness = 0.299*rgb[0] + 0.587*rgb[1] + 0.114*rgb[2]\n\n    ax3.text(i*2 + 0.9, 0.5, f'{label}\\nL={lightness:.2f}',\n            ha='center', va='center', fontsize=9, fontweight='bold',\n            color='white' if lightness &lt; 0.5 else 'black')\n\nax3.set_xlim(0, 10)\nax3.set_ylim(0, 1)\nax3.set_title('✓ ACCEPTABLE: Intentional Gradient (Single Hue Family, Smooth Transition)',\n              fontsize=13, fontweight='bold', color='green', pad=15)\nax3.axis('off')\n\nplt.tight_layout()\nplt.savefig('color_balance_lightness.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\n\n\nRule 3: Biological Logic in Color Assignment\nPrinciple: Colors should follow scientific conventions and intuitive associations.\nExamples:\n# 1. WT, KO, Rescue: Color proximity reflects biological relationship\nBIOLOGICAL_LOGIC = {\n    'WT': '#7F8C8D',      # Wild-type: neutral gray (baseline)\n    'Rescue': '#5D6D7E',  # Rescue: similar gray (close to WT) ← KEY POINT\n    'KO': '#E74C3C'       # Knockout: red (different/problem)\n}\n# → WT and Rescue should have SIMILAR colors (both are functional states)\n\n# 2. Disease severity: Darker = more severe (intuitive)\nDISEASE_SEVERITY = {\n    'Healthy': '#D5F4E6',      # Very light green\n    'Mild': '#82E0AA',         # Light green\n    'Moderate': '#F39C12',     # Orange (warning)\n    'Severe': '#E67E22',       # Dark orange\n    'Critical': '#C0392B'      # Dark red (danger)\n}\n\n# 3. Traffic light convention: Red=stop/problem, Green=go/healthy\nINTUITIVE_ASSOCIATIONS = {\n    'Control': '#27AE60',      # Green = healthy/baseline\n    'Disease': '#E74C3C',      # Red = problem\n    'Treatment': '#3498DB'     # Blue = intervention\n}\n\n# 4. Temperature: Blue=cold, Red=hot\nTEMPERATURE_SCALE = {\n    'cold': '#3498DB',\n    'warm': '#F39C12',\n    'hot': '#E74C3C'\n}\nCode Example: WT-KO-Rescue Color Logic\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# BAD: KO and Rescue have similar colors (confusing relationship)\nax1 = axes[0]\nconditions_bad = ['WT', 'KO', 'Rescue']\nvalues_bad = [100, 45, 95]\ncolors_bad = ['#7F8C8D', '#E74C3C', '#C0392B']  # KO and Rescue both reddish!\n\nbars1 = ax1.bar(conditions_bad, values_bad, color=colors_bad,\n               edgecolor='black', linewidth=2, width=0.6)\nax1.set_ylabel('Function (%)', fontsize=12, fontweight='bold')\nax1.set_ylim(0, 120)\nax1.set_title('❌ BAD: KO and Rescue Look Similar\\n(Implies they are related states)',\n              fontsize=13, fontweight='bold', color='red')\nax1.axhline(100, color='black', linestyle='--', linewidth=1, alpha=0.5)\nax1.text(2.5, 102, 'WT baseline', fontsize=9, style='italic')\n\n# GOOD: WT and Rescue similar (both functional), KO different\nax2 = axes[1]\nconditions_good = ['WT', 'KO', 'Rescue']\nvalues_good = [100, 45, 95]\ncolors_good = ['#7F8C8D', '#E74C3C', '#5D6D7E']  # WT and Rescue similar grays!\n\nbars2 = ax2.bar(conditions_good, values_good, color=colors_good,\n               edgecolor='black', linewidth=2, width=0.6)\nax2.set_ylabel('Function (%)', fontsize=12, fontweight='bold')\nax2.set_ylim(0, 120)\nax2.set_title('✓ GOOD: WT and Rescue Similar Colors\\n(Correctly shows functional relationship)',\n              fontsize=13, fontweight='bold', color='green')\nax2.axhline(100, color='black', linestyle='--', linewidth=1, alpha=0.5)\n\n# Add annotations showing color logic\nax2.annotate('', xy=(0, 110), xytext=(2, 110),\n            arrowprops=dict(arrowstyle='&lt;-&gt;', color='green', lw=3))\nax2.text(1, 113, 'Similar colors =\\nSimilar function', ha='center',\n        fontsize=9, fontweight='bold', color='green',\n        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n\nax2.annotate('', xy=(1, -8), xytext=(1, -8),\n            arrowprops=dict(arrowstyle='-', color='red', lw=0))\nax2.text(1, -12, 'Different color =\\nLoss of function', ha='center',\n        fontsize=9, fontweight='bold', color='red',\n        bbox=dict(boxstyle='round', facecolor='#FFCCCC', alpha=0.7))\n\nplt.tight_layout()\nplt.savefig('wt_ko_rescue_color_logic.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\n\n\nRule 4: NA/Missing Data Color Strategy\nPrinciple: NA colors must be distinguishable and EXCLUDED from the main color scheme.\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(42)\n\n# Simulate data with missing values\ndata = {\n    'Gene': [f'Gene{i}' for i in range(1, 26)],\n    'Sample1': np.random.randn(25),\n    'Sample2': np.random.randn(25),\n    'Sample3': np.random.randn(25),\n    'Sample4': np.random.randn(25)\n}\n\ndf = pd.DataFrame(data).set_index('Gene')\n\n# Introduce NA values\ndf.iloc[3:6, 1] = np.nan\ndf.iloc[10:12, 2] = np.nan\ndf.iloc[18, 3] = np.nan\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# BAD: NA color within main palette (confusing)\nax1 = axes[0]\ndata_for_plot = df.fillna(-999)  # Sentinel value\nim1 = ax1.imshow(data_for_plot, cmap='RdBu_r', aspect='auto',\n                 vmin=-2, vmax=2)\nax1.set_title('❌ BAD: NA Blends with Data\\n(Can\\'t distinguish missing values)',\n              fontsize=13, fontweight='bold', color='red')\nax1.set_xlabel('Samples', fontsize=11, fontweight='bold')\nax1.set_ylabel('Genes', fontsize=11, fontweight='bold')\nax1.set_xticks(range(4))\nax1.set_xticklabels(['Sample1', 'Sample2', 'Sample3', 'Sample4'], rotation=45, ha='right')\nplt.colorbar(im1, ax=ax1, label='Expression (Z-score)')\n\n# GOOD: NA in distinct color (crosshatch or gray)\nax2 = axes[1]\n\n# Create masked array\ndata_masked = np.ma.masked_where(np.isnan(df.values), df.values)\n\nim2 = ax2.imshow(data_masked, cmap='RdBu_r', aspect='auto',\n                 vmin=-2, vmax=2)\n\n# Add gray rectangles for NA values\nfor i in range(df.shape[0]):\n    for j in range(df.shape[1]):\n        if np.isnan(df.values[i, j]):\n            ax2.add_patch(plt.Rectangle((j-0.5, i-0.5), 1, 1,\n                                       facecolor='#D3D3D3',\n                                       edgecolor='black',\n                                       linewidth=1.5,\n                                       hatch='///',\n                                       fill=True))\n\nax2.set_title('✓ GOOD: NA in Distinct Color\\n(Crosshatch pattern, separate from scale)',\n              fontsize=13, fontweight='bold', color='green')\nax2.set_xlabel('Samples', fontsize=11, fontweight='bold')\nax2.set_ylabel('Genes', fontsize=11, fontweight='bold')\nax2.set_xticks(range(4))\nax2.set_xticklabels(['Sample1', 'Sample2', 'Sample3', 'Sample4'], rotation=45, ha='right')\n\ncbar2 = plt.colorbar(im2, ax=ax2, label='Expression (Z-score)')\n\n# Add NA legend\nfrom matplotlib.patches import Patch\nna_patch = Patch(facecolor='#D3D3D3', edgecolor='black',\n                hatch='///', label='NA / Missing')\nax2.legend(handles=[na_patch], loc='upper right', frameon=True)\n\nplt.tight_layout()\nplt.savefig('na_color_strategy.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\nR Equivalent:\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\n\n# Create data with NAs\nset.seed(42)\ndata &lt;- expand.grid(\n  Gene = paste0('Gene', 1:25),\n  Sample = paste0('Sample', 1:4)\n) %&gt;%\n  mutate(Expression = rnorm(n()))\n\n# Introduce NAs\ndata$Expression[30:35] &lt;- NA\ndata$Expression[60:62] &lt;- NA\n\n# Plot with distinct NA handling\nggplot(data, aes(x = Sample, y = Gene, fill = Expression)) +\n  geom_tile(color = 'white', size = 0.5) +\n\n  # Main color scale (for non-NA values)\n  scale_fill_gradient2(low = '#3498DB', mid = 'white', high = '#E74C3C',\n                      midpoint = 0, na.value = '#D3D3D3',  # Gray for NA\n                      name = 'Expression\\n(Z-score)') +\n\n  # Add pattern to NA tiles (requires ggpattern package)\n  # library(ggpattern)\n  # geom_tile_pattern(data = filter(data, is.na(Expression)),\n  #                   pattern = 'crosshatch', pattern_density = 0.5,\n  #                   fill = '#D3D3D3', color = 'black', size = 1) +\n\n  labs(title = '✓ NA Values in Distinct Gray (Separate from Scale)',\n       x = 'Samples', y = 'Genes') +\n\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(face = 'bold', size = 13, hjust = 0.5, color = 'darkgreen'),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = 'right'\n  )\n\nggsave('na_color_strategy_r.png', width = 10, height = 8, dpi = 300)\n\n\n\nRule 5: Sequential Colors - Single Hue Families\nWhen to use: Continuous data (e.g., expression levels, concentrations, counts)\nPrinciple: Use gradations of a single hue to show magnitude, not rainbow colors.\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import LinearSegmentedColormap\n\nnp.random.seed(42)\n\n# Simulate continuous data (e.g., gene expression)\ndata = np.random.rand(10, 10) * 100\n\nfig, axes = plt.subplots(1, 3, figsize=(16, 5))\n\n# BAD: Rainbow (not perceptually uniform, no clear magnitude)\nax1 = axes[0]\nim1 = ax1.imshow(data, cmap='jet', aspect='auto')\nax1.set_title('❌ BAD: Rainbow\\n(Unclear magnitude progression)',\n              fontsize=13, fontweight='bold', color='red')\nplt.colorbar(im1, ax=ax1, label='Expression')\n\n# GOOD: Single hue gradient (clear magnitude)\nax2 = axes[1]\nim2 = ax2.imshow(data, cmap='Blues', aspect='auto')\nax2.set_title('✓ GOOD: Single Hue (Blue)\\n(Clear: Light → Dark = Low → High)',\n              fontsize=13, fontweight='bold', color='green')\nplt.colorbar(im2, ax=ax2, label='Expression')\n\n# ALSO GOOD: Custom single-hue gradient\nax3 = axes[2]\ncolors_custom = ['#FFFFFF', '#EBF5FB', '#D6EAF8', '#AED6F1',\n                '#85C1E9', '#5DADE2', '#3498DB', '#2E86C1',\n                '#2874A6', '#21618C']\ncmap_custom = LinearSegmentedColormap.from_list('custom_blues', colors_custom)\nim3 = ax3.imshow(data, cmap=cmap_custom, aspect='auto')\nax3.set_title('✓ ALSO GOOD: Custom Blue Gradient\\n(Smooth progression)',\n              fontsize=13, fontweight='bold', color='green')\nplt.colorbar(im3, ax=ax3, label='Expression')\n\nplt.tight_layout()\nplt.savefig('sequential_color_single_hue.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2: The Language of Color</span>"
    ]
  },
  {
    "objectID": "Chapter 2.html#shape-selection-and-usage-new-section",
    "href": "Chapter 2.html#shape-selection-and-usage-new-section",
    "title": "Chapter 2: The Language of Color",
    "section": "2.9 Shape Selection and Usage (NEW SECTION)",
    "text": "2.9 Shape Selection and Usage (NEW SECTION)\n\nRule: Shape Must Provide Clear Contrast\nPrinciple: Regular vs. irregular shapes, filled vs. open - use contrast to distinguish groups.\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Simulate data for different conditions\nconditions = ['Control', 'Treatment A', 'Treatment B', 'Treatment C']\nn_points = 30\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# BAD: Similar shapes (hard to distinguish)\nax1 = axes[0]\nshapes_bad = ['o', 's', '^', 'v']  # All filled, similar sizes\nfor i, (cond, marker) in enumerate(zip(conditions, shapes_bad)):\n    x = np.random.randn(n_points) + i*2\n    y = np.random.randn(n_points)\n    ax1.scatter(x, y, s=80, marker=marker, color='#3498DB',\n               alpha=0.6, edgecolors='black', linewidths=1,\n               label=cond)\n\nax1.set_xlabel('Variable X', fontsize=12, fontweight='bold')\nax1.set_ylabel('Variable Y', fontsize=12, fontweight='bold')\nax1.set_title('❌ BAD: Subtle Shape Differences\\n(Hard to distinguish quickly)',\n              fontsize=13, fontweight='bold', color='red')\nax1.legend(loc='upper left', frameon=True, fontsize=10)\nax1.grid(alpha=0.3)\n\n# GOOD: Contrasting shapes (easy to distinguish)\nax2 = axes[1]\nshapes_good = ['o', 's', '^', 'D']  # Mix of regular shapes\nfills = [True, False, True, False]  # Alternate filled/open\ncolors_contrast = ['#3498DB', '#3498DB', '#E74C3C', '#E74C3C']\n\nfor i, (cond, marker, filled, color) in enumerate(zip(conditions, shapes_good, fills, colors_contrast)):\n    x = np.random.randn(n_points) + i*2\n    y = np.random.randn(n_points)\n\n    if filled:\n        ax2.scatter(x, y, s=100, marker=marker, color=color,\n                   alpha=0.7, edgecolors='black', linewidths=1.5,\n                   label=cond)\n    else:\n        ax2.scatter(x, y, s=100, marker=marker, facecolors='none',\n                   edgecolors=color, linewidths=2,\n                   label=cond)\n\nax2.set_xlabel('Variable X', fontsize=12, fontweight='bold')\nax2.set_ylabel('Variable Y', fontsize=12, fontweight='bold')\nax2.set_title('✓ GOOD: High Contrast Shapes\\n(Filled/Open + Color + Shape)',\n              fontsize=13, fontweight='bold', color='green')\nax2.legend(loc='upper left', frameon=True, fontsize=10)\nax2.grid(alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('shape_contrast.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\nShape Palette Recommendations:\n# Accessible shape combinations (easily distinguishable)\nSHAPE_PALETTE_GOOD = {\n    'Group1': {'marker': 'o', 'fill': True, 'size': 80},    # Filled circle\n    'Group2': {'marker': 's', 'fill': False, 'size': 80},   # Open square\n    'Group3': {'marker': '^', 'fill': True, 'size': 100},   # Filled triangle\n    'Group4': {'marker': 'D', 'fill': False, 'size': 70}    # Open diamond\n}\n\n# Bad: Too subtle differences\nSHAPE_PALETTE_BAD = {\n    'Group1': {'marker': 'o', 'fill': True, 'size': 80},    # Filled circle\n    'Group2': {'marker': 'o', 'fill': True, 'size': 90},    # Slightly larger circle (!)\n    'Group3': {'marker': 'o', 'fill': True, 'size': 70},    # Slightly smaller circle (!)\n    'Group4': {'marker': 's', 'fill': True, 'size': 80}     # Square (finally different)\n}\n\nChapter 2 Complete Summary:\nYou now understand: - Color theory (RGB, HSV, CIELAB) and perceptual uniformity - Palette types (sequential, diverging, qualitative) matched to data types - Saturation logic (deep=important/significant, light=background) - Restraint (3-color maximum) and consistency (same concept=same color) - Field conventions and when/how to deviate - Accessibility (colorblind-safe, redundant encoding, testing) - Integrity (no manipulation, symmetric scales, transparency) - Logical edge cases (all significant, missing data, meaningful zero, cyclic data, multiple scales)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2: The Language of Color</span>"
    ]
  },
  {
    "objectID": "Chapter 3.html",
    "href": "Chapter 3.html",
    "title": "Chapter 3: Typography, Annotation & Labels",
    "section": "",
    "text": "3.1 The Functional Role of Text in Scientific Figures",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3: Typography, Annotation & Labels</span>"
    ]
  },
  {
    "objectID": "Chapter 3.html#the-functional-role-of-text-in-scientific-figures",
    "href": "Chapter 3.html#the-functional-role-of-text-in-scientific-figures",
    "title": "Chapter 3: Typography, Annotation & Labels",
    "section": "",
    "text": "Text is Not Decoration—It’s Data Infrastructure\nIn scientific figures, every text element serves a specific functional purpose. Unlike artistic or marketing graphics where text might be styled for aesthetic impact, scientific text must prioritize:\n\nClarity: Instant comprehension without ambiguity\nHierarchy: Guide reader to information in logical order\nPrecision: Accurate communication of units, values, and relationships\nAccessibility: Readable across viewing conditions (screen, print, projection)\nConsistency: Predictable patterns reduce cognitive load\n\nText Elements in a Complete Figure:\nEssential text components:\n├─ Title/Caption (what is being shown)\n├─ Axis labels (what dimensions represent)\n├─ Axis tick labels (scale values)\n├─ Legend (what colors/symbols mean)\n├─ Data labels (optional: direct value annotation)\n├─ Statistical annotations (significance markers, p-values)\n└─ Panel labels (A, B, C for multi-panel figures)\n\n\n\nThe Hierarchy of Text Importance\nLevel 1: Critical (Must Read) - Axis labels with units - Legend identifying groups - Panel labels (A, B, C) → Bold, 10-12pt, high contrast\nLevel 2: Important (Should Read) - Axis tick values - Figure title/caption number - Statistical significance markers → Regular weight, 9-10pt\nLevel 3: Supporting (May Read) - Secondary annotations - Supplementary notes → Regular weight, 8-9pt, possibly lighter gray\nCode Example (Python) - Text Hierarchy:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Sample data\nnp.random.seed(42)\ncategories = ['Control', 'Treatment A', 'Treatment B']\nvalues = [25, 32, 28]\nerrors = [3, 4, 3.5]\n\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Data\nbars = ax.bar(categories, values, color=['#7F8C8D', '#3498DB', '#E74C3C'],\n              edgecolor='black', linewidth=1.5, width=0.6)\nax.errorbar(categories, values, yerr=errors, fmt='none',\n            ecolor='black', capsize=8, linewidth=2)\n\n# LEVEL 1: Critical - Axis labels (bold, large)\nax.set_xlabel('Treatment Group', fontsize=12, fontweight='bold', color='#000000')\nax.set_ylabel('Cell Viability (%)', fontsize=12, fontweight='bold', color='#000000')\n\n# LEVEL 2: Important - Tick labels (regular, medium)\nax.tick_params(axis='both', labelsize=10, colors='#333333')\n\n# Add statistical annotation (Level 2)\nax.text(1, 35, '***', ha='center', va='bottom',\n        fontsize=14, fontweight='bold', color='#000000')\nax.plot([0, 1], [34, 34], 'k-', linewidth=1.5)\n\n# LEVEL 3: Supporting - Explanatory note (smaller, lighter)\nax.text(0.02, 0.98, '*** p &lt; 0.001', transform=ax.transAxes,\n        fontsize=8, va='top', ha='left', color='#666666', style='italic')\n\n# Title (Level 1)\nax.set_title('Effect of Treatment on Cell Viability',\n             fontsize=13, fontweight='bold', pad=15)\n\nax.set_ylim(0, 45)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('text_hierarchy_example.png', dpi=300,\n            bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R) - Text Hierarchy:\nlibrary(ggplot2)\n\n# Data\ndata &lt;- data.frame(\n  group = factor(c('Control', 'Treatment A', 'Treatment B'),\n                 levels = c('Control', 'Treatment A', 'Treatment B')),\n  value = c(25, 32, 28),\n  error = c(3, 4, 3.5)\n)\n\ncolors &lt;- c('Control' = '#7F8C8D', 'Treatment A' = '#3498DB', 'Treatment B' = '#E74C3C')\n\np &lt;- ggplot(data, aes(x = group, y = value, fill = group)) +\n  geom_bar(stat = 'identity', color = 'black', size = 1, width = 0.6) +\n  geom_errorbar(aes(ymin = value - error, ymax = value + error),\n                width = 0.25, size = 1) +\n  scale_fill_manual(values = colors) +\n\n  # LEVEL 1: Critical - Axis labels (bold, large)\n  labs(x = 'Treatment Group',\n       y = 'Cell Viability (%)',\n       title = 'Effect of Treatment on Cell Viability') +\n\n  # Statistical annotation (Level 2)\n  annotate('segment', x = 1, xend = 2, y = 34, yend = 34, size = 1) +\n  annotate('text', x = 1.5, y = 35, label = '***',\n           size = 5, fontface = 'bold') +\n\n  # LEVEL 3: Supporting note\n  annotate('text', x = 0.6, y = 43, label = '*** p &lt; 0.001',\n           size = 2.8, hjust = 0, fontface = 'italic', color = '#666666') +\n\n  ylim(0, 45) +\n\n  theme_classic(base_size = 11) +\n  theme(\n    # Level 1: Critical text\n    axis.title = element_text(face = 'bold', size = 12, color = '#000000'),\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 13),\n\n    # Level 2: Important\n    axis.text = element_text(size = 10, color = '#333333'),\n\n    legend.position = 'none',\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\nggsave('text_hierarchy_example.png', p, width = 8, height = 6,\n       dpi = 300, bg = 'white')",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3: Typography, Annotation & Labels</span>"
    ]
  },
  {
    "objectID": "Chapter 3.html#font-selection-for-scientific-figures",
    "href": "Chapter 3.html#font-selection-for-scientific-figures",
    "title": "Chapter 3: Typography, Annotation & Labels",
    "section": "3.2 Font Selection for Scientific Figures",
    "text": "3.2 Font Selection for Scientific Figures\n\nThe Golden Rule: Sans-Serif for Figures, Serif for Text\nWhy sans-serif for figures: - Better legibility at small sizes - Cleaner appearance when scaled/compressed - Works better with data (numbers, symbols) - Maintains clarity in digital and print\nRecommended Font Families:\nTier 1: Universally Available, Publication-Ready\nArial: Clean, neutral, universally supported\nHelvetica: Professional standard (Mac default, expensive license)\nCalibri: Modern, readable (Microsoft Office default)\nTier 2: Enhanced Readability\nRoboto: Google's open-source, excellent screen rendering\nOpen Sans: Friendly, highly legible, free\nSource Sans Pro: Adobe's open-source, designed for UI\nTier 3: Specialized Scientific\nCMU Sans (Computer Modern): Matches LaTeX documents\nDejaVu Sans: Unicode support, open-source\nLiberation Sans: Metric-compatible with Arial (open-source)\nFonts to AVOID in Scientific Figures:\n❌ Comic Sans: Unprofessional\n❌ Papyrus: Decorative, illegible at small sizes\n❌ Brush Script: Artistic, not data-appropriate\n❌ Elaborate serifs (Times, Garamond) in graphs: Cluttered at small sizes\nCode Example (Python) - Font Consistency:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Set global font parameters (do this ONCE at start of script)\nplt.rcParams.update({\n    'font.family': 'sans-serif',\n    'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],  # Fallback order\n    'font.size': 10,\n    'axes.labelsize': 11,\n    'axes.titlesize': 12,\n    'xtick.labelsize': 9,\n    'ytick.labelsize': 9,\n    'legend.fontsize': 9,\n    'figure.titlesize': 14\n})\n\n# Sample figure\nnp.random.seed(42)\nx = np.linspace(0, 10, 50)\ny = 2*x + np.random.randn(50)*2\n\nfig, ax = plt.subplots(figsize=(7, 5))\nax.scatter(x, y, color='#3498DB', s=50, alpha=0.7, edgecolors='black', linewidths=0.5)\nax.plot(x, 2*x, 'r--', linewidth=2, label='y = 2x')\n\nax.set_xlabel('Independent Variable (units)')\nax.set_ylabel('Dependent Variable (units)')\nax.set_title('Consistent Sans-Serif Typography')\nax.legend(loc='upper left', frameon=True)\nax.grid(alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('font_consistency.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Font family: Arial/Helvetica\")\nprint(\"✓ Consistent sizing across all text elements\")\nCode Example (R) - Font Consistency:\nlibrary(ggplot2)\n\n# Sample data\nset.seed(42)\ndata &lt;- data.frame(\n  x = seq(0, 10, length.out = 50),\n  y = 2 * seq(0, 10, length.out = 50) + rnorm(50, 0, 2)\n)\n\np &lt;- ggplot(data, aes(x = x, y = y)) +\n  geom_point(color = '#3498DB', size = 3, alpha = 0.7) +\n  geom_abline(intercept = 0, slope = 2, color = 'red', linetype = 'dashed', size = 1) +\n\n  labs(x = 'Independent Variable (units)',\n       y = 'Dependent Variable (units)',\n       title = 'Consistent Sans-Serif Typography') +\n\n  # Specify font family (will fall back to system default if not available)\n  theme_classic(base_size = 10, base_family = 'Arial') +\n  theme(\n    axis.title = element_text(size = 11, face = 'bold'),\n    plot.title = element_text(hjust = 0.5, size = 12, face = 'bold'),\n    axis.text = element_text(size = 9),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\nggsave('font_consistency.png', p, width = 7, height = 5,\n       dpi = 300, bg = 'white')\n\ncat(\"✓ Font family: Arial\\n\")\ncat(\"✓ Consistent sizing across all text elements\\n\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3: Typography, Annotation & Labels</span>"
    ]
  },
  {
    "objectID": "Chapter 3.html#axis-labels-units-and-clarity",
    "href": "Chapter 3.html#axis-labels-units-and-clarity",
    "title": "Chapter 3: Typography, Annotation & Labels",
    "section": "3.3 Axis Labels: Units and Clarity",
    "text": "3.3 Axis Labels: Units and Clarity\n\nThe Non-Negotiable Rule: Always Include Units\nFormat: “Variable Name (units)”\n✓ CORRECT:\n  \"Temperature (°C)\"\n  \"Time (hours)\"\n  \"Concentration (μM)\"\n  \"Expression Level (FPKM)\"\n  \"Velocity (m/s)\"\n\n❌ WRONG:\n  \"Temperature\" (What scale? Celsius? Kelvin? Fahrenheit?)\n  \"Time\" (Seconds? Minutes? Hours? Days?)\n  \"Expression\" (Arbitrary units? Fold change? FPKM?)\n\n\nSpecial Cases: Dimensionless and Normalized Data\nWhen data has no units:\nAcceptable labels for dimensionless quantities:\n✓ \"Correlation Coefficient (r)\" → range -1 to 1, dimensionless\n✓ \"Probability (p)\" → range 0 to 1, dimensionless\n✓ \"Fold Change (log₂)\" → ratio, logarithm specified\n✓ \"Normalized Expression (AU)\" → AU = Arbitrary Units (acknowledges normalization)\n✓ \"Relative Abundance (%)\" → percentage is the unit\nWhen you’ve normalized but original units existed:\n✓ GOOD: \"Normalized Expression (% of maximum)\"\n✓ GOOD: \"Fluorescence Intensity (AU)\" + note in methods about normalization\n✓ ACCEPTABLE: \"Response (normalized)\" + full description in caption\n\n❌ BAD: \"Expression\" with no indication of normalization\n\n\nLogical Consistency: Axes Must Match Data\nCommon Error: Mismatch between label and actual data\n❌ INCONSISTENT:\nLabel: \"Temperature (°C)\"\nData range: 273-373\n→ These are Kelvin values!\n\n✓ FIX:\nLabel: \"Temperature (K)\" OR convert data to Celsius\n\n---\n\n❌ INCONSISTENT:\nLabel: \"Time (hours)\"\nTick marks: 0, 60, 120, 180, 240\n→ These are minutes!\n\n✓ FIX:\nLabel: \"Time (minutes)\" OR convert to hours (0, 1, 2, 3, 4)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3: Typography, Annotation & Labels</span>"
    ]
  },
  {
    "objectID": "Chapter 3.html#panel-labels-and-multi-figure-organization",
    "href": "Chapter 3.html#panel-labels-and-multi-figure-organization",
    "title": "Chapter 3: Typography, Annotation & Labels",
    "section": "3.4 Panel Labels and Multi-Figure Organization",
    "text": "3.4 Panel Labels and Multi-Figure Organization\n\nThe Standard Convention: A, B, C, D…\nWhen figures contain multiple panels, panel labels provide critical navigational structure that allows the main text to reference specific subfigures precisely.\nStandard Format:\n✓ STANDARD: Bold, uppercase letters (A, B, C, D...)\n✓ Position: Top-left corner of each panel (outside or just inside)\n✓ Size: Slightly larger than axis labels (13-14pt when axis labels are 11pt)\n✓ Color: Black or very dark gray\nWhy This Matters:\nIn manuscript text:\n\"Treatment A showed significant improvement (Figure 2B),\nwhile histological analysis revealed reduced inflammation (Figure 2C).\"\n\nWithout clear panel labels:\n\"Treatment A showed improvement (see second panel in Figure 2?)\"\n→ Ambiguous, unprofessional\n\n\n\nPlacement Options\nOption 1: Outside panel (most common in publications)\nAdvantages:\n✓ Doesn't obscure data\n✓ Clear visual separation\n✓ Consistent position across panels\n\nDisadvantages:\n✗ Requires extra space in figure layout\nOption 2: Inside panel, top-left corner\nAdvantages:\n✓ Space-efficient\n✓ Works well when panels have white space in corner\n\nDisadvantages:\n✗ Can obscure data if corner contains information\n✗ May need background box for visibility\nCode Example (Python) - Panel Labels:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# Sample data for each panel\nfor idx, ax in enumerate(axes.flat):\n    # Different plot type for each panel\n    if idx == 0:\n        # Scatter plot\n        x = np.random.randn(50)\n        y = 2*x + np.random.randn(50)\n        ax.scatter(x, y, color='#3498DB', s=50, alpha=0.7, edgecolors='black', linewidths=0.5)\n        ax.set_xlabel('Variable X (units)', fontsize=11, fontweight='bold')\n        ax.set_ylabel('Variable Y (units)', fontsize=11, fontweight='bold')\n        ax.set_title('Correlation Analysis', fontsize=12, fontweight='bold')\n\n    elif idx == 1:\n        # Bar chart\n        categories = ['Group 1', 'Group 2', 'Group 3']\n        values = [25, 32, 28]\n        ax.bar(categories, values, color=['#7F8C8D', '#3498DB', '#E74C3C'],\n              edgecolor='black', linewidth=1.5)\n        ax.set_ylabel('Response (AU)', fontsize=11, fontweight='bold')\n        ax.set_title('Group Comparison', fontsize=12, fontweight='bold')\n\n    elif idx == 2:\n        # Line plot\n        time = np.linspace(0, 10, 50)\n        signal = np.sin(time) + np.random.randn(50)*0.1\n        ax.plot(time, signal, color='#27AE60', linewidth=2.5)\n        ax.set_xlabel('Time (s)', fontsize=11, fontweight='bold')\n        ax.set_ylabel('Signal (mV)', fontsize=11, fontweight='bold')\n        ax.set_title('Temporal Dynamics', fontsize=12, fontweight='bold')\n\n    else:\n        # Heatmap\n        data = np.random.randn(10, 10)\n        im = ax.imshow(data, cmap='RdBu_r', aspect='auto')\n        ax.set_xlabel('Sample', fontsize=11, fontweight='bold')\n        ax.set_ylabel('Gene', fontsize=11, fontweight='bold')\n        ax.set_title('Expression Pattern', fontsize=12, fontweight='bold')\n        plt.colorbar(im, ax=ax, fraction=0.046)\n\n    # PANEL LABEL: Outside, top-left\n    panel_label = chr(65 + idx)  # A, B, C, D\n    ax.text(-0.15, 1.05, panel_label,\n           transform=ax.transAxes,  # Coordinates relative to panel\n           fontsize=16, fontweight='bold',\n           va='top', ha='right',\n           color='black')\n\n    # Style\n    ax.grid(alpha=0.3)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\nplt.tight_layout()\nplt.savefig('panel_labels_example.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Panel labels: A, B, C, D (bold, outside panels)\")\nCode Example (R) - Panel Labels:\nlibrary(ggplot2)\nlibrary(patchwork)\n\nset.seed(42)\n\n# Panel A: Scatter plot\np_a &lt;- ggplot(data.frame(x = rnorm(50), y = 2*rnorm(50) + rnorm(50)),\n             aes(x = x, y = y)) +\n  geom_point(color = '#3498DB', size = 3, alpha = 0.7) +\n  labs(x = 'Variable X (units)', y = 'Variable Y (units)',\n       title = 'Correlation Analysis') +\n  theme_classic(base_size = 11) +\n  theme(\n    axis.title = element_text(face = 'bold', size = 11),\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 12),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Panel B: Bar chart\np_b &lt;- ggplot(data.frame(group = c('Group 1', 'Group 2', 'Group 3'),\n                        value = c(25, 32, 28)),\n             aes(x = group, y = value, fill = group)) +\n  geom_bar(stat = 'identity', color = 'black', size = 1) +\n  scale_fill_manual(values = c('#7F8C8D', '#3498DB', '#E74C3C')) +\n  labs(y = 'Response (AU)', title = 'Group Comparison') +\n  theme_classic(base_size = 11) +\n  theme(\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(face = 'bold', size = 11),\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 12),\n    legend.position = 'none',\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Panel C: Line plot\np_c &lt;- ggplot(data.frame(time = seq(0, 10, length.out = 50),\n                        signal = sin(seq(0, 10, length.out = 50)) + rnorm(50, 0, 0.1)),\n             aes(x = time, y = signal)) +\n  geom_line(color = '#27AE60', size = 1.5) +\n  labs(x = 'Time (s)', y = 'Signal (mV)',\n       title = 'Temporal Dynamics') +\n  theme_classic(base_size = 11) +\n  theme(\n    axis.title = element_text(face = 'bold', size = 11),\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 12),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Panel D: Heatmap\nlibrary(reshape2)\nheatmap_data &lt;- melt(matrix(rnorm(100), 10, 10))\np_d &lt;- ggplot(heatmap_data, aes(x = Var2, y = Var1, fill = value)) +\n  geom_tile() +\n  scale_fill_gradient2(low = '#2166AC', mid = 'white', high = '#B2182B',\n                       midpoint = 0, name = 'Value') +\n  labs(x = 'Sample', y = 'Gene', title = 'Expression Pattern') +\n  theme_minimal(base_size = 11) +\n  theme(\n    axis.title = element_text(face = 'bold', size = 11),\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 12),\n    panel.grid = element_blank()\n  )\n\n# Combine with panel labels\ncombined &lt;- (p_a + p_b) / (p_c + p_d) +\n  plot_annotation(tag_levels = 'A') +  # Automatic A, B, C, D labeling\n  plot_layout(guides = 'collect') &\n  theme(\n    plot.tag = element_text(size = 16, face = 'bold'),\n    plot.tag.position = c(0, 1)  # Top-left\n  )\n\nggsave('panel_labels_example.png', combined, width = 12, height = 10,\n       dpi = 300, bg = 'white')\n\ncat(\"✓ Panel labels: A, B, C, D (bold, outside panels)\\n\")\n\n\n\nLogical Panel Organization\nPrinciple: Arrange panels to support narrative flow\nReading Order Conventions:\nWestern convention (most journals):\n└─ Left-to-right, top-to-bottom (like text)\n   A  B\n   C  D\n\nSome journals accept:\n└─ Top-to-bottom, left-to-right (column-wise)\n   A  C\n   B  D\n\n✓ State clearly in caption if non-standard order\nLogical Grouping Strategies:\nStrategy 1: Temporal Progression\nPanel A: Baseline (time 0)\nPanel B: Early response (6 hours)\nPanel C: Late response (24 hours)\nPanel D: Recovery (48 hours)\n\n→ Left-to-right naturally represents time flow\nStrategy 2: Methodological Hierarchy\nPanel A: Raw data (microscopy image)\nPanel B: Processed data (segmented/quantified)\nPanel C: Summary statistics (bar chart)\nPanel D: Model fitting (correlation plot)\n\n→ Top-to-bottom represents analysis pipeline\nStrategy 3: Comparative Structure\n      Control    Treatment\nA, B: [Image]    [Image]\nC, D: [Quant]    [Quant]\n\n→ Columns = conditions, Rows = data types\n→ Facilitates direct comparison",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3: Typography, Annotation & Labels</span>"
    ]
  },
  {
    "objectID": "Chapter 3.html#statistical-annotations-significance-markers",
    "href": "Chapter 3.html#statistical-annotations-significance-markers",
    "title": "Chapter 3: Typography, Annotation & Labels",
    "section": "3.5 Statistical Annotations: Significance Markers",
    "text": "3.5 Statistical Annotations: Significance Markers\n\nThe Standard Notation System\nAsterisk convention (most common):\n*     p &lt; 0.05  (significant)\n**    p &lt; 0.01  (highly significant)\n***   p &lt; 0.001 (very highly significant)\nn.s.  p ≥ 0.05  (not significant)\nWhen to Use: - Quick visual indication of significance - Comparing multiple groups - Space constraints prevent detailed statistics\nWhen NOT to Use: - Exact p-values are critical (report actual values) - Only one comparison (just state p-value) - Effect sizes matter more than p-values\n\n\n\nProper Placement and Formatting\nCode Example (Python) - Statistical Annotations:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Sample data: comparing 4 groups\ngroups = ['Control', 'Drug A', 'Drug B', 'Drug C']\nvalues = [25, 32, 28, 35]\nerrors = [3, 3.5, 3, 4]\n\n# P-values for comparisons (vs. control)\np_values = [None, 0.008, 0.15, 0.0003]  # None for control (no self-comparison)\n\nfig, ax = plt.subplots(figsize=(9, 6))\n\n# Colors: gray for control, blue/red for treatments\ncolors = ['#7F8C8D', '#3498DB', '#3498DB', '#E74C3C']\n\nbars = ax.bar(groups, values, color=colors,\n              edgecolor='black', linewidth=1.5, width=0.6)\nax.errorbar(groups, values, yerr=errors, fmt='none',\n           ecolor='black', capsize=8, linewidth=2)\n\n# Add significance annotations\nfor i, (group, value, error, p) in enumerate(zip(groups, values, errors, p_values)):\n    if p is not None:\n        # Determine significance marker\n        if p &lt; 0.001:\n            marker = '***'\n        elif p &lt; 0.01:\n            marker = '**'\n        elif p &lt; 0.05:\n            marker = '*'\n        else:\n            marker = 'n.s.'\n\n        # Position above error bar\n        y_pos = value + error + 1.5\n\n        # Bracket connecting to control\n        bracket_y = value + error + 0.5\n        ax.plot([0, i], [bracket_y, bracket_y], 'k-', linewidth=1.2)\n        ax.plot([0, 0], [bracket_y - 0.3, bracket_y], 'k-', linewidth=1.2)\n        ax.plot([i, i], [bracket_y - 0.3, bracket_y], 'k-', linewidth=1.2)\n\n        # Marker\n        ax.text(i/2, y_pos, marker, ha='center', va='bottom',\n               fontsize=12, fontweight='bold')\n\n# Labels\nax.set_ylabel('Response (AU)', fontsize=12, fontweight='bold')\nax.set_title('Statistical Annotations: Comparison to Control',\n            fontsize=13, fontweight='bold', pad=15)\n\n# Legend for significance\nlegend_text = '* p &lt; 0.05\\n** p &lt; 0.01\\n*** p &lt; 0.001\\nn.s. = not significant'\nax.text(0.98, 0.98, legend_text, transform=ax.transAxes,\n       fontsize=9, va='top', ha='right',\n       bbox=dict(boxstyle='round', facecolor='white', edgecolor='black'))\n\nax.set_ylim(0, 50)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('statistical_annotations.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R) - Statistical Annotations:\nlibrary(ggplot2)\nlibrary(ggsignif)\n\n# Data\ndata &lt;- data.frame(\n  group = factor(c('Control', 'Drug A', 'Drug B', 'Drug C'),\n                levels = c('Control', 'Drug A', 'Drug B', 'Drug C')),\n  value = c(25, 32, 28, 35),\n  error = c(3, 3.5, 3, 4)\n)\n\ncolors &lt;- c('Control' = '#7F8C8D', 'Drug A' = '#3498DB',\n            'Drug B' = '#3498DB', 'Drug C' = '#E74C3C')\n\n# P-values\ncomparisons &lt;- list(\n  c('Control', 'Drug A'),\n  c('Control', 'Drug B'),\n  c('Control', 'Drug C')\n)\n\np_values &lt;- c(0.008, 0.15, 0.0003)\n\n# Convert to annotation format\nannotations &lt;- sapply(p_values, function(p) {\n  if (p &lt; 0.001) '***'\n  else if (p &lt; 0.01) '**'\n  else if (p &lt; 0.05) '*'\n  else 'n.s.'\n})\n\np &lt;- ggplot(data, aes(x = group, y = value, fill = group)) +\n  geom_bar(stat = 'identity', color = 'black', size = 1, width = 0.6) +\n  geom_errorbar(aes(ymin = value - error, ymax = value + error),\n               width = 0.25, size = 1) +\n  scale_fill_manual(values = colors) +\n\n  # Add significance brackets\n  geom_signif(comparisons = comparisons,\n              annotations = annotations,\n              y_position = c(36, 33, 40),\n              tip_length = 0.02,\n              textsize = 4,\n              fontface = 'bold') +\n\n  labs(y = 'Response (AU)',\n       title = 'Statistical Annotations: Comparison to Control') +\n\n  # Legend for markers\n  annotate('text', x = 3.7, y = 48,\n           label = '* p &lt; 0.05\\n** p &lt; 0.01\\n*** p &lt; 0.001\\nn.s. = not significant',\n           hjust = 0, vjust = 1, size = 3,\n           lineheight = 0.9) +\n\n  ylim(0, 50) +\n\n  theme_classic(base_size = 12) +\n  theme(\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(face = 'bold', size = 12),\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 13),\n    legend.position = 'none',\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\nggsave('statistical_annotations.png', p, width = 9, height = 6,\n       dpi = 300, bg = 'white')\n\n\n\nReporting Exact P-Values\nWhen exact values matter:\n✓ GOOD: Include in caption or on figure\n\"Drug A vs. Control: p = 0.008\"\n\"Drug C vs. Control: p = 0.0003\"\n\n✓ BETTER: Combine visual markers with exact values\nMarkers on figure (**)\nCaption: \"** p = 0.008, *** p = 0.0003 (unpaired t-test)\"\nJournal requirements vary: - Nature: Often prefers exact p-values in text/caption - Cell: Accepts asterisk notation with key - Science: Varies by article type\nCheck target journal guidelines!",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3: Typography, Annotation & Labels</span>"
    ]
  },
  {
    "objectID": "Chapter 3.html#direct-labeling-vs.-legends",
    "href": "Chapter 3.html#direct-labeling-vs.-legends",
    "title": "Chapter 3: Typography, Annotation & Labels",
    "section": "3.6 Direct Labeling vs. Legends",
    "text": "3.6 Direct Labeling vs. Legends\n\nThe Usability Principle: Minimize Eye Travel\nLegend disadvantages: - Requires back-and-forth eye movement - Matching colors to categories requires working memory - Easy to misinterpret if legend order doesn’t match visual prominence\nDirect labeling advantages: - Instant association (no memory needed) - Faster interpretation - Better for colorblind readers (less reliance on color alone)\nWhen to use each:\nUse DIRECT LABELS when:\n✓ Few categories (≤5)\n✓ Space available near data\n✓ Lines/points spatially separated\n✓ Presentation/poster context (distant viewing)\nUse LEGEND when:\n✓ Many categories (&gt;5)\n✓ Data elements overlap (no space for labels)\n✓ Consistency across multi-panel figure (shared legend)\nCode Example (Python) - Direct Labeling:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\ntime = np.linspace(0, 24, 100)\n\n# Three treatment groups\ndata = {\n    'Control': 100 + np.cumsum(np.random.randn(100) * 2),\n    'Treatment A': 100 + np.cumsum(np.random.randn(100) * 2 + 0.3),\n    'Treatment B': 100 + np.cumsum(np.random.randn(100) * 2 + 0.6)\n}\n\ncolors = {\n    'Control': '#7F8C8D',\n    'Treatment A': '#3498DB',\n    'Treatment B': '#E74C3C'\n}\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Panel A: Traditional legend\nax1 = axes[0]\nfor group, values in data.items():\n    ax1.plot(time, values, color=colors[group], linewidth=2.5, label=group)\n\nax1.set_xlabel('Time (hours)', fontsize=11, fontweight='bold')\nax1.set_ylabel('Response (%)', fontsize=11, fontweight='bold')\nax1.set_title('A. Traditional Legend\\n(Requires eye travel)',\n             fontsize=12, fontweight='bold')\nax1.legend(loc='upper left', frameon=True, fontsize=10)\nax1.grid(alpha=0.3)\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# Panel B: Direct labeling\nax2 = axes[1]\nfor group, values in data.items():\n    ax2.plot(time, values, color=colors[group], linewidth=2.5)\n\n    # Place label at end of line\n    ax2.text(time[-1] + 0.5, values[-1], group,\n            color=colors[group], fontsize=10, fontweight='bold',\n            va='center', ha='left')\n\nax2.set_xlabel('Time (hours)', fontsize=11, fontweight='bold')\nax2.set_ylabel('Response (%)', fontsize=11, fontweight='bold')\nax2.set_title('B. Direct Labeling\\n(Instant association)',\n             fontsize=12, fontweight='bold')\nax2.grid(alpha=0.3)\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\nax2.set_xlim(0, 27)  # Extra space for labels\n\nplt.tight_layout()\nplt.savefig('direct_labeling_vs_legend.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R) - Direct Labeling:\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\nlibrary(directlabels)\n\nset.seed(42)\ntime &lt;- seq(0, 24, length.out = 100)\n\ndata &lt;- data.frame(\n  time = rep(time, 3),\n  response = c(\n    100 + cumsum(rnorm(100, 0, 2)),\n    100 + cumsum(rnorm(100, 0.3, 2)),\n    100 + cumsum(rnorm(100, 0.6, 2))\n  ),\n  group = rep(c('Control', 'Treatment A', 'Treatment B'), each = 100)\n)\n\ncolors &lt;- c('Control' = '#7F8C8D',\n            'Treatment A' = '#3498DB',\n            'Treatment B' = '#E74C3C')\n\n# Panel A: Traditional legend\np_a &lt;- ggplot(data, aes(x = time, y = response, color = group)) +\n  geom_line(size = 1.5) +\n  scale_color_manual(values = colors) +\n  labs(x = 'Time (hours)', y = 'Response (%)',\n       title = 'A. Traditional Legend\\n(Requires eye travel)',\n       color = NULL) +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 12),\n    axis.title = element_text(face = 'bold'),\n    legend.position = c(0.2, 0.85),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Panel B: Direct labeling\np_b &lt;- ggplot(data, aes(x = time, y = response, color = group)) +\n  geom_line(size = 1.5) +\n  scale_color_manual(values = colors) +\n  geom_text(data = data %&gt;% group_by(group) %&gt;% slice_tail(n = 1),\n            aes(label = group, x = time + 1),\n            hjust = 0, fontface = 'bold', size = 3.5) +\n  labs(x = 'Time (hours)', y = 'Response (%)',\n       title = 'B. Direct Labeling\\n(Instant association)') +\n  xlim(0, 27) +  # Extra space for labels\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 12),\n    axis.title = element_text(face = 'bold'),\n    legend.position = 'none',\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\ncombined &lt;- p_a | p_b\nggsave('direct_labeling_vs_legend.png', combined, width = 14, height = 5,\n       dpi = 300, bg = 'white')\n\nSummary of Chapter 3 so far:\n✓ Text hierarchy: Critical (bold, large) &gt; Important (regular) &gt; Supporting (small, light) ✓ Font choice: Sans-serif (Arial/Helvetica) for figures ✓ Axis labels: Always include units: “Variable (unit)” ✓ Panel labels: Bold A, B, C, D in top-left corners ✓ Statistical annotations: Asterisks with clear legend; exact p-values when needed ✓ Direct labeling: Preferred over legends when space allows",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3: Typography, Annotation & Labels</span>"
    ]
  },
  {
    "objectID": "Chapter 3.html#figure-captions-complete-but-concise",
    "href": "Chapter 3.html#figure-captions-complete-but-concise",
    "title": "Chapter 3: Typography, Annotation & Labels",
    "section": "3.7 Figure Captions: Complete but Concise",
    "text": "3.7 Figure Captions: Complete but Concise\n\nThe Essential Function of Captions\nA well-written caption allows a figure to be self-contained—a reader should understand the key message without reading the full manuscript text. This is critical because:\n\nReaders scan figures first before committing to reading the full paper\nFigures get reused in presentations, reviews, where full context isn’t available\nJournal requirements mandate self-explanatory figures\nAccessibility for readers who skip to results\n\n\n\n\nThe Standard Caption Structure\nTemplate Format:\n[Figure Number]. [One-sentence summary]. [Detailed description].\n[Sample size/statistics]. [Significance indicators]. [Technical details].\nExample Anatomy:\nFigure 3. Treatment A reduces tumor volume in xenograft mice.\n(A) Representative H&E staining of tumor sections from control and\ntreatment groups at day 21 (scale bar: 100 μm). (B) Quantification\nof tumor volume over time (n=8 mice per group, mean ± SEM).\n(C) Kaplan-Meier survival curves showing improved survival in\ntreatment group (log-rank test, ***p &lt; 0.001). All experiments\nperformed in triplicate. Error bars: SEM. * p&lt;0.05, ** p&lt;0.01,\n*** p&lt;0.001 (two-way ANOVA with Tukey post-hoc).\nBreakdown:\n✓ Title sentence: \"Treatment A reduces tumor volume...\"\n  → States main finding clearly\n\n✓ Panel descriptions: \"(A) Representative H&E staining...\"\n  → Maps to panel labels, describes content\n\n✓ Sample sizes: \"n=8 mice per group\"\n  → Essential for interpretation\n\n✓ Statistical methods: \"two-way ANOVA with Tukey post-hoc\"\n  → Allows reader to assess rigor\n\n✓ Technical specs: \"scale bar: 100 μm\"\n  → Critical for microscopy/imaging\n\n\n\nWhat MUST Be Included\nNon-negotiable elements:\n1. Sample size (n)\n✓ \"n=3 biological replicates\"\n✓ \"n=50 cells per condition from 3 independent experiments\"\n✓ \"n=15 patients per group\"\n\n❌ Never omit sample size\n→ Reader cannot assess statistical power or reliability\n2. Error bar definition\n✓ \"Error bars: SEM\"\n✓ \"Error bars: SD\"\n✓ \"Boxes: IQR, whiskers: 1.5×IQR\"\n\n❌ \"Error bars shown\" (which type?)\n→ SEM vs SD dramatically affects interpretation\n3. Statistical test and significance threshold\n✓ \"Unpaired t-test, *p&lt;0.05\"\n✓ \"One-way ANOVA with Dunnett's post-hoc, **p&lt;0.01\"\n✓ \"Mann-Whitney U test (non-parametric), p=0.003\"\n\n❌ \"Groups were significantly different\" (what test? what p?)\n4. Scale information (for images)\n✓ \"Scale bar: 50 μm\"\n✓ \"Field of view: 200×200 μm\"\n✓ \"All images same magnification (40×)\"\n\n❌ No scale information on microscopy\n→ Renders images scientifically useless\n\n\n\nLogical Caption Organization\nFor multi-panel figures, use consistent structure:\nFormat A: Panel-by-panel description\nFigure 2. [Overall title].\n(A) [Panel A description with methods and n].\n(B) [Panel B description with methods and n].\n(C) [Panel C description with methods and n].\n[Shared statistical details]. [Abbreviations].\nFormat B: Grouped description\nFigure 2. [Overall title].\n(A-C) [Common description for panels A-C].\n(D, E) [Related panels described together].\n[All statistics and methods]. [Abbreviations].\nCode Example Caption (for figure from section 3.4):\nFigure 2. Multi-modal analysis of treatment effects on cellular response.\n(A) Correlation between baseline marker X and response variable Y in\ncontrol cells (n=50 cells, Pearson r=0.73, p&lt;0.001). (B) Quantification\nof cellular response across treatment groups (n=3 biological replicates,\neach with 200 cells per condition, mean ± SEM, one-way ANOVA with Tukey\npost-hoc, **p&lt;0.01 vs control). (C) Temporal dynamics of signal intensity\nfollowing treatment application (n=4 independent experiments, mean ± SEM,\nsampling rate: 100 Hz). (D) Hierarchical clustering heatmap of gene\nexpression changes (n=10 genes, 8 samples per condition, color scale:\nlog₂ fold change, diverging blue-white-red). All experiments performed\nat 37°C in standard culture conditions. AU: arbitrary units.\nWhat this caption does well: - Every panel explicitly labeled - Sample sizes clear for each analysis - Statistical methods specified - Technical details included (sampling rate, temperature) - Abbreviations defined - Stands alone without main text\n\n\n\nCommon Caption Mistakes\nMistake 1: Vague descriptions\n❌ \"Expression levels are shown\"\n✓ \"qRT-PCR quantification of gene X expression normalized to β-actin\n   (n=4 biological replicates, mean ± SD, **p&lt;0.01, unpaired t-test)\"\nMistake 2: Missing critical methods\n❌ \"Cells were stained and imaged\"\n✓ \"Cells were immunostained with anti-tubulin antibody (1:500, Abcam\n   ab11304) and imaged on confocal microscope (Zeiss LSM 880, 63×\n   objective, scale bar: 10 μm)\"\nMistake 3: Undefined abbreviations\n❌ \"FPKM values shown in heatmap\"\n✓ \"FPKM (Fragments Per Kilobase Million) values shown in heatmap\"\n\nOr define at first use:\n\"Expression quantified as FPKM (Fragments Per Kilobase Million)\"\nMistake 4: No error bar definition\n❌ \"Error bars represent variability\"\n✓ \"Error bars: standard error of the mean (SEM)\"\nMistake 5: Statistical significance without context\n❌ \"***p&lt;0.001\"\n✓ \"***p&lt;0.001 by two-way ANOVA with Bonferroni correction\"\n\n\n\nLength Guidelines\nTarget length:\nSimple single-panel figure: 2-4 sentences\nComplex multi-panel figure: 6-10 sentences\nAvoid: &gt;15 sentences (break into multiple figures)\nBalance completeness with readability:\nToo short (incomplete):\n\"Figure 1. Expression data. Error bars: SEM.\"\n→ Missing methods, n, statistics\n\nToo long (overwhelming):\n\"Figure 1. We performed RNA-seq on samples collected at multiple\ntimepoints using Illumina NextSeq with 75bp paired-end reads,\nwhich were then aligned to the reference genome using STAR aligner\nversion 2.7.3a with default parameters except... [300 words]\"\n→ Methods belong in Methods section, not caption\n\nJust right:\n\"Figure 1. Temporal gene expression dynamics. RNA-seq quantification\nof differentially expressed genes (DESeq2, adjusted p&lt;0.05) across\ntimepoints (n=3 biological replicates per timepoint). Heatmap colors:\nlog₂ fold change vs. t=0. See Methods for sequencing details.\"\n→ Essential info + pointer to full methods\n\n\n\nJournal-Specific Requirements\nCheck your target journal’s guidelines:\nNature family:\n- Captions should be concise but complete\n- Define all abbreviations\n- Include statistical tests and n\n- Methods details belong in Methods, not captions\nCell family:\n- Similar to Nature\n- Emphasize reproducibility info (n, replicates)\n- Related panels can share some description\nPLOS family:\n- Very detailed captions encouraged\n- Must be understandable without main text\n- Can include more methods details than Nature/Cell\nIEEE/ACM (computational):\n- Focus on algorithm/model details\n- Parameter settings in caption acceptable\n- Less emphasis on biological replicates\n\n\n\n3.9 Text Hierarchy: Information vs. Support Text\nPrinciple: Distinguish between information text (gene names, pathway labels) and support text (axes, legends).\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Panel A: BAD - All text same size (no hierarchy)\nax1 = axes[0]\ngenes = ['TP53', 'BRCA1', 'MYC', 'KRAS']\nexpression = [120, 85, 150, 95]\n\nbars1 = ax1.barh(genes, expression, color='#3498DB', edgecolor='black', linewidth=1.5)\nax1.set_xlabel('Expression Level (FPKM)', fontsize=10)  # Same size\nax1.set_ylabel('Gene', fontsize=10)  # Same size\nax1.set_title('Gene Expression Profile', fontsize=10)  # Same size!\nax1.set_xlim(0, 180)\n\n# Add values - also same size\nfor i, (gene, val) in enumerate(zip(genes, expression)):\n    ax1.text(val + 3, i, f'{val}', va='center', fontsize=10)  # Same size\n\nax1.set_title('❌ BAD: All Text Same Size\\n(No hierarchy, everything equally important)',\n              fontsize=12, fontweight='bold', color='red', pad=15)\n\n# Panel B: GOOD - Clear hierarchy (information &gt; support)\nax2 = axes[1]\nbars2 = ax2.barh(genes, expression, color='#27AE60', edgecolor='black', linewidth=1.5)\n\n# INFORMATION TEXT: Larger, bold (what you want reader to remember)\nax2.set_ylabel('Gene', fontsize=14, fontweight='bold', color='black')  # Larger\nfor i, gene in enumerate(genes):\n    ax2.text(-5, i, gene, va='center', ha='right',\n            fontsize=13, fontweight='bold', color='black')  # Key information!\n\n# Add expression values (also information)\nfor i, (gene, val) in enumerate(zip(genes, expression)):\n    ax2.text(val + 3, i, f'{val}', va='center',\n            fontsize=12, fontweight='bold', color='black')\n\n# SUPPORT TEXT: Smaller, lighter (provides context)\nax2.set_xlabel('Expression Level (FPKM)', fontsize=10, color='gray')  # Smaller, gray\nax2.tick_params(axis='x', labelsize=9, labelcolor='gray')  # Support info\nax2.set_yticks([])  # Remove y-tick labels (genes are directly labeled)\nax2.set_xlim(-20, 180)\n\nax2.set_title('✓ GOOD: Clear Text Hierarchy\\n(Information text &gt; Support text)',\n              fontsize=13, fontweight='bold', color='green', pad=15)\n\nplt.tight_layout()\nplt.savefig('text_hierarchy_information_vs_support.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.show()\n\n\n\n3.10 Coordinate Axes and Legend Simplification\nPrinciple: Simplify coordinate labels and legends to reduce visual clutter while maintaining clarity.\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n# BAD Example 1: Over-detailed axis labels\nax1 = axes[0, 0]\ntime = np.arange(0, 24, 0.5)\nsignal = 50 + 10*np.sin(2*np.pi*time/12) + np.random.randn(len(time))*2\n\nax1.plot(time, signal, 'o-', color='#3498DB', linewidth=2, markersize=4)\n\n# Over-detailed tick labels\nax1.set_xticks(np.arange(0, 25, 2))\nax1.set_xticklabels([f'{h}:00:00' for h in range(0, 25, 2)],\n                     rotation=45, fontsize=8)  # Too detailed!\nax1.set_xlabel('Time (hours:minutes:seconds)', fontsize=10)\nax1.set_ylabel('Signal Intensity (arbitrary units, normalized to baseline)',\n               fontsize=10)  # Too wordy!\nax1.set_title('❌ BAD: Over-Detailed Labels\\n(Unnecessary precision, hard to read)',\n              fontsize=12, fontweight='bold', color='red')\nax1.grid(alpha=0.3)\n\n# GOOD Example 1: Simplified axis labels\nax2 = axes[0, 1]\nax2.plot(time, signal, 'o-', color='#27AE60', linewidth=2.5, markersize=5)\n\n# Simplified tick labels (just hours)\nax2.set_xticks(np.arange(0, 25, 4))\nax2.set_xticklabels([f'{h}' for h in range(0, 25, 4)], fontsize=10)\nax2.set_xlabel('Time (hours)', fontsize=12, fontweight='bold')  # Simple, clear\nax2.set_ylabel('Signal (AU)', fontsize=12, fontweight='bold')  # AU = Arbitrary Units\nax2.set_title('✓ GOOD: Simplified Labels\\n(Essential information only)',\n              fontsize=13, fontweight='bold', color='green')\nax2.grid(alpha=0.3)\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\n\n# BAD Example 2: Redundant legend\nax3 = axes[1, 0]\nconditions = ['Control Group (n=10, Mean±SD)',\n              'Treatment Group A (n=10, Mean±SD)',\n              'Treatment Group B (n=10, Mean±SD)']\ncolors = ['#7F8C8D', '#3498DB', '#E74C3C']\n\nfor i, (cond, color) in enumerate(zip(conditions, colors)):\n    y = 50 + i*10 + np.random.randn(len(time))*2\n    ax3.plot(time, y, 'o-', color=color, linewidth=2,\n            markersize=4, label=cond)\n\nax3.set_xlabel('Time (hours)', fontsize=11, fontweight='bold')\nax3.set_ylabel('Response (AU)', fontsize=11, fontweight='bold')\nax3.set_title('❌ BAD: Redundant Legend Text\\n(Too much detail in legend)',\n              fontsize=12, fontweight='bold', color='red')\nax3.legend(loc='upper left', fontsize=8, frameon=True)\nax3.grid(alpha=0.3)\n\n# GOOD Example 2: Simplified legend\nax4 = axes[1, 1]\nconditions_simple = ['Control', 'Treatment A', 'Treatment B']\n\nfor i, (cond, color) in enumerate(zip(conditions_simple, colors)):\n    y = 50 + i*10 + np.random.randn(len(time))*2\n    ax4.plot(time, y, 'o-', color=color, linewidth=2.5,\n            markersize=5, label=cond, alpha=0.8)\n\nax4.set_xlabel('Time (hours)', fontsize=12, fontweight='bold')\nax4.set_ylabel('Response (AU)', fontsize=12, fontweight='bold')\nax4.set_title('✓ GOOD: Simplified Legend\\n(Details in caption: \"n=10, Mean±SD\")',\n              fontsize=13, fontweight='bold', color='green')\nax4.legend(loc='upper left', fontsize=11, frameon=True,\n          framealpha=0.9, edgecolor='black')\nax4.grid(alpha=0.3)\nax4.spines['top'].set_visible(False)\nax4.spines['right'].set_visible(False)\n\n# Add note about caption\nax4.text(0.5, -0.15, 'Note: \"All data shown as mean ± SD, n=10 per group\"',\n        transform=ax4.transAxes, ha='center', fontsize=9,\n        style='italic', color='gray')\n\nplt.tight_layout()\nplt.savefig('simplify_axes_legend.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\nGuidelines for Axis Simplification:\n# Simplification Rules:\n\n# 1. TIME AXES:\n# BAD:  \"Time (hours:minutes:seconds)\"\n# GOOD: \"Time (hours)\"  → Put precision in Methods\n\n# 2. LONG VARIABLE NAMES:\n# BAD:  \"Relative Fluorescence Intensity (normalized to control)\"\n# GOOD: \"Relative Intensity (AU)\"  → Full description in caption\n\n# 3. UNITS:\n# BAD:  \"Concentration (micromolar, μM)\"\n# GOOD: \"Concentration (μM)\"  → One unit symbol is enough\n\n# 4. STATISTICAL INFO:\n# BAD:  \"Response (Mean ± Standard Error of Mean, n=5)\"\n# GOOD: \"Response (AU)\"  → Statistical details in caption\n\n# 5. LEGEND DETAILS:\n# BAD:  \"Wild-type mice, age 8-12 weeks, n=15, p&lt;0.05 vs control\"\n# GOOD: \"Wild-type\"  → Details in caption or Methods\n\n\n\n3.11 Information Text: Gene and Pathway Labels\nPrinciple: Make critical information (gene names, pathways) prominent and clear, but avoid overwhelming detail.\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nfrom matplotlib.patches import FancyBboxPatch\nimport numpy as np\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 7))\n\n# BAD: Too many gene labels (overwhelming)\nax1 = axes[0]\nn_genes = 50\nx = np.random.randn(n_genes)\ny = np.random.randn(n_genes)\ncolors = np.random.choice(['#3498DB', '#E74C3C', '#27AE60'], n_genes)\ngene_names = [f'Gene{i+1}' for i in range(n_genes)]\n\nax1.scatter(x, y, c=colors, s=80, alpha=0.6, edgecolors='black', linewidths=0.5)\n\n# Label ALL genes (too many!)\nfor i, gene in enumerate(gene_names):\n    ax1.text(x[i], y[i], gene, fontsize=6, ha='center')\n\nax1.set_xlabel('PC1', fontsize=11, fontweight='bold')\nax1.set_ylabel('PC2', fontsize=11, fontweight='bold')\nax1.set_title('❌ BAD: Too Many Labels\\n(Overwhelming, unreadable)',\n              fontsize=13, fontweight='bold', color='red')\nax1.grid(alpha=0.3)\n\n# GOOD: Only label important genes\nax2 = axes[1]\nax2.scatter(x, y, c=colors, s=100, alpha=0.6, edgecolors='black', linewidths=0.5)\n\n# Identify top 5 \"significant\" genes (example: most extreme positions)\ndistances = np.sqrt(x**2 + y**2)\ntop_indices = np.argsort(distances)[-5:]\n\n# Label only important genes with clear callouts\nfor idx in top_indices:\n    # Gene point\n    ax2.scatter(x[idx], y[idx], s=200, facecolors='none',\n               edgecolors='black', linewidths=3, zorder=10)\n\n    # Callout annotation\n    ax2.annotate(gene_names[idx],\n                xy=(x[idx], y[idx]),\n                xytext=(20, 20), textcoords='offset points',\n                fontsize=11, fontweight='bold',\n                bbox=dict(boxstyle='round,pad=0.5',\n                         facecolor='yellow', alpha=0.8,\n                         edgecolor='black', linewidth=1.5),\n                arrowprops=dict(arrowstyle='-&gt;',\n                               connectionstyle='arc3,rad=0.3',\n                               lw=2, color='black'))\n\nax2.set_xlabel('PC1', fontsize=12, fontweight='bold')\nax2.set_ylabel('PC2', fontsize=12, fontweight='bold')\nax2.set_title('✓ GOOD: Label Only Key Genes\\n(Clear focus on important information)',\n              fontsize=13, fontweight='bold', color='green')\nax2.grid(alpha=0.3)\n\n# Add note\nax2.text(0.02, 0.02, f'Top 5 of {n_genes} genes labeled\\n(Full list in Table S1)',\n        transform=ax2.transAxes, fontsize=9, style='italic',\n        verticalalignment='bottom',\n        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n\nplt.tight_layout()\nplt.savefig('information_text_gene_labels.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\nPathway/Network Diagram Information Text:\nimport matplotlib.pyplot as plt\nimport networkx as nx\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 7))\n\n# Create example pathway network\nG = nx.DiGraph()\nnodes = ['Receptor', 'Kinase1', 'Kinase2', 'TF', 'Gene']\nedges = [('Receptor', 'Kinase1'), ('Kinase1', 'Kinase2'),\n         ('Kinase2', 'TF'), ('TF', 'Gene')]\nG.add_nodes_from(nodes)\nG.add_edges_from(edges)\n\npos = {\n    'Receptor': (0, 0),\n    'Kinase1': (1, 0.5),\n    'Kinase2': (2, 0.5),\n    'TF': (3, 0.3),\n    'Gene': (4, 0)\n}\n\n# BAD: Too much detail on diagram\nax1 = axes[0]\nnode_labels = {\n    'Receptor': 'EGFR\\n(Epidermal Growth\\nFactor Receptor)\\nMembrane protein\\nBinds EGF ligand',\n    'Kinase1': 'RAF\\n(Rapidly Accelerated\\nFibrosarcoma)\\nSerine/threonine kinase',\n    'Kinase2': 'MEK\\n(MAP/ERK Kinase)\\nDual-specificity kinase',\n    'TF': 'ERK\\n(Extracellular signal-\\nRegulated Kinase)\\nTranscription regulator',\n    'Gene': 'Target Gene\\n(e.g., FOS, MYC)\\nExpression regulation'\n}\n\nnx.draw_networkx_nodes(G, pos, ax=ax1, node_color='#3498DB',\n                      node_size=3000, alpha=0.7)\nnx.draw_networkx_edges(G, pos, ax=ax1, edge_color='black',\n                      width=2, arrowsize=20, arrowstyle='-&gt;')\nnx.draw_networkx_labels(G, pos, node_labels, ax=ax1,\n                       font_size=7, font_weight='bold')\n\nax1.set_xlim(-0.5, 4.5)\nax1.set_ylim(-1, 1.5)\nax1.axis('off')\nax1.set_title('❌ BAD: Too Much Detail\\n(Cluttered, hard to read)',\n              fontsize=13, fontweight='bold', color='red', pad=20)\n\n# GOOD: Simplified labels, details in caption\nax2 = axes[1]\nnode_labels_simple = {\n    'Receptor': 'EGFR',\n    'Kinase1': 'RAF',\n    'Kinase2': 'MEK',\n    'TF': 'ERK',\n    'Gene': 'Target\\nGene'\n}\n\n# Color-code by function\nnode_colors = ['#E74C3C', '#3498DB', '#3498DB', '#F39C12', '#27AE60']\n\nnx.draw_networkx_nodes(G, pos, ax=ax2, node_color=node_colors,\n                      node_size=2500, alpha=0.8, edgecolors='black', linewidths=2)\nnx.draw_networkx_edges(G, pos, ax=ax2, edge_color='black',\n                      width=3, arrowsize=25, arrowstyle='-&gt;')\nnx.draw_networkx_labels(G, pos, node_labels_simple, ax=ax2,\n                       font_size=12, font_weight='bold')\n\nax2.set_xlim(-0.5, 4.5)\nax2.set_ylim(-1, 1.5)\nax2.axis('off')\nax2.set_title('✓ GOOD: Simplified Labels\\n(Details in caption)',\n              fontsize=13, fontweight='bold', color='green', pad=20)\n\n# Add legend for colors\nlegend_elements = [\n    mpatches.Patch(facecolor='#E74C3C', edgecolor='black',\n                   label='Receptor'),\n    mpatches.Patch(facecolor='#3498DB', edgecolor='black',\n                   label='Kinases'),\n    mpatches.Patch(facecolor='#F39C12', edgecolor='black',\n                   label='Transcription Factor'),\n    mpatches.Patch(facecolor='#27AE60', edgecolor='black',\n                   label='Gene')\n]\nax2.legend(handles=legend_elements, loc='upper right',\n          fontsize=10, frameon=True, title='Component Type')\n\n# Caption text suggestion\nfig.text(0.5, 0.02,\n        'Caption example: \"EGFR/RAF/MEK/ERK signaling cascade. '\\\n        'EGFR: Epidermal Growth Factor Receptor (membrane receptor). '\\\n        'RAF/MEK/ERK: Sequential kinase cascade (detailed in Methods).\"',\n        ha='center', fontsize=9, style='italic', wrap=True)\n\nplt.tight_layout(rect=[0, 0.05, 1, 1])\nplt.savefig('pathway_information_text.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3: Typography, Annotation & Labels</span>"
    ]
  },
  {
    "objectID": "Chapter 3.html#common-typography-mistakes-and-how-to-avoid-them",
    "href": "Chapter 3.html#common-typography-mistakes-and-how-to-avoid-them",
    "title": "Chapter 3: Typography, Annotation & Labels",
    "section": "3.12 Common Typography Mistakes and How to Avoid Them",
    "text": "3.12 Common Typography Mistakes and How to Avoid Them\n\nMistake 1: Inconsistent Font Sizing\nThe Problem:\n❌ BAD EXAMPLE:\n- Axis labels: 11pt\n- Panel A title: 14pt\n- Panel B title: 12pt (inconsistent!)\n- Legend: 8pt in panel A, 10pt in panel B\n→ Looks unprofessional, distracts reader\nThe Fix:\n✓ ESTABLISH HIERARCHY ONCE, APPLY EVERYWHERE:\n\nFont size scale:\n- Panel labels: 14pt bold\n- Titles: 12pt bold\n- Axis labels: 11pt bold\n- Tick labels: 9pt regular\n- Legends: 9pt regular\n- Annotations: 9pt regular/italic\n- Footnotes: 8pt regular\n\nCode implementation: Set rcParams globally (Python) or theme (R)\nCode Example (Python) - Consistent Sizing:\nimport matplotlib.pyplot as plt\n\n# SET ONCE at beginning of script\nFONT_SIZES = {\n    'panel_label': 14,\n    'title': 12,\n    'axis_label': 11,\n    'tick_label': 9,\n    'legend': 9,\n    'annotation': 9\n}\n\nplt.rcParams.update({\n    'font.size': FONT_SIZES['tick_label'],\n    'axes.labelsize': FONT_SIZES['axis_label'],\n    'axes.titlesize': FONT_SIZES['title'],\n    'legend.fontsize': FONT_SIZES['legend'],\n    'xtick.labelsize': FONT_SIZES['tick_label'],\n    'ytick.labelsize': FONT_SIZES['tick_label']\n})\n\n# Now all figures use consistent sizing\n# Panel labels added manually with FONT_SIZES['panel_label']\nCode Example (R) - Consistent Sizing:\nlibrary(ggplot2)\n\n# DEFINE ONCE\nFONT_SIZES &lt;- list(\n  panel_label = 14,\n  title = 12,\n  axis_label = 11,\n  tick_label = 9,\n  legend = 9,\n  annotation = 9\n)\n\n# Create reusable theme\nmy_theme &lt;- theme_classic(base_size = FONT_SIZES$tick_label) +\n  theme(\n    axis.title = element_text(size = FONT_SIZES$axis_label, face = 'bold'),\n    plot.title = element_text(size = FONT_SIZES$title, face = 'bold', hjust = 0.5),\n    legend.text = element_text(size = FONT_SIZES$legend),\n    legend.title = element_text(size = FONT_SIZES$legend, face = 'bold'),\n    axis.text = element_text(size = FONT_SIZES$tick_label)\n  )\n\n# Apply to all plots\np &lt;- ggplot(...) + ... + my_theme\n\n\n\nMistake 2: Poor Contrast (Low Readability)\nThe Problem:\n❌ Light gray text on white background\n❌ Yellow text on white background (invisible)\n❌ Low-contrast colors for critical labels\n\nResult: Illegible when printed, invisible in bright rooms\nThe Fix:\n✓ ALWAYS test contrast ratio:\n\nMinimum WCAG AA standard: 4.5:1 for normal text\nBetter: 7:1 (AAA standard)\n\nSafe text colors on white background:\n✓ Black (#000000) - 21:1 contrast\n✓ Dark gray (#333333) - 12.6:1 contrast\n✓ Dark blue (#003366) - 10.4:1 contrast\n\nUnsafe:\n❌ Light gray (#CCCCCC) - 1.6:1 contrast\n❌ Pastel yellow (#FFFF99) - 1.2:1 contrast\nTesting tool:\nWebAIM Contrast Checker: webaim.org/resources/contrastchecker/\nInput: Background color + Text color\nOutput: Pass/Fail for WCAG standards\n\n\n\nMistake 3: Overlapping Text\nThe Problem:\n❌ Axis labels collide with tick labels\n❌ Data labels overlap each other\n❌ Legend obscures data points\nThe Fix:\n✓ Rotate text when necessary:\n- X-axis labels at 45° if long category names\n- Never rotate &gt;90° (unreadable)\n\n✓ Adjust label positions programmatically:\n- matplotlib: adjustText library for automatic label placement\n- R: ggrepel package for non-overlapping labels\n\n✓ Increase figure size if crowded\n✓ Consider splitting into multiple panels\nCode Example (Python) - Avoiding Overlap:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom adjustText import adjust_text  # pip install adjustText\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Generate scatter data\nx = np.random.rand(20) * 10\ny = np.random.rand(20) * 10\nlabels = [f'Gene{i+1}' for i in range(20)]\n\n# BAD: Overlapping labels\nax1 = axes[0]\nax1.scatter(x, y, s=50, color='#3498DB', edgecolors='black', linewidths=0.5)\nfor i, label in enumerate(labels):\n    ax1.text(x[i], y[i], label, fontsize=8, ha='center')\n\nax1.set_title('❌ BAD: Overlapping Labels', fontsize=12, fontweight='bold', color='red')\nax1.set_xlabel('Variable X', fontsize=11, fontweight='bold')\nax1.set_ylabel('Variable Y', fontsize=11, fontweight='bold')\n\n# GOOD: Adjusted labels (non-overlapping)\nax2 = axes[1]\nax2.scatter(x, y, s=50, color='#3498DB', edgecolors='black', linewidths=0.5)\n\ntexts = []\nfor i, label in enumerate(labels):\n    texts.append(ax2.text(x[i], y[i], label, fontsize=8, ha='center'))\n\n# Automatically adjust positions to avoid overlap\nadjust_text(texts, ax=ax2, arrowprops=dict(arrowstyle='-', color='gray', lw=0.5))\n\nax2.set_title('✓ GOOD: Adjusted Labels', fontsize=12, fontweight='bold', color='green')\nax2.set_xlabel('Variable X', fontsize=11, fontweight='bold')\nax2.set_ylabel('Variable Y', fontsize=11, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('overlapping_text_fix.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R) - Avoiding Overlap:\nlibrary(ggplot2)\nlibrary(ggrepel)  # For non-overlapping labels\n\nset.seed(42)\ndata &lt;- data.frame(\n  x = runif(20, 0, 10),\n  y = runif(20, 0, 10),\n  label = paste0('Gene', 1:20)\n)\n\n# BAD: Overlapping labels\np_bad &lt;- ggplot(data, aes(x = x, y = y)) +\n  geom_point(color = '#3498DB', size = 3) +\n  geom_text(aes(label = label), size = 3, hjust = 0.5, vjust = 0.5) +\n  labs(title = '❌ BAD: Overlapping Labels',\n       x = 'Variable X', y = 'Variable Y') +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 12),\n    axis.title = element_text(face = 'bold')\n  )\n\n# GOOD: Adjusted labels with ggrepel\np_good &lt;- ggplot(data, aes(x = x, y = y)) +\n  geom_point(color = '#3498DB', size = 3) +\n  geom_text_repel(aes(label = label), size = 3,\n                  box.padding = 0.5, point.padding = 0.3,\n                  segment.color = 'gray50', segment.size = 0.3) +\n  labs(title = '✓ GOOD: Adjusted Labels',\n       x = 'Variable X', y = 'Variable Y') +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 12),\n    axis.title = element_text(face = 'bold')\n  )\n\nlibrary(patchwork)\ncombined &lt;- p_bad | p_good\nggsave('overlapping_text_fix.png', combined, width = 14, height = 5,\n       dpi = 300, bg = 'white')\n\n\n\nMistake 4: Unclear Axis Notation\nThe Problem:\n❌ Scientific notation without clear base:\nAxis label: \"1e6\" (is this 1×10⁶? 1e⁶?)\n\n❌ Confusing multiplication symbols:\n\"Time (x10³ s)\" — what does x mean here?\n\n❌ Units in tick labels instead of axis label:\nY-axis ticks: \"5 mg/mL\", \"10 mg/mL\", \"15 mg/mL\"\n→ Redundant, cluttered\nThe Fix:\n✓ USE PROPER SUPERSCRIPTS for exponents:\n\"Concentration (×10⁶ cells/mL)\" or \"Concentration (10⁶ cells/mL)\"\n\n✓ UNITS ON AXIS LABEL, not tick labels:\nLabel: \"Concentration (mg/mL)\"\nTicks: \"5\", \"10\", \"15\"\n\n✓ EXPLICIT scientific notation:\nLabel: \"Distance (10³ km)\" meaning values are in thousands of km\nTick showing \"5\" = 5000 km\nCode Example (Python) - Proper Axis Notation:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.ticker import FuncFormatter\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Sample data in large numbers\nx = np.linspace(0, 10, 50)\ny = np.random.rand(50) * 1e6  # Values in millions\n\n# BAD: Automatic scientific notation (unclear)\nax1 = axes[0]\nax1.plot(x, y, 'o-', color='#3498DB', linewidth=2, markersize=4)\nax1.set_xlabel('Time (s)', fontsize=11, fontweight='bold')\nax1.set_ylabel('Cell Count', fontsize=11, fontweight='bold')  # No units!\nax1.set_title('❌ BAD: Unclear Notation', fontsize=12, fontweight='bold', color='red')\nax1.grid(alpha=0.3)\n\n# GOOD: Explicit scaling in label\nax2 = axes[1]\nax2.plot(x, y/1e6, 'o-', color='#27AE60', linewidth=2, markersize=4)  # Scale data\nax2.set_xlabel('Time (s)', fontsize=11, fontweight='bold')\nax2.set_ylabel('Cell Count (×10⁶)', fontsize=11, fontweight='bold')  # Clear units\nax2.set_title('✓ GOOD: Explicit Scaling', fontsize=12, fontweight='bold', color='green')\nax2.grid(alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('axis_notation_fix.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R) - Proper Axis Notation:\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(patchwork)\n\nset.seed(42)\ndata &lt;- data.frame(\n  time = seq(0, 10, length.out = 50),\n  count = runif(50, 0, 1) * 1e6  # Values in millions\n)\n\n# BAD: Automatic scientific notation\np_bad &lt;- ggplot(data, aes(x = time, y = count)) +\n  geom_line(color = '#3498DB', size = 1.2) +\n  geom_point(color = '#3498DB', size = 2) +\n  labs(x = 'Time (s)', y = 'Cell Count',  # No scale indicated!\n       title = '❌ BAD: Unclear Notation') +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 12),\n    axis.title = element_text(face = 'bold'),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\n# GOOD: Explicit scaling\np_good &lt;- ggplot(data, aes(x = time, y = count / 1e6)) +  # Scale data\n  geom_line(color = '#27AE60', size = 1.2) +\n  geom_point(color = '#27AE60', size = 2) +\n  labs(x = 'Time (s)', y = 'Cell Count (×10⁶)',  # Clear units\n       title = '✓ GOOD: Explicit Scaling') +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 12),\n    axis.title = element_text(face = 'bold'),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\ncombined &lt;- p_bad | p_good\nggsave('axis_notation_fix.png', combined, width = 12, height = 5,\n       dpi = 300, bg = 'white')\n\n\n\nMistake 5: Ambiguous Legends\nThe Problem:\n❌ Legend says: \"Treatment\"\n→ Which treatment? A, B, or C?\n\n❌ Legend uses symbols without explanation:\n\"●\" (what does circle mean?)\n\"▲\" (triangle significance?)\n\n❌ Legend order doesn't match visual prominence\nThe Fix:\n✓ SPECIFIC labels:\nNot: \"Treatment\"\nBut: \"Treatment A (10 μM)\", \"Treatment B (50 μM)\"\n\n✓ COMBINE symbols with text:\n\"● Control (n=15)\"\n\"▲ Drug A (n=15)\"\n\"■ Drug B (n=15)\"\n\n✓ ORDER logically:\n- Control first\n- Experimental conditions in ascending dose/time\n- Or match left-to-right/top-to-bottom order in figure\n\n\n\nTypography Checklist Before Submission\n\nFont family consistent across all panels (Arial/Helvetica)\nFont sizes consistent within hierarchy (use template)\nHigh contrast (black or #333333 on white)\nNo overlapping text (use adjustText/ggrepel if needed)\nAxis labels include units in format “Variable (unit)”\nScientific notation explicit (×10⁶ not 1e6)\nLegends specific (“Drug A 10μM” not just “Drug A”)\nPanel labels bold (A, B, C…) and consistently placed\nStatistical annotations clear (, ,  defined)\nCaption complete: n, statistics, error bar type, scale bars\n\n\nEnd of Chapter 3: Typography, Annotation & Labels\nKey Takeaways: - Text is functional infrastructure, not decoration - Hierarchy guides attention: Bold/large for critical, regular/small for supporting - Sans-serif fonts (Arial/Helvetica) for all figures - Axis labels must include units: “Variable (unit)” - Panel labels (A, B, C) enable precise referencing - Statistical annotations need clear notation and legend - Direct labeling &gt; Legends when space allows - Captions must be self-contained: n, methods, statistics, definitions - Consistency in sizing, spacing, and formatting signals professionalism",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3: Typography, Annotation & Labels</span>"
    ]
  },
  {
    "objectID": "Chapter 4.html",
    "href": "Chapter 4.html",
    "title": "Chapter 4: Data Encoding & Graph Selection",
    "section": "",
    "text": "4.1 The Fundamental Principle: Match Plot Type to Data Structure",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chapter 4: Data Encoding & Graph Selection</span>"
    ]
  },
  {
    "objectID": "Chapter 4.html#the-fundamental-principle-match-plot-type-to-data-structure",
    "href": "Chapter 4.html#the-fundamental-principle-match-plot-type-to-data-structure",
    "title": "Chapter 4: Data Encoding & Graph Selection",
    "section": "",
    "text": "Why Graph Selection Matters\nThe choice of visualization type is not arbitrary or aesthetic—it must be determined by:\n\nData structure (continuous, categorical, temporal, hierarchical, etc.)\nComparison type (distribution, relationship, composition, temporal change)\nNumber of variables (univariate, bivariate, multivariate)\nMessage priority (what insight should jump out immediately?)\n\nUsing the wrong plot type is not a stylistic choice—it’s a scientific error that misrepresents your data.\n\n\n\nThe Data-Plot Decision Tree\nSTART: What am I trying to show?\n\n├─ COMPARISON between groups\n│   ├─ Few groups (&lt;10), one variable\n│   │   └─ Bar chart, dot plot, box plot\n│   ├─ Many groups (&gt;10), one variable\n│   │   └─ Violin plot, ridgeline plot, small multiples\n│   └─ Two+ variables across groups\n│       └─ Grouped bar chart, heatmap, PCA plot\n│\n├─ DISTRIBUTION of one variable\n│   ├─ Single distribution\n│   │   └─ Histogram, density plot, box plot\n│   ├─ Multiple distributions to compare\n│   │   └─ Overlapping density, violin plot, box plot grid\n│   └─ Distribution + summary stats\n│       └─ Box plot, violin plot with mean/median\n│\n├─ RELATIONSHIP between two variables\n│   ├─ Both continuous (quantitative)\n│   │   └─ Scatter plot, line graph (if ordered), hexbin (if dense)\n│   ├─ One continuous, one categorical\n│   │   └─ Box plot, violin plot, strip plot\n│   └─ Both categorical\n│       └─ Heatmap, mosaic plot, grouped bar chart\n│\n├─ CHANGE OVER TIME (temporal)\n│   ├─ Single time series\n│   │   └─ Line graph\n│   ├─ Multiple time series (few)\n│   │   └─ Line graph with multiple lines\n│   ├─ Multiple time series (many)\n│   │   └─ Small multiples, spaghetti plot, heatmap\n│   └─ Cyclic patterns\n│       └─ Circular/polar plot, seasonal decomposition\n│\n├─ COMPOSITION (parts of a whole)\n│   ├─ Static composition\n│   │   └─ Stacked bar chart (avoid pie charts)\n│   ├─ Composition changing over time\n│   │   └─ Area chart, stacked bar chart over time\n│   └─ Hierarchical composition\n│       └─ Treemap, sunburst diagram\n│\n└─ SPATIAL/NETWORK relationships\n    ├─ Geographic data\n    │   └─ Choropleth map, point map, heat map\n    ├─ Network/graph data\n    │   └─ Node-link diagram, adjacency matrix\n    └─ Hierarchical relationships\n        └─ Dendrogram, tree diagram, sankey diagram",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chapter 4: Data Encoding & Graph Selection</span>"
    ]
  },
  {
    "objectID": "Chapter 4.html#comparison-showing-differences-between-groups",
    "href": "Chapter 4.html#comparison-showing-differences-between-groups",
    "title": "Chapter 4: Data Encoding & Graph Selection",
    "section": "4.2 Comparison: Showing Differences Between Groups",
    "text": "4.2 Comparison: Showing Differences Between Groups\n\nBar Charts: The Standard for Categorical Comparisons\nWhen to use: - Comparing discrete categories - Showing absolute values (not proportions) - Few to moderate number of categories (&lt;15) - When exact values matter\nBest practices:\n✓ Always start y-axis at zero (bars represent magnitude)\n✓ Order categories logically (not alphabetically unless necessary)\n✓ Use consistent bar width\n✓ Leave space between bars (width:gap ratio ~3:1)\n✓ Add error bars if showing means (specify SEM or SD)\nCommon mistakes:\n❌ Truncated y-axis (exaggerates small differences)\n❌ 3D bars (perspective distortion)\n❌ Too many categories (visual clutter)\n❌ Inconsistent ordering across panels\nCode Example (Python) - Proper Bar Chart:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Sample data: treatment comparison\ncategories = ['Control', 'Drug A\\n(10 μM)', 'Drug B\\n(50 μM)', 'Drug C\\n(100 μM)']\nvalues = [25.3, 32.7, 28.1, 35.9]\nerrors = [2.8, 3.1, 3.5, 4.2]\nn_samples = [15, 15, 15, 15]\n\n# Color scheme: gray for control, blue/red for treatments\ncolors = ['#7F8C8D', '#3498DB', '#3498DB', '#E74C3C']\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# BAD: Truncated axis, no error bars\nax1 = axes[0]\nax1.bar(categories, values, color=colors, edgecolor='black', linewidth=1.5, width=0.6)\nax1.set_ylim(20, 40)  # Truncated!\nax1.set_ylabel('Cell Viability (%)', fontsize=11, fontweight='bold')\nax1.set_title('❌ BAD: Truncated Axis\\n(Exaggerates differences)',\n             fontsize=12, fontweight='bold', color='red')\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# GOOD: Full axis, error bars, sample sizes\nax2 = axes[1]\nbars = ax2.bar(categories, values, color=colors,\n              edgecolor='black', linewidth=1.5, width=0.6)\nax2.errorbar(categories, values, yerr=errors, fmt='none',\n            ecolor='black', capsize=8, linewidth=2)\n\n# Add sample sizes on bars\nfor i, (bar, n) in enumerate(zip(bars, n_samples)):\n    height = bar.get_height()\n    ax2.text(bar.get_x() + bar.get_width()/2., height + errors[i] + 1,\n            f'n={n}', ha='center', va='bottom', fontsize=9)\n\nax2.set_ylim(0, 50)  # Full scale from zero\nax2.set_ylabel('Cell Viability (%)', fontsize=11, fontweight='bold')\nax2.set_title('✓ GOOD: Full Scale + Error Bars + n\\n(Honest representation)',\n             fontsize=12, fontweight='bold', color='green')\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\nax2.grid(axis='y', alpha=0.3)\n\n# Add statistical comparison\nax2.plot([1, 3], [42, 42], 'k-', linewidth=1.5)\nax2.text(2, 43, '**', ha='center', fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('bar_chart_best_practices.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R) - Proper Bar Chart:\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n\n# Data\ndata &lt;- data.frame(\n  category = factor(c('Control', 'Drug A\\n(10 μM)', 'Drug B\\n(50 μM)', 'Drug C\\n(100 μM)'),\n                   levels = c('Control', 'Drug A\\n(10 μM)', 'Drug B\\n(50 μM)', 'Drug C\\n(100 μM)')),\n  value = c(25.3, 32.7, 28.1, 35.9),\n  error = c(2.8, 3.1, 3.5, 4.2),\n  n = c(15, 15, 15, 15)\n)\n\ncolors &lt;- c('Control' = '#7F8C8D', 'Drug A\\n(10 μM)' = '#3498DB',\n            'Drug B\\n(50 μM)' = '#3498DB', 'Drug C\\n(100 μM)' = '#E74C3C')\n\n# BAD: Truncated axis\np_bad &lt;- ggplot(data, aes(x = category, y = value, fill = category)) +\n  geom_bar(stat = 'identity', color = 'black', size = 1, width = 0.6) +\n  scale_fill_manual(values = colors) +\n  coord_cartesian(ylim = c(20, 40)) +  # Truncated!\n  labs(y = 'Cell Viability (%)',\n       title = '❌ BAD: Truncated Axis\\n(Exaggerates differences)') +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 12),\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(face = 'bold'),\n    legend.position = 'none'\n  )\n\n# GOOD: Full scale, error bars, sample sizes\np_good &lt;- ggplot(data, aes(x = category, y = value, fill = category)) +\n  geom_bar(stat = 'identity', color = 'black', size = 1, width = 0.6) +\n  geom_errorbar(aes(ymin = value - error, ymax = value + error),\n               width = 0.25, size = 1) +\n  scale_fill_manual(values = colors) +\n\n  # Add sample sizes\n  geom_text(aes(label = paste0('n=', n), y = value + error + 2),\n           size = 3, vjust = 0) +\n\n  # Statistical annotation\n  annotate('segment', x = 2, xend = 4, y = 42, yend = 42, size = 1) +\n  annotate('text', x = 3, y = 43, label = '**', size = 5, fontface = 'bold') +\n\n  ylim(0, 50) +\n  labs(y = 'Cell Viability (%)',\n       title = '✓ GOOD: Full Scale + Error Bars + n\\n(Honest representation)') +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 12),\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(face = 'bold'),\n    legend.position = 'none',\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\ncombined &lt;- p_bad | p_good\nggsave('bar_chart_best_practices.png', combined, width = 14, height = 5,\n       dpi = 300, bg = 'white')\n\n\n\nBox Plots: Showing Full Distribution\nWhen to use: - Showing distribution shape, not just mean - Comparing distributions across groups - Detecting outliers - When sample size is moderate to large (n&gt;20 recommended)\nWhat box plots show:\nComponents:\n├─ Box: Interquartile range (IQR = 25th to 75th percentile)\n├─ Line inside box: Median (50th percentile)\n├─ Whiskers: Typically extend to 1.5×IQR or min/max\n└─ Points beyond whiskers: Outliers\n\n✓ Shows: distribution shape, spread, skewness, outliers\n❌ Hides: exact sample size (unless noted), bimodality (if subtle)\n\nAdvantages over bar charts: - Shows data distribution, not just mean - Highlights outliers automatically - More informative for skewed data - Better for comparing variability\nCode Example (Python) - Box Plot:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Generate data with different distributions\ncontrol = np.random.normal(25, 5, 50)\ndrug_a = np.random.normal(32, 4, 50)\ndrug_b = np.concatenate([np.random.normal(28, 3, 45),\n                         np.array([15, 18, 42, 45, 48])])  # With outliers\ndrug_c = np.random.lognormal(3.5, 0.3, 50)  # Skewed distribution\n\ndata = [control, drug_a, drug_b, drug_c]\nlabels = ['Control', 'Drug A', 'Drug B', 'Drug C']\ncolors = ['#7F8C8D', '#3498DB', '#3498DB', '#E74C3C']\n\nfig, ax = plt.subplots(figsize=(9, 6))\n\n# Create box plot\nbp = ax.boxplot(data, labels=labels, patch_artist=True,\n               widths=0.6,\n               boxprops=dict(linewidth=1.5),\n               whiskerprops=dict(linewidth=1.5),\n               capprops=dict(linewidth=1.5),\n               medianprops=dict(color='red', linewidth=2),\n               flierprops=dict(marker='o', markerfacecolor='black',\n                             markersize=6, alpha=0.5))\n\n# Color boxes\nfor patch, color in zip(bp['boxes'], colors):\n    patch.set_facecolor(color)\n    patch.set_alpha(0.7)\n\n# Add mean markers (in addition to median line)\nmeans = [np.mean(d) for d in data]\nax.scatter(range(1, len(means)+1), means, marker='D', s=80,\n          color='white', edgecolors='black', linewidths=2,\n          zorder=3, label='Mean')\n\nax.set_ylabel('Cell Viability (%)', fontsize=12, fontweight='bold')\nax.set_title('Box Plot: Full Distribution Comparison',\n            fontsize=13, fontweight='bold')\n\n# Add legend\nax.legend(loc='upper left', frameon=True, fontsize=10)\n\n# Add sample sizes\nfor i, n in enumerate([len(d) for d in data]):\n    ax.text(i+1, ax.get_ylim()[0] + 2, f'n={n}',\n           ha='center', fontsize=9, style='italic')\n\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.grid(axis='y', alpha=0.3)\n\n# Add explanation annotations\nax.annotate('', xy=(1.2, np.percentile(control, 75)),\n           xytext=(1.5, np.percentile(control, 75)),\n           arrowprops=dict(arrowstyle='-&gt;', lw=1.5))\nax.text(1.6, np.percentile(control, 75), '75th percentile',\n       fontsize=8, va='center')\n\nax.annotate('', xy=(1.2, np.percentile(control, 50)),\n           xytext=(1.5, np.percentile(control, 50)),\n           arrowprops=dict(arrowstyle='-&gt;', lw=1.5, color='red'))\nax.text(1.6, np.percentile(control, 50), 'Median',\n       fontsize=8, va='center', color='red')\n\nplt.tight_layout()\nplt.savefig('box_plot_example.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R) - Box Plot:\nlibrary(ggplot2)\nlibrary(dplyr)\n\nset.seed(42)\n\n# Generate data\ndata &lt;- data.frame(\n  group = rep(c('Control', 'Drug A', 'Drug B', 'Drug C'), each = 50),\n  value = c(\n    rnorm(50, 25, 5),\n    rnorm(50, 32, 4),\n    c(rnorm(45, 28, 3), c(15, 18, 42, 45, 48)),  # With outliers\n    rlnorm(50, 3.5, 0.3)  # Skewed\n  )\n)\n\ndata$group &lt;- factor(data$group, levels = c('Control', 'Drug A', 'Drug B', 'Drug C'))\n\ncolors &lt;- c('Control' = '#7F8C8D', 'Drug A' = '#3498DB',\n            'Drug B' = '#3498DB', 'Drug C' = '#E74C3C')\n\n# Calculate means for overlay\nmeans &lt;- data %&gt;%\n  group_by(group) %&gt;%\n  summarise(mean_val = mean(value))\n\n# Calculate sample sizes\nsample_sizes &lt;- data %&gt;%\n  group_by(group) %&gt;%\n  summarise(n = n(), min_val = min(value) - 5)\n\np &lt;- ggplot(data, aes(x = group, y = value, fill = group)) +\n  geom_boxplot(alpha = 0.7, outlier.shape = 16, outlier.size = 2,\n              outlier.alpha = 0.5, width = 0.6) +\n\n  # Add mean markers\n  geom_point(data = means, aes(y = mean_val),\n            shape = 23, size = 4, fill = 'white', color = 'black', stroke = 1.5) +\n\n  # Color scheme\n  scale_fill_manual(values = colors) +\n\n  # Add sample sizes\n  geom_text(data = sample_sizes, aes(y = min_val, label = paste0('n=', n)),\n           size = 3, fontface = 'italic') +\n\n  labs(y = 'Cell Viability (%)',\n       title = 'Box Plot: Full Distribution Comparison') +\n\n  theme_classic(base_size = 12) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 13),\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(face = 'bold'),\n    legend.position = 'none',\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Add annotations\np &lt;- p +\n  annotate('segment', x = 1.2, xend = 1.5,\n          y = quantile(data$value[data$group == 'Control'], 0.75),\n          yend = quantile(data$value[data$group == 'Control'], 0.75),\n          arrow = arrow(length = unit(0.2, 'cm')), size = 1) +\n  annotate('text', x = 1.6, y = quantile(data$value[data$group == 'Control'], 0.75),\n          label = '75th percentile', hjust = 0, size = 3) +\n  annotate('segment', x = 1.2, xend = 1.5,\n          y = median(data$value[data$group == 'Control']),\n          yend = median(data$value[data$group == 'Control']),\n          arrow = arrow(length = unit(0.2, 'cm')), size = 1, color = 'red') +\n  annotate('text', x = 1.6, y = median(data$value[data$group == 'Control']),\n          label = 'Median', hjust = 0, size = 3, color = 'red')\n\nggsave('box_plot_example.png', p, width = 9, height = 6,\n       dpi = 300, bg = 'white')\n\n\n\nViolin Plots: Enhanced Distribution Visualization\nWhen to use: - Showing full distribution density (better than box plots for bimodal/multimodal data) - Comparing distribution shapes across groups - When you want both density and quartiles visible\nAdvantages: - Shows distribution shape more clearly than box plots - Reveals bimodality (two peaks) that box plots hide - More informative than histograms for comparisons\nCode Example (Python) - Violin Plot:\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\nnp.random.seed(42)\n\n# Generate bimodal data (two peaks) - box plot would hide this!\ncontrol = np.random.normal(25, 3, 50)\ndrug_a = np.concatenate([np.random.normal(20, 2, 25),\n                         np.random.normal(35, 2, 25)])  # Bimodal!\ndrug_b = np.random.normal(32, 4, 50)\n\n# Combine into DataFrame for seaborn\nimport pandas as pd\ndf = pd.DataFrame({\n    'Group': ['Control']*50 + ['Drug A']*50 + ['Drug B']*50,\n    'Value': np.concatenate([control, drug_a, drug_b])\n})\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Box plot (HIDES bimodality)\nax1 = axes[0]\nsns.boxplot(data=df, x='Group', y='Value', ax=ax1,\n           palette=['#7F8C8D', '#3498DB', '#E74C3C'])\nax1.set_ylabel('Cell Viability (%)', fontsize=12, fontweight='bold')\nax1.set_xlabel('')\nax1.set_title('Box Plot: Hides Bimodal Distribution\\n(Drug A appears normal)',\n             fontsize=12, fontweight='bold', color='red')\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# Violin plot (REVEALS bimodality)\nax2 = axes[1]\nsns.violinplot(data=df, x='Group', y='Value', ax=ax2,\n              palette=['#7F8C8D', '#3498DB', '#E74C3C'],\n              inner='box')  # Add box plot inside\nax2.set_ylabel('Cell Viability (%)', fontsize=12, fontweight='bold')\nax2.set_xlabel('')\nax2.set_title('Violin Plot: Reveals Bimodal Distribution\\n(Drug A has two response populations)',\n             fontsize=12, fontweight='bold', color='green')\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\n\n# Highlight bimodal peaks in Drug A\nax2.annotate('', xy=(1, 20), xytext=(1.3, 20),\n            arrowprops=dict(arrowstyle='-&gt;', lw=2, color='red'))\nax2.text(1.4, 20, 'Peak 1:\\nNon-responders', fontsize=9, va='center', color='red')\n\nax2.annotate('', xy=(1, 35), xytext=(1.3, 35),\n            arrowprops=dict(arrowstyle='-&gt;', lw=2, color='red'))\nax2.text(1.4, 35, 'Peak 2:\\nResponders', fontsize=9, va='center', color='red')\n\nplt.tight_layout()\nplt.savefig('violin_vs_box_bimodal.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chapter 4: Data Encoding & Graph Selection</span>"
    ]
  },
  {
    "objectID": "Chapter 4.html#distribution-revealing-data-structure",
    "href": "Chapter 4.html#distribution-revealing-data-structure",
    "title": "Chapter 4: Data Encoding & Graph Selection",
    "section": "4.3 Distribution: Revealing Data Structure",
    "text": "4.3 Distribution: Revealing Data Structure\n\nHistograms: Binning Continuous Data\nWhen to use: - Showing frequency distribution of continuous data - Revealing distribution shape (normal, skewed, bimodal) - Understanding data spread before statistical analysis - Sample size: moderate to large (n&gt;30 recommended)\nCritical Decision: Bin Width\nThe choice of bin width (or number of bins) dramatically affects interpretation—this is NOT a trivial aesthetic choice.\nThe Problem:\nToo few bins (wide bins):\n→ Over-smoothing, lose detail, miss patterns\n\nToo many bins (narrow bins):\n→ Over-granular, random noise dominates, no pattern visible\n\nGoldilocks zone:\n→ Reveals true structure without artificial patterns\nBin Selection Rules:\nRule of thumb formulas:\n1. Sturges' formula: k = ⌈log₂(n) + 1⌉\n   → Works for normal distributions, n &gt; 30\n\n2. Freedman-Diaconis: bin width = 2×IQR×n^(-1/3)\n   → Robust to outliers, good for skewed data\n\n3. Scott's rule: bin width = 3.49×σ×n^(-1/3)\n   → Optimal for normal distributions\n\nModern approach: Try multiple, choose most informative\nCode Example (Python) - Histogram Bin Selection:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Generate data with known structure (bimodal)\ndata = np.concatenate([\n    np.random.normal(20, 3, 300),  # First peak\n    np.random.normal(35, 4, 200)   # Second peak\n])\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# Too few bins (misses bimodality)\nax1 = axes[0, 0]\nax1.hist(data, bins=5, color='#3498DB', edgecolor='black', linewidth=1.5, alpha=0.7)\nax1.set_xlabel('Value', fontsize=11, fontweight='bold')\nax1.set_ylabel('Frequency', fontsize=11, fontweight='bold')\nax1.set_title('❌ TOO FEW BINS (n=5)\\n(Misses bimodal structure)',\n             fontsize=11, fontweight='bold', color='red')\nax1.grid(axis='y', alpha=0.3)\n\n# Too many bins (over-granular, noisy)\nax2 = axes[0, 1]\nax2.hist(data, bins=100, color='#3498DB', edgecolor='black', linewidth=0.5, alpha=0.7)\nax2.set_xlabel('Value', fontsize=11, fontweight='bold')\nax2.set_ylabel('Frequency', fontsize=11, fontweight='bold')\nax2.set_title('❌ TOO MANY BINS (n=100)\\n(Noisy, no clear pattern)',\n             fontsize=11, fontweight='bold', color='red')\nax2.grid(axis='y', alpha=0.3)\n\n# Just right: Sturges' formula\nn_sturges = int(np.ceil(np.log2(len(data)) + 1))\nax3 = axes[1, 0]\nax3.hist(data, bins=n_sturges, color='#27AE60', edgecolor='black', linewidth=1.5, alpha=0.7)\nax3.set_xlabel('Value', fontsize=11, fontweight='bold')\nax3.set_ylabel('Frequency', fontsize=11, fontweight='bold')\nax3.set_title(f'✓ STURGES\\' RULE (n={n_sturges})\\n(Reveals bimodal structure)',\n             fontsize=11, fontweight='bold', color='green')\nax3.grid(axis='y', alpha=0.3)\n\n# Freedman-Diaconis (alternative)\niqr = np.percentile(data, 75) - np.percentile(data, 25)\nbin_width_fd = 2 * iqr * len(data)**(-1/3)\nn_fd = int(np.ceil((data.max() - data.min()) / bin_width_fd))\nax4 = axes[1, 1]\nax4.hist(data, bins=n_fd, color='#E67E22', edgecolor='black', linewidth=1.5, alpha=0.7)\nax4.set_xlabel('Value', fontsize=11, fontweight='bold')\nax4.set_ylabel('Frequency', fontsize=11, fontweight='bold')\nax4.set_title(f'✓ FREEDMAN-DIACONIS (n={n_fd})\\n(Alternative, robust to outliers)',\n             fontsize=11, fontweight='bold', color='green')\nax4.grid(axis='y', alpha=0.3)\n\n# Highlight the two peaks in correct histograms\nfor ax in [ax3, ax4]:\n    ax.axvline(20, color='red', linestyle='--', linewidth=2, alpha=0.7)\n    ax.axvline(35, color='red', linestyle='--', linewidth=2, alpha=0.7)\n    ax.text(20, ax.get_ylim()[1]*0.9, 'Peak 1', ha='center', fontsize=9,\n           color='red', fontweight='bold')\n    ax.text(35, ax.get_ylim()[1]*0.9, 'Peak 2', ha='center', fontsize=9,\n           color='red', fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('histogram_bin_selection.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(f\"Data: n={len(data)}\")\nprint(f\"Sturges' bins: {n_sturges}\")\nprint(f\"Freedman-Diaconis bins: {n_fd}\")\nCode Example (R) - Histogram Bin Selection:\nlibrary(ggplot2)\nlibrary(patchwork)\n\nset.seed(42)\n\n# Generate bimodal data\ndata &lt;- data.frame(\n  value = c(rnorm(300, 20, 3), rnorm(200, 35, 4))\n)\n\n# Calculate bin numbers\nn &lt;- nrow(data)\nn_sturges &lt;- ceiling(log2(n) + 1)\n\niqr &lt;- IQR(data$value)\nbin_width_fd &lt;- 2 * iqr * n^(-1/3)\nn_fd &lt;- ceiling((max(data$value) - min(data$value)) / bin_width_fd)\n\n# Too few bins\np1 &lt;- ggplot(data, aes(x = value)) +\n  geom_histogram(bins = 5, fill = '#3498DB', color = 'black',\n                size = 1, alpha = 0.7) +\n  labs(x = 'Value', y = 'Frequency',\n       title = paste0('❌ TOO FEW BINS (n=5)\\n(Misses bimodal structure)')) +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 11),\n    axis.title = element_text(face = 'bold'),\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Too many bins\np2 &lt;- ggplot(data, aes(x = value)) +\n  geom_histogram(bins = 100, fill = '#3498DB', color = 'black',\n                size = 0.3, alpha = 0.7) +\n  labs(x = 'Value', y = 'Frequency',\n       title = paste0('❌ TOO MANY BINS (n=100)\\n(Noisy, no clear pattern)')) +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 11),\n    axis.title = element_text(face = 'bold'),\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Sturges' rule\np3 &lt;- ggplot(data, aes(x = value)) +\n  geom_histogram(bins = n_sturges, fill = '#27AE60', color = 'black',\n                size = 1, alpha = 0.7) +\n  geom_vline(xintercept = c(20, 35), color = 'red', linetype = 'dashed', size = 1, alpha = 0.7) +\n  annotate('text', x = 20, y = Inf, label = 'Peak 1', vjust = 1.5, hjust = 0.5,\n          color = 'red', fontface = 'bold', size = 3) +\n  annotate('text', x = 35, y = Inf, label = 'Peak 2', vjust = 1.5, hjust = 0.5,\n          color = 'red', fontface = 'bold', size = 3) +\n  labs(x = 'Value', y = 'Frequency',\n       title = paste0('✓ STURGES\\' RULE (n=', n_sturges, ')\\n(Reveals bimodal structure)')) +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 11),\n    axis.title = element_text(face = 'bold'),\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Freedman-Diaconis\np4 &lt;- ggplot(data, aes(x = value)) +\n  geom_histogram(bins = n_fd, fill = '#E67E22', color = 'black',\n                size = 1, alpha = 0.7) +\n  geom_vline(xintercept = c(20, 35), color = 'red', linetype = 'dashed', size = 1, alpha = 0.7) +\n  annotate('text', x = 20, y = Inf, label = 'Peak 1', vjust = 1.5, hjust = 0.5,\n          color = 'red', fontface = 'bold', size = 3) +\n  annotate('text', x = 35, y = Inf, label = 'Peak 2', vjust = 1.5, hjust = 0.5,\n          color = 'red', fontface = 'bold', size = 3) +\n  labs(x = 'Value', y = 'Frequency',\n       title = paste0('✓ FREEDMAN-DIACONIS (n=', n_fd, ')\\n(Alternative, robust to outliers)')) +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 11),\n    axis.title = element_text(face = 'bold'),\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\ncombined &lt;- (p1 | p2) / (p3 | p4)\nggsave('histogram_bin_selection.png', combined, width = 12, height = 10,\n       dpi = 300, bg = 'white')\n\ncat(paste0(\"Data: n=\", n, \"\\n\"))\ncat(paste0(\"Sturges' bins: \", n_sturges, \"\\n\"))\ncat(paste0(\"Freedman-Diaconis bins: \", n_fd, \"\\n\"))\n\n\n\nDensity Plots: Smooth Distribution Curves\nWhen to use: - Comparing multiple distributions (overlay easier than multiple histograms) - Emphasizing distribution shape over exact frequencies - When you want a smoothed representation (less dependent on binning)\nAdvantages over histograms: - No bin width decision needed - Cleaner visual for overlapping distributions - Better for presentations (smoother = more professional appearance)\nDisadvantages: - Can over-smooth and hide real features - Requires bandwidth parameter (similar issue to bin width) - May extend beyond actual data range (creates impossible values)\nCode Example (Python) - Density Plot Comparison:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import stats\n\nnp.random.seed(42)\n\n# Three treatment groups with different distributions\ncontrol = np.random.normal(25, 5, 100)\ndrug_a = np.random.normal(32, 4, 100)\ndrug_b = np.random.lognormal(3.3, 0.3, 100)  # Skewed\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Overlapping histograms (cluttered)\nax1 = axes[0]\nax1.hist(control, bins=20, alpha=0.5, label='Control', color='#7F8C8D', edgecolor='black')\nax1.hist(drug_a, bins=20, alpha=0.5, label='Drug A', color='#3498DB', edgecolor='black')\nax1.hist(drug_b, bins=20, alpha=0.5, label='Drug B', color='#E74C3C', edgecolor='black')\nax1.set_xlabel('Response', fontsize=11, fontweight='bold')\nax1.set_ylabel('Frequency', fontsize=11, fontweight='bold')\nax1.set_title('Histograms: Overlapping (Cluttered)',\n             fontsize=12, fontweight='bold')\nax1.legend(loc='upper right', frameon=True, fontsize=10)\nax1.grid(axis='y', alpha=0.3)\n\n# Density plots (cleaner)\nax2 = axes[1]\n\n# Calculate density\ndensity_control = stats.gaussian_kde(control)\ndensity_drug_a = stats.gaussian_kde(drug_a)\ndensity_drug_b = stats.gaussian_kde(drug_b)\n\nx_range = np.linspace(0, 60, 300)\n\nax2.plot(x_range, density_control(x_range), color='#7F8C8D',\n        linewidth=3, label='Control')\nax2.fill_between(x_range, density_control(x_range), alpha=0.3, color='#7F8C8D')\n\nax2.plot(x_range, density_drug_a(x_range), color='#3498DB',\n        linewidth=3, label='Drug A')\nax2.fill_between(x_range, density_drug_a(x_range), alpha=0.3, color='#3498DB')\n\nax2.plot(x_range, density_drug_b(x_range), color='#E74C3C',\n        linewidth=3, label='Drug B')\nax2.fill_between(x_range, density_drug_b(x_range), alpha=0.3, color='#E74C3C')\n\nax2.set_xlabel('Response', fontsize=11, fontweight='bold')\nax2.set_ylabel('Density', fontsize=11, fontweight='bold')\nax2.set_title('Density Plots: Smooth Comparison',\n             fontsize=12, fontweight='bold')\nax2.legend(loc='upper right', frameon=True, fontsize=10)\nax2.grid(axis='y', alpha=0.3)\n\n# Annotate distribution characteristics\nax2.text(32, 0.08, 'Normal\\n(symmetric)', ha='center', fontsize=9,\n        bbox=dict(boxstyle='round', facecolor='#3498DB', alpha=0.3))\nax2.text(35, 0.05, 'Skewed right\\n(long tail)', ha='center', fontsize=9,\n        bbox=dict(boxstyle='round', facecolor='#E74C3C', alpha=0.3))\n\nplt.tight_layout()\nplt.savefig('density_vs_histogram.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R) - Density Plot Comparison:\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n\nset.seed(42)\n\n# Generate data\ndata &lt;- data.frame(\n  value = c(\n    rnorm(100, 25, 5),          # Control\n    rnorm(100, 32, 4),          # Drug A\n    rlnorm(100, 3.3, 0.3)       # Drug B (skewed)\n  ),\n  group = rep(c('Control', 'Drug A', 'Drug B'), each = 100)\n)\n\ncolors &lt;- c('Control' = '#7F8C8D', 'Drug A' = '#3498DB', 'Drug B' = '#E74C3C')\n\n# Overlapping histograms\np1 &lt;- ggplot(data, aes(x = value, fill = group)) +\n  geom_histogram(bins = 20, alpha = 0.5, color = 'black', size = 0.5, position = 'identity') +\n  scale_fill_manual(values = colors) +\n  labs(x = 'Response', y = 'Frequency',\n       title = 'Histograms: Overlapping (Cluttered)',\n       fill = NULL) +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 12),\n    axis.title = element_text(face = 'bold'),\n    legend.position = c(0.85, 0.85),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Density plots\np2 &lt;- ggplot(data, aes(x = value, fill = group, color = group)) +\n  geom_density(alpha = 0.3, size = 1.5) +\n  scale_fill_manual(values = colors) +\n  scale_color_manual(values = colors) +\n  labs(x = 'Response', y = 'Density',\n       title = 'Density Plots: Smooth Comparison',\n       fill = NULL, color = NULL) +\n\n  # Annotations\n  annotate('text', x = 32, y = 0.08, label = 'Normal\\n(symmetric)', hjust = 0.5,\n          size = 3, lineheight = 0.9) +\n  annotate('rect', xmin = 29, xmax = 35, ymin = 0.065, ymax = 0.095,\n          fill = '#3498DB', alpha = 0.3) +\n  annotate('text', x = 35, y = 0.05, label = 'Skewed right\\n(long tail)', hjust = 0.5,\n          size = 3, lineheight = 0.9) +\n  annotate('rect', xmin = 32, xmax = 38, ymin = 0.035, ymax = 0.065,\n          fill = '#E74C3C', alpha = 0.3) +\n\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', size = 12),\n    axis.title = element_text(face = 'bold'),\n    legend.position = c(0.85, 0.85),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\ncombined &lt;- p1 | p2\nggsave('density_vs_histogram.png', combined, width = 14, height = 6,\n       dpi = 300, bg = 'white')",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chapter 4: Data Encoding & Graph Selection</span>"
    ]
  },
  {
    "objectID": "Chapter 4.html#relationships-scatter-plots-and-correlation",
    "href": "Chapter 4.html#relationships-scatter-plots-and-correlation",
    "title": "Chapter 4: Data Encoding & Graph Selection",
    "section": "4.4 Relationships: Scatter Plots and Correlation",
    "text": "4.4 Relationships: Scatter Plots and Correlation\n\nScatter Plots: The Gold Standard for Continuous Relationships\nWhen to use: - Showing relationship between two continuous variables - Detecting correlation, clusters, or outliers - Visualizing raw data before statistical modeling\nCritical: Never Rely on Correlation Coefficient Alone\nAnscombe’s Quartet: The Classic Warning\nFour datasets with identical statistics: - Mean of X: 9.0 - Mean of Y: 7.5 - Correlation: r = 0.816 - Linear regression: y = 3 + 0.5x\nBut completely different visual patterns!\nCode Example (Python) - Anscombe’s Quartet:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Anscombe's Quartet data\nanscombe = {\n    'I': {\n        'x': [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],\n        'y': [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]\n    },\n    'II': {\n        'x': [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],\n        'y': [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74]\n    },\n    'III': {\n        'x': [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],\n        'y': [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73]\n    },\n    'IV': {\n        'x': [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8],\n        'y': [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]\n    }\n}\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\naxes = axes.flatten()\n\nfor idx, (label, data) in enumerate(anscombe.items()):\n    ax = axes[idx]\n    x = np.array(data['x'])\n    y = np.array(data['y'])\n\n    # Scatter plot\n    ax.scatter(x, y, s=100, color='#3498DB', edgecolors='black', linewidths=1.5, alpha=0.7)\n\n    # Fit line\n    z = np.polyfit(x, y, 1)\n    p = np.poly1d(z)\n    x_line = np.linspace(x.min(), x.max(), 100)\n    ax.plot(x_line, p(x_line), 'r--', linewidth=2, label=f'y = {z[1]:.2f} + {z[0]:.2f}x')\n\n    # Calculate correlation\n    r = np.corrcoef(x, y)[0, 1]\n\n    # Labels\n    ax.set_xlabel('X', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Y', fontsize=11, fontweight='bold')\n    ax.set_title(f'Dataset {label}\\nr = {r:.3f}, y = {z[1]:.2f} + {z[0]:.2f}x',\n                fontsize=11, fontweight='bold')\n    ax.set_xlim(0, 20)\n    ax.set_ylim(0, 14)\n    ax.grid(alpha=0.3)\n    ax.legend(loc='upper left', frameon=True, fontsize=9)\n\n    # Add interpretation\n    interpretations = {\n        'I': 'Linear relationship\\n(as expected)',\n        'II': 'Nonlinear relationship\\n(parabolic)',\n        'III': 'Linear with outlier\\n(one point distorts)',\n        'IV': 'No relationship\\n(one point creates false correlation)'\n    }\n\n    ax.text(0.98, 0.02, interpretations[label],\n           transform=ax.transAxes, fontsize=9, va='bottom', ha='right',\n           bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))\n\nplt.suptitle('Anscombe\\'s Quartet: Same Statistics, Different Patterns\\nALWAYS PLOT YOUR DATA!',\n            fontsize=14, fontweight='bold', y=1.00)\nplt.tight_layout()\nplt.savefig('anscombes_quartet.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R) - Anscombe’s Quartet:\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(dplyr)\n\n# Anscombe's quartet is built into R\ndata(anscombe)\n\n# Reshape for plotting\nanscombe_long &lt;- data.frame(\n  set = rep(c('I', 'II', 'III', 'IV'), each = 11),\n  x = c(anscombe$x1, anscombe$x2, anscombe$x3, anscombe$x4),\n  y = c(anscombe$y1, anscombe$y2, anscombe$y3, anscombe$y4)\n)\n\n# Calculate stats for each set\nstats_df &lt;- anscombe_long %&gt;%\n  group_by(set) %&gt;%\n  summarise(\n    r = cor(x, y),\n    lm_intercept = coef(lm(y ~ x))[1],\n    lm_slope = coef(lm(y ~ x))[2]\n  )\n\n# Merge with data\nanscombe_long &lt;- anscombe_long %&gt;%\n  left_join(stats_df, by = 'set')\n\n# Interpretations\ninterpretations &lt;- data.frame(\n  set = c('I', 'II', 'III', 'IV'),\n  interpretation = c(\n    'Linear relationship\\n(as expected)',\n    'Nonlinear relationship\\n(parabolic)',\n    'Linear with outlier\\n(one point distorts)',\n    'No relationship\\n(one point creates false correlation)'\n  )\n)\n\nanscombe_long &lt;- anscombe_long %&gt;%\n  left_join(interpretations, by = 'set')\n\n# Plot\nplots &lt;- lapply(c('I', 'II', 'III', 'IV'), function(dataset) {\n  data_subset &lt;- anscombe_long %&gt;% filter(set == dataset)\n\n  ggplot(data_subset, aes(x = x, y = y)) +\n    geom_point(size = 4, color = '#3498DB', alpha = 0.7) +\n    geom_smooth(method = 'lm', se = FALSE, color = 'red', linetype = 'dashed', size = 1.2) +\n\n    labs(x = 'X', y = 'Y',\n         title = paste0('Dataset ', dataset, '\\n',\n                       sprintf('r = %.3f, y = %.2f + %.2fx',\n                              data_subset$r[1],\n                              data_subset$lm_intercept[1],\n                              data_subset$lm_slope[1]))) +\n\n    annotate('label', x = 18, y = 2, label = unique(data_subset$interpretation),\n            hjust = 1, vjust = 0, size = 3, lineheight = 0.9,\n            fill = 'yellow', alpha = 0.3) +\n\n    xlim(0, 20) +\n    ylim(0, 14) +\n\n    theme_classic(base_size = 11) +\n    theme(\n      plot.title = element_text(hjust = 0.5, face = 'bold', size = 10),\n      axis.title = element_text(face = 'bold'),\n      panel.grid.major = element_line(color = 'gray90', size = 0.3)\n    )\n})\n\ncombined &lt;- (plots[[1]] | plots[[2]]) / (plots[[3]] | plots[[4]]) +\n  plot_annotation(\n    title = 'Anscombe\\'s Quartet: Same Statistics, Different Patterns\\nALWAYS PLOT YOUR DATA!',\n    theme = theme(plot.title = element_text(hjust = 0.5, face = 'bold', size = 14))\n  )\n\nggsave('anscombes_quartet.png', combined, width = 12, height = 10,\n       dpi = 300, bg = 'white')\n\n\n\nScatter Plot Best Practices\n1. Show ALL data points (unless n is very large)\n✓ GOOD: Every observation visible\n→ Reveals outliers, clusters, patterns\n\n❌ BAD: Only showing means or aggregated summaries\n→ Hides individual variation and data structure\n2. Add transparency when points overlap\n# For overlapping points\nplt.scatter(x, y, alpha=0.5)  # 50% transparency\n3. Include uncertainty/confidence intervals for trend lines\n# Show confidence band\nsns.regplot(x='var1', y='var2', data=df, scatter_kws={'alpha':0.5})\n4. Report correlation AND test significance\nIn caption:\n\"Pearson r = 0.73, p &lt; 0.001, n = 50\"\n\nNot just:\n\"Strong correlation observed\" (vague, unquantified)\n5. Consider scale transformations for skewed data\nIf data spans orders of magnitude:\n→ Log-transform one or both axes\n→ State transformation in axis label: \"log₁₀(Concentration)\"\n\nSummary of Chapter 4 so far:\n✓ Match plot type to data structure (not personal preference) ✓ Bar charts: Start at zero, include error bars, show n ✓ Box plots: Show full distribution, reveal outliers ✓ Violin plots: Better for bimodal/complex distributions ✓ Histograms: Choose bin width carefully (Sturges’, FD rule) ✓ Density plots: Cleaner for comparisons, but avoid over-smoothing ✓ Scatter plots: Show raw data, always plot (don’t just report r)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chapter 4: Data Encoding & Graph Selection</span>"
    ]
  },
  {
    "objectID": "Chapter 4.html#temporal-data-time-series-best-practices",
    "href": "Chapter 4.html#temporal-data-time-series-best-practices",
    "title": "Chapter 4: Data Encoding & Graph Selection",
    "section": "4.5 Temporal Data: Time Series Best Practices",
    "text": "4.5 Temporal Data: Time Series Best Practices\n\nLine Graphs: The Standard for Continuous Time\nWhen to use: - Showing change over continuous time - Comparing trends across groups - When order matters (temporal, sequential processes)\nCritical Principle: Lines Imply Continuity\n✓ USE LINES when:\n- Data collected continuously or at regular intervals\n- Interpolation between points is reasonable\n- Time is truly continuous\n\n❌ DO NOT use lines when:\n- Data points are independent categories\n- No meaningful values exist between points\n- Comparing discrete, unordered groups\n\n\n\nThe Multiple Time Series Challenge\nProblem: More than 3-4 time series become visually cluttered\nSolutions:\nOption 1: Small Multiples (Faceting)\nInstead of: 10 overlapping lines in one panel\nUse: 10 small panels, each with one line\n→ Clearer individual patterns\n→ Easier to compare specific features\nOption 2: Highlight Key Series\nBackground: All series in light gray (de-emphasized)\nForeground: Key series in bold color\n→ Context without clutter\n→ Focus on important comparison\nOption 3: Interactive (for digital formats)\nHover/click to highlight specific series\nNot viable for print, but powerful for web/presentations\nCode Example (Python) - Time Series Strategies:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Simulate 8 time series\ntime = np.linspace(0, 24, 100)\nn_series = 8\n\n# Generate different trends\nseries_data = []\nfor i in range(n_series):\n    trend = 100 + (i-4)*5  # Different baselines\n    noise = np.random.randn(100) * 3\n    seasonal = 10 * np.sin(2 * np.pi * time / 24 + i * np.pi/4)\n    series_data.append(trend + seasonal + noise)\n\nlabels = [f'Sample {i+1}' for i in range(n_series)]\n\nfig = plt.figure(figsize=(16, 12))\n\n# BAD: All series overlapping (cluttered)\nax1 = plt.subplot(3, 2, 1)\nfor i, data in enumerate(series_data):\n    ax1.plot(time, data, linewidth=2, label=labels[i])\nax1.set_xlabel('Time (hours)', fontsize=10, fontweight='bold')\nax1.set_ylabel('Response', fontsize=10, fontweight='bold')\nax1.set_title('❌ BAD: All Overlapping\\n(Impossible to distinguish)',\n             fontsize=11, fontweight='bold', color='red')\nax1.legend(loc='upper right', fontsize=7, ncol=2)\nax1.grid(alpha=0.3)\n\n# GOOD: Small multiples\nfor i in range(n_series):\n    ax = plt.subplot(3, 4, i+5)\n    ax.plot(time, series_data[i], linewidth=2, color='#3498DB')\n    ax.set_title(labels[i], fontsize=9, fontweight='bold')\n    ax.set_ylim(70, 130)\n    if i &gt;= 4:\n        ax.set_xlabel('Time (h)', fontsize=8)\n    if i % 4 == 0:\n        ax.set_ylabel('Response', fontsize=8)\n    ax.grid(alpha=0.3)\n    ax.tick_params(labelsize=7)\n\n# Add title for small multiples section\nfig.text(0.55, 0.63, '✓ GOOD: Small Multiples\\n(Each series clear)',\n        fontsize=11, fontweight='bold', color='green', ha='center')\n\n# GOOD: Highlight one series\nax3 = plt.subplot(3, 2, 2)\n# Plot all in gray (background)\nfor i, data in enumerate(series_data):\n    ax3.plot(time, data, linewidth=1, color='#CCCCCC', alpha=0.6)\n# Highlight one in color\nax3.plot(time, series_data[3], linewidth=3, color='#E74C3C', label='Sample 4 (highlighted)')\nax3.set_xlabel('Time (hours)', fontsize=10, fontweight='bold')\nax3.set_ylabel('Response', fontsize=10, fontweight='bold')\nax3.set_title('✓ GOOD: Highlight Key Series\\n(Context without clutter)',\n             fontsize=11, fontweight='bold', color='green')\nax3.legend(loc='upper right', fontsize=9)\nax3.grid(alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('time_series_strategies.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R) - Time Series Strategies:\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(patchwork)\n\nset.seed(42)\n\n# Generate data\ntime &lt;- seq(0, 24, length.out = 100)\nn_series &lt;- 8\n\ndata_long &lt;- do.call(rbind, lapply(1:n_series, function(i) {\n  trend &lt;- 100 + (i-4)*5\n  noise &lt;- rnorm(100, 0, 3)\n  seasonal &lt;- 10 * sin(2 * pi * time / 24 + i * pi/4)\n\n  data.frame(\n    time = time,\n    value = trend + seasonal + noise,\n    sample = paste0('Sample ', i)\n  )\n}))\n\n# BAD: All overlapping\np_bad &lt;- ggplot(data_long, aes(x = time, y = value, color = sample)) +\n  geom_line(size = 1.2) +\n  labs(x = 'Time (hours)', y = 'Response',\n       title = '❌ BAD: All Overlapping\\n(Impossible to distinguish)',\n       color = NULL) +\n  theme_classic(base_size = 10) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 11),\n    axis.title = element_text(face = 'bold'),\n    legend.position = 'right',\n    legend.text = element_text(size = 7),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\n# GOOD: Small multiples\np_small_multiples &lt;- ggplot(data_long, aes(x = time, y = value)) +\n  geom_line(color = '#3498DB', size = 1) +\n  facet_wrap(~ sample, ncol = 4) +\n  labs(x = 'Time (h)', y = 'Response',\n       title = '✓ GOOD: Small Multiples\\n(Each series clear)') +\n  theme_classic(base_size = 9) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 11),\n    axis.title = element_text(face = 'bold', size = 8),\n    strip.text = element_text(face = 'bold', size = 8),\n    strip.background = element_rect(fill = 'gray90'),\n    panel.grid.major = element_line(color = 'gray90', size = 0.2)\n  )\n\n# GOOD: Highlight key series\ndata_highlight &lt;- data_long %&gt;%\n  mutate(highlight = ifelse(sample == 'Sample 4', 'Sample 4 (highlighted)', 'Other'))\n\np_highlight &lt;- ggplot(data_highlight, aes(x = time, y = value, group = sample)) +\n  # Background (all gray)\n  geom_line(data = data_highlight %&gt;% filter(highlight == 'Other'),\n           color = '#CCCCCC', size = 0.8, alpha = 0.6) +\n  # Foreground (highlighted)\n  geom_line(data = data_highlight %&gt;% filter(highlight == 'Sample 4 (highlighted)'),\n           aes(color = highlight), size = 2) +\n  scale_color_manual(values = c('Sample 4 (highlighted)' = '#E74C3C')) +\n  labs(x = 'Time (hours)', y = 'Response',\n       title = '✓ GOOD: Highlight Key Series\\n(Context without clutter)',\n       color = NULL) +\n  theme_classic(base_size = 10) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 11),\n    axis.title = element_text(face = 'bold'),\n    legend.position = c(0.8, 0.9),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Combine\ncombined &lt;- (p_bad | p_highlight) / p_small_multiples +\n  plot_layout(heights = c(1, 1.5))\n\nggsave('time_series_strategies.png', combined, width = 16, height = 12,\n       dpi = 300, bg = 'white')\n\n\n\nError Bands for Time Series\nWhen multiple replicates exist:\nOptions for showing variability:\n1. Mean line + shaded error band (SEM or SD)\n2. Mean line + error bars at key timepoints (not every point)\n3. Individual traces in light color + mean in bold\n\n✓ BEST: Shaded band (cleanest, doesn't clutter)\n✓ ACCEPTABLE: Error bars at sparse intervals\n❌ AVOID: Error bars at every point (cluttered)\nCode Example (Python) - Error Bands:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Simulate repeated measurements\ntime = np.linspace(0, 24, 50)\nn_replicates = 8\n\n# Generate replicates\nreplicates = []\nfor i in range(n_replicates):\n    baseline = 100\n    signal = 20 * np.sin(2 * np.pi * time / 24)\n    noise = np.random.randn(len(time)) * 5\n    replicates.append(baseline + signal + noise)\n\nreplicates = np.array(replicates)\n\n# Calculate statistics\nmean_signal = np.mean(replicates, axis=0)\nsem_signal = np.std(replicates, axis=0) / np.sqrt(n_replicates)\nsd_signal = np.std(replicates, axis=0)\n\nfig, axes = plt.subplots(1, 3, figsize=(16, 5))\n\n# CLUTTERED: Error bars at every point\nax1 = axes[0]\nax1.errorbar(time, mean_signal, yerr=sem_signal,\n            fmt='o-', color='#3498DB', linewidth=2, markersize=4,\n            capsize=3, capthick=1, elinewidth=1)\nax1.set_xlabel('Time (hours)', fontsize=10, fontweight='bold')\nax1.set_ylabel('Response', fontsize=10, fontweight='bold')\nax1.set_title('❌ CLUTTERED: Error Bars Every Point\\n(Visually overwhelming)',\n             fontsize=11, fontweight='bold', color='red')\nax1.grid(alpha=0.3)\nax1.set_ylim(60, 140)\n\n# ACCEPTABLE: Error bars at sparse intervals\nax2 = axes[1]\nax2.plot(time, mean_signal, 'o-', color='#3498DB', linewidth=2.5, markersize=3)\n# Error bars only every 10th point\nsparse_indices = range(0, len(time), 10)\nax2.errorbar(time[sparse_indices], mean_signal[sparse_indices],\n            yerr=sem_signal[sparse_indices],\n            fmt='none', ecolor='black', capsize=5, capthick=2, elinewidth=2)\nax2.set_xlabel('Time (hours)', fontsize=10, fontweight='bold')\nax2.set_ylabel('Response', fontsize=10, fontweight='bold')\nax2.set_title('✓ ACCEPTABLE: Sparse Error Bars\\n(Clear but informative)',\n             fontsize=11, fontweight='bold', color='green')\nax2.grid(alpha=0.3)\nax2.set_ylim(60, 140)\n\n# BEST: Shaded error band\nax3 = axes[2]\nax3.plot(time, mean_signal, color='#3498DB', linewidth=3, label='Mean')\nax3.fill_between(time, mean_signal - sem_signal, mean_signal + sem_signal,\n                color='#3498DB', alpha=0.3, label='±SEM')\nax3.set_xlabel('Time (hours)', fontsize=10, fontweight='bold')\nax3.set_ylabel('Response', fontsize=10, fontweight='bold')\nax3.set_title('✓ BEST: Shaded Error Band\\n(Clean and informative)',\n             fontsize=11, fontweight='bold', color='green')\nax3.legend(loc='upper right', frameon=True, fontsize=9)\nax3.grid(alpha=0.3)\nax3.set_ylim(60, 140)\n\n# Add sample size annotation\nfor ax in axes:\n    ax.text(0.02, 0.98, f'n={n_replicates} replicates',\n           transform=ax.transAxes, fontsize=9, va='top', ha='left',\n           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n\nplt.tight_layout()\nplt.savefig('time_series_error_bands.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chapter 4: Data Encoding & Graph Selection</span>"
    ]
  },
  {
    "objectID": "Chapter 4.html#when-not-to-use-certain-plot-types",
    "href": "Chapter 4.html#when-not-to-use-certain-plot-types",
    "title": "Chapter 4: Data Encoding & Graph Selection",
    "section": "4.6 When NOT to Use Certain Plot Types",
    "text": "4.6 When NOT to Use Certain Plot Types\n\nPie Charts: Generally Avoid in Scientific Figures\nWhy pie charts fail:\nProblems:\n1. Humans are bad at comparing angles (worse than lengths)\n2. Hard to read exact values\n3. Doesn't work well for many categories (&gt;5)\n4. 3D pie charts are even worse (perspective distortion)\n5. Slices arranged by size require extra cognitive processing\n\nEvidence: Cleveland & McGill (1984) hierarchy of visual encoding:\nPosition along scale &gt; Length &gt; Angle &gt; Area\n→ Pie charts use weakest encoding (angle)\nBetter alternatives:\nInstead of pie chart, use:\n✓ Bar chart (horizontal if long labels)\n✓ Dot plot (when space limited)\n✓ Stacked bar chart (if showing composition over time/groups)\nCode Example (Python) - Pie Chart vs. Bar Chart:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Sample data: cell type composition\ncategories = ['T cells', 'B cells', 'Macrophages', 'Neutrophils', 'NK cells', 'Other']\nvalues = [32, 18, 25, 12, 8, 5]\ncolors = ['#E74C3C', '#3498DB', '#2ECC71', '#F39C12', '#9B59B6', '#95A5A6']\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Pie chart (hard to compare)\nax1 = axes[0]\nwedges, texts, autotexts = ax1.pie(values, labels=categories, colors=colors,\n                                    autopct='%1.1f%%', startangle=90)\nfor autotext in autotexts:\n    autotext.set_color('white')\n    autotext.set_fontweight('bold')\n    autotext.set_fontsize(9)\nax1.set_title('❌ PIE CHART: Hard to Compare Angles\\n(Which is larger: B cells or Neutrophils?)',\n             fontsize=11, fontweight='bold', color='red')\n\n# Bar chart (easy to compare)\nax2 = axes[1]\n# Sort by value for easier comparison\nsorted_indices = np.argsort(values)[::-1]\nsorted_categories = [categories[i] for i in sorted_indices]\nsorted_values = [values[i] for i in sorted_indices]\nsorted_colors = [colors[i] for i in sorted_indices]\n\nbars = ax2.barh(sorted_categories, sorted_values, color=sorted_colors,\n               edgecolor='black', linewidth=1.5)\nax2.set_xlabel('Percentage (%)', fontsize=11, fontweight='bold')\nax2.set_title('✓ BAR CHART: Easy to Compare Lengths\\n(Clear ordering: T cells &gt; Macrophages &gt; B cells)',\n             fontsize=11, fontweight='bold', color='green')\nax2.invert_yaxis()  # Highest at top\nax2.grid(axis='x', alpha=0.3)\n\n# Add value labels\nfor i, (bar, val) in enumerate(zip(bars, sorted_values)):\n    ax2.text(val + 0.5, i, f'{val}%', va='center', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('pie_vs_bar_comparison.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R) - Pie Chart vs. Bar Chart:\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Data\ndata &lt;- data.frame(\n  category = factor(c('T cells', 'B cells', 'Macrophages', 'Neutrophils', 'NK cells', 'Other')),\n  value = c(32, 18, 25, 12, 8, 5)\n)\n\ncolors &lt;- c('T cells' = '#E74C3C', 'B cells' = '#3498DB',\n            'Macrophages' = '#2ECC71', 'Neutrophils' = '#F39C12',\n            'NK cells' = '#9B59B6', 'Other' = '#95A5A6')\n\n# Pie chart (ggplot doesn't encourage pies, but we'll make one to show why they're bad)\np_pie &lt;- ggplot(data, aes(x = \"\", y = value, fill = category)) +\n  geom_bar(stat = \"identity\", width = 1, color = 'black', size = 1) +\n  coord_polar(\"y\", start = 0) +\n  geom_text(aes(label = paste0(value, '%')),\n            position = position_stack(vjust = 0.5),\n            color = 'white', fontface = 'bold', size = 3.5) +\n  scale_fill_manual(values = colors) +\n  labs(title = '❌ PIE CHART: Hard to Compare Angles\\n(Which is larger: B cells or Neutrophils?)',\n       fill = NULL) +\n  theme_void() +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'red', size = 11),\n    legend.position = 'right'\n  )\n\n# Bar chart (sorted for clarity)\ndata_sorted &lt;- data %&gt;%\n  arrange(desc(value)) %&gt;%\n  mutate(category = factor(category, levels = category))\n\np_bar &lt;- ggplot(data_sorted, aes(x = category, y = value, fill = category)) +\n  geom_bar(stat = 'identity', color = 'black', size = 1, width = 0.7) +\n  geom_text(aes(label = paste0(value, '%')),\n           vjust = -0.5, fontface = 'bold', size = 3.5) +\n  scale_fill_manual(values = colors) +\n  labs(y = 'Percentage (%)',\n       title = '✓ BAR CHART: Easy to Compare Lengths\\n(Clear ordering: T cells &gt; Macrophages &gt; B cells)') +\n  ylim(0, 40) +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = 'bold', color = 'darkgreen', size = 11),\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(face = 'bold'),\n    legend.position = 'none',\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3),\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\ncombined &lt;- p_pie | p_bar\nggsave('pie_vs_bar_comparison.png', combined, width = 14, height = 6,\n       dpi = 300, bg = 'white')\n\n\n\nDual Y-Axes: Use with Extreme Caution\nWhy dual y-axes are problematic:\nProblems:\n1. Scale manipulation can create false correlations\n2. Cognitively demanding (which line matches which axis?)\n3. Can be used to mislead (intentionally or accidentally)\n4. No standard for which variable goes on which axis\n\nExample of manipulation:\nBy adjusting scale ranges, you can make ANY two variables\nappear correlated or anti-correlated\nWhen dual y-axes ARE acceptable:\n✓ Same variable, different units (e.g., °C and °F)\n✓ Tightly coupled variables (input/output of same process)\n✓ When separate panels would lose temporal alignment\n\nBUT: Always justify in caption why dual axes are necessary\nBetter alternatives:\n✓ Two separate panels (stacked vertically, aligned time axes)\n✓ Normalize both variables to 0-100% scale\n✓ Show correlation as scatter plot instead\nCode Example (Python) - Dual Axes Problem:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Two unrelated variables\ntime = np.linspace(0, 10, 100)\nvariable_1 = 50 + 10*np.sin(time) + np.random.randn(100)*2\nvariable_2 = 200 + 50*np.sin(time + 1.5) + np.random.randn(100)*5\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# MISLEADING: Dual axes with manipulated scales\nax1 = axes[0]\ncolor1 = '#E74C3C'\ncolor2 = '#3498DB'\n\n# Plot variable 1\nl1 = ax1.plot(time, variable_1, color=color1, linewidth=2.5, label='Variable 1')\nax1.set_xlabel('Time (hours)', fontsize=11, fontweight='bold')\nax1.set_ylabel('Variable 1 (units)', color=color1, fontsize=11, fontweight='bold')\nax1.tick_params(axis='y', labelcolor=color1)\nax1.set_ylim(20, 80)  # Manipulated range\n\n# Plot variable 2 on second y-axis\nax1_twin = ax1.twinx()\nl2 = ax1_twin.plot(time, variable_2, color=color2, linewidth=2.5, label='Variable 2')\nax1_twin.set_ylabel('Variable 2 (units)', color=color2, fontsize=11, fontweight='bold')\nax1_twin.tick_params(axis='y', labelcolor=color2)\nax1_twin.set_ylim(120, 280)  # Manipulated to make lines appear correlated\n\nax1.set_title('❌ MISLEADING: Dual Y-Axes\\n(Scales manipulated to suggest correlation)',\n             fontsize=11, fontweight='bold', color='red')\nax1.grid(alpha=0.3)\n\n# Add warning annotation\nax1.text(0.5, 0.5, 'WARNING:\\nScales can be adjusted\\nto create false patterns!',\n         transform=ax1.transAxes, ha='center', va='center',\n         fontsize=10, fontweight='bold', color='red',\n         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n\n# BETTER: Separate panels (aligned)\nax2 = axes[1]\n\n# Normalize both to 0-100 scale for fair comparison\nvar1_norm = (variable_1 - variable_1.min()) / (variable_1.max() - variable_1.min()) * 100\nvar2_norm = (variable_2 - variable_2.min()) / (variable_2.max() - variable_2.min()) * 100\n\nax2.plot(time, var1_norm, color=color1, linewidth=2.5, label='Variable 1 (normalized)')\nax2.plot(time, var2_norm, color=color2, linewidth=2.5, label='Variable 2 (normalized)')\nax2.set_xlabel('Time (hours)', fontsize=11, fontweight='bold')\nax2.set_ylabel('Normalized Value (0-100%)', fontsize=11, fontweight='bold')\nax2.set_title('✓ BETTER: Normalized to Same Scale\\n(Honest comparison)',\n             fontsize=11, fontweight='bold', color='green')\nax2.legend(loc='upper right', frameon=True, fontsize=10)\nax2.grid(alpha=0.3)\nax2.set_ylim(0, 100)\n\nplt.tight_layout()\nplt.savefig('dual_axes_problem.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\n\n\n\n3D Plots: Almost Always Avoid\nWhy 3D plots fail in publications:\nProblems:\n1. Perspective distortion (closer points look bigger)\n2. Occlusion (front objects hide back objects)\n3. Difficult to read exact values\n4. Rotation angle is arbitrary (different angles = different story)\n5. Doesn't print well (loses depth cues)\n\nThe 3D illusion only works on screen with rotation interaction\nWhen 3D is acceptable:\n✓ 3D molecular structures (actual 3D objects)\n✓ Medical imaging (CT/MRI reconstructions)\n✓ Spatial mapping (genuine 3D physical phenomena)\n\n❌ NOT for: Bar charts, pie charts, scatter plots (use 2D instead)\nAlternatives to 3D scatter plots:\nInstead of 3D scatter:\n✓ Color/size as 3rd dimension in 2D plot\n✓ Multiple 2D projections (XY, XZ, YZ panels)\n✓ Interactive HTML plots (for digital only)\n✓ Contour plots or heatmaps\n\n\n\nThe “Chartjunk” Principle\nEdward Tufte’s concept: Maximize data-ink ratio\nData-ink ratio = Ink used for data / Total ink used\n\n✓ GOOD: High ratio (most ink shows data)\n❌ BAD: Low ratio (decorations dominate)\n\nExamples of chartjunk to avoid:\n- 3D effects on 2D data\n- Gradients/textures on bars (use solid colors)\n- Grid lines that overwhelm data\n- Excessive decorative elements\n- Unnecessary backgrounds\n- Ornamental fonts\nModern Minimalism in Scientific Figures:\nKeep:\n✓ Data points/lines\n✓ Axes and labels\n✓ Legend (if necessary)\n✓ Minimal grid (light, unobtrusive)\n✓ Error bars/confidence bands\n\nRemove:\n❌ Chart borders (top/right spines)\n❌ Background colors (use white)\n❌ 3D effects\n❌ Drop shadows\n❌ Decorative clip art\n\n\n\n4.7 Bar Plot Error Bars: Correct Usage\nCritical Rule: Error bars must be scientifically justified and clearly labeled.\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n# Example data\nconditions = ['Control', 'Treatment A', 'Treatment B']\nn_replicates = 5\n\n# Simulate biological replicates\ndata = {\n    'Control': np.random.normal(25, 3, n_replicates),\n    'Treatment A': np.random.normal(35, 4, n_replicates),\n    'Treatment B': np.random.normal(30, 3.5, n_replicates)\n}\n\nmeans = [np.mean(data[c]) for c in conditions]\nstds = [np.std(data[c], ddof=1) for c in conditions]  # Sample SD\nsems = [np.std(data[c], ddof=1) / np.sqrt(len(data[c])) for c in conditions]  # SEM\n\n# Panel A: BAD - No error bars \nax1.text(0.5, 0.95, 'No variability shown!\\nHow reliable is this?',\n        transform=ax1.transAxes, ha='center', va='top',\n        fontsize=10, style='italic', color='red',\n        bbox=dict(boxstyle='round', facecolor='#FFCCCC', alpha=0.8))\n\n# Panel B: UNCLEAR - Error bars without label\nax2 = axes[0, 1]\nax2.bar(conditions, means, yerr=stds, capsize=8,\n       color='#3498DB', edgecolor='black', linewidth=1.5)\nax2.set_ylabel('Response (AU)', fontsize=11, fontweight='bold')\nax2.set_ylim(0, 50)\nax2.set_title('❌ UNCLEAR: Unlabeled Error Bars\\n(SD? SEM? 95% CI?)',\n              fontsize=12, fontweight='bold', color='red')\n\n# Panel C: GOOD - SD with label\nax3 = axes[1, 0]\nax3.bar(conditions, means, yerr=stds, capsize=8,\n       color='#3498DB', edgecolor='black', linewidth=1.5)\nax3.set_ylabel('Response (AU)\\n(Mean ± SD)', fontsize=11, fontweight='bold')\nax3.set_ylim(0, 50)\nax3.set_title('✓ GOOD: Labeled as SD\\n(Shows data spread)',\n              fontsize=12, fontweight='bold', color='green')\n\n# Add sample sizes\nfor i, (cond, mean, std) in enumerate(zip(conditions, means, stds)):\n    ax3.text(i, mean + std + 2, f'n={n_replicates}',\n            ha='center', fontsize=9, style='italic')\n\n# Panel D: ALSO GOOD - SEM with label\nax4 = axes[1, 1]\nax4.bar(conditions, means, yerr=sems, capsize=8,\n       color='#27AE60', edgecolor='black', linewidth=1.5)\nax4.set_ylabel('Response (AU)\\n(Mean ± SEM)', fontsize=11, fontweight='bold')\nax4.set_ylim(0, 50)\nax4.set_title('✓ ALSO GOOD: Labeled as SEM\\n(Shows precision of mean)',\n              fontsize=12, fontweight='bold', color='green')\n\n# Add sample sizes\nfor i, (cond, mean, sem) in enumerate(zip(conditions, means, sems)):\n    ax4.text(i, mean + sem + 2, f'n={n_replicates}',\n            ha='center', fontsize=9, style='italic')\n\nplt.tight_layout()\nplt.savefig('error_bars_correct_usage.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\nDecision Tree: Which Error Bar to Use?\n\"\"\"\nWHEN TO USE EACH ERROR BAR TYPE:\n\n1. STANDARD DEVIATION (SD):\n   ✓ Shows spread/variability of the data\n   ✓ Use when: Describing population variability is important\n   ✓ Interpretation: ~68% of data falls within ±1 SD\n   ✓ Example: \"Control group has high variability (SD=8)\"\n\n2. STANDARD ERROR OF THE MEAN (SEM):\n   ✓ Shows precision of the mean estimate\n   ✓ Use when: Comparing means between groups\n   ✓ Interpretation: Narrower bars = more precise mean\n   ✓ Formula: SEM = SD / sqrt(n)\n   ✓ Note: ALWAYS report n (sample size)\n\n3. 95% CONFIDENCE INTERVAL:\n   ✓ Shows range likely to contain true mean\n   ✓ Use when: Making statistical inference\n   ✓ Interpretation: If bars don't overlap, likely significant difference\n   ✓ Formula: CI = mean ± (t_critical × SEM)\n\nGOLDEN RULE: ALWAYS LABEL WHICH TYPE YOU'RE USING!\n\"\"\"\n\n# Code example with all three types\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import stats\n\nnp.random.seed(42)\n\nconditions = ['Control', 'Treatment']\nn = 10  # Sample size\ndata_ctrl = np.random.normal(50, 10, n)\ndata_trt = np.random.normal(65, 12, n)\n\nmeans = [data_ctrl.mean(), data_trt.mean()]\nsds = [data_ctrl.std(ddof=1), data_trt.std(ddof=1)]\nsems = [data_ctrl.std(ddof=1)/np.sqrt(n), data_trt.std(ddof=1)/np.sqrt(n)]\n\n# Calculate 95% CI\nt_crit = stats.t.ppf(0.975, df=n-1)  # Two-tailed, df=n-1\nci95 = [sem * t_crit for sem in sems]\n\nfig, axes = plt.subplots(1, 3, figsize=(16, 5))\n\n# Plot 1: SD\nax1 = axes[0]\nax1.bar(conditions, means, yerr=sds, capsize=10,\n       color='#3498DB', edgecolor='black', linewidth=2, width=0.5)\nax1.set_ylabel('Response (AU)', fontsize=12, fontweight='bold')\nax1.set_ylim(0, 100)\nax1.set_title('Standard Deviation (SD)\\nShows data spread',\n              fontsize=13, fontweight='bold')\nax1.text(0.5, 0.95, f'n={n} per group', transform=ax1.transAxes,\n        ha='center', va='top', fontsize=10, fontweight='bold',\n        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n\n# Plot 2: SEM\nax2 = axes[1]\nax2.bar(conditions, means, yerr=sems, capsize=10,\n       color='#27AE60', edgecolor='black', linewidth=2, width=0.5)\nax2.set_ylabel('Response (AU)', fontsize=12, fontweight='bold')\nax2.set_ylim(0, 100)\nax2.set_title('Standard Error of Mean (SEM)\\nShows precision of mean',\n              fontsize=13, fontweight='bold')\nax2.text(0.5, 0.95, f'n={n} per group', transform=ax2.transAxes,\n        ha='center', va='top', fontsize=10, fontweight='bold',\n        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n\n# Plot 3: 95% CI\nax3 = axes[2]\nax3.bar(conditions, means, yerr=ci95, capsize=10,\n       color='#E74C3C', edgecolor='black', linewidth=2, width=0.5)\nax3.set_ylabel('Response (AU)', fontsize=12, fontweight='bold')\nax3.set_ylim(0, 100)\nax3.set_title('95% Confidence Interval\\nLikely range of true mean',\n              fontsize=13, fontweight='bold')\nax3.text(0.5, 0.95, f'n={n} per group', transform=ax3.transAxes,\n        ha='center', va='top', fontsize=10, fontweight='bold',\n        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n\n# Add comparison note\nfig.text(0.5, 0.02, 'Note: Same data, different error bar types → Different visual impression',\n        ha='center', fontsize=11, style='italic', fontweight='bold')\n\nplt.tight_layout(rect=[0, 0.05, 1, 1])\nplt.savefig('error_bar_types_comparison.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\nCritical Mistake: Using Bar Plots When You Shouldn’t\n# Bar plots are often MISUSED - here are better alternatives\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Simulate data with different distributions\ncontrol = np.random.normal(50, 10, 100)\ntreatment = np.concatenate([\n    np.random.normal(40, 5, 50),   # Bimodal distribution!\n    np.random.normal(70, 5, 50)\n])\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n# BAD: Bar plot hides bimodal distribution\nax1 = axes[0, 0]\nmeans = [control.mean(), treatment.mean()]\nstds = [control.std(), treatment.std()]\nconditions = ['Control', 'Treatment']\n\nax1.bar(conditions, means, yerr=stds, capsize=8,\n       color='#3498DB', edgecolor='black', linewidth=2)\nax1.set_ylabel('Response (AU)', fontsize=11, fontweight='bold')\nax1.set_ylim(0, 100)\nax1.set_title('❌ BAD: Bar Plot\\n(Hides important distribution shape)',\n              fontsize=12, fontweight='bold', color='red')\n\n# BETTER: Box plot shows distribution\nax2 = axes[0, 1]\nbp = ax2.boxplot([control, treatment], labels=conditions,\n                 patch_artist=True, widths=0.5)\nfor patch in bp['boxes']:\n    patch.set_facecolor('#3498DB')\n    patch.set_alpha(0.7)\nax2.set_ylabel('Response (AU)', fontsize=11, fontweight='bold')\nax2.set_ylim(0, 100)\nax2.set_title('✓ BETTER: Box Plot\\n(Shows quartiles, outliers)',\n              fontsize=12, fontweight='bold', color='green')\nax2.grid(axis='y', alpha=0.3)\n\n# EVEN BETTER: Violin plot shows full distribution\nax3 = axes[1, 0]\nparts = ax3.violinplot([control, treatment], positions=[1, 2],\n                       widths=0.7, showmeans=True, showmedians=True)\nfor pc in parts['bodies']:\n    pc.set_facecolor('#3498DB')\n    pc.set_alpha(0.7)\nax3.set_xticks([1, 2])\nax3.set_xticklabels(conditions)\nax3.set_ylabel('Response (AU)', fontsize=11, fontweight='bold')\nax3.set_ylim(0, 100)\nax3.set_title('✓ EVEN BETTER: Violin Plot\\n(Shows BIMODAL distribution in treatment!)',\n              fontsize=12, fontweight='bold', color='green')\nax3.grid(axis='y', alpha=0.3)\n\n# BEST: Show individual points + summary\nax4 = axes[1, 1]\n# Scatter individual points with jitter\nx_ctrl = np.random.normal(1, 0.04, len(control))\nx_trt = np.random.normal(2, 0.04, len(treatment))\nax4.scatter(x_ctrl, control, alpha=0.4, s=30, color='#3498DB', edgecolors='black', linewidths=0.5)\nax4.scatter(x_trt, treatment, alpha=0.4, s=30, color='#E74C3C', edgecolors='black', linewidths=0.5)\n\n# Overlay mean ± SEM\nax4.errorbar([1, 2], means, yerr=[s/np.sqrt(100) for s in stds],\n            fmt='D', markersize=12, color='black', markerfacecolor='yellow',\n            capsize=10, linewidth=3, label='Mean ± SEM')\n\nax4.set_xticks([1, 2])\nax4.set_xticklabels(conditions)\nax4.set_xlim(0.5, 2.5)\nax4.set_ylabel('Response (AU)', fontsize=11, fontweight='bold')\nax4.set_ylim(0, 100)\nax4.set_title('✓ BEST: Individual Points + Summary\\n(Shows BOTH raw data and summary)',\n              fontsize=12, fontweight='bold', color='green')\nax4.legend(loc='upper left', frameon=True, fontsize=10)\nax4.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('when_not_to_use_barplot.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chapter 4: Data Encoding & Graph Selection</span>"
    ]
  },
  {
    "objectID": "Chapter 4.html#chapter-4-summary-complete-graph-selection-guide",
    "href": "Chapter 4.html#chapter-4-summary-complete-graph-selection-guide",
    "title": "Chapter 4: Data Encoding & Graph Selection",
    "section": "Chapter 4 Summary: Complete Graph Selection Guide",
    "text": "Chapter 4 Summary: Complete Graph Selection Guide\nQuick Reference Table:\n\n\n\n\n\n\n\n\n\nData Type\nBest Plot\nAcceptable Alternatives\nAvoid\n\n\n\n\nCompare groups (continuous)\nBar chart, Box plot, Violin plot\nDot plot, Strip plot\nPie chart, 3D bars\n\n\nCompare groups (many)\nSmall multiples, Heatmap\nGrouped violin, Faceted box\nSingle cluttered plot\n\n\nDistribution (single)\nHistogram, Density, Box plot\nViolin plot, ECDF\nPie chart (not applicable)\n\n\nDistribution (multiple)\nOverlapping density, Violin, Box\nRidgeline plot\nMultiple pie charts\n\n\nRelationship (continuous)\nScatter plot\nHexbin (if dense), 2D density\nLine plot (if not ordered)\n\n\nTime series (few)\nLine graph\nArea chart\nBar chart, Pie chart\n\n\nTime series (many)\nSmall multiples, Highlight key\nHeatmap, Spaghetti plot\nAll overlapping\n\n\nComposition (parts of whole)\nStacked bar, Treemap\nStacked area (over time)\nPie chart\n\n\nSpatial data\nMap (choropleth/point), Heatmap\nContour plot\n3D surface (in print)\n\n\nCorrelation matrix\nHeatmap, Corrplot\nNetwork diagram\nTable only\n\n\n\n\nEnd of Chapter 4: Data Encoding & Graph Selection\nKey Takeaways: - Match plot to data structure, not personal preference - Bar charts: Zero baseline, error bars, sorted logically - Box/Violin plots: Show full distribution, not just mean - Histograms: Bin width matters (use Sturges’ or FD rule) - Scatter plots: Always plot raw data (Anscombe’s warning) - Time series: Use lines for continuous, small multiples for many - Avoid: Pie charts, dual y-axes (unless justified), 3D effects - Maximize data-ink ratio: Remove chartjunk, keep focus on data",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chapter 4: Data Encoding & Graph Selection</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html",
    "href": "Chapter 5.html",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "",
    "text": "5.1 The Gestalt Principles Applied to Scientific Figures",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#the-gestalt-principles-applied-to-scientific-figures",
    "href": "Chapter 5.html#the-gestalt-principles-applied-to-scientific-figures",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "",
    "text": "Visual Perception Fundamentals\nThe human visual system automatically organizes visual information according to Gestalt principles—innate perceptual patterns that emerged from evolutionary psychology. Understanding these principles allows you to design figures that are instantly interpretable.\nThe Core Insight: &gt; Readers perceive relationships between elements before conscious analysis. Poor layout creates false groupings; good layout guides interpretation effortlessly.\n\n\n\nPrinciple 1: Proximity (Nearness Implies Relatedness)\nThe Rule: Elements placed close together are perceived as belonging to the same group.\nApplication in Figures:\n✓ CORRECT spacing:\n- Panels within a figure: Close together (related)\n- Figures in manuscript: Separated (distinct)\n- Axis label + axis: Immediate proximity (clear association)\n- Legend + plot: Adjacent (functional relationship)\n\n❌ INCORRECT spacing:\n- Equal spacing between all panels (loses grouping information)\n- Legend far from plot (requires search)\n- Caption separated from figure by page break\nCode Example (Python) - Proximity in Multi-Panel Layouts:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Generate sample data for 6 panels\ndata_sets = [np.random.randn(50) + i*2 for i in range(6)]\n\nfig = plt.figure(figsize=(16, 10))\n\n# BAD: Equal spacing (no grouping information)\nfig.text(0.25, 0.95, '❌ BAD: Equal Spacing (No Visual Grouping)',\n         ha='center', fontsize=14, fontweight='bold', color='red')\n\ngs_bad = fig.add_gridspec(3, 2, left=0.05, right=0.45, top=0.85, bottom=0.55,\n                          wspace=0.3, hspace=0.4)  # Equal spacing\n\nfor i in range(6):\n    ax = fig.add_subplot(gs_bad[i//2, i%2])\n    ax.hist(data_sets[i], bins=15, color='#3498DB', edgecolor='black', alpha=0.7)\n    ax.set_title(f'Panel {chr(65+i)}', fontsize=10, fontweight='bold')\n    ax.set_ylabel('Frequency', fontsize=9)\n    ax.tick_params(labelsize=8)\n\n# Add misleading text\nfig.text(0.25, 0.52, 'All panels equally spaced\\n→ No visual hierarchy or grouping',\n         ha='center', fontsize=9, style='italic', color='red')\n\n# GOOD: Grouped spacing (proximity shows relationship)\nfig.text(0.75, 0.95, '✓ GOOD: Grouped Spacing (Clear Relationship)',\n         ha='center', fontsize=14, fontweight='bold', color='green')\n\n# Create two groups: Control (A-C) and Treatment (D-F)\n# Group 1: Tighter spacing within group\ngs_good_ctrl = fig.add_gridspec(3, 1, left=0.55, right=0.68, top=0.85, bottom=0.55,\n                                hspace=0.15)  # Tight spacing\n\n# Group 2: Separated from group 1\ngs_good_trt = fig.add_gridspec(3, 1, left=0.77, right=0.90, top=0.85, bottom=0.55,\n                               hspace=0.15)  # Tight spacing\n\n# Plot Control group\nfor i in range(3):\n    ax = fig.add_subplot(gs_good_ctrl[i])\n    ax.hist(data_sets[i], bins=15, color='#7F8C8D', edgecolor='black', alpha=0.7)\n    ax.set_title(f'Panel {chr(65+i)}', fontsize=10, fontweight='bold')\n    ax.set_ylabel('Frequency', fontsize=9)\n    ax.tick_params(labelsize=8)\n    if i == 0:\n        ax.text(0.5, 1.15, 'CONTROL', transform=ax.transAxes,\n               ha='center', fontsize=11, fontweight='bold',\n               bbox=dict(boxstyle='round', facecolor='#7F8C8D', alpha=0.3))\n\n# Plot Treatment group\nfor i in range(3, 6):\n    ax = fig.add_subplot(gs_good_trt[i-3])\n    ax.hist(data_sets[i], bins=15, color='#E74C3C', edgecolor='black', alpha=0.7)\n    ax.set_title(f'Panel {chr(65+i)}', fontsize=10, fontweight='bold')\n    ax.set_ylabel('Frequency', fontsize=9)\n    ax.tick_params(labelsize=8)\n    if i == 3:\n        ax.text(0.5, 1.15, 'TREATMENT', transform=ax.transAxes,\n               ha='center', fontsize=11, fontweight='bold',\n               bbox=dict(boxstyle='round', facecolor='#E74C3C', alpha=0.3))\n\n# Add explanatory text\nfig.text(0.725, 0.52, 'Tight spacing within groups\\n→ Clear visual grouping',\n         ha='center', fontsize=9, style='italic', color='green')\n\nplt.savefig('proximity_principle.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R) - Proximity in Multi-Panel Layouts:\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(grid)\n\nset.seed(42)\n\n# Generate data\ndata_list &lt;- lapply(1:6, function(i) {\n  data.frame(value = rnorm(50, mean = i*2, sd = 1))\n})\n\n# Create individual plots\nplots &lt;- lapply(1:6, function(i) {\n  ggplot(data_list[[i]], aes(x = value)) +\n    geom_histogram(bins = 15, fill = '#3498DB', color = 'black', alpha = 0.7) +\n    labs(title = paste0('Panel ', LETTERS[i]), y = 'Frequency') +\n    theme_classic(base_size = 9) +\n    theme(\n      plot.title = element_text(face = 'bold', size = 10, hjust = 0.5),\n      axis.title = element_text(face = 'bold', size = 9)\n    )\n})\n\n# BAD: Equal spacing\np_bad &lt;- wrap_plots(plots, ncol = 2, nrow = 3) +\n  plot_annotation(\n    title = '❌ BAD: Equal Spacing (No Visual Grouping)',\n    subtitle = 'All panels equally spaced → No visual hierarchy or grouping',\n    theme = theme(\n      plot.title = element_text(face = 'bold', size = 14, color = 'red', hjust = 0.5),\n      plot.subtitle = element_text(face = 'italic', size = 9, color = 'red', hjust = 0.5)\n    )\n  )\n\n# GOOD: Grouped spacing\n# Control group (gray)\nplots_ctrl &lt;- lapply(1:3, function(i) {\n  ggplot(data_list[[i]], aes(x = value)) +\n    geom_histogram(bins = 15, fill = '#7F8C8D', color = 'black', alpha = 0.7) +\n    labs(title = paste0('Panel ', LETTERS[i]), y = 'Frequency') +\n    theme_classic(base_size = 9) +\n    theme(\n      plot.title = element_text(face = 'bold', size = 10, hjust = 0.5),\n      axis.title = element_text(face = 'bold', size = 9)\n    )\n})\n\n# Treatment group (red)\nplots_trt &lt;- lapply(4:6, function(i) {\n  ggplot(data_list[[i]], aes(x = value)) +\n    geom_histogram(bins = 15, fill = '#E74C3C', color = 'black', alpha = 0.7) +\n    labs(title = paste0('Panel ', LETTERS[i]), y = 'Frequency') +\n    theme_classic(base_size = 9) +\n    theme(\n      plot.title = element_text(face = 'bold', size = 10, hjust = 0.5),\n      axis.title = element_text(face = 'bold', size = 9)\n    )\n})\n\n# Combine with tight spacing within groups\nctrl_combined &lt;- wrap_plots(plots_ctrl, ncol = 1) +\n  plot_annotation(title = 'CONTROL',\n                  theme = theme(plot.title = element_text(face = 'bold', size = 11, hjust = 0.5)))\n\ntrt_combined &lt;- wrap_plots(plots_trt, ncol = 1) +\n  plot_annotation(title = 'TREATMENT',\n                  theme = theme(plot.title = element_text(face = 'bold', size = 11, hjust = 0.5)))\n\np_good &lt;- (ctrl_combined | trt_combined) +\n  plot_annotation(\n    title = '✓ GOOD: Grouped Spacing (Clear Relationship)',\n    subtitle = 'Tight spacing within groups → Clear visual grouping',\n    theme = theme(\n      plot.title = element_text(face = 'bold', size = 14, color = 'darkgreen', hjust = 0.5),\n      plot.subtitle = element_text(face = 'italic', size = 9, color = 'darkgreen', hjust = 0.5)\n    )\n  )\n\n# Save (since we can't easily combine bad and good in one figure with patchwork,\n# we'll save separately or use grid)\n\n# For demonstration, save good example\nggsave('proximity_principle_good.png', p_good, width = 14, height = 10,\n       dpi = 300, bg = 'white')\n\n\n\nPrinciple 2: Similarity (Like Elements Group Together)\nThe Rule: Elements that share visual properties (color, shape, size, orientation) are perceived as related.\nApplication:\n✓ CORRECT use:\n- Same color for same experimental group across all panels\n- Same marker shape for same variable type\n- Consistent line styles for same condition\n\n❌ INCORRECT:\n- Different colors for same group in different panels\n- Inconsistent symbols without semantic reason\nExample from Section 2.5:\nIf \"Drug A\" is blue in Figure 1, it MUST be blue in Figures 2, 3, 4...\n→ Similarity creates immediate recognition\n→ Inconsistency forces mental translation (cognitive load)\n\n\n\nPrinciple 3: Closure (Mind Completes Incomplete Shapes)\nApplication in Figure Layout:\nUse closure to create implied groupings:\n- Boxes/borders around related panels (creates enclosure)\n- Aligned edges create implicit boundaries\n- White space separates groups (implicit border)\nCode Example (Python) - Using Enclosure for Grouping:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import FancyBboxPatch\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(2, 3, figsize=(14, 8))\n\n# Generate sample data\nfor i, ax in enumerate(axes.flat):\n    data = np.random.randn(100) + i\n    ax.hist(data, bins=15, color='#3498DB', edgecolor='black', alpha=0.7)\n    ax.set_title(f'Panel {chr(65+i)}', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Frequency', fontsize=10)\n    ax.tick_params(labelsize=9)\n\n# Add enclosure boxes to create visual groups\n# Group 1: Panels A, B, C (top row - Method 1)\nbbox1 = FancyBboxPatch((0.08, 0.55), 0.85, 0.38,\n                       boxstyle=\"round,pad=0.01\",\n                       edgecolor='#27AE60', facecolor='none',\n                       linewidth=3, transform=fig.transFigure,\n                       clip_on=False, zorder=10)\nfig.patches.append(bbox1)\nfig.text(0.5, 0.94, 'Method 1 Results', ha='center', fontsize=12,\n        fontweight='bold', color='#27AE60')\n\n# Group 2: Panels D, E, F (bottom row - Method 2)\nbbox2 = FancyBboxPatch((0.08, 0.08), 0.85, 0.38,\n                       boxstyle=\"round,pad=0.01\",\n                       edgecolor='#E67E22', facecolor='none',\n                       linewidth=3, transform=fig.transFigure,\n                       clip_on=False, zorder=10)\nfig.patches.append(bbox2)\nfig.text(0.5, 0.47, 'Method 2 Results', ha='center', fontsize=12,\n        fontweight='bold', color='#E67E22')\n\nplt.suptitle('Using Enclosure to Create Visual Grouping\\n(Closure Principle)',\n            fontsize=14, fontweight='bold', y=0.98)\n\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.savefig('closure_principle_grouping.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\n\n\n\nPrinciple 4: Continuity (Eyes Follow Paths)\nApplication:\nAlignment creates visual flow:\n✓ Align panel edges (creates reading path)\n✓ Align axis limits when comparing (facilitates comparison)\n✓ Use consistent panel sizes (smooth visual scanning)\n\n❌ AVOID:\n- Misaligned panels (jagged, disorganized)\n- Different aspect ratios without justification\n- Inconsistent spacing (disrupts flow)\n\n\n\nPrinciple 5: Figure-Ground (Foreground vs. Background)\nApplication:\nCreate clear hierarchy:\n✓ Data elements (foreground): Bold, saturated colors\n✓ Grid/axes (background): Light gray, thin lines\n✓ Annotations (mid-ground): Medium contrast\n\nVisual hierarchy = Information hierarchy",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#the-grid-system-for-scientific-figures",
    "href": "Chapter 5.html#the-grid-system-for-scientific-figures",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "5.2 The Grid System for Scientific Figures",
    "text": "5.2 The Grid System for Scientific Figures\n\nWhy Grids Matter\nA grid system provides invisible structure that: - Ensures consistent alignment - Creates visual rhythm - Facilitates comparison across panels - Signals professionalism\nThe Standard: Column-Based Grid\nCommon layouts:\n- 1-column: Full width (simple figures)\n- 2-column: Split left/right (comparisons)\n- 3-column: Triptych (sequential processes)\n- 2×2 grid: Four related panels\n- Mixed: Large main + smaller supporting panels\n\n\n\nLayout Strategy 1: Equal Weight Panels\nWhen to use: All panels equally important, same data type\nCode Example (Python) - Balanced 2×2 Grid:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# Generate different plot types\nplot_types = [\n    ('Scatter', 'scatter'),\n    ('Line', 'line'),\n    ('Bar', 'bar'),\n    ('Box', 'box')\n]\n\nfor idx, (title, ptype) in enumerate(plot_types):\n    ax = axes.flat[idx]\n\n    if ptype == 'scatter':\n        x = np.random.randn(50)\n        y = 2*x + np.random.randn(50)\n        ax.scatter(x, y, s=50, color='#3498DB', alpha=0.7, edgecolors='black', linewidths=0.5)\n        ax.set_xlabel('Variable X', fontsize=10, fontweight='bold')\n        ax.set_ylabel('Variable Y', fontsize=10, fontweight='bold')\n\n    elif ptype == 'line':\n        time = np.linspace(0, 10, 50)\n        signal = 5 + 2*np.sin(time) + np.random.randn(50)*0.5\n        ax.plot(time, signal, 'o-', color='#27AE60', linewidth=2, markersize=4)\n        ax.set_xlabel('Time (s)', fontsize=10, fontweight='bold')\n        ax.set_ylabel('Signal (mV)', fontsize=10, fontweight='bold')\n\n    elif ptype == 'bar':\n        categories = ['A', 'B', 'C', 'D']\n        values = [25, 32, 28, 35]\n        ax.bar(categories, values, color='#E74C3C', edgecolor='black', linewidth=1.5)\n        ax.set_ylabel('Response (AU)', fontsize=10, fontweight='bold')\n\n    elif ptype == 'box':\n        data = [np.random.normal(20+i*5, 3, 50) for i in range(4)]\n        bp = ax.boxplot(data, labels=['G1', 'G2', 'G3', 'G4'], patch_artist=True)\n        for patch in bp['boxes']:\n            patch.set_facecolor('#F39C12')\n        ax.set_ylabel('Measurement', fontsize=10, fontweight='bold')\n\n    # Panel label\n    ax.text(-0.15, 1.05, chr(65+idx), transform=ax.transAxes,\n           fontsize=16, fontweight='bold', va='top')\n\n    ax.set_title(f'{title} Plot', fontsize=11, fontweight='bold')\n    ax.grid(alpha=0.3)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\nplt.suptitle('Equal Weight Grid Layout (2×2)', fontsize=14, fontweight='bold', y=0.98)\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.savefig('equal_weight_grid.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\n\n\nLayout Strategy 2: Dominant Panel + Supporting Panels\nWhen to use: One main finding + supporting evidence or details\nStructure:\n┌─────────────┬─────┐\n│             │  B  │\n│      A      ├─────┤\n│  (main)     │  C  │\n│             ├─────┤\n└─────────────┴─────┘\n\nA: Large (60-70% of space) - Main result\nB, C: Small (15-20% each) - Supporting/methods\nCode Example (Python) - Dominant Layout:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\nfig = plt.figure(figsize=(14, 8))\n\n# Create grid: 2 rows, 2 columns with different sizes\ngs = fig.add_gridspec(2, 2, width_ratios=[3, 1], height_ratios=[1, 1],\n                      hspace=0.3, wspace=0.3)\n\n# Panel A: Main result (large, spans 2 rows)\nax_main = fig.add_subplot(gs[:, 0])\nx = np.random.randn(200)\ny = 2.5*x + np.random.randn(200)*1.5\nax_main.scatter(x, y, s=60, color='#3498DB', alpha=0.6, edgecolors='black', linewidths=0.5)\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nx_line = np.linspace(x.min(), x.max(), 100)\nax_main.plot(x_line, p(x_line), 'r--', linewidth=3, label=f'y = {z[1]:.2f} + {z[0]:.2f}x')\nax_main.set_xlabel('Treatment Dose (μM)', fontsize=12, fontweight='bold')\nax_main.set_ylabel('Cell Response (AU)', fontsize=12, fontweight='bold')\nax_main.set_title('Main Result: Dose-Response Relationship', fontsize=13, fontweight='bold')\nax_main.legend(loc='upper left', fontsize=11, frameon=True)\nax_main.grid(alpha=0.3)\nax_main.text(-0.1, 1.05, 'A', transform=ax_main.transAxes,\n            fontsize=18, fontweight='bold', va='top')\n\n# Panel B: Supporting (top right)\nax_b = fig.add_subplot(gs[0, 1])\ncategories = ['Control', 'Treated']\nvalues = [25, 35]\nerrors = [3, 4]\nax_b.bar(categories, values, color=['#7F8C8D', '#E74C3C'],\n        edgecolor='black', linewidth=1.5, width=0.5)\nax_b.errorbar(categories, values, yerr=errors, fmt='none',\n             ecolor='black', capsize=6, linewidth=2)\nax_b.set_ylabel('Viability (%)', fontsize=10, fontweight='bold')\nax_b.set_title('Endpoint Viability', fontsize=10, fontweight='bold')\nax_b.set_ylim(0, 50)\nax_b.grid(axis='y', alpha=0.3)\nax_b.text(-0.25, 1.1, 'B', transform=ax_b.transAxes,\n         fontsize=16, fontweight='bold', va='top')\n\n# Panel C: Supporting (bottom right)\nax_c = fig.add_subplot(gs[1, 1])\ntime = np.linspace(0, 24, 50)\nsignal = 100 + 20*np.sin(2*np.pi*time/24) + np.random.randn(50)*3\nax_c.plot(time, signal, 'o-', color='#27AE60', linewidth=2, markersize=3)\nax_c.set_xlabel('Time (h)', fontsize=10, fontweight='bold')\nax_c.set_ylabel('Signal', fontsize=10, fontweight='bold')\nax_c.set_title('Temporal Control', fontsize=10, fontweight='bold')\nax_c.grid(alpha=0.3)\nax_c.text(-0.25, 1.1, 'C', transform=ax_c.transAxes,\n         fontsize=16, fontweight='bold', va='top')\n\nplt.suptitle('Dominant Layout: Main Result + Supporting Evidence',\n            fontsize=14, fontweight='bold', y=0.98)\n\nplt.savefig('dominant_panel_layout.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\nCode Example (R) - Dominant Layout:\nlibrary(ggplot2)\nlibrary(patchwork)\n\nset.seed(42)\n\n# Panel A: Main result (large)\ndata_main &lt;- data.frame(\n  dose = rnorm(200, 0, 1),\n  response = 2.5 * rnorm(200, 0, 1) + rnorm(200, 0, 1.5)\n)\n\np_main &lt;- ggplot(data_main, aes(x = dose, y = response)) +\n  geom_point(size = 3, color = '#3498DB', alpha = 0.6) +\n  geom_smooth(method = 'lm', se = TRUE, color = 'red', linetype = 'dashed', size = 1.5) +\n  labs(x = 'Treatment Dose (μM)', y = 'Cell Response (AU)',\n       title = 'Main Result: Dose-Response Relationship') +\n  theme_classic(base_size = 12) +\n  theme(\n    plot.title = element_text(face = 'bold', size = 13, hjust = 0.5),\n    axis.title = element_text(face = 'bold', size = 12),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Panel B: Supporting\ndata_b &lt;- data.frame(\n  category = factor(c('Control', 'Treated'), levels = c('Control', 'Treated')),\n  value = c(25, 35),\n  error = c(3, 4)\n)\n\np_b &lt;- ggplot(data_b, aes(x = category, y = value, fill = category)) +\n  geom_bar(stat = 'identity', color = 'black', size = 1, width = 0.5) +\n  geom_errorbar(aes(ymin = value - error, ymax = value + error),\n               width = 0.2, size = 1) +\n  scale_fill_manual(values = c('Control' = '#7F8C8D', 'Treated' = '#E74C3C')) +\n  labs(y = 'Viability (%)', title = 'Endpoint Viability') +\n  ylim(0, 50) +\n  theme_classic(base_size = 10) +\n  theme(\n    plot.title = element_text(face = 'bold', size = 10, hjust = 0.5),\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(face = 'bold', size = 10),\n    legend.position = 'none',\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Panel C: Supporting\ndata_c &lt;- data.frame(\n  time = seq(0, 24, length.out = 50),\n  signal = 100 + 20*sin(2*pi*seq(0, 24, length.out = 50)/24) + rnorm(50, 0, 3)\n)\n\np_c &lt;- ggplot(data_c, aes(x = time, y = signal)) +\n  geom_line(color = '#27AE60', size = 1.2) +\n  geom_point(color = '#27AE60', size = 2) +\n  labs(x = 'Time (h)', y = 'Signal', title = 'Temporal Control') +\n  theme_classic(base_size = 10) +\n  theme(\n    plot.title = element_text(face = 'bold', size = 10, hjust = 0.5),\n    axis.title = element_text(face = 'bold', size = 10),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Combine with dominant layout\nlayout &lt;- \"\nAAB\nAAC\n\"\n\ncombined &lt;- p_main + p_b + p_c +\n  plot_layout(design = layout) +\n  plot_annotation(\n    title = 'Dominant Layout: Main Result + Supporting Evidence',\n    tag_levels = 'A',\n    theme = theme(\n      plot.title = element_text(face = 'bold', size = 14, hjust = 0.5),\n      plot.tag = element_text(size = 18, face = 'bold')\n    )\n  )\n\nggsave('dominant_panel_layout.png', combined, width = 14, height = 8,\n       dpi = 300, bg = 'white')\n\n\n\nLayout Strategy 3: Sequential/Narrative Flow\nWhen to use: Showing a process, temporal sequence, or methodological pipeline\nStructure: Left-to-right or top-to-bottom progression\nTime 0 → Time 1 → Time 2 → Time 3\n  OR\nStep 1 ↓\nStep 2 ↓\nStep 3 ↓\nStep 4 ↓\nVisual cues for flow: - Arrows between panels - Progressive color intensity - Consistent aspect ratio (smooth scanning)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#aspect-ratios-and-panel-sizing",
    "href": "Chapter 5.html#aspect-ratios-and-panel-sizing",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "5.3 Aspect Ratios and Panel Sizing",
    "text": "5.3 Aspect Ratios and Panel Sizing\n\nThe Golden Ratio and Practical Aspect Ratios\nAspect ratio = Width / Height\nDifferent ratios serve different purposes and affect perception:\nCommon aspect ratios in scientific figures:\n1:1 (Square)\n- Use for: Heatmaps, correlation matrices, symmetric data\n- Perception: Balanced, no directional bias\n- Example: 6×6 inches\n\n4:3 (Standard)\n- Use for: General purpose, presentations\n- Perception: Slightly wider, comfortable viewing\n- Example: 8×6 inches\n\n16:9 (Widescreen)\n- Use for: Time series, horizontal comparisons\n- Perception: Emphasizes horizontal progression\n- Example: 10×5.625 inches\n\n3:2 (Classic photography)\n- Use for: Balanced figures, portraits\n- Perception: Natural, versatile\n- Example: 9×6 inches\n\nGolden ratio (~1.618:1)\n- Use for: Aesthetically pleasing single panels\n- Perception: Harmonious, professional\n- Example: 9.7×6 inches\n\n\n\nMatching Aspect Ratio to Data Structure\nThe Principle: Aspect ratio should emphasize data relationships\nHorizontal (Wide) Ratios:\n✓ BEST for:\n- Time series (time flows left-to-right)\n- Sequential processes\n- Many categories on x-axis\n- Comparisons across groups\n\nExample: 16:9 or 2:1\nVertical (Tall) Ratios:\n✓ BEST for:\n- Hierarchical trees/dendrograms\n- Stacked plots (multiple time series)\n- Rank-ordered lists\n- Vertical processes\n\nExample: 1:2 or 9:16\nSquare Ratios:\n✓ BEST for:\n- Symmetric relationships (correlation matrices)\n- Spatial data without directional bias\n- Heatmaps with equal dimensions\n- Network diagrams\n\nExample: 1:1\n\nCode Example (Python) - Aspect Ratio Effects:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Generate time series data\ntime = np.linspace(0, 24, 100)\nsignal = 100 + 20*np.sin(2*np.pi*time/24) + np.random.randn(100)*3\n\nfig, axes = plt.subplots(3, 1, figsize=(12, 12))\n\n# Aspect ratio 1: Too tall (vertical bias)\nax1 = axes[0]\nax1.plot(time, signal, 'o-', color='#3498DB', linewidth=2, markersize=3)\nax1.set_xlabel('Time (hours)', fontsize=10, fontweight='bold')\nax1.set_ylabel('Response', fontsize=10, fontweight='bold')\nax1.set_title('❌ TOO TALL (1:3 aspect)\\nEmphasizes vertical, hard to see temporal pattern',\n             fontsize=11, fontweight='bold', color='red')\nax1.set_aspect('auto')\nax1.grid(alpha=0.3)\n\n# Aspect ratio 2: Good (horizontal emphasis)\nax2 = axes[1]\nax2.plot(time, signal, 'o-', color='#27AE60', linewidth=2, markersize=3)\nax2.set_xlabel('Time (hours)', fontsize=10, fontweight='bold')\nax2.set_ylabel('Response', fontsize=10, fontweight='bold')\nax2.set_title('✓ GOOD (3:1 aspect)\\nEmphasizes horizontal flow, clear temporal pattern',\n             fontsize=11, fontweight='bold', color='green')\nax2.set_aspect('auto')\nax2.grid(alpha=0.3)\n\n# For comparison: Make ax2 appear wider by adjusting position\npos = ax2.get_position()\nax2.set_position([pos.x0, pos.y0, pos.width, pos.height*0.5])\n\n# Aspect ratio 3: Square (no directional emphasis)\nax3 = axes[2]\nax3.plot(time, signal, 'o-', color='#E67E22', linewidth=2, markersize=3)\nax3.set_xlabel('Time (hours)', fontsize=10, fontweight='bold')\nax3.set_ylabel('Response', fontsize=10, fontweight='bold')\nax3.set_title('⚠ SQUARE (1:1 aspect)\\nNo directional bias, but less ideal for time series',\n             fontsize=11, fontweight='bold', color='orange')\nax3.set_aspect('auto')\nax3.grid(alpha=0.3)\n\nplt.suptitle('Aspect Ratio Impact on Time Series Perception',\n            fontsize=14, fontweight='bold', y=0.98)\n\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.savefig('aspect_ratio_effects.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Aspect ratio affects data perception\")\nprint(\"✓ Match ratio to data structure (wide for time, square for symmetric)\")\n\n\n\nPanel Size Consistency Rules\nWithin a single figure:\n✓ CONSISTENT sizes when:\n- Comparing similar data types\n- All panels equally important\n- Direct visual comparison needed\n\n✓ VARIABLE sizes when:\n- Main result + supporting evidence\n- Different data types (image vs. plot)\n- Hierarchical importance\nAcross figures in manuscript:\n✓ Keep consistent:\n- Axis label font sizes\n- Marker sizes\n- Line widths\n- Color schemes\n\n✓ Can vary:\n- Overall figure dimensions (based on content)\n- Number of panels\n- Layout structure",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#white-space-the-unsung-hero",
    "href": "Chapter 5.html#white-space-the-unsung-hero",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "5.4 White Space: The Unsung Hero",
    "text": "5.4 White Space: The Unsung Hero\n\nThe Power of Negative Space\nWhite space (or negative space) is NOT wasted space—it’s functional design element that:\n\nSeparates groups (visual breathing room)\nDirects attention (eyes rest on dense areas)\nReduces cognitive load (prevents overwhelming)\nSignals professionalism (crowded = amateur)\n\n\n\n\nThe Density Principle\nRule of thumb: 40-60% white space in scientific figures\nToo dense (&lt;30% white space):\n→ Overwhelming, cluttered\n→ Hard to identify key elements\n→ Looks amateur\n\nToo sparse (&gt;70% white space):\n→ Inefficient use of space\n→ May appear incomplete\n→ Poor for publications with page limits\n\nOptimal (40-60%):\n→ Clear visual hierarchy\n→ Easy to scan\n→ Professional appearance\n\nCode Example (Python) - White Space Management:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Sample data\ncategories = ['Group A', 'Group B', 'Group C', 'Group D']\nvalues = [25, 32, 28, 35]\nerrors = [3, 4, 3.5, 4.2]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# BAD: Too cramped (insufficient white space)\nax1 = axes[0]\nbars = ax1.bar(categories, values, width=0.95, color='#3498DB',  # Width = 0.95 (very wide)\n              edgecolor='black', linewidth=1.5)\nax1.errorbar(categories, values, yerr=errors, fmt='none',\n            ecolor='black', capsize=8, linewidth=2)\nax1.set_ylabel('Response (AU)', fontsize=11, fontweight='bold')\nax1.set_title('❌ BAD: Insufficient White Space\\n(Cramped, hard to distinguish)',\n             fontsize=12, fontweight='bold', color='red')\nax1.set_ylim(0, 45)\nax1.grid(axis='y', alpha=0.3)\n# Add cluttered annotations\nfor i, (bar, val) in enumerate(zip(bars, values)):\n    ax1.text(i, val + errors[i] + 1, f'{val}±{errors[i]:.1f}',\n            ha='center', fontsize=8)\n# Remove spines\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# GOOD: Appropriate white space\nax2 = axes[1]\nbars = ax2.bar(categories, values, width=0.6, color='#27AE60',  # Width = 0.6 (breathing room)\n              edgecolor='black', linewidth=1.5)\nax2.errorbar(categories, values, yerr=errors, fmt='none',\n            ecolor='black', capsize=8, linewidth=2)\nax2.set_ylabel('Response (AU)', fontsize=11, fontweight='bold')\nax2.set_title('✓ GOOD: Appropriate White Space\\n(Clear, easy to read)',\n             fontsize=12, fontweight='bold', color='green')\nax2.set_ylim(0, 45)\nax2.grid(axis='y', alpha=0.3)\n# Spaced annotations\nfor i, (bar, val) in enumerate(zip(bars, values)):\n    ax2.text(i, 42, f'n=15', ha='center', fontsize=9, style='italic')\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\n\nplt.tight_layout()\nplt.savefig('white_space_importance.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\n\n\n\nMargin and Padding Guidelines\nStandard spacing hierarchy:\nBetween figure and edge (outer margin):\n- Minimum: 0.5 inches (1.27 cm)\n- Recommended: 0.75-1 inch (prevents cropping)\n\nBetween panels (internal spacing):\n- Related panels: 0.25-0.5 inches\n- Separate groups: 0.75-1 inch\n\nBetween elements within panel:\n- Axis to tick labels: ~0.1 inches\n- Tick labels to axis label: ~0.15 inches\n- Title to plot area: ~0.2 inches\nIn code (Python):\n# Set spacing explicitly\nplt.tight_layout(pad=1.5,      # Outer padding\n                h_pad=2.0,     # Vertical spacing between panels\n                w_pad=2.0)     # Horizontal spacing between panels\n\n# Or manually with subplots_adjust\nplt.subplots_adjust(left=0.1, right=0.95,   # Outer margins\n                   top=0.92, bottom=0.08,\n                   hspace=0.3, wspace=0.3)  # Internal spacing",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#multi-figure-consistency-across-a-manuscript",
    "href": "Chapter 5.html#multi-figure-consistency-across-a-manuscript",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "5.5 Multi-Figure Consistency Across a Manuscript",
    "text": "5.5 Multi-Figure Consistency Across a Manuscript\n\nThe Style Guide Approach\nCreate a figure style guide at the START of manuscript preparation:\nDocument specifications:\n├─ Font family: Arial\n├─ Font sizes:\n│   ├─ Panel labels: 14pt bold\n│   ├─ Titles: 12pt bold\n│   ├─ Axis labels: 11pt bold\n│   ├─ Tick labels: 9pt regular\n│   └─ Annotations: 9pt regular/italic\n├─ Colors:\n│   ├─ Control: #7F8C8D (gray)\n│   ├─ Treatment A: #3498DB (blue)\n│   ├─ Treatment B: #E74C3C (red)\n│   └─ Significant: #E67E22 (orange highlights)\n├─ Line widths:\n│   ├─ Data lines: 2.5pt\n│   ├─ Axis lines: 1.5pt\n│   └─ Grid lines: 0.5pt, alpha=0.3\n├─ Marker sizes:\n│   ├─ Scatter points: 50-80 (matplotlib units)\n│   └─ Line markers: 5-6\n└─ Aspect ratios:\n    ├─ Time series: 16:9 or 3:1\n    ├─ Comparisons: 4:3 or 3:2\n    └─ Heatmaps: 1:1 or data-dependent\n\n\n\nTemplate System Implementation\nPython template:\nimport matplotlib.pyplot as plt\n\n# Define once, use everywhere\nFIGURE_STYLE = {\n    'font.family': 'sans-serif',\n    'font.sans-serif': ['Arial', 'Helvetica'],\n    'font.size': 9,\n    'axes.labelsize': 11,\n    'axes.titlesize': 12,\n    'axes.linewidth': 1.5,\n    'xtick.labelsize': 9,\n    'ytick.labelsize': 9,\n    'legend.fontsize': 9,\n    'figure.titlesize': 14,\n    'lines.linewidth': 2.5,\n    'lines.markersize': 6,\n    'grid.alpha': 0.3,\n    'grid.linewidth': 0.5\n}\n\n# Colors (semantic consistency)\nCOLORS = {\n    'control': '#7F8C8D',\n    'treatment_a': '#3498DB',\n    'treatment_b': '#E74C3C',\n    'significant': '#E67E22'\n}\n\n# Apply globally\nplt.rcParams.update(FIGURE_STYLE)\n\n# Function to set consistent panel formatting\ndef format_panel(ax, xlabel, ylabel, title, panel_label):\n    \"\"\"Apply consistent formatting to all panels\"\"\"\n    ax.set_xlabel(xlabel, fontweight='bold')\n    ax.set_ylabel(ylabel, fontweight='bold')\n    ax.set_title(title, fontweight='bold')\n    ax.text(-0.15, 1.05, panel_label, transform=ax.transAxes,\n           fontsize=16, fontweight='bold', va='top')\n    ax.grid(alpha=0.3)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    return ax\n\n# Example usage\nfig, ax = plt.subplots(figsize=(7, 5))\nax.plot([1, 2, 3], [1, 4, 2], color=COLORS['treatment_a'])\nformat_panel(ax, 'Time (s)', 'Response (AU)', 'Example Plot', 'A')\nplt.savefig('consistent_figure.png', dpi=300, bbox_inches='tight')\nplt.close()\nR template:\nlibrary(ggplot2)\n\n# Define theme once\nmanuscript_theme &lt;- theme_classic(base_size = 11, base_family = 'Arial') +\n  theme(\n    axis.title = element_text(face = 'bold', size = 11),\n    plot.title = element_text(face = 'bold', size = 12, hjust = 0.5),\n    axis.text = element_text(size = 9),\n    legend.text = element_text(size = 9),\n    legend.title = element_text(face = 'bold', size = 9),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3),\n    plot.tag = element_text(size = 16, face = 'bold')\n  )\n\n# Colors (semantic consistency)\nCOLORS &lt;- list(\n  control = '#7F8C8D',\n  treatment_a = '#3498DB',\n  treatment_b = '#E74C3C',\n  significant = '#E67E22'\n)\n\n# Example usage\np &lt;- ggplot(data, aes(x = time, y = response)) +\n  geom_line(color = COLORS$treatment_a, size = 1.5) +\n  labs(x = 'Time (s)', y = 'Response (AU)', title = 'Example Plot', tag = 'A') +\n  manuscript_theme\n\nggsave('consistent_figure.png', p, width = 7, height = 5, dpi = 300)\n\n\n\nCross-Figure Checklist\nBefore submitting manuscript, verify:\n\nAll figures use same font family\nFont sizes consistent (panel labels, axes, etc.)\nColor schemes consistent (Control always gray, Drug A always blue, etc.)\nLine widths consistent across figure types\nMarker sizes consistent\nPanel label format consistent (A, B, C… in same position)\nAspect ratios appropriate for each data type\nWhite space balanced (not too cramped or too sparse)\nGrid styles consistent (if used)\nError bar styles consistent (SEM vs SD documented)\nStatistical annotations consistent (, ,  system)\nAll figures export at same DPI (300 minimum)\nFile formats consistent (TIFF/PNG for publication)\n\n\n\n\nVersion Control for Figures\nBest practices:\nFile naming convention:\nfigure1_version1_20250107.png\nfigure1_version2_20250115.png (after revisions)\nfigure1_final_20250120.png\n\nTrack changes:\n- Keep log of what changed between versions\n- Save original high-resolution files separately\n- Document software versions used\n\nSummary of Chapter 5 so far:\n✓ Gestalt principles: Proximity, similarity, closure guide perception ✓ Grid systems: Structured layouts (equal weight, dominant, sequential) ✓ Aspect ratios: Match to data (wide for time, square for symmetric) ✓ White space: 40-60% optimal, prevents crowding ✓ Consistency: Style guide + templates ensure manuscript coherence\n\nEnd of Chapter 5: Layout, Composition & Figure Assembly\nFinal Figure Assembly Workflow:\n1. Define style guide (fonts, colors, sizes)\n2. Create templates (Python rcParams / R themes)\n3. Generate individual panels with consistent formatting\n4. Assemble using grid system (appropriate layout strategy)\n5. Balance white space (check density)\n6. Add panel labels (A, B, C...) consistently\n7. Verify aspect ratios match data types\n8. Cross-check against manuscript figures for consistency\n9. Export at publication quality (300 DPI, TIFF/PNG)\n10. Review entire figure set side-by-side before submission\n\n\n\n5.6 Irregular Shapes in Regular Frames\nPrinciple: Irregular plots (network diagrams, UMAPs, dendrograms) should be contained in regular rectangular frames for easy comparison.\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport numpy as np\nfrom matplotlib.patches import Rectangle\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n# Panel A: BAD - Irregular network without frame\nax1 = axes[0, 0]\nG1 = nx.random_geometric_graph(20, 0.3)\npos1 = nx.spring_layout(G1)\nnx.draw_networkx(G1, pos=pos1, ax=ax1, node_color='#3498DB',\n                node_size=300, with_labels=False, edge_color='gray')\nax1.set_title('❌ BAD: No Frame\\n(Hard to compare size/scale)',\n              fontsize=12, fontweight='bold', color='red')\nax1.axis('off')\n\n# Panel B: GOOD - Network in regular frame\nax2 = axes[0, 1]\nG2 = nx.random_geometric_graph(20, 0.3)\npos2 = nx.spring_layout(G2)\nnx.draw_networkx(G2, pos=pos2, ax=ax2, node_color='#27AE60',\n                node_size=300, with_labels=False, edge_color='gray')\n\n# Add visible frame\nax2.set_xlim(-1.2, 1.2)\nax2.set_ylim(-1.2, 1.2)\nfor spine in ax2.spines.values():\n    spine.set_visible(True)\n    spine.set_linewidth(2)\n    spine.set_edgecolor('black')\n\nax2.set_title('✓ GOOD: Regular Frame\\n(Easy to compare)',\n              fontsize=12, fontweight='bold', color='green')\nax2.set_aspect('equal')\n\n# Panel C: Multiple irregular shapes without frames (confusing)\nax3 = axes[1, 0]\nax3.axis('off')\nax3.set_title('❌ BAD: Multiple Irregular Shapes\\n(No alignment reference)',\n              fontsize=12, fontweight='bold', color='red')\n\n# Draw two networks at different positions/sizes\nG3a = nx.random_geometric_graph(15, 0.35)\npos3a = nx.spring_layout(G3a, scale=0.3, center=(0.25, 0.7))\nnx.draw_networkx(G3a, pos=pos3a, ax=ax3, node_color='#3498DB',\n                node_size=200, with_labels=False, edge_color='gray')\n\nG3b = nx.random_geometric_graph(18, 0.3)\npos3b = nx.spring_layout(G3b, scale=0.4, center=(0.75, 0.3))\nnx.draw_networkx(G3b, pos=pos3b, ax=ax3, node_color='#E74C3C',\n                node_size=200, with_labels=False, edge_color='gray')\n\nax3.set_xlim(0, 1)\nax3.set_ylim(0, 1)\n\n# Panel D: Same networks in regular frames (clear comparison)\nax4 = axes[1, 1]\nax4.axis('off')\nax4.set_title('✓ GOOD: Regular Frames Enable Comparison',\n              fontsize=12, fontweight='bold', color='green')\n\n# Create two subplot axes within ax4\nfrom matplotlib.gridspec import GridSpec\ninner_gs = GridSpec(1, 2, figure=fig,\n                   left=0.52, right=0.98, bottom=0.05, top=0.45,\n                   wspace=0.1)\n\nax4a = fig.add_subplot(inner_gs[0])\nax4b = fig.add_subplot(inner_gs[1])\n\n# Network A in frame\nG4a = nx.random_geometric_graph(15, 0.35)\npos4a = nx.spring_layout(G4a)\nnx.draw_networkx(G4a, pos=pos4a, ax=ax4a, node_color='#3498DB',\n                node_size=200, with_labels=False, edge_color='gray')\nax4a.set_xlim(-1.2, 1.2)\nax4a.set_ylim(-1.2, 1.2)\nax4a.set_aspect('equal')\nfor spine in ax4a.spines.values():\n    spine.set_visible(True)\n    spine.set_linewidth(2)\n    spine.set_edgecolor('black')\nax4a.set_title('Network A', fontsize=10, fontweight='bold')\n\n# Network B in frame (same size frame!)\nG4b = nx.random_geometric_graph(18, 0.3)\npos4b = nx.spring_layout(G4b)\nnx.draw_networkx(G4b, pos=pos4b, ax=ax4b, node_color='#E74C3C',\n                node_size=200, with_labels=False, edge_color='gray')\nax4b.set_xlim(-1.2, 1.2)  # SAME LIMITS\nax4b.set_ylim(-1.2, 1.2)  # SAME LIMITS\nax4b.set_aspect('equal')\nfor spine in ax4b.spines.values():\n    spine.set_visible(True)\n    spine.set_linewidth(2)\n    spine.set_edgecolor('black')\nax4b.set_title('Network B', fontsize=10, fontweight='bold')\n\n# Add panel labels\nfor i, ax in enumerate([ax1, ax2, ax3]):\n    ax.text(-0.1, 1.05, chr(65+i), transform=ax.transAxes,\n           fontsize=16, fontweight='bold', va='top')\n\nax4.text(-0.1, 1.05, 'D', transform=ax4.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\nplt.savefig('irregular_shapes_regular_frames.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\n\n\n\n5.7 Layout Logic: Reading Direction and Narrative Flow\nPrinciple: Panel arrangement should follow logical narrative progression.\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\nfig = plt.figure(figsize=(16, 10))\n\n# Example: Experimental workflow visualization\n# Logical flow: Sample → Process → Analysis → Result\n\n# BAD layout: Random arrangement\nax_bad = fig.add_subplot(2, 2, 1)\nax_bad.text(0.5, 0.5, '❌ BAD LAYOUT\\n\\nRandom order:\\nC → A → D → B\\n\\nNo logical flow!',\n           ha='center', va='center', fontsize=12, fontweight='bold',\n           bbox=dict(boxstyle='round', facecolor='#FFCCCC', alpha=0.8))\nax_bad.axis('off')\nax_bad.set_title('Random Panel Arrangement', fontsize=13, fontweight='bold', color='red')\n\n# GOOD layout: Left-to-right, top-to-bottom flow\nax_good = fig.add_subplot(2, 2, 2)\nax_good.text(0.5, 0.5, '✓ GOOD LAYOUT\\n\\nLogical order:\\nA → B → C → D\\n\\nFollows workflow!',\n            ha='center', va='center', fontsize=12, fontweight='bold',\n            bbox=dict(boxstyle='round', facecolor='#CCFFCC', alpha=0.8))\nax_good.axis('off')\nax_good.set_title('Logical Panel Arrangement', fontsize=13, fontweight='bold', color='green')\n\n# Detailed example: Multi-step experiment\ngs = fig.add_gridspec(2, 4, left=0.05, right=0.95, bottom=0.05, top=0.45,\n                     hspace=0.3, wspace=0.3)\n\n# Panel A: Sample collection\nax_a = fig.add_subplot(gs[0, 0])\nax_a.bar(['Ctrl', 'Trt'], [10, 10], color=['#7F8C8D', '#3498DB'],\n        edgecolor='black', linewidth=2)\nax_a.set_ylabel('Samples', fontsize=10, fontweight='bold')\nax_a.set_title('A. Sample Collection', fontsize=11, fontweight='bold')\nax_a.text(0.5, 0.95, 'STEP 1', transform=ax_a.transAxes,\n         ha='center', va='top', fontsize=9, fontweight='bold',\n         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n\n# Arrow to next step\nax_arrow1 = fig.add_subplot(gs[0, :2])\nax_arrow1.annotate('', xy=(0.75, 0.5), xytext=(0.25, 0.5),\n                  arrowprops=dict(arrowstyle='-&gt;', lw=3, color='black'),\n                  xycoords='axes fraction')\nax_arrow1.axis('off')\n\n# Panel B: Processing\nax_b = fig.add_subplot(gs[0, 1])\n# Simulate gel/blot\ngel_data = np.random.rand(10, 4)\nax_b.imshow(gel_data, cmap='gray_r', aspect='auto')\nax_b.set_title('B. Western Blot', fontsize=11, fontweight='bold')\nax_b.axis('off')\nax_b.text(0.5, 0.95, 'STEP 2', transform=ax_b.transAxes,\n         ha='center', va='top', fontsize=9, fontweight='bold',\n         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n\n# Panel C: Quantification\nax_c = fig.add_subplot(gs[0, 2])\nvalues = [100, 145]\nax_c.bar(['Ctrl', 'Trt'], values, color=['#7F8C8D', '#3498DB'],\n        edgecolor='black', linewidth=2)\nax_c.set_ylabel('Protein Level (%)', fontsize=10, fontweight='bold')\nax_c.set_title('C. Quantification', fontsize=11, fontweight='bold')\nax_c.axhline(100, color='red', linestyle='--', linewidth=1, alpha=0.5)\nax_c.text(0.5, 0.95, 'STEP 3', transform=ax_c.transAxes,\n         ha='center', va='top', fontsize=9, fontweight='bold',\n         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n\n# Panel D: Statistical analysis\nax_d = fig.add_subplot(gs[0, 3])\n# Scatter with error bars\nx_data = [1, 2]\ny_data = [100, 145]\nerrors = [8, 12]\nax_d.errorbar(x_data, y_data, yerr=errors, fmt='o', markersize=12,\n             capsize=10, linewidth=2, color='black')\nax_d.set_xlim(0.5, 2.5)\nax_d.set_xticks([1, 2])\nax_d.set_xticklabels(['Ctrl', 'Trt'])\nax_d.set_ylabel('Protein Level (%)', fontsize=10, fontweight='bold')\nax_d.set_title('D. Statistics (n=3)', fontsize=11, fontweight='bold')\nax_d.plot([1, 2], [155, 155], 'k-', linewidth=2)\nax_d.text(1.5, 158, '**', ha='center', fontsize=14, fontweight='bold')\nax_d.text(0.5, 0.95, 'STEP 4', transform=ax_d.transAxes,\n         ha='center', va='top', fontsize=9, fontweight='bold',\n         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n\n# Add flow arrows between all panels in bottom row\nfor i in range(3):\n    ax_flow = fig.add_subplot(gs[0, :])\n    ax_flow.annotate('', xy=((i+1.5)/4, 0.5), xytext=((i+0.5)/4, 0.5),\n                    arrowprops=dict(arrowstyle='-&gt;', lw=2.5, color='blue'),\n                    xycoords='axes fraction')\n    ax_flow.axis('off')\n\nplt.savefig('layout_logic_narrative_flow.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\n\n\n\n5.8 Panel Size Considerations: The A4 Paper Test\nPractical tip: Use physical A4 paper to test figure size on screen.\n# Guideline for sizing figures\n\n\"\"\"\nFIGURE SIZE GUIDELINES:\n\n1. SINGLE COLUMN (journal dependent):\n   - Nature/Science: 89 mm (3.5 inches)\n   - Cell: 85 mm (3.35 inches)\n   - PLOS: 83 mm (3.27 inches)\n\n   → In code: figsize=(3.5, 2.5) for 3.5\" × 2.5\"\n\n2. DOUBLE COLUMN:\n   - Nature/Science: 183 mm (7.2 inches)\n   - Cell: 178 mm (7 inches)\n   - PLOS: 173 mm (6.8 inches)\n\n   → In code: figsize=(7, 5) for 7\" × 5\"\n\n3. A4 PAPER TEST:\n   - A4 = 210 mm × 297 mm (8.27\" × 11.69\")\n   - Print your figure at intended size\n   - Place on screen next to code\n   - Check:\n     * Can you read smallest text?\n     * Are symbols distinguishable?\n     * Is white space appropriate?\n\"\"\"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Example: Create figure at publication size\nfig, axes = plt.subplots(2, 2, figsize=(7, 6))  # Double column width\n\n# ... add your plots ...\n\n# Before saving, test print:\n# 1. Save as PDF: plt.savefig('test_print.pdf', dpi=300)\n# 2. Print at 100% scale (NO \"fit to page\")\n# 3. Place printed version on screen\n# 4. Compare to on-screen version\n\n# Check minimum font sizes\nmin_fontsize = 6  # points (minimum readable after reduction)\n\nfor ax in axes.flat:\n    ax.set_xlabel('X Label', fontsize=11)  # Will reduce to ~8pt\n    ax.set_ylabel('Y Label', fontsize=11)\n    ax.tick_params(labelsize=9)  # Will reduce to ~6.5pt\n    ax.set_title('Title', fontsize=12)  # Will reduce to ~8.5pt\n\n# Journal may reduce figure by 50-75%\n# So design at final size, not current screen size!\n\nplt.tight_layout()\nplt.savefig('size_test_figure.png', dpi=300, bbox_inches='tight')\nplt.close()",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#part-i-pre-design-decision-framework",
    "href": "Chapter 5.html#part-i-pre-design-decision-framework",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "Part I: Pre-Design Decision Framework",
    "text": "Part I: Pre-Design Decision Framework\n\nStep 1: Define Your Message\nAsk yourself:\n1. What is the ONE key finding this figure must communicate?\n2. Who is the audience? (Specialists vs. general scientists)\n3. What comparison is most important? (Groups, time, relationships)\n4. What level of detail is required? (Overview vs. granular)\n\n→ Answer determines: Plot type, layout complexity, detail level\n\n\nStep 2: Assess Your Data Structure\nData characteristics checklist:\n Continuous or categorical variables?\n How many variables? (1, 2, 3+)\n Sample size? (n &lt; 20, 20-100, &gt;100)\n Distribution shape? (Normal, skewed, bimodal)\n Temporal component? (Time series, sequential)\n Hierarchical or grouped structure?\n Comparisons needed? (Between groups, over time, correlations)\n\n→ Determines: Plot type selection (see Part II)\n\n\nStep 3: Choose Plot Type\nSee detailed decision tree in Part II\n\n\nStep 4: Establish Style Specifications\nBefore creating ANY figures, document:\n Font family (Arial/Helvetica recommended)\n Font size hierarchy (panel labels &gt; titles &gt; axis labels &gt; ticks)\n Color scheme (3 colors maximum, semantic consistency)\n Line widths (data: 2-3pt, axes: 1-1.5pt, grid: 0.5pt)\n Marker sizes (scatter: 50-80, line markers: 5-6)\n Error bar type (SEM vs SD - must be consistent)\n\n→ Create template file to enforce consistency",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#part-ii-plot-type-selection-matrix",
    "href": "Chapter 5.html#part-ii-plot-type-selection-matrix",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "Part II: Plot Type Selection Matrix",
    "text": "Part II: Plot Type Selection Matrix\n\nFor Comparing Groups\n\n\n\n\n\n\n\n\nScenario\nBest Plot\nKey Considerations\n\n\n\n\nFew groups (&lt;5), one variable\nBar chart\nStart at zero, show error bars, include n\n\n\nFew groups, show distribution\nBox plot or Violin plot\nBox = quartiles, Violin = density shape\n\n\nMany groups (&gt;5)\nSmall multiples or Heatmap\nAvoid single cluttered panel\n\n\nBimodal/complex distributions\nViolin plot\nBox plot will hide multiple peaks\n\n\n\n\n\nFor Showing Distributions\n\n\n\n\n\n\n\n\nScenario\nBest Plot\nKey Considerations\n\n\n\n\nSingle distribution\nHistogram or Density plot\nChoose bin width carefully (Sturges’, FD)\n\n\nCompare 2-3 distributions\nOverlapping density plots\nTransparency helps\n\n\nCompare many distributions\nRidgeline plot or Box plot grid\nMaintain consistent scales\n\n\n\n\n\nFor Relationships\n\n\n\n\n\n\n\n\nScenario\nBest Plot\nKey Considerations\n\n\n\n\nTwo continuous variables\nScatter plot\nAlways plot raw data (Anscombe warning!)\n\n\nDense scatter (&gt;1000 points)\nHexbin or 2D density\nAvoid point occlusion\n\n\nCorrelation matrix\nHeatmap with hierarchical clustering\nSymmetric diverging colormap\n\n\n\n\n\nFor Temporal Data\n\n\n\n\n\n\n\n\nScenario\nBest Plot\nKey Considerations\n\n\n\n\nSingle time series\nLine graph\nLines imply continuity\n\n\nFew time series (2-4)\nLine graph, different colors\nAdd legend or direct labels\n\n\nMany time series (&gt;5)\nSmall multiples OR Highlight one + gray others\nAvoid spaghetti plot\n\n\nTime series with error\nShaded error band (SEM/SD)\nCleaner than error bars at every point\n\n\n\n\n\nWhat to AVOID\n\n\n\n\n\n\n\n\nNever Use\nWhy\nUse Instead\n\n\n\n\nPie charts\nAngles harder to compare than lengths\nBar chart (horizontal if long labels)\n\n\n3D effects on 2D data\nPerspective distortion, occlusion\nStandard 2D with color/size for 3rd dimension\n\n\nDual y-axes (usually)\nEasily manipulated to mislead\nSeparate panels or normalize to same scale\n\n\nTruncated bar charts\nExaggerates small differences\nAlways start bars at zero",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#part-iii-color-decision-framework",
    "href": "Chapter 5.html#part-iii-color-decision-framework",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "Part III: Color Decision Framework",
    "text": "Part III: Color Decision Framework\n\nStep 1: Identify Data Type\nSequential (ordered, one direction):\n→ Use: Single-hue gradient (light → dark)\n→ Colormap: viridis, plasma, YlOrRd, Blues\n→ Example: Gene expression (0 to max)\n\nDiverging (ordered, two directions from center):\n→ Use: Two-hue gradient with neutral center\n→ Colormap: RdBu, PiYG, BrBG (ensure symmetric!)\n→ Example: Fold change (-∞ to +∞, center at 0)\n\nCategorical (unordered groups):\n→ Use: Distinct hues, equal saturation\n→ Colormap: Okabe-Ito palette, Set2, Dark2\n→ Example: Different cell types, treatment groups\n\n\nStep 2: Apply Semantic Color Logic\nControl/Baseline: Gray (#7F8C8D)\nExperimental conditions: Colors (distinct hues)\nSignificant results: Deeper saturation\nNon-significant: Lighter saturation or gray\n\nCRITICAL: Same group = same color across ALL figures\n\n\nStep 3: Accessibility Check\nMandatory checks before finalizing:\n Uses colorblind-safe palette (Okabe-Ito recommended)\n Redundant encoding applied (color + shape/line style)\n Tested with Color Oracle or Coblis simulator\n Works in grayscale (print test)\n Text contrast meets WCAG AA (4.5:1 minimum)\n\n\nStep 4: Special Cases\nAll values significant?\n→ Don't use binary deep/light colors\n→ Encode magnitude with continuous gradient\n\nMissing data (NA)?\n→ NEVER use a color from your gradient\n→ Use distinct color (gray with black border) OR pattern (crosshatch)\n\nCyclic data (time of day, angles)?\n→ Use cyclic colormap (twilight, hsv)\n→ Start and end colors must be similar",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#part-iv-typography-annotation-checklist",
    "href": "Chapter 5.html#part-iv-typography-annotation-checklist",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "Part IV: Typography & Annotation Checklist",
    "text": "Part IV: Typography & Annotation Checklist\n\nFont Specifications\nFont hierarchy (apply consistently):\nPanel labels:     14-16pt, bold, black\nTitles:           12-13pt, bold, black\nAxis labels:      11pt, bold, black  ← ALWAYS include units: \"Variable (unit)\"\nTick labels:      9pt, regular, dark gray (#333)\nLegend text:      9pt, regular, black\nAnnotations:      9-10pt, regular/italic, black or dark gray\n\nFont family: Sans-serif (Arial, Helvetica, Calibri)\n\n\nAxis Label Requirements\nFormat: \"Variable Name (units)\"\n\nExamples:\n✓ \"Temperature (°C)\"\n✓ \"Time (hours)\"\n✓ \"Expression Level (FPKM)\"\n✓ \"Fold Change (log₂)\"\n\n❌ NEVER:\n- \"Temperature\" (missing units)\n- \"Expression\" (ambiguous scale)\n- \"Time\" (seconds? hours? days?)\n\n\nStatistical Annotations\nStandard notation:\n*     p &lt; 0.05\n**    p &lt; 0.01\n***   p &lt; 0.001\nn.s.  p ≥ 0.05\n\nRequired in caption:\n- Statistical test used (e.g., \"two-way ANOVA with Tukey post-hoc\")\n- Exact p-values if critical (e.g., \"p = 0.003\")\n- Sample sizes (e.g., \"n = 15 per group\")\n\n\nCaption Structure\n[Figure #]. [One-sentence summary of main finding].\n(A) [Panel A description: what + how + n + stats].\n(B) [Panel B description: what + how + n + stats].\n[Error bar definition]. [Statistical methods]. [Abbreviations].\n\nExample:\n\"Figure 2. Treatment A reduces tumor volume in xenograft mice.\n(A) Tumor volume over time (n=8 mice per group, mean ± SEM,\ntwo-way ANOVA, **p&lt;0.01). (B) Survival curves (log-rank test,\n***p&lt;0.001). Error bars: SEM. * p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001.\"",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#part-v-layout-composition-checklist",
    "href": "Chapter 5.html#part-v-layout-composition-checklist",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "Part V: Layout & Composition Checklist",
    "text": "Part V: Layout & Composition Checklist\n\nPanel Arrangement\nEqual weight (all panels equally important):\n└─ Use: 2×2, 3×3, or uniform grid\n└─ Spacing: Equal margins between all panels\n\nDominant panel (one main + supporting):\n└─ Use: Large panel (60-70%) + small panels (15-20%)\n└─ Spacing: Main panel prominent, supporting clustered nearby\n\nSequential/narrative (process flow):\n└─ Use: Left-to-right or top-to-bottom progression\n└─ Spacing: Tight within sequence, clear breaks between stages\n\n\nAspect Ratio Selection\nData Type          → Recommended Aspect Ratio\nTime series        → 16:9 or 3:1 (wide)\nGroup comparisons  → 4:3 or 3:2 (standard)\nHeatmaps           → 1:1 or data-dependent (square/rectangular)\nHierarchical trees → 1:2 or 9:16 (tall)\nSpatial maps       → Match geographic proportions\n\n\nWhite Space Guidelines\nTarget: 40-60% white space\n\nSpacing hierarchy (smallest to largest):\n1. Within panel: 0.1-0.2 inches (axis to labels)\n2. Between related panels: 0.25-0.5 inches\n3. Between panel groups: 0.75-1 inch\n4. Figure outer margin: 0.75-1 inch\n\nBar chart specific:\n- Bar width : gap ratio ≈ 3:1\n- Leave breathing room between bars",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#part-vi-pre-submission-quality-control",
    "href": "Chapter 5.html#part-vi-pre-submission-quality-control",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "Part VI: Pre-Submission Quality Control",
    "text": "Part VI: Pre-Submission Quality Control\n\nTechnical Specifications\nResolution:\n Minimum 300 DPI for publication\n 600 DPI if images contain fine details (microscopy)\n\nFile formats:\n TIFF or PNG for final submission (lossless)\n Vector formats (PDF, EPS) for line graphs if allowed\n RGB color mode (unless journal requires CMYK)\n\nDimensions:\n Check journal specifications (often 3.5\" or 7\" column width)\n Export at intended print size (don't rely on scaling)\n\n\nCross-Figure Consistency Check\nVerify across ALL manuscript figures:\n Font family identical\n Font sizes consistent (panel labels, axes, ticks)\n Color schemes consistent (Control always gray, Drug A always blue, etc.)\n Line widths uniform\n Marker sizes uniform\n Panel label format consistent (A, B, C... placement)\n Error bar definition consistent (all SEM or all SD)\n Statistical notation consistent (*, **, ***)\n Grid styles consistent (if used)\n Legend positions logical\n\n\nAccessibility Verification\nFinal checks before submission:\n Colorblind-safe palette used (Okabe-Ito, ColorBrewer CVD-safe)\n Redundant encoding present (color + shape/line for critical distinctions)\n Tested with Color Oracle or Coblis\n Prints clearly in grayscale\n Text contrast sufficient (WCAG AA: 4.5:1)\n Font sizes readable when printed at target size\n No reliance on color alone for critical information\n\n\nEthical Compliance\nImage integrity (microscopy, gels, photos):\n No selective brightness/contrast adjustments\n All adjustments applied uniformly to all comparison images\n Linear adjustments only (no gamma correction)\n Original, unprocessed images available if requested\n All processing documented in Methods section\n\nColor scale integrity:\n Symmetric scales for diverging data (no manipulation)\n No truncated axes (unless explicitly justified)\n Colormap choices documented in caption\n Missing data handled appropriately (not hidden)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#part-vii-common-mistakes-quick-reference",
    "href": "Chapter 5.html#part-vii-common-mistakes-quick-reference",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "Part VII: Common Mistakes Quick Reference",
    "text": "Part VII: Common Mistakes Quick Reference\n\nTop 10 Errors to Avoid\n\n\n\n\n\n\n\n\nError\nWhy It’s Wrong\nCorrect Approach\n\n\n\n\n1. Truncated bar chart y-axis\nExaggerates small differences\nAlways start at zero for bar charts\n\n\n2. Using pie charts\nAngles harder to compare than lengths\nUse bar chart instead\n\n\n3. Missing units on axes\nReader can’t interpret scale\n“Variable (unit)” format required\n\n\n4. Inconsistent colors across figures\nConfuses readers, breaks semantic meaning\nDefine color scheme once, use everywhere\n\n\n5. No sample size reported\nCan’t assess reliability\nState n in caption or on figure\n\n\n6. Error bar type undefined\nSEM vs SD gives different interpretation\nAlways specify “Error bars: SEM” or “SD”\n\n\n7. Missing colorblind accessibility\nExcludes 8% of male readers\nUse Okabe-Ito palette + redundant encoding\n\n\n8. All-significant data with binary coloring\nLoses magnitude information\nUse continuous gradient for effect size\n\n\n9. Overlapping text labels\nIllegible, unprofessional\nUse adjustText (Python) or ggrepel (R)\n\n\n10. 3D effects on 2D data\nPerspective distortion, looks gimmicky\nUse standard 2D with color/size for 3rd variable",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#part-viii-software-specific-quick-commands",
    "href": "Chapter 5.html#part-viii-software-specific-quick-commands",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "Part VIII: Software-Specific Quick Commands",
    "text": "Part VIII: Software-Specific Quick Commands\n\nPython (Matplotlib) Essential Commands\nimport matplotlib.pyplot as plt\n\n# Global style setup (run once at start)\nplt.rcParams.update({\n    'font.family': 'sans-serif',\n    'font.sans-serif': ['Arial', 'Helvetica'],\n    'font.size': 9,\n    'axes.labelsize': 11,\n    'axes.titlesize': 12,\n    'lines.linewidth': 2.5,\n    'grid.alpha': 0.3\n})\n\n# Okabe-Ito colorblind-safe palette\nOKABE_ITO = {\n    'orange': '#E69F00',\n    'sky_blue': '#56B4E9',\n    'bluish_green': '#009E73',\n    'yellow': '#F0E442',\n    'blue': '#0072B2',\n    'vermilion': '#D55E00',\n    'reddish_purple': '#CC79A7',\n    'black': '#000000'\n}\n\n# Remove top and right spines (cleaner look)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n# Save at publication quality\nplt.savefig('figure.png', dpi=300, bbox_inches='tight', facecolor='white')\n\n\nR (ggplot2) Essential Commands\nlibrary(ggplot2)\n\n# Reusable theme\nmanuscript_theme &lt;- theme_classic(base_size = 11, base_family = 'Arial') +\n  theme(\n    axis.title = element_text(face = 'bold', size = 11),\n    plot.title = element_text(face = 'bold', size = 12, hjust = 0.5),\n    axis.text = element_text(size = 9),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3),\n    plot.tag = element_text(size = 16, face = 'bold')\n  )\n\n# Okabe-Ito palette\nOKABE_ITO &lt;- c(\n  orange = '#E69F00',\n  sky_blue = '#56B4E9',\n  bluish_green = '#009E73',\n  yellow = '#F0E442',\n  blue = '#0072B2',\n  vermilion = '#D55E00',\n  reddish_purple = '#CC79A7',\n  black = '#000000'\n)\n\n# Apply to plot\np &lt;- ggplot(...) +\n  geom_point(color = OKABE_ITO['sky_blue']) +\n  manuscript_theme\n\n# Save at publication quality\nggsave('figure.png', p, width = 7, height = 5, dpi = 300, bg = 'white')",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#part-ix-journal-specific-considerations",
    "href": "Chapter 5.html#part-ix-journal-specific-considerations",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "Part IX: Journal-Specific Considerations",
    "text": "Part IX: Journal-Specific Considerations\n\nNature Family\nRequirements:\n- Figures must be self-explanatory\n- Concise but complete captions\n- Define all abbreviations\n- 300 DPI minimum\n- RGB color mode\n- TIFF preferred for final submission\n\nCaption style:\n- Brief title sentence\n- Panel descriptions (a, b, c in lowercase)\n- Statistical methods in caption or Methods\n- Scale bars required for all images\n\n\nCell Family\nRequirements:\n- Similar to Nature\n- Emphasize reproducibility (n, replicates clearly stated)\n- Can use supplementary figures liberally\n- 300-600 DPI\n- Color figures encouraged (no extra charge)\n\nCaption style:\n- Related panels can share description\n- \"(A-C)\" notation for grouped panels\n- Error bar type must be specified\n\n\nPLOS Family\nRequirements:\n- Very detailed captions encouraged\n- Must be understandable without main text\n- Can include more methods detail in caption than Nature/Cell\n- 300 DPI\n- Figures published under CC-BY license (open access)\n\nCaption style:\n- More verbose acceptable\n- Extensive statistical details in caption\n- All abbreviations defined at first use",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#part-x-emergency-troubleshooting",
    "href": "Chapter 5.html#part-x-emergency-troubleshooting",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "Part X: Emergency Troubleshooting",
    "text": "Part X: Emergency Troubleshooting\n\n“My figure looks cluttered”\nSolutions:\n1. Reduce number of elements (combine categories, show fewer time points)\n2. Increase white space (widen margins, reduce bar width)\n3. Use small multiples instead of overlaying everything\n4. Remove non-essential grid lines\n5. Simplify color palette (remove gradients, use solid colors)\n6. Increase font sizes (yes, bigger is often clearer)\n\n\n“Colors don’t distinguish well”\nSolutions:\n1. Test with Color Oracle simulator\n2. Switch to Okabe-Ito palette\n3. Add redundant encoding (shapes, line styles)\n4. Increase saturation difference\n5. Check contrast ratio (aim for &gt;4.5:1)\n6. Avoid red-green combinations\n\n\n“Text is illegible”\nSolutions:\n1. Increase font size (minimum 9pt for tick labels)\n2. Use bold for critical text (axis labels, panel labels)\n3. Increase contrast (black text on white background)\n4. Remove text overlap (use adjustText or ggrepel)\n5. Rotate long axis labels 45° if necessary\n6. Simplify category names if too long\n\n\n“Figure doesn’t fit journal specifications”\nSolutions:\n1. Check journal's figure guidelines (width, DPI, format)\n2. Redesign for column width (single vs. double column)\n3. Reduce number of panels (move some to supplement)\n4. Adjust aspect ratio to match journal template\n5. Export at exact required dimensions (don't rely on scaling)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#part-xi-final-submission-checklist",
    "href": "Chapter 5.html#part-xi-final-submission-checklist",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "Part XI: Final Submission Checklist",
    "text": "Part XI: Final Submission Checklist\nBefore submitting manuscript:\n\nFigure Files:\n All figures exported at 300+ DPI\n Correct file format (TIFF/PNG or as specified)\n RGB color mode (unless CMYK required)\n Files named according to journal guidelines\n Correct dimensions (match journal column widths)\n\nVisual Consistency:\n All figures use identical font family and sizes\n Color schemes consistent across all figures\n Panel labels (A, B, C...) in consistent position\n Line widths and marker sizes uniform\n Error bar styles and definitions consistent\n\nScientific Content:\n All axes have labels with units\n All panels have clear titles or descriptions\n Sample sizes (n) stated in captions\n Statistical methods documented\n Error bar types specified (SEM vs SD)\n Significance markers defined (*, **, ***)\n Scale bars present on all images (microscopy, maps)\n\nAccessibility:\n Colorblind-safe palettes used\n Redundant encoding applied where needed\n Tested with colorblind simulator\n Works in grayscale\n Text contrast sufficient (WCAG AA)\n\nCaptions:\n Self-contained (understandable without main text)\n All panels described\n Sample sizes and statistics included\n Abbreviations defined\n Technical details provided (scale bars, magnifications, etc.)\n\nEthics:\n No image manipulation beyond linear adjustments\n All adjustments applied uniformly to comparison images\n Original unprocessed images available\n Processing documented in Methods\n No misleading color scale manipulation",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#part-xii-resources-and-tools",
    "href": "Chapter 5.html#part-xii-resources-and-tools",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "Part XII: Resources and Tools",
    "text": "Part XII: Resources and Tools\n\nColor Tools\nPalette generators:\n- ColorBrewer 2.0: colorbrewer2.org (CVD-safe filter available)\n- Coolors: coolors.co (palette generator)\n- Adobe Color: color.adobe.com\n\nAccessibility testing:\n- Color Oracle: colororacle.org (desktop, free, real-time CVD simulation)\n- Coblis: coblis.blogspot.com (web-based, image upload)\n- WebAIM Contrast Checker: webaim.org/resources/contrastchecker/\n\nRecommended palettes:\n- Okabe-Ito: Universally colorblind-safe (8 colors)\n- Viridis: Perceptually uniform, colorblind-safe (sequential)\n- RdBu: Diverging, colorblind-safe (with proper use)\n\n\nLayout and Design References\nBooks:\n- \"The Visual Display of Quantitative Information\" by Edward Tufte\n- \"Fundamentals of Data Visualization\" by Claus O. Wilke (free online)\n- \"Better Presentations\" by Jonathan Schwabish\n\nOnline guides:\n- Fundamentals of Data Visualization: clauswilke.com/dataviz/\n- Data-to-Viz: data-to-viz.com (plot type decision tree)\n- From Data to Viz: python graph gallery: python-graph-gallery.com\n\n\nSoftware Documentation\nPython:\n- Matplotlib: matplotlib.org/stable/tutorials/\n- Seaborn: seaborn.pydata.org/tutorial.html\n- Plotly: plotly.com/python/\n\nR:\n- ggplot2: ggplot2.tidyverse.org\n- patchwork (multi-panel): patchwork.data-imaginist.com\n- cowplot (publication-ready): wilkelab.org/cowplot/\n\nStatistics:\n- GraphPad Prism tutorials: graphpad.com/guides/\n- JASP (free): jasp-stats.org",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 5.html#conclusion-the-path-to-publication-quality-figures",
    "href": "Chapter 5.html#conclusion-the-path-to-publication-quality-figures",
    "title": "Chapter 5: Layout, Composition & Figure Assembly",
    "section": "Conclusion: The Path to Publication-Quality Figures",
    "text": "Conclusion: The Path to Publication-Quality Figures\nRemember the hierarchy of priorities:\n\nScientific accuracy (correct data representation)\nClarity (immediate comprehension of key message)\nAccessibility (colorblind-safe, high contrast, clear labels)\nConsistency (uniform style across manuscript)\nAesthetics (professional appearance, but never at expense of 1-4)\n\nWhen in doubt: - Ask: “Does this choice help or hinder understanding?” - Simplify rather than embellish - Test on colleagues unfamiliar with your work - Refer back to journal requirements - Prioritize data over decoration\nScientific figures are functional communication tools, not art. Every design choice must serve the goal of clear, honest, accessible data presentation.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 5: Layout, Composition & Figure Assembly</span>"
    ]
  },
  {
    "objectID": "Chapter 6.html",
    "href": "Chapter 6.html",
    "title": "Chapter 6: Technical Specifications & Publication Requirements",
    "section": "",
    "text": "6.1 Resolution and Image Quality",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Chapter 6: Technical Specifications & Publication Requirements</span>"
    ]
  },
  {
    "objectID": "Chapter 6.html#resolution-and-image-quality",
    "href": "Chapter 6.html#resolution-and-image-quality",
    "title": "Chapter 6: Technical Specifications & Publication Requirements",
    "section": "",
    "text": "Understanding DPI (Dots Per Inch)\nThe Critical Rule: Resolution must match final print size, not screen appearance.\nWhat DPI means:\nDPI = Dots (pixels) Per Inch when printed\n\nExample:\n- Image: 3000 × 2000 pixels\n- Printed at 10\" × 6.67\": 3000/10 = 300 DPI ✓\n- Printed at 20\" × 13.33\": 3000/20 = 150 DPI ❌ (too low)\n\nKey insight: Same image file, different DPI depending on print size\n\n\n\nPublication DPI Standards\nMinimum requirements by content type:\nLine art (graphs, charts, diagrams):\n- Minimum: 300 DPI\n- Recommended: 600 DPI\n- Reasoning: Sharp edges, crisp text\n\nPhotographs/Microscopy:\n- Minimum: 300 DPI\n- Recommended: 600 DPI for fine details\n- Maximum practical: 1200 DPI (diminishing returns beyond this)\n\nCombination (line art + photos):\n- Minimum: 300 DPI\n- Recommended: 600 DPI\n- Reasoning: Must satisfy highest requirement\n\nScreen/web only:\n- 72-96 DPI acceptable\n- But export print versions at 300 DPI anyway\n\n\n\nCommon Resolution Mistakes\nMistake 1: Upsampling low-resolution images\n❌ WRONG approach:\n1. Create figure at 100 DPI (screen resolution)\n2. \"Increase resolution\" to 300 DPI in image editor\n→ Doesn't add information, just enlarges pixels (blurry)\n\n✓ CORRECT approach:\n1. Create figure at 300 DPI from the start\n2. Set figure size in inches at creation\n→ Generates true high-resolution image\nMistake 2: Relying on vector formats incorrectly\nVector formats (PDF, EPS, SVG):\n✓ Good for: Line graphs, bar charts, scatter plots\n✓ Scales infinitely without quality loss\n✓ Small file sizes\n\n❌ Not good for: Rasterized components (imagesasterized components (images, complex gradients)\n→ Embedded images still need 300 DPI\n\nHybrid approach:\n- Save graph as vector\n- Ensure embedded images are high-resolution\nCode Example (Python) - Setting DPI Correctly:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Method 1: Set figure size and DPI at creation\nfig, ax = plt.subplots(figsize=(7, 5), dpi=300)  # 7\"×5\" at 300 DPI = 2100×1500 pixels\n\nx = np.random.randn(100)\ny = 2*x + np.random.randn(100)\nax.scatter(x, y, s=50, color='#3498DB', alpha=0.7, edgecolors='black', linewidths=0.5)\nax.set_xlabel('Variable X (units)', fontsize=11, fontweight='bold')\nax.set_ylabel('Variable Y (units)', fontsize=11, fontweight='bold')\nax.set_title('High-Resolution Figure (300 DPI)', fontsize=12, fontweight='bold')\nax.grid(alpha=0.3)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n# Save with explicit DPI (this overrides figure DPI if different)\nplt.savefig('figure_300dpi.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.savefig('figure_600dpi.png', dpi=600, bbox_inches='tight', facecolor='white')  # For fine details\n\nplt.close()\n\n# Check file sizes\nimport os\nsize_300 = os.path.getsize('figure_300dpi.png') / 1024  # KB\nsize_600 = os.path.getsize('figure_600dpi.png') / 1024  # KB\n\nprint(f\"300 DPI file size: {size_300:.1f} KB\")\nprint(f\"600 DPI file size: {size_600:.1f} KB\")\nprint(f\"Ratio: {size_600/size_300:.1f}x larger at 600 DPI\")\nCode Example (R) - Setting DPI Correctly:\nlibrary(ggplot2)\n\nset.seed(42)\ndata &lt;- data.frame(\n  x = rnorm(100),\n  y = 2*rnorm(100) + rnorm(100)\n)\n\np &lt;- ggplot(data, aes(x = x, y = y)) +\n  geom_point(size = 3, color = '#3498DB', alpha = 0.7) +\n  labs(x = 'Variable X (units)',\n       y = 'Variable Y (units)',\n       title = 'High-Resolution Figure (300 DPI)') +\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(face = 'bold', size = 12, hjust = 0.5),\n    axis.title = element_text(face = 'bold'),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\n# Save at different DPI levels\nggsave('figure_300dpi.png', p,\n       width = 7, height = 5, dpi = 300, bg = 'white')\n\nggsave('figure_600dpi.png', p,\n       width = 7, height = 5, dpi = 600, bg = 'white')\n\n# Check file sizes\nfile_info_300 &lt;- file.info('figure_300dpi.png')\nfile_info_600 &lt;- file.info('figure_600dpi.png')\n\ncat(sprintf(\"300 DPI file size: %.1f KB\\n\", file_info_300$size / 1024))\ncat(sprintf(\"600 DPI file size: %.1f KB\\n\", file_info_600$size / 1024))\ncat(sprintf(\"Ratio: %.1fx larger at 600 DPI\\n\",\n            file_info_600$size / file_info_300$size))",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Chapter 6: Technical Specifications & Publication Requirements</span>"
    ]
  },
  {
    "objectID": "Chapter 6.html#file-formats-for-publication",
    "href": "Chapter 6.html#file-formats-for-publication",
    "title": "Chapter 6: Technical Specifications & Publication Requirements",
    "section": "6.2 File Formats for Publication",
    "text": "6.2 File Formats for Publication\n\nFormat Decision Tree\nIs your figure purely vector (lines, shapes, text)?\n├─ YES → Use vector format\n│   ├─ PDF (most universal)\n│   ├─ EPS (legacy journals)\n│   └─ SVG (web/interactive)\n│\n└─ NO (contains images/raster elements) → Use raster format\n    ├─ TIFF (publication standard, lossless)\n    ├─ PNG (good alternative, lossless, smaller files)\n    └─ AVOID JPEG (lossy compression, artifacts)\n\n\n\nFormat Comparison\n\n\n\n\n\n\n\n\n\n\nFormat\nLossless?\nBest For\nPros\nCons\n\n\n\n\nTIFF\nYes\nFinal publication submission\nIndustry standard, supports layers/alpha\nLarge files\n\n\nPNG\nYes\nWeb, supplementary materials\nSmaller than TIFF, transparency support\nLimited metadata\n\n\nPDF\nDepends\nVector graphics, multi-page\nUniversal, scalable, embeds fonts\nCan include low-res images if not careful\n\n\nEPS\nYes\nVector for print\nPostScript standard, scalable\nBeing phased out by PDF\n\n\nSVG\nYes\nWeb/interactive graphics\nScalable, editable, small files\nLimited journal support\n\n\nJPEG\nNO ❌\nAVOID for science\nSmall files\nLossy compression creates artifacts\n\n\n\n\n\n\nWhy JPEG is Dangerous for Scientific Figures\nJPEG compression creates artifacts that can distort data:\nCode Example (Python) - JPEG Artifact Demonstration:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\n\n# Create a figure with sharp edges\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# Original high-quality image\nax1 = axes[0]\ndata = np.random.randint(0, 256, (100, 100, 3), dtype=np.uint8)\nax1.imshow(data)\nax1.set_title('Original (Random Pixels)', fontsize=12, fontweight='bold')\nax1.axis('off')\n\n# Save and reload as PNG (lossless)\nplt.savefig('temp_lossless.png', dpi=300, bbox_inches='tight')\nimg_png = Image.open('temp_lossless.png')\nax2 = axes[1]\nax2.imshow(img_png)\nax2.set_title('✓ PNG (Lossless)\\nNo artifacts', fontsize=12, fontweight='bold', color='green')\nax2.axis('off')\n\n# Save and reload as JPEG (lossy)\nplt.savefig('temp_lossy.jpg', dpi=300, bbox_inches='tight', quality=85)\nimg_jpg = Image.open('temp_lossy.jpg')\nax3 = axes[2]\nax3.imshow(img_jpg)\nax3.set_title('❌ JPEG (Lossy)\\nCompression artifacts visible',\n             fontsize=12, fontweight='bold', color='red')\nax3.axis('off')\n\nplt.tight_layout()\nplt.savefig('jpeg_artifacts_demo.png', dpi=300, bbox_inches='tight')\nplt.close()\n\n# Clean up temp files\nimport os\nos.remove('temp_lossless.png')\nos.remove('temp_lossy.jpg')\n\nprint(\"JPEG artifacts demonstration created\")\nprint(\"Notice: Blocky patterns (8×8 pixel blocks) visible in JPEG version\")\nVisual evidence of JPEG problems:\nSharp edges → Ringing artifacts (halos around edges)\nFlat colors → Blockiness (8×8 pixel compression blocks)\nFine details → Loss of subtle features\nText → Blurry/fuzzy edges\nJournals that explicitly FORBID JPEG: - Nature family (Nature, Nature Methods, etc.) - Cell family (Cell, Molecular Cell, etc.) - Science - PLOS family (strongly discouraged)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Chapter 6: Technical Specifications & Publication Requirements</span>"
    ]
  },
  {
    "objectID": "Chapter 6.html#color-modes-rgb-vs.-cmyk",
    "href": "Chapter 6.html#color-modes-rgb-vs.-cmyk",
    "title": "Chapter 6: Technical Specifications & Publication Requirements",
    "section": "6.3 Color Modes: RGB vs. CMYK",
    "text": "6.3 Color Modes: RGB vs. CMYK\n\nUnderstanding Color Spaces\nRGB (Red, Green, Blue):\nUse: Screen display, digital publication\nColor range: Wide gamut (more colors available)\nStandard for: Online journals, supplementary materials, presentations\n\nHow it works:\n- Additive color (light-based)\n- Black = no light (0, 0, 0)\n- White = all light (255, 255, 255)\nCMYK (Cyan, Magenta, Yellow, Black):\nUse: Print publication\nColor range: Smaller gamut (some RGB colors can't be printed)\nStandard for: Traditional print journals\n\nHow it works:\n- Subtractive color (ink-based)\n- White = no ink (paper color)\n- Black = all inks mixed\n\n\n\nRGB vs. CMYK Decision\nModern reality: Most journals want RGB\n✓ Use RGB when:\n- Journal specifies RGB (most do now)\n- Figures will be online (increasing standard)\n- Unsure (RGB is safer default)\n- Your figures use vivid colors (wider gamut)\n\n✓ Use CMYK when:\n- Journal explicitly requires CMYK\n- Print-only publication (rare)\n- Preparing for commercial printing\nCommon mistake: Converting RGB → CMYK yourself\n❌ WRONG:\nYou convert to CMYK → Colors shift → Looks dull\n\n✓ CORRECT:\nSubmit RGB → Journal's printer converts → Optimized conversion\nHow to check your image color mode:\n# Python\nfrom PIL import Image\nimg = Image.open('figure.png')\nprint(f\"Color mode: {img.mode}\")  # Should be 'RGB' or 'RGBA'\n# R\nlibrary(png)\nimg &lt;- readPNG('figure.png')\nif (dim(img)[3] == 3) {\n  cat(\"Color mode: RGB\\n\")\n} else if (dim(img)[3] == 4) {\n  cat(\"Color mode: RGBA (RGB + alpha channel)\\n\")\n}",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Chapter 6: Technical Specifications & Publication Requirements</span>"
    ]
  },
  {
    "objectID": "Chapter 6.html#journal-specific-requirements",
    "href": "Chapter 6.html#journal-specific-requirements",
    "title": "Chapter 6: Technical Specifications & Publication Requirements",
    "section": "6.4 Journal-Specific Requirements",
    "text": "6.4 Journal-Specific Requirements\n\nReading and Interpreting Figure Guidelines\nEvery journal has a “Guide for Authors” or “Figure Guidelines”—READ IT CAREFULLY\nCommon specification categories:\n1. Dimensions\n   - Single column width (usually 3.5 inches / 89 mm)\n   - Double column width (usually 7 inches / 178 mm)\n   - Full page width (varies)\n   - Maximum height (often 9-10 inches)\n\n2. Resolution\n   - Line art: 600-1000 DPI\n   - Photos: 300-600 DPI\n   - Combination: 300-600 DPI\n\n3. File format\n   - Preferred: TIFF, EPS, PDF\n   - Acceptable: PNG (some journals)\n   - Avoid: JPEG, GIF, BMP\n\n4. Color mode\n   - RGB (most common now)\n   - CMYK (traditional print journals)\n\n5. File size limits\n   - Per figure: 5-20 MB common\n   - Total submission: 50-100 MB typical\n\n6. Fonts\n   - Embedded/outlined required\n   - Minimum size: 6-8 pt after reduction\n   - Preferred: Arial, Helvetica, Times\n\n7. Special requirements\n   - Separate files for each panel (some journals)\n   - Layered files (editable)\n   - Color charge (rare now, but check)\n\n\n\nExample Journal Requirements\nNature:\n- Dimensions: Single column 89 mm, double 183 mm, full 247 mm\n- Format: TIFF, EPS, or PDF\n- Resolution: 300 DPI photos, 600 DPI line art\n- Color: RGB preferred\n- Fonts: Must be embedded\n- Labels: Bold sans-serif, minimum 7 pt final size\n- Special: Submit figures at intended publication size\nCell:\n- Dimensions: 1 column 85 mm, 2 columns 178 mm\n- Format: TIFF, EPS, PDF, or AI (Adobe Illustrator)\n- Resolution: 300 DPI minimum, 600 preferred for line art\n- Color: RGB\n- Fonts: Arial or Helvetica, embedded\n- Special: Figures may be reduced up to 75% for publication\nPLOS ONE:\n- Dimensions: Width 670-2010 pixels\n- Format: TIFF, EPS, PDF, PNG acceptable\n- Resolution: 300-600 DPI\n- Color: RGB\n- Fonts: No specific requirement (but Arial/Helvetica recommended)\n- Special: Figures published under CC-BY license (open access)\nScience:\n- Dimensions: 1 column 5.5 cm, 2 columns 12 cm, 3 columns 18.3 cm\n- Format: PDF, TIFF, EPS, PNG\n- Resolution: 300 DPI minimum\n- Color: RGB or CMYK acceptable\n- Fonts: Sans-serif preferred, minimum 6 pt after reduction\n- Special: Very strict image integrity policies\n\n\n\nPre-Submission Checklist Builder\nGenerate custom checklist based on target journal:\ndef generate_journal_checklist(journal_name):\n    \"\"\"\n    Create custom pre-submission checklist for specific journal\n    \"\"\"\n    guidelines = {\n        'Nature': {\n            'dimensions': ['89mm (single column)', '183mm (double)', '247mm (full)'],\n            'format': ['TIFF', 'EPS', 'PDF'],\n            'resolution': '300 DPI (photos), 600 DPI (line art)',\n            'color': 'RGB',\n            'font_min': '7pt after reduction',\n            'special': 'Submit at intended size, embed fonts'\n        },\n        'Cell': {\n            'dimensions': ['85mm (1 col)', '178mm (2 col)'],\n            'format': ['TIFF', 'EPS', 'PDF', 'AI'],\n            'resolution': '300-600 DPI',\n            'color': 'RGB',\n            'font_min': 'Readable after 75% reduction',\n            'special': 'May be reduced up to 75%'\n        },\n        'PLOS ONE': {\n            'dimensions': ['670-2010 pixels width'],\n            'format': ['TIFF', 'EPS', 'PDF', 'PNG'],\n            'resolution': '300-600 DPI',\n            'color': 'RGB',\n            'font_min': 'No minimum specified',\n            'special': 'CC-BY license (open access)'\n        }\n    }\n\n    if journal_name not in guidelines:\n        return \"Journal not in database. Check journal website.\"\n\n    specs = guidelines[journal_name]\n\n    checklist = f\"\"\"\n    === {journal_name} Figure Submission Checklist ===\n\n     Dimensions match journal specs: {', '.join(specs['dimensions'])}\n     File format: {', '.join(specs['format'])}\n     Resolution: {specs['resolution']}\n     Color mode: {specs['color']}\n     Font size: {specs['font_min']}\n     Special requirements: {specs['special']}\n\n     All panels labeled (A, B, C...)\n     Scale bars present (if applicable)\n     Captions complete and self-contained\n     Supplementary figures numbered separately\n     Files named according to journal convention\n     Image integrity: No manipulation beyond linear adjustments\n    \"\"\"\n\n    return checklist\n\n# Example usage\nprint(generate_journal_checklist('Nature'))",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Chapter 6: Technical Specifications & Publication Requirements</span>"
    ]
  },
  {
    "objectID": "Chapter 6.html#image-compression-and-file-optimization",
    "href": "Chapter 6.html#image-compression-and-file-optimization",
    "title": "Chapter 6: Technical Specifications & Publication Requirements",
    "section": "6.5 Image Compression and File Optimization",
    "text": "6.5 Image Compression and File Optimization\n\nBalancing Quality and File Size\nThe challenge: High-resolution images = large files, but journals have size limits\nOptimization strategies:\n1. Choose appropriate file format\nFor line graphs/charts:\n✓ PDF (vector, small file, scalable)\n✓ EPS (if journal requires)\n\nFor photos/images:\n✓ PNG with compression level 6-9 (lossless but smaller)\n✓ TIFF with LZW compression (lossless)\n\nFor combinations:\n✓ PDF with high-quality raster settings\n✓ TIFF with LZW compression\n2. Optimize image dimensions\nDon't create unnecessarily large images:\n❌ WASTEFUL: 10,000 × 10,000 pixels for 7-inch figure\n✓ OPTIMAL: 2,100 × 1,500 pixels (7\" × 5\" at 300 DPI)\n\nRule: Pixels = Inches × DPI\n3. Flatten layers if not needed\nLayered TIFF files can be 10x larger:\n✓ Keep layers if journal requires editable files\n✓ Flatten layers for final submission if allowed\nCode Example (Python) - Image Optimization:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\nimport os\n\nnp.random.seed(42)\n\n# Create sample figure\nfig, ax = plt.subplots(figsize=(7, 5))\nx = np.random.randn(100)\ny = 2*x + np.random.randn(100)\nax.scatter(x, y, s=50, color='#3498DB', alpha=0.7)\nax.set_xlabel('Variable X', fontsize=11, fontweight='bold')\nax.set_ylabel('Variable Y', fontsize=11, fontweight='bold')\nax.set_title('File Size Optimization Demo', fontsize=12, fontweight='bold')\nax.grid(alpha=0.3)\n\n# Save with different formats and settings\nformats = {\n    'PNG_default': {'format': 'png', 'dpi': 300},\n    'PNG_compressed': {'format': 'png', 'dpi': 300, 'optimize': True},\n    'TIFF_uncompressed': {'format': 'tiff', 'dpi': 300},\n    'TIFF_LZW': {'format': 'tiff', 'dpi': 300, 'compression': 'tiff_lzw'},\n    'PDF_vector': {'format': 'pdf', 'dpi': 300}\n}\n\nfile_sizes = {}\n\nfor name, kwargs in formats.items():\n    filename = f'test_{name}.{kwargs[\"format\"]}'\n    plt.savefig(filename, bbox_inches='tight', facecolor='white', **kwargs)\n    file_sizes[name] = os.path.getsize(filename) / 1024  # KB\n\n    # Clean up\n    os.remove(filename)\n\nplt.close()\n\n# Display comparison\nprint(\"File Size Comparison (same figure, different formats):\")\nprint(\"=\" * 50)\nfor name, size in sorted(file_sizes.items(), key=lambda x: x[1]):\n    print(f\"{name:20} : {size:6.1f} KB\")\n\n# Calculate savings\nlargest = max(file_sizes.values())\nsmallest = min(file_sizes.values())\nprint(f\"\\nOptimization savings: {(1 - smallest/largest)*100:.1f}% size reduction\")\nExpected output:\nFile Size Comparison (same figure, different formats):\n==================================================\nPDF_vector           :   45.2 KB  ← Smallest (vector)\nPNG_compressed       :  156.8 KB  ← Good balance\nPNG_default          :  203.5 KB\nTIFF_LZW            :  287.3 KB\nTIFF_uncompressed   :  892.1 KB  ← Largest\n\nOptimization savings: 94.9% size reduction\n\n\n\nWhen File Sizes Are Too Large\nProblem: Figure exceeds journal’s file size limit (e.g., 10 MB)\nSolutions (in order of preference):\n1. Optimize compression (lossless)\n   - Use PNG with optimization\n   - Use TIFF with LZW compression\n   - Flatten unnecessary layers\n\n2. Reduce unnecessary resolution\n   - If figure is 600 DPI but journal requires 300 DPI, downsample\n   - If figure is larger than needed, resize to exact print dimensions\n\n3. Split complex figures\n   - Break into multiple files (Figure 1A, 1B, 1C as separate files)\n   - Some journals prefer this anyway\n\n4. Reduce color depth (carefully!)\n   - If grayscale image, save as 8-bit grayscale (not RGB)\n   - If indexed color appropriate, convert (rare in science)\n\n5. Move to supplementary materials\n   - Less critical figures → supplement\n   - High-resolution originals → supplement, lower-res in main text\nCode Example (Python) - Batch Image Optimization:\nfrom PIL import Image\nimport os\n\ndef optimize_image(input_path, output_path, max_size_mb=10, target_dpi=300):\n    \"\"\"\n    Optimize image while preserving quality\n\n    Parameters:\n    - input_path: Source image file\n    - output_path: Destination file\n    - max_size_mb: Maximum file size in MB\n    - target_dpi: Target DPI (will downsample if higher)\n    \"\"\"\n    img = Image.open(input_path)\n\n    # Get current DPI\n    dpi = img.info.get('dpi', (300, 300))\n    current_dpi = dpi[0] if isinstance(dpi, tuple) else dpi\n\n    # Downsample if exceeds target DPI\n    if current_dpi &gt; target_dpi:\n        scale_factor = target_dpi / current_dpi\n        new_size = tuple(int(dim * scale_factor) for dim in img.size)\n        img = img.resize(new_size, Image.Resampling.LANCZOS)\n        print(f\"Downsampled from {current_dpi} to {target_dpi} DPI\")\n\n    # Save with optimization\n    save_kwargs = {\n        'dpi': (target_dpi, target_dpi),\n        'optimize': True\n    }\n\n    if output_path.lower().endswith('.png'):\n        save_kwargs['compress_level'] = 9  # Maximum PNG compression\n    elif output_path.lower().endswith(('.tif', '.tiff')):\n        save_kwargs['compression'] = 'tiff_lzw'  # LZW compression for TIFF\n\n    img.save(output_path, **save_kwargs)\n\n    # Check file size\n    size_mb = os.path.getsize(output_path) / (1024 * 1024)\n\n    if size_mb &gt; max_size_mb:\n        print(f\"Warning: File size {size_mb:.2f} MB exceeds {max_size_mb} MB\")\n        print(\"Consider: Reducing dimensions, splitting figure, or moving to supplement\")\n    else:\n        print(f\"✓ Optimized file size: {size_mb:.2f} MB (within {max_size_mb} MB limit)\")\n\n    return size_mb\n\n# Example usage\n# optimize_image('large_figure.png', 'optimized_figure.png', max_size_mb=10, target_dpi=300)\n\nEnd of Chapter 6: Technical Specifications & Publication Requirements\nKey Takeaways: - 300 DPI minimum for publication (600 DPI for line art) - Create at target size, don’t upsample later - TIFF or PNG for raster images (never JPEG) - PDF for vector graphics - RGB color mode (unless journal specifies CMYK) - Read journal guidelines carefully—requirements vary - Optimize file sizes without losing quality (compression, appropriate dimensions) - Check before submission: DPI, format, color mode, file size, dimensions",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Chapter 6: Technical Specifications & Publication Requirements</span>"
    ]
  },
  {
    "objectID": "Chapter 7.html",
    "href": "Chapter 7.html",
    "title": "Chapter 7: Common Figure Types Deep Dive",
    "section": "",
    "text": "7.1 Heatmaps: Visualizing Matrix Data",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 7: Common Figure Types Deep Dive</span>"
    ]
  },
  {
    "objectID": "Chapter 7.html#heatmaps-visualizing-matrix-data",
    "href": "Chapter 7.html#heatmaps-visualizing-matrix-data",
    "title": "Chapter 7: Common Figure Types Deep Dive",
    "section": "",
    "text": "When to Use Heatmaps\nIdeal scenarios:\n✓ Gene expression matrices (genes × samples)\n✓ Correlation matrices (variables × variables)\n✓ Spatial patterns (location × location)\n✓ Time-course data (features × time points)\n✓ Any large matrix where patterns &gt; individual values\nWhen NOT to use:\n❌ Few data points (&lt;10×10) — use bar charts or tables\n❌ When exact values are critical — add numbers or use alternative\n❌ Categorical data without ordering — consider other encodings\n\n\n\nCritical Design Decisions for Heatmaps\nDecision 1: Colormap Selection\nType of data → Colormap choice\n\nSequential (one direction, e.g., 0 to max):\n✓ Use: Viridis, Plasma, YlOrRd, Blues\nExample: Gene expression (FPKM 0-1000)\n\nDiverging (two directions from center):\n✓ Use: RdBu (red-blue), RdYlGn, PiYG\nExample: Fold change (log₂ -3 to +3, center at 0)\n\nCategorical (unordered groups):\n✓ Use: Distinct hues, equal saturation\nExample: Cluster assignments\nDecision 2: Normalization Strategy\nRow normalization (Z-score by gene):\n- Highlights relative patterns across samples\n- Each row mean=0, SD=1\n- Use when: Comparing patterns, not absolute levels\n\nColumn normalization (by sample):\n- Highlights relative patterns across genes\n- Use when: Sample-to-sample differences are key\n\nNo normalization (raw values):\n- Shows absolute magnitudes\n- Use when: Actual values matter (e.g., concentrations)\nDecision 3: Clustering and Ordering\nHierarchical clustering:\n✓ Reveals groups/patterns automatically\n✓ Shows dendrogram (tree structure)\n✓ Use: Exploratory analysis\n\nManual ordering:\n✓ Test specific hypotheses\n✓ Control presentation order\n✓ Use: Confirmatory analysis, known groups\n\nOrdered by value:\n✓ Simple sorting (high to low)\n✓ Use: Ranking, prioritization\n\nCode Example (Python) - Comprehensive Heatmap:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nfrom scipy.spatial.distance import pdist\n\nnp.random.seed(42)\n\n# Generate synthetic gene expression data\nn_genes = 50\nn_samples = 12\n\n# Three sample groups with different expression patterns\ngroup1 = np.random.normal(5, 1, (n_genes, 4))\ngroup2 = np.random.normal(8, 1.5, (n_genes, 4))\ngroup3 = np.random.normal(6, 1, (n_genes, 4))\n\n# Some genes upregulated in group2\ngroup2[:15, :] += 3\n\ndata = np.hstack([group1, group2, group3])\n\n# Sample and gene names\ngenes = [f'Gene{i+1}' for i in range(n_genes)]\nsamples = [f'Ctrl{i+1}' for i in range(4)] + \\\n          [f'TrtA{i+1}' for i in range(4)] + \\\n          [f'TrtB{i+1}' for i in range(4)]\n\n# Create figure with subplots\nfig = plt.figure(figsize=(16, 12))\n\n# Layout: Main heatmap + dendrograms + colorbars\ngs = fig.add_gridspec(3, 3,\n                      width_ratios=[0.5, 4, 0.15],  # Dendrogram | Heatmap | Colorbar\n                      height_ratios=[0.5, 4, 0.15],  # Dendrogram | Heatmap | Sample labels\n                      hspace=0.02, wspace=0.02)\n\n# === PANEL 1: Basic heatmap (no clustering) ===\nax_basic = fig.add_subplot(3, 3, 1)\nsns.heatmap(data[:20, :6], cmap='viridis', cbar=False, ax=ax_basic,\n            xticklabels=samples[:6], yticklabels=genes[:20])\nax_basic.set_title('A. Basic Heatmap\\n(No clustering)',\n                   fontsize=11, fontweight='bold', pad=10)\nax_basic.set_xlabel('')\nax_basic.set_ylabel('Genes', fontsize=10, fontweight='bold')\n\n# === PANEL 2: Hierarchical clustering ===\nax_clust = fig.add_subplot(3, 3, 2)\n\n# Perform hierarchical clustering\nrow_linkage = linkage(data, method='average', metric='euclidean')\ncol_linkage = linkage(data.T, method='average', metric='euclidean')\n\n# Plot with clustered rows and columns\nsns.clustermap(data, cmap='RdBu_r', center=6.5,\n               row_linkage=row_linkage, col_linkage=col_linkage,\n               figsize=(8, 10), cbar_pos=(0.02, 0.8, 0.03, 0.15),\n               dendrogram_ratio=0.15,\n               xticklabels=samples, yticklabels=False)\n\n# Note: clustermap creates its own figure, so we save separately\nplt.savefig('heatmap_clustered.png', dpi=300, bbox_inches='tight')\nplt.close()\n\n# === PANEL 3: With annotations ===\nax_annot = fig.add_subplot(3, 3, 3)\n\n# Normalized data (Z-score by row)\ndata_norm = (data - data.mean(axis=1, keepdims=True)) / data.std(axis=1, keepdims=True)\n\nsns.heatmap(data_norm[:20, :6], cmap='RdBu_r', center=0,\n            cbar=True, ax=ax_annot,\n            xticklabels=samples[:6], yticklabels=False,\n            cbar_kws={'label': 'Z-score'})\nax_annot.set_title('C. Row-Normalized\\n(Z-score)',\n                   fontsize=11, fontweight='bold', pad=10)\nax_annot.set_xlabel('Samples', fontsize=10, fontweight='bold')\n\n# Add sample group annotations\nfor i in range(6):\n    if i &lt; 2:\n        color = '#7F8C8D'  # Control\n    elif i &lt; 4:\n        color = '#3498DB'  # Treatment A\n    else:\n        color = '#E74C3C'  # Treatment B\n\n    ax_annot.add_patch(plt.Rectangle((i, -1), 1, 0.5,\n                                     facecolor=color, edgecolor='black', linewidth=2,\n                                     clip_on=False))\n\n# === PANEL 4: Common mistakes ===\nax_bad = fig.add_subplot(3, 3, 4)\n\n# Bad: Rainbow colormap (not perceptually uniform)\nsns.heatmap(data[:20, :6], cmap='jet', cbar=False, ax=ax_bad,\n            xticklabels=samples[:6], yticklabels=False)\nax_bad.set_title('❌ BAD: Rainbow Colormap\\n(Not perceptually uniform)',\n                 fontsize=11, fontweight='bold', color='red', pad=10)\nax_bad.set_xlabel('Samples', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('heatmap_comprehensive.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"Heatmap examples created:\")\nprint(\"1. heatmap_comprehensive.png - Multiple panels showing best practices\")\nprint(\"2. heatmap_clustered.png - Full hierarchical clustering example\")\nCode Example (R) - Comprehensive Heatmap:\nlibrary(ggplot2)\nlibrary(pheatmap)\nlibrary(RColorBrewer)\nlibrary(viridis)\n\nset.seed(42)\n\n# Generate synthetic data\nn_genes &lt;- 50\nn_samples &lt;- 12\n\ngroup1 &lt;- matrix(rnorm(n_genes * 4, mean = 5, sd = 1), n_genes, 4)\ngroup2 &lt;- matrix(rnorm(n_genes * 4, mean = 8, sd = 1.5), n_genes, 4)\ngroup3 &lt;- matrix(rnorm(n_genes * 4, mean = 6, sd = 1), n_genes, 4)\n\n# Upregulate some genes in group2\ngroup2[1:15, ] &lt;- group2[1:15, ] + 3\n\ndata &lt;- cbind(group1, group2, group3)\n\n# Names\nrownames(data) &lt;- paste0('Gene', 1:n_genes)\ncolnames(data) &lt;- c(paste0('Ctrl', 1:4),\n                    paste0('TrtA', 1:4),\n                    paste0('TrtB', 1:4))\n\n# Sample annotations\nsample_groups &lt;- data.frame(\n  Group = factor(rep(c('Control', 'Treatment A', 'Treatment B'), each = 4))\n)\nrownames(sample_groups) &lt;- colnames(data)\n\n# Annotation colors\nann_colors &lt;- list(\n  Group = c('Control' = '#7F8C8D',\n            'Treatment A' = '#3498DB',\n            'Treatment B' = '#E74C3C')\n)\n\n# === HEATMAP 1: Basic (no clustering) ===\npng('heatmap_basic.png', width = 2400, height = 2000, res = 300)\npheatmap(data[1:20, 1:6],\n         color = viridis(100),\n         cluster_rows = FALSE,\n         cluster_cols = FALSE,\n         main = 'Basic Heatmap (No clustering)',\n         fontsize = 10,\n         fontsize_row = 8,\n         fontsize_col = 9)\ndev.off()\n\n# === HEATMAP 2: Hierarchical clustering with annotations ===\npng('heatmap_clustered_annotated.png', width = 2800, height = 3000, res = 300)\npheatmap(data,\n         color = colorRampPalette(rev(brewer.pal(n = 7, name = \"RdBu\")))(100),\n         scale = \"row\",  # Z-score normalization\n         clustering_distance_rows = \"euclidean\",\n         clustering_distance_cols = \"euclidean\",\n         clustering_method = \"average\",\n         annotation_col = sample_groups,\n         annotation_colors = ann_colors,\n         show_rownames = FALSE,\n         fontsize = 10,\n         fontsize_col = 9,\n         main = 'Hierarchical Clustering with Annotations')\ndev.off()\n\n# === HEATMAP 3: Row-normalized (Z-score) ===\ndata_norm &lt;- t(scale(t(data)))  # Z-score by row\n\npng('heatmap_normalized.png', width = 2800, height = 3000, res = 300)\npheatmap(data_norm,\n         color = colorRampPalette(rev(brewer.pal(n = 7, name = \"RdBu\")))(100),\n         breaks = seq(-3, 3, length.out = 101),  # Symmetric scale\n         cluster_rows = TRUE,\n         cluster_cols = TRUE,\n         annotation_col = sample_groups,\n         annotation_colors = ann_colors,\n         show_rownames = FALSE,\n         fontsize = 10,\n         fontsize_col = 9,\n         main = 'Row-Normalized (Z-score)')\ndev.off()\n\n# === HEATMAP 4: BAD EXAMPLE (rainbow colormap) ===\npng('heatmap_bad_rainbow.png', width = 2400, height = 2000, res = 300)\npheatmap(data[1:20, 1:6],\n         color = rainbow(100),  # BAD: Rainbow colormap\n         cluster_rows = FALSE,\n         cluster_cols = FALSE,\n         main = '❌ BAD: Rainbow Colormap (Not perceptually uniform)',\n         fontsize = 10,\n         fontsize_row = 8,\n         fontsize_col = 9)\ndev.off()\n\ncat(\"Heatmap examples created:\\n\")\ncat(\"1. heatmap_basic.png\\n\")\ncat(\"2. heatmap_clustered_annotated.png\\n\")\ncat(\"3. heatmap_normalized.png\\n\")\ncat(\"4. heatmap_bad_rainbow.png\\n\")\n\n\n\nHeatmap Best Practices Checklist\nBefore creating heatmap:\n Decide normalization strategy (raw, row Z-score, column Z-score)\n Choose appropriate colormap (sequential vs. diverging)\n Determine clustering method (or manual ordering)\n Set symmetric scale if diverging (e.g., -3 to +3)\n\nVisual elements:\n Colorbar with clear label and units\n Sample/row annotations if grouped\n Dendrogram if using hierarchical clustering\n Grid lines (subtle) if helpful for reading specific cells\n\nAvoid:\n❌ Rainbow colormap (jet, hsv)\n❌ Asymmetric scales for diverging data\n❌ Too many rows/columns (&gt;100 makes individual cells unreadable)\n❌ Missing colorbar or unlabeled colorbar",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 7: Common Figure Types Deep Dive</span>"
    ]
  },
  {
    "objectID": "Chapter 7.html#volcano-plots-differential-expression-analysis",
    "href": "Chapter 7.html#volcano-plots-differential-expression-analysis",
    "title": "Chapter 7: Common Figure Types Deep Dive",
    "section": "7.2 Volcano Plots: Differential Expression Analysis",
    "text": "7.2 Volcano Plots: Differential Expression Analysis\n\nWhat Volcano Plots Show\nPurpose: Simultaneously visualize: 1. Magnitude of change (x-axis: fold change) 2. Statistical significance (y-axis: -log₁₀(p-value))\nCommon in: Genomics, proteomics, metabolomics\n\n\n\nAnatomy of a Volcano Plot\nStructure:\n                  High significance\n                         ↑\n                         │\n  Down-regulated    │    Up-regulated\n  (significant)     │    (significant)\n        ←───────────┼───────────→\n     -log₂FC    Center   +log₂FC\n                    (0)\n                         │\n                         ↓\n                  Low significance\n\nQuadrants:\n- Top-left: Down-regulated + significant\n- Top-right: Up-regulated + significant\n- Bottom: Not significant (regardless of fold change)\n\nCode Example (Python) - Volcano Plot:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Simulate differential expression data\nn_genes = 2000\n\n# Log2 fold changes (mostly around 0, some large changes)\nlog2fc = np.random.normal(0, 1.5, n_genes)\nlog2fc[:50] += 3  # 50 upregulated genes\nlog2fc[50:100] -= 3  # 50 downregulated genes\n\n# P-values (mostly high, some low for significant genes)\np_values = np.random.uniform(0.01, 1, n_genes)\np_values[:100] = np.random.uniform(0.0001, 0.01, 100)  # Significant genes\n\n# Convert to -log10(p)\nneg_log10_p = -np.log10(p_values)\n\n# Define significance thresholds\nfc_threshold = 1.0  # Log2 fold change threshold\np_threshold = 0.05  # P-value threshold\nneg_log10_p_threshold = -np.log10(p_threshold)\n\n# Classify genes\nsignificant_up = (log2fc &gt; fc_threshold) & (p_values &lt; p_threshold)\nsignificant_down = (log2fc &lt; -fc_threshold) & (p_values &lt; p_threshold)\nnot_significant = ~(significant_up | significant_down)\n\n# Create figure\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# === PANEL A: Basic volcano plot ===\nax1 = axes[0]\n\n# Plot not significant genes (gray, in background)\nax1.scatter(log2fc[not_significant], neg_log10_p[not_significant],\n           s=15, color='#CCCCCC', alpha=0.5, label='Not significant')\n\n# Plot significant down-regulated (blue)\nax1.scatter(log2fc[significant_down], neg_log10_p[significant_down],\n           s=30, color='#3498DB', alpha=0.8, edgecolors='black', linewidths=0.5,\n           label=f'Down ({np.sum(significant_down)})')\n\n# Plot significant up-regulated (red)\nax1.scatter(log2fc[significant_up], neg_log10_p[significant_up],\n           s=30, color='#E74C3C', alpha=0.8, edgecolors='black', linewidths=0.5,\n           label=f'Up ({np.sum(significant_up)})')\n\n# Add threshold lines\nax1.axhline(neg_log10_p_threshold, color='black', linestyle='--', linewidth=1.5, alpha=0.7)\nax1.axvline(fc_threshold, color='black', linestyle='--', linewidth=1.5, alpha=0.7)\nax1.axvline(-fc_threshold, color='black', linestyle='--', linewidth=1.5, alpha=0.7)\n\n# Labels\nax1.set_xlabel('Log₂ Fold Change', fontsize=12, fontweight='bold')\nax1.set_ylabel('-Log₁₀ (P-value)', fontsize=12, fontweight='bold')\nax1.set_title('A. Volcano Plot: Differential Expression',\n             fontsize=13, fontweight='bold')\n\n# Add threshold annotations\nax1.text(fc_threshold + 0.2, ax1.get_ylim()[0] + 0.5,\n        f'FC &gt; {2**fc_threshold:.1f}×', fontsize=9, rotation=90, va='bottom')\nax1.text(-fc_threshold - 0.2, ax1.get_ylim()[0] + 0.5,\n        f'FC &lt; {2**-fc_threshold:.1f}×', fontsize=9, rotation=90, va='bottom', ha='right')\nax1.text(ax1.get_xlim()[0] + 0.5, neg_log10_p_threshold + 0.3,\n        f'p &lt; {p_threshold}', fontsize=9)\n\nax1.legend(loc='upper right', frameon=True, fontsize=10)\nax1.grid(alpha=0.3)\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# === PANEL B: Common mistakes ===\nax2 = axes[1]\n\n# BAD: No fold change threshold (only p-value)\nsignificant_p_only = p_values &lt; p_threshold\n\nax2.scatter(log2fc[~significant_p_only], neg_log10_p[~significant_p_only],\n           s=15, color='#CCCCCC', alpha=0.5, label='Not significant')\nax2.scatter(log2fc[significant_p_only], neg_log10_p[significant_p_only],\n           s=30, color='#E74C3C', alpha=0.8, edgecolors='black', linewidths=0.5,\n           label=f'p &lt; {p_threshold} (ignoring FC)')\n\n# Only p-value threshold line\nax2.axhline(neg_log10_p_threshold, color='black', linestyle='--', linewidth=1.5, alpha=0.7)\n\nax2.set_xlabel('Log₂ Fold Change', fontsize=12, fontweight='bold')\nax2.set_ylabel('-Log₁₀ (P-value)', fontsize=12, fontweight='bold')\nax2.set_title('❌ B. BAD: No Fold Change Threshold\\n(Includes small, insignificant changes)',\n             fontsize=13, fontweight='bold', color='red')\n\nax2.legend(loc='upper right', frameon=True, fontsize=10)\nax2.grid(alpha=0.3)\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\n\nplt.tight_layout()\nplt.savefig('volcano_plot_comparison.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\n# Print summary statistics\nprint(\"Volcano Plot Summary:\")\nprint(f\"Total genes: {n_genes}\")\nprint(f\"Significant up-regulated: {np.sum(significant_up)}\")\nprint(f\"Significant down-regulated: {np.sum(significant_down)}\")\nprint(f\"Not significant: {np.sum(not_significant)}\")\nprint(f\"\\nThresholds:\")\nprint(f\"- Fold change: ±{2**fc_threshold:.2f}× (log₂ ±{fc_threshold})\")\nprint(f\"- P-value: {p_threshold} (-log₁₀ = {neg_log10_p_threshold:.2f})\")\nCode Example (R) - Volcano Plot:\nlibrary(ggplot2)\nlibrary(ggrepel)\n\nset.seed(42)\n\n# Simulate data\nn_genes &lt;- 2000\n\nlog2fc &lt;- rnorm(n_genes, 0, 1.5)\nlog2fc[1:50] &lt;- log2fc[1:50] + 3  # Upregulated\nlog2fc[51:100] &lt;- log2fc[51:100] - 3  # Downregulated\n\np_values &lt;- runif(n_genes, 0.01, 1)\np_values[1:100] &lt;- runif(100, 0.0001, 0.01)  # Significant\n\nneg_log10_p &lt;- -log10(p_values)\n\n# Thresholds\nfc_threshold &lt;- 1.0\np_threshold &lt;- 0.05\nneg_log10_p_threshold &lt;- -log10(p_threshold)\n\n# Create dataframe\ndata &lt;- data.frame(\n  gene = paste0('Gene', 1:n_genes),\n  log2fc = log2fc,\n  neg_log10_p = neg_log10_p,\n  p_value = p_values\n)\n\n# Classify\ndata$status &lt;- 'Not significant'\ndata$status[data$log2fc &gt; fc_threshold & data$p_value &lt; p_threshold] &lt;- 'Up-regulated'\ndata$status[data$log2fc &lt; -fc_threshold & data$p_value &lt; p_threshold] &lt;- 'Down-regulated'\ndata$status &lt;- factor(data$status, levels = c('Down-regulated', 'Not significant', 'Up-regulated'))\n\n# Colors\ncolors &lt;- c('Down-regulated' = '#3498DB',\n            'Not significant' = '#CCCCCC',\n            'Up-regulated' = '#E74C3C')\n\n# === PLOT A: Good volcano plot ===\np_good &lt;- ggplot(data, aes(x = log2fc, y = neg_log10_p, color = status)) +\n  geom_point(aes(size = status, alpha = status)) +\n  scale_color_manual(values = colors) +\n  scale_size_manual(values = c('Down-regulated' = 3, 'Not significant' = 1.5, 'Up-regulated' = 3)) +\n  scale_alpha_manual(values = c('Down-regulated' = 0.8, 'Not significant' = 0.5, 'Up-regulated' = 0.8)) +\n\n  # Threshold lines\n  geom_hline(yintercept = neg_log10_p_threshold, linetype = 'dashed', size = 1, alpha = 0.7) +\n  geom_vline(xintercept = c(-fc_threshold, fc_threshold), linetype = 'dashed', size = 1, alpha = 0.7) +\n\n  # Annotations\n  annotate('text', x = fc_threshold + 0.3, y = 1,\n          label = paste0('FC &gt; ', round(2^fc_threshold, 1), '×'),\n          angle = 90, vjust = -0.5, size = 3) +\n  annotate('text', x = -fc_threshold - 0.3, y = 1,\n          label = paste0('FC &lt; ', round(2^-fc_threshold, 1), '×'),\n          angle = 90, vjust = 1.5, size = 3) +\n  annotate('text', x = min(data$log2fc) + 1, y = neg_log10_p_threshold + 0.3,\n          label = paste0('p &lt; ', p_threshold), size = 3) +\n\n  labs(x = 'Log₂ Fold Change',\n       y = '-Log₁₀ (P-value)',\n       title = 'A. Volcano Plot: Differential Expression',\n       color = NULL, size = NULL, alpha = NULL) +\n\n  theme_classic(base_size = 12) +\n  theme(\n    plot.title = element_text(face = 'bold', size = 13, hjust = 0.5),\n    axis.title = element_text(face = 'bold', size = 12),\n    legend.position = c(0.85, 0.85),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\nggsave('volcano_plot_good.png', p_good, width = 8, height = 6, dpi = 300, bg = 'white')\n\n# === PLOT B: BAD (no FC threshold) ===\ndata_bad &lt;- data\ndata_bad$status_bad &lt;- ifelse(data_bad$p_value &lt; p_threshold,\n                              'p &lt; 0.05 (ignoring FC)',\n                              'Not significant')\n\np_bad &lt;- ggplot(data_bad, aes(x = log2fc, y = neg_log10_p, color = status_bad)) +\n  geom_point(aes(size = status_bad, alpha = status_bad)) +\n  scale_color_manual(values = c('p &lt; 0.05 (ignoring FC)' = '#E74C3C',\n                                'Not significant' = '#CCCCCC')) +\n  scale_size_manual(values = c('p &lt; 0.05 (ignoring FC)' = 3, 'Not significant' = 1.5)) +\n  scale_alpha_manual(values = c('p &lt; 0.05 (ignoring FC)' = 0.8, 'Not significant' = 0.5)) +\n\n  geom_hline(yintercept = neg_log10_p_threshold, linetype = 'dashed', size = 1, alpha = 0.7) +\n\n  labs(x = 'Log₂ Fold Change',\n       y = '-Log₁₀ (P-value)',\n       title = '❌ B. BAD: No Fold Change Threshold\\n(Includes small, insignificant changes)',\n       color = NULL, size = NULL, alpha = NULL) +\n\n  theme_classic(base_size = 12) +\n  theme(\n    plot.title = element_text(face = 'bold', size = 13, hjust = 0.5, color = 'red'),\n    axis.title = element_text(face = 'bold', size = 12),\n    legend.position = c(0.8, 0.85),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  )\n\nggsave('volcano_plot_bad.png', p_bad, width = 8, height = 6, dpi = 300, bg = 'white')\n\n# Print summary\ncat(\"Volcano Plot Summary:\\n\")\ncat(sprintf(\"Total genes: %d\\n\", n_genes))\ncat(sprintf(\"Significant up-regulated: %d\\n\", sum(data$status == 'Up-regulated')))\ncat(sprintf(\"Significant down-regulated: %d\\n\", sum(data$status == 'Down-regulated')))\ncat(sprintf(\"Not significant: %d\\n\", sum(data$status == 'Not significant')))\ncat(sprintf(\"\\nThresholds:\\n\"))\ncat(sprintf(\"- Fold change: ±%.2f× (log₂ ±%.1f)\\n\", 2^fc_threshold, fc_threshold))\ncat(sprintf(\"- P-value: %.2f (-log₁₀ = %.2f)\\n\", p_threshold, neg_log10_p_threshold))\n\n\n\nVolcano Plot Best Practices\nEssential elements:\n Log₂ fold change on x-axis (NOT linear fold change)\n -Log₁₀ p-value on y-axis (emphasizes small p-values)\n BOTH fold change AND p-value thresholds (two-criteria filtering)\n Clear color distinction (up vs. down vs. not significant)\n Threshold lines marked\n\nCommon thresholds:\n- Fold change: ±1 (log₂) = ±2× linear\n- P-value: 0.05 or adjusted p-value (FDR &lt; 0.05)\n\nAvoid:\n❌ Using only p-value threshold (includes biologically irrelevant small changes)\n❌ Linear fold change on x-axis (compresses negative values)\n❌ Unlabeled axes (reader can't interpret scale)\n❌ Missing threshold lines",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 7: Common Figure Types Deep Dive</span>"
    ]
  },
  {
    "objectID": "Chapter 7.html#pca-plots-and-dimensionality-reduction",
    "href": "Chapter 7.html#pca-plots-and-dimensionality-reduction",
    "title": "Chapter 7: Common Figure Types Deep Dive",
    "section": "7.3 PCA Plots and Dimensionality Reduction",
    "text": "7.3 PCA Plots and Dimensionality Reduction\n\nUnderstanding PCA Visualization\nPrincipal Component Analysis (PCA): Reduces high-dimensional data (e.g., thousands of genes) to 2-3 principal components for visualization.\nWhat PCA Shows:\nPurpose: Reveal overall structure in high-dimensional data\n- Clusters: Similar samples group together\n- Outliers: Samples that deviate from groups\n- Variance: How much variation each PC explains\n- Batch effects: Unwanted technical variation\n\nCommon in: Genomics, metabolomics, single-cell analysis\n\n\n\nCritical PCA Design Elements\nElement 1: Explained Variance\n✓ ALWAYS report variance explained by each PC:\n\"PC1 (45.3%), PC2 (18.7%)\"\n\nWhy it matters:\n- Low variance (e.g., PC1=12%) suggests weak signal or many factors\n- High variance (e.g., PC1=80%) suggests dominant pattern\n- Helps interpret biological meaning\nElement 2: Color Encoding\nColor by biological variable of interest:\n✓ Treatment group, tissue type, disease status, time point\n\nNOT by technical variables (unless investigating batch effects):\n❌ Sequencing batch, extraction date, plate number (unless that's the focus)\nElement 3: Confidence Ellipses\nShow group spread:\n✓ 95% confidence ellipses around groups\n✓ Convex hulls (enclose all points in group)\n\nReveals:\n- Within-group variability\n- Between-group separation\n- Overlap between conditions\n\nCode Example (Python) - Comprehensive PCA Plot:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom matplotlib.patches import Ellipse\nimport matplotlib.transforms as transforms\n\nnp.random.seed(42)\n\n# Generate synthetic high-dimensional data (e.g., gene expression)\nn_samples = 60\nn_features = 1000\n\n# Three groups with different patterns\ngroup_size = 20\n\n# Group 1: Control\ngroup1 = np.random.randn(group_size, n_features) * 0.5\ngroup1[:, :100] += 2  # Shift first 100 features\n\n# Group 2: Treatment A\ngroup2 = np.random.randn(group_size, n_features) * 0.6\ngroup2[:, 100:200] += 3  # Shift different features\n\n# Group 3: Treatment B\ngroup3 = np.random.randn(group_size, n_features) * 0.55\ngroup3[:, 200:300] += 2.5  # Yet different features\n\n# Combine data\nX = np.vstack([group1, group2, group3])\nlabels = np.array(['Control']*group_size + ['Treatment A']*group_size + ['Treatment B']*group_size)\n\n# Standardize features (critical for PCA)\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Perform PCA\npca = PCA(n_components=3)\nX_pca = pca.fit_transform(X_scaled)\n\n# Extract PC scores\npc1 = X_pca[:, 0]\npc2 = X_pca[:, 1]\npc3 = X_pca[:, 2]\n\n# Variance explained\nvar_explained = pca.explained_variance_ratio_ * 100\n\n# Create figure\nfig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n# === PANEL A: Basic PCA (PC1 vs PC2) ===\nax1 = axes[0, 0]\n\ncolors_map = {'Control': '#7F8C8D', 'Treatment A': '#3498DB', 'Treatment B': '#E74C3C'}\nmarkers_map = {'Control': 'o', 'Treatment A': 's', 'Treatment B': '^'}\n\nfor group in ['Control', 'Treatment A', 'Treatment B']:\n    mask = labels == group\n    ax1.scatter(pc1[mask], pc2[mask],\n               s=80, color=colors_map[group], marker=markers_map[group],\n               alpha=0.7, edgecolors='black', linewidths=1,\n               label=f'{group} (n={np.sum(mask)})')\n\nax1.set_xlabel(f'PC1 ({var_explained[0]:.1f}% variance)', fontsize=11, fontweight='bold')\nax1.set_ylabel(f'PC2 ({var_explained[1]:.1f}% variance)', fontsize=11, fontweight='bold')\nax1.set_title('A. Basic PCA Plot\\n(Without confidence regions)',\n             fontsize=12, fontweight='bold')\nax1.legend(loc='upper right', frameon=True, fontsize=10)\nax1.grid(alpha=0.3)\nax1.axhline(0, color='black', linewidth=0.8, alpha=0.3)\nax1.axvline(0, color='black', linewidth=0.8, alpha=0.3)\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# Panel label\nax1.text(-0.12, 1.05, 'A', transform=ax1.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\n# === PANEL B: PCA with 95% confidence ellipses ===\nax2 = axes[0, 1]\n\ndef confidence_ellipse(x, y, ax, n_std=2.0, facecolor='none', **kwargs):\n    \"\"\"Draw confidence ellipse\"\"\"\n    if x.size != y.size:\n        raise ValueError(\"x and y must be the same size\")\n\n    cov = np.cov(x, y)\n    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n\n    ell_radius_x = np.sqrt(1 + pearson)\n    ell_radius_y = np.sqrt(1 - pearson)\n    ellipse = Ellipse((0, 0), width=ell_radius_x * 2, height=ell_radius_y * 2,\n                     facecolor=facecolor, **kwargs)\n\n    scaleov[0, 0]) * n_std\n    mean_x = np.mean(x)\n\n    scale_y = np.sqrt(cov[1, 1]) * n_std\n    mean_y = np.mean(y)\n\n    transf = transforms.Affine2D() \\\n        .scale(scale_x, scale_y) \\\n        .translate(mean_x, mean_y)\n\n    ellipse.set_transform(transf + ax.transData)\n    return ax.add_patch(ellipse)\n\n# Plot points and ellipses\nfor group in ['Control', 'Treatment A', 'Treatment B']:\n    mask = labels == group\n    ax2.scatter(pc1[mask], pc2[mask],\n               s=80, color=colors_map[group], marker=markers_map[group],\n               alpha=0.7, edgecolors='black', linewidths=1,\n               label=f'{group} (n={np.sum(mask)})')\n\n    # Add 95% confidence ellipse\n    confidence_ellipse(pc1[mask], pc2[mask], ax2, n_std=2.0,\n                      edgecolor=colors_map[group], linewidth=2.5,\n                      facecolor=colors_map[group], alpha=0.1)\n\nax2.set_xlabel(f'PC1 ({var_explained[0]:.1f}% variance)', fontsize=11, fontweight='bold')\nax2.set_ylabel(f'PC2 ({var_explained[1]:.1f}% variance)', fontsize=11, fontweight='bold')\nax2.set_title('B. PCA with 95% Confidence Ellipses\\n(Shows group spread)',\n             fontsize=12, fontweight='bold')\nax2.legend(loc='upper right', frameon=True, fontsize=10)\nax2.grid(alpha=0.3)\nax2.axhline(0, color='black', linewidth=0.8, alpha=0.3)\nax2.axvline(0, color='black', linewidth=0.8, alpha=0.3)\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\n\nax2.text(-0.12, 1.05, 'B', transform=ax2.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\n# === PANEL C: Scree plot (variance explained) ===\nax3 = axes[1, 0]\n\nn_components = min(10, X_scaled.shape[1])\npca_full = PCA(n_components=n_components)\npca_full.fit(X_scaled)\n\ncomponents = range(1, n_components + 1)\nvar_exp = pca_full.explained_variance_ratio_ * 100\n\nax3.bar(components, var_exp, color='#3498DB', edgecolor='black', linewidth=1.5, alpha=0.7)\nax3.plot(components, var_exp, 'ro-', linewidth=2, markersize=8)\n\nax3.set_xlabel('Principal Component', fontsize=11, fontweight='bold')\nax3.set_ylabel('Variance Explained (%)', fontsize=11, fontweight='bold')\nax3.set_title('C. Scree Plot\\n(How many PCs to consider?)',\n             fontsize=12, fontweight='bold')\nax3.set_xticks(components)\nax3.grid(axis='y', alpha=0.3)\nax3.spines['top'].set_visible(False)\nax3.spines['right'].set_visible(False)\n\n# Add cumulative variance line\nax3_twin = ax3.twinx()\ncumvar = np.cumsum(var_exp)\nax3_twin.plot(components, cumvar, 'g^--', linewidth=2, markersize=8, alpha=0.7,\n             label='Cumulative')\nax3_twin.set_ylabel('Cumulative Variance (%)', fontsize=11, fontweight='bold', color='green')\nax3_twin.tick_params(axis='y', labelcolor='green')\nax3_twin.spines['top'].set_visible(False)\nax3_twin.legend(loc='lower right', frameon=True, fontsize=9)\n\nax3.text(-0.12, 1.05, 'C', transform=ax3.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\n# === PANEL D: 3D PCA (PC1 vs PC2 vs PC3) ===\nax4 = fig.add_subplot(2, 2, 4, projection='3d')\n\nfor group in ['Control', 'Treatment A', 'Treatment B']:\n    mask = labels == group\n    ax4.scatter(pc1[mask], pc2[mask], pc3[mask],\n               s=80, color=colors_map[group], marker=markers_map[group],\n               alpha=0.7, edgecolors='black', linewidths=1,\n               label=f'{group}')\n\nax4.set_xlabel(f'PC1 ({var_explained[0]:.1f}%)', fontsize=10, fontweight='bold')\nax4.set_ylabel(f'PC2 ({var_explained[1]:.1f}%)', fontsize=10, fontweight='bold')\nax4.set_zlabel(f'PC3 ({var_explained[2]:.1f}%)', fontsize=10, fontweight='bold')\nax4.set_title('D. 3D PCA Plot\\n(PC1-PC2-PC3)', fontsize=12, fontweight='bold', pad=20)\nax4.legend(loc='upper left', frameon=True, fontsize=9)\n\nax4.text2D(-0.12, 1.05, 'D', transform=ax4.transAxes,\n          fontsize=16, fontweight='bold', va='top')\n\nplt.tight_layout()\nplt.savefig('pca_comprehensive.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\n# Print summary\nprint(\"PCA Analysis Summary:\")\nprint(f\"Total samples: {n_samples}\")\nprint(f\"Total features: {n_features}\")\nprint(f\"\\nVariance explained:\")\nfor i, var in enumerate(var_explained[:5]):\n    print(f\"  PC{i+1}: {var:.2f}%\")\nprint(f\"\\nCumulative variance (first 3 PCs): {np.sum(var_explained[:3]):.2f}%\")\nCode Example (R) - Comprehensive PCA Plot:\nlibrary(ggplot2)\nlibrary(ggrepel)\nlibrary(patchwork)\nlibrary(ggforce)  # For stat_ellipse\n\nset.seed(42)\n\n# Generate synthetic data\nn_samples &lt;- 60\nn_features &lt;- 1000\ngroup_size &lt;- 20\n\n# Three groups\ngroup1 &lt;- matrix(rnorm(group_size * n_features, 0, 0.5), group_size, n_features)\ngroup1[, 1:100] &lt;- group1[, 1:100] + 2\n\ngroup2 &lt;- matrix(rnorm(group_size * n_features, 0, 0.6), group_size, n_features)\ngroup2[, 101:200] &lt;- group2[, 101:200] + 3\n\ngroup3 &lt;- matrix(rnorm(group_size * n_features, 0, 0.55), group_size, n_features)\ngroup3[, 201:300] &lt;- group3[, 201:300] + 2.5\n\nX &lt;- rbind(group1, group2, group3)\nlabels &lt;- factor(rep(c('Control', 'Treatment A', 'Treatment B'), each = group_size))\n\n# Standardize and perform PCA\nX_scaled &lt;- scale(X)\npca_result &lt;- prcomp(X_scaled, center = FALSE, scale. = FALSE)\n\n# Extract PC scores\npca_data &lt;- data.frame(\n  PC1 = pca_result$x[, 1],\n  PC2 = pca_result$x[, 2],\n  PC3 = pca_result$x[, 3],\n  Group = labels\n)\n\n# Variance explained\nvar_explained &lt;- summary(pca_result)$importance[2, ] * 100\n\n# Colors\ncolors &lt;- c('Control' = '#7F8C8D',\n            'Treatment A' = '#3498DB',\n            'Treatment B' = '#E74C3C')\n\n# === PANEL A: Basic PCA ===\np_a &lt;- ggplot(pca_data, aes(x = PC1, y = PC2, color = Group, shape = Group)) +\n  geom_point(size = 4, alpha = 0.7) +\n  scale_color_manual(values = colors) +\n  scale_shape_manual(values = c(16, 15, 17)) +  # circle, square, triangle\n\n  geom_hline(yintercept = 0, color = 'black', size = 0.5, alpha = 0.3) +\n  geom_vline(xintercept = 0, color = 'black', size = 0.5, alpha = 0.3) +\n\n  labs(x = sprintf('PC1 (%.1f%% variance)', var_explained[1]),\n       y = sprintf('PC2 (%.1f%% variance)', var_explained[2]),\n       title = 'A. Basic PCA Plot\\n(Without confidence regions)',\n       color = NULL, shape = NULL) +\n\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(face = 'bold', size = 12, hjust = 0.5),\n    axis.title = element_text(face = 'bold'),\n    legend.position = c(0.85, 0.15),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3),\n    plot.tag = element_text(size = 16, face = 'bold')\n  )\n\n# === PANEL B: PCA with confidence ellipses ===\np_b &lt;- ggplot(pca_data, aes(x = PC1, y = PC2, color = Group, fill = Group, shape = Group)) +\n  geom_point(size = 4, alpha = 0.7) +\n  stat_ellipse(aes(fill = Group), geom = \"polygon\", alpha = 0.1, level = 0.95, size = 1.5) +\n\n  scale_color_manual(values = colors) +\n  scale_fill_manual(values = colors) +\n  scale_shape_manual(values = c(16, 15, 17)) +\n\n  geom_hline(yintercept = 0, color = 'black', size = 0.5, alpha = 0.3) +\n  geom_vline(xintercept = 0, color = 'black', size = 0.5, alpha = 0.3) +\n\n  labs(x = sprintf('PC1 (%.1f%% variance)', var_explained[1]),\n       y = sprintf('PC2 (%.1f%% variance)', var_explained[2]),\n       title = 'B. PCA with 95% Confidence Ellipses\\n(Shows group spread)',\n       color = NULL, fill = NULL, shape = NULL) +\n\n  guides(fill = guide_legend(override.aes = list(alpha = 0.3))) +\n\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(face = 'bold', size = 12, hjust = 0.5),\n    axis.title = element_text(face = 'bold'),\n    legend.position = c(0.85, 0.15),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3),\n    plot.tag = element_text(size = 16, face = 'bold')\n  )\n\n# === PANEL C: Scree plot ===\nscree_data &lt;- data.frame(\n  PC = 1:10,\n  Variance = var_explained[1:10],\n  Cumulative = cumsum(var_explained[1:10])\n)\n\np_c &lt;- ggplot(scree_data, aes(x = PC, y = Variance)) +\n  geom_bar(stat = 'identity', fill = '#3498DB', color = 'black', size = 1, alpha = 0.7) +\n  geom_line(color = 'red', size = 1.5) +\n  geom_point(color = 'red', size = 3) +\n\n  labs(x = 'Principal Component',\n       y = 'Variance Explained (%)',\n       title = 'C. Scree Plot\\n(How many PCs to consider?)') +\n\n  scale_x_continuous(breaks = 1:10) +\n\n  theme_classic(base_size = 11) +\n  theme(\n    plot.title = element_text(face = 'bold', size = 12, hjust = 0.5),\n    axis.title = element_text(face = 'bold'),\n    panel.grid.major.y = element_line(color = 'gray90', size = 0.3),\n    plot.tag = element_text(size = 16, face = 'bold')\n  )\n\n# Add cumulative line\np_c &lt;- p_c +\n  geom_line(aes(y = Cumulative), color = 'darkgreen', size = 1.5, linetype = 'dashed') +\n  geom_point(aes(y = Cumulative), color = 'darkgreen', size = 3, shape = 17)\n\n# Combine plots\ncombined &lt;- (p_a | p_b) / (p_c | plot_spacer()) +\n  plot_annotation(tag_levels = 'A') &\n  theme(plot.tag = element_text(size = 16, face = 'bold'))\n\nggsave('pca_comprehensive.png', combined, width = 14, height = 12, dpi = 300, bg = 'white')\n\n# Print summary\ncat(\"PCA Analysis Summary:\\n\")\ncat(sprintf(\"Total samples: %d\\n\", n_samples))\ncat(sprintf(\"Total features: %d\\n\", n_features))\ncat(\"\\nVariance explained:\\n\")\nfor(i in 1:5) {\n  cat(sprintf(\"  PC%d: %.2f%%\\n\", i, var_explained[i]))\n}\ncat(sprintf(\"\\nCumulative variance (first 3 PCs): %.2f%%\\n\", sum(var_explained[1:3])))\n\n\n\nPCA Plot Best Practices Checklist\nEssential elements:\n Variance explained in axis labels: \"PC1 (45.3% variance)\"\n Clear color/shape encoding by biological variable\n Confidence ellipses or convex hulls for groups\n Grid lines at x=0, y=0 (show PC center)\n Legend with sample sizes per group\n\nInterpretation aids:\n Scree plot (show how many PCs capture variance)\n Loadings plot (which features drive separation) — optional\n 3D plot if PC3 explains &gt;10% variance\n\nAvoid:\n❌ No variance explained reported (reader can't assess importance)\n❌ Coloring by technical batch without justification\n❌ Truncated axes that hide outliers\n❌ Using PCA on non-normalized data (scale features first!)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 7: Common Figure Types Deep Dive</span>"
    ]
  },
  {
    "objectID": "Chapter 7.html#survival-curves-kaplan-meier-plots",
    "href": "Chapter 7.html#survival-curves-kaplan-meier-plots",
    "title": "Chapter 7: Common Figure Types Deep Dive",
    "section": "7.4 Survival Curves (Kaplan-Meier Plots)",
    "text": "7.4 Survival Curves (Kaplan-Meier Plots)\n\nUnderstanding Survival Analysis Visualization\nKaplan-Meier (KM) curve: Shows probability of survival over time, accounting for censored data (subjects lost to follow-up or still alive at study end).\nCommon in: Clinical trials, cancer research, reliability engineering\nKey components:\n1. Survival probability (y-axis): 0 to 1 (or 0% to 100%)\n2. Time (x-axis): Days, months, years since baseline\n3. Step function: Drops at each event (death, failure)\n4. Censored data markers: Tick marks for subjects without event\n5. Confidence bands: Uncertainty around survival estimate\n6. Log-rank test: Statistical comparison between groups\n\nCode Example (Python) - Kaplan-Meier Survival Curve:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom lifelines import KaplanMeierFitter\nfrom lifelines.statistics import logrank_test\n\nnp.random.seed(42)\n\n# Simulate survival data for two treatment groups\nn_control = 50\nn_treatment = 50\n\n# Control group: Worse survival\ntime_control = np.random.exponential(scale=12, size=n_control)  # Months\nevent_control = np.random.rand(n_control) &lt; 0.7  # 70% events (deaths)\n\n# Treatment group: Better survival\ntime_treatment = np.random.exponential(scale=20, size=n_treatment)  # Months\nevent_treatment = np.random.rand(n_treatment) &lt; 0.5  # 50% events\n\n# Fit Kaplan-Meier curves\nkmf_control = KaplanMeierFitter()\nkmf_control.fit(time_control, event_control, label='Control')\n\nkmf_treatment = KaplanMeierFitter()\nkmf_treatment.fit(time_treatment, event_treatment, label='Treatment')\n\n# Statistical test\nresults = logrank_test(time_control, time_treatment,\n                       event_control, event_treatment)\np_value = results.p_value\n\n# Create figure\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# === PANEL A: Good KM curve ===\nax1 = axes[0]\n\n# Plot survival curves\nkmf_control.plot_survival_function(ax=ax1, ci_show=True,\n                                   color='#7F8C8D', linewidth=3,\n                                   alpha=0.8)\nkmf_treatment.plot_survival_function(ax=ax1, ci_show=True,\n                                     color='#E74C3C', linewidth=3,\n                                     alpha=0.8)\n\n# Add censored markers (tick marks)\n# Note: lifelines plots these automatically as '+' markers\n\n# Formatting\nax1.set_xlabel('Time (months)', fontsize=12, fontweight='bold')\nax1.set_ylabel('Survival Probability', fontsize=12, fontweight='bold')\nax1.set_title('✓ Kaplan-Meier Survival Curves\\n(With confidence bands)',\n             fontsize=13, fontweight='bold', color='green')\nax1.set_ylim(0, 1.05)\nax1.set_xlim(0, None)\nax1.grid(alpha=0.3)\nax1.legend(loc='lower left', frameon=True, fontsize=11,\n          title=f'Log-rank p = {p_value:.3f}')\n\n# Add median survival lines\nmedian_control = kmf_control.median_survival_time_\nmedian_treatment = kmf_treatment.median_survival_time_\n\nax1.axhline(0.5, color='black', linestyle='--', linewidth=1, alpha=0.5)\nax1.axvline(median_control, color='#7F8C8D', linestyle=':', linewidth=2, alpha=0.7)\nax1.axvline(median_treatment, color='#E74C3C', linestyle=':', linewidth=2, alpha=0.7)\n\n# Annotate median survival\nax1.text(median_control + 1, 0.52, f'Median: {median_control:.1f} mo',\n        fontsize=9, color='#7F8C8D', fontweight='bold')\nax1.text(median_treatment + 1, 0.47, f'Median: {median_treatment:.1f} mo',\n        fontsize=9, color='#E74C3C', fontweight='bold')\n\n# Number at risk table (simplified annotation)\nax1.text(0.02, 0.05,\n        f'Numbers at risk:\\nControl: {n_control} patients\\nTreatment: {n_treatment} patients',\n        transform=ax1.transAxes, fontsize=9, va='bottom',\n        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# Panel label\nax1.text(-0.12, 1.05, 'A', transform=ax1.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\n# === PANEL B: Common mistakes ===\nax2 = axes[1]\n\n# Plot without confidence bands (less informative)\nkmf_control.plot_survival_function(ax=ax2, ci_show=False,\n                                   color='#7F8C8D', linewidth=3,\n                                   alpha=0.8)\nkmf_treatment.plot_survival_function(ax=ax2, ci_show=False,\n                                     color='#E74C3C', linewidth=3,\n                                     alpha=0.8)\n\nax2.set_xlabel('Time (months)', fontsize=12, fontweight='bold')\nax2.set_ylabel('Survival Probability', fontsize=12, fontweight='bold')\nax2.set_title('❌ Common Mistakes:\\n(No confidence bands, no statistics)',\n             fontsize=13, fontweight='bold', color='red')\nax2.set_ylim(0, 1.05)\nax2.set_xlim(0, None)\nax2.grid(alpha=0.3)\nax2.legend(loc='lower left', frameon=True, fontsize=11)\n\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\n\nax2.text(-0.12, 1.05, 'B', transform=ax2.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\nplt.tight_layout()\nplt.savefig('kaplan_meier_survival.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\n# Print summary statistics\nprint(\"Survival Analysis Summary:\")\nprint(f\"\\nControl group (n={n_control}):\")\nprint(f\"  Median survival: {median_control:.2f} months\")\nprint(f\"  Events (deaths): {np.sum(event_control)} ({np.sum(event_control)/n_control*100:.1f}%)\")\n\nprint(f\"\\nTreatment group (n={n_treatment}):\")\nprint(f\"  Median survival: {median_treatment:.2f} months\")\nprint(f\"  Events (deaths): {np.sum(event_treatment)} ({np.sum(event_treatment)/n_treatment*100:.1f}%)\")\n\nprint(f\"\\nLog-rank test:\")\nprint(f\"  p-value: {p_value:.4f}\")\nif p_value &lt; 0.05:\n    print(\"  Conclusion: Significant difference between groups\")\nelse:\n    print(\"  Conclusion: No significant difference between groups\")\n\n\n\nSurvival Curve Best Practices\nEssential elements:\n Y-axis: 0 to 1 (or 0% to 100%), starts at 1.0\n X-axis: Starts at 0 (baseline)\n Step function (NOT smooth curve)\n Confidence bands (95% CI) shaded or as dashed lines\n Censored data marked (tick marks or '+' symbols)\n Log-rank test p-value reported\n Median survival times noted (optional lines)\n Number at risk table below plot (or in legend)\n\nCaption must include:\n- Sample size per group\n- Number of events (deaths) per group\n- Follow-up duration\n- Statistical test used (log-rank test)\n\nAvoid:\n❌ Smooth interpolation (survival probability drops only at events)\n❌ No confidence bands (hides uncertainty)\n❌ Missing censored data indicators\n❌ No statistical comparison (log-rank test)\n❌ Y-axis not starting at 1.0",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 7: Common Figure Types Deep Dive</span>"
    ]
  },
  {
    "objectID": "Chapter 7.html#roc-curves-and-performance-metrics",
    "href": "Chapter 7.html#roc-curves-and-performance-metrics",
    "title": "Chapter 7: Common Figure Types Deep Dive",
    "section": "7.5 ROC Curves and Performance Metrics",
    "text": "7.5 ROC Curves and Performance Metrics\n\nUnderstanding ROC (Receiver Operating Characteristic) Curves\nPurpose: Evaluate classifier or diagnostic test performance across all possible decision thresholds.\nWhat ROC shows:\nX-axis: False Positive Rate (FPR) = 1 - Specificity\nY-axis: True Positive Rate (TPR) = Sensitivity\n\nKey metrics:\n- AUC (Area Under Curve): Overall discriminative ability\n  * AUC = 1.0: Perfect classifier\n  * AUC = 0.5: Random guessing (diagonal line)\n  * AUC &lt; 0.5: Worse than random (inverse predictions)\n\nCommon in: Machine learning, diagnostics, biomarker validation\n\n\n\nCritical ROC Design Elements\nElement 1: Diagonal Reference Line\n✓ ALWAYS include diagonal (y=x) line representing random chance\n→ Shows baseline performance\n→ Curves above = better than random\n→ Curves below = worse than random (possibly inverted predictions)\nElement 2: AUC with Confidence Interval\n✓ Report: AUC = 0.85 (95% CI: 0.78-0.91)\n❌ NEVER report AUC alone without CI\n→ CI indicates uncertainty/sample size effect\nElement 3: Optimal Operating Point\nMark optimal threshold on curve:\n- Balance sensitivity and specificity\n- Often chosen by Youden's index: max(Sensitivity + Specificity - 1)\n- Or based on clinical cost/benefit considerations\n\nCode Example (Python) - ROC Curve Analysis:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom scipy import stats\n\nnp.random.seed(42)\n\n# Simulate binary classification results\nn_samples = 500\n\n# True labels (0 = negative, 1 = positive)\ny_true = np.random.binomial(1, 0.4, n_samples)\n\n# Predicted probabilities (imperfect classifier)\n# Positive cases have higher scores on average\ny_scores_good = np.where(y_true == 1,\n                         np.random.beta(7, 3, n_samples),  # Higher scores\n                         np.random.beta(3, 7, n_samples))  # Lower scores\n\ny_scores_poor = np.where(y_true == 1,\n                         np.random.beta(5, 5, n_samples),  # Only slightly higher\n                         np.random.beta(5, 5, n_samples))  # Similar distribution\n\n# Calculate ROC curves\nfpr_good, tpr_good, thresholds_good = roc_curve(y_true, y_scores_good)\nfpr_poor, tpr_poor, thresholds_poor = roc_curve(y_true, y_scores_poor)\n\n# Calculate AUC\nauc_good = auc(fpr_good, tpr_good)\nauc_poor = auc(fpr_poor, tpr_poor)\n\n# Bootstrap confidence intervals for AUC (simplified)\ndef bootstrap_auc(y_true, y_scores, n_bootstrap=1000):\n    aucs = []\n    n = len(y_true)\n    for _ in range(n_bootstrap):\n        idx = np.random.choice(n, n, replace=True)\n        try:\n            aucs.append(roc_auc_score(y_true[idx], y_scores[idx]))\n        except:\n            continue\n    return np.percentile(aucs, [2.5, 97.5])\n\nci_good = bootstrap_auc(y_true, y_scores_good, 1000)\nci_poor = bootstrap_auc(y_true, y_scores_poor, 1000)\n\n# Find optimal threshold (Youden's index)\nj_good = tpr_good - fpr_good\noptimal_idx_good = np.argmax(j_good)\noptimal_threshold_good = thresholds_good[optimal_idx_good]\noptimal_fpr_good = fpr_good[optimal_idx_good]\noptimal_tpr_good = tpr_good[optimal_idx_good]\n\n# Create figure\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# === PANEL A: Good ROC curve ===\nax1 = axes[0]\n\n# Plot diagonal (random chance)\nax1.plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.5, label='Random (AUC=0.50)')\n\n# Plot good classifier\nax1.plot(fpr_good, tpr_good, color='#E74C3C', linewidth=3,\n        label=f'Good Classifier (AUC={auc_good:.3f}, 95% CI: {ci_good[0]:.3f}-{ci_good[1]:.3f})')\n\n# Fill area under curve\nax1.fill_between(fpr_good, tpr_good, alpha=0.2, color='#E74C3C')\n\n# Mark optimal operating point\nax1.plot(optimal_fpr_good, optimal_tpr_good, 'bo', markersize=12,\n        label=f'Optimal threshold = {optimal_threshold_good:.3f}')\nax1.annotate(f'Sensitivity: {optimal_tpr_good:.3f}\\nSpecificity: {1-optimal_fpr_good:.3f}',\n            xy=(optimal_fpr_good, optimal_tpr_good),\n            xytext=(optimal_fpr_good + 0.15, optimal_tpr_good - 0.15),\n            fontsize=9, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n            arrowprops=dict(arrowstyle='-&gt;', lw=1.5))\n\n# Formatting\nax1.set_xlabel('False Positive Rate (1 - Specificity)', fontsize=12, fontweight='bold')\nax1.set_ylabel('True Positive Rate (Sensitivity)', fontsize=12, fontweight='bold')\nax1.set_title('✓ A. ROC Curve: Good Classifier\\n(AUC &gt;&gt; 0.5)',\n             fontsize=13, fontweight='bold', color='green')\nax1.set_xlim(-0.05, 1.05)\nax1.set_ylim(-0.05, 1.05)\nax1.set_aspect('equal')\nax1.legend(loc='lower right', frameon=True, fontsize=10)\nax1.grid(alpha=0.3)\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# Panel label\nax1.text(-0.12, 1.05, 'A', transform=ax1.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\n# === PANEL B: Comparison with poor classifier ===\nax2 = axes[1]\n\n# Plot diagonal\nax2.plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.5, label='Random (AUC=0.50)')\n\n# Plot good classifier\nax2.plot(fpr_good, tpr_good, color='#E74C3C', linewidth=3,\n        label=f'Good Classifier (AUC={auc_good:.3f})')\n\n# Plot poor classifier\nax2.plot(fpr_poor, tpr_poor, color='#7F8C8D', linewidth=3,\n        label=f'Poor Classifier (AUC={auc_poor:.3f})')\n\n# Statistical comparison annotation\nax2.text(0.5, 0.2, f'ΔAUC = {auc_good - auc_poor:.3f}',\n        ha='center', fontsize=11, fontweight='bold',\n        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n\n# Formatting\nax2.set_xlabel('False Positive Rate (1 - Specificity)', fontsize=12, fontweight='bold')\nax2.set_ylabel('True Positive Rate (Sensitivity)', fontsize=12, fontweight='bold')\nax2.set_title('B. ROC Comparison:\\nGood vs. Poor Classifier',\n             fontsize=13, fontweight='bold')\nax2.set_xlim(-0.05, 1.05)\nax2.set_ylim(-0.05, 1.05)\nax2.set_aspect('equal')\nax2.legend(loc='lower right', frameon=True, fontsize=10)\nax2.grid(alpha=0.3)\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\n\nax2.text(-0.12, 1.05, 'B', transform=ax2.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\nplt.tight_layout()\nplt.savefig('roc_curve_analysis.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\n# Print summary\nprint(\"ROC Curve Analysis Summary:\")\nprint(f\"\\nGood Classifier:\")\nprint(f\"  AUC: {auc_good:.4f}\")\nprint(f\"  95% CI: [{ci_good[0]:.4f}, {ci_good[1]:.4f}]\")\nprint(f\"  Optimal threshold: {optimal_threshold_good:.4f}\")\nprint(f\"  At optimal: Sensitivity={optimal_tpr_good:.3f}, Specificity={1-optimal_fpr_good:.3f}\")\n\nprint(f\"\\nPoor Classifier:\")\nprint(f\"  AUC: {auc_poor:.4f}\")\nprint(f\"  95% CI: [{ci_poor[0]:.4f}, {ci_poor[1]:.4f}]\")\n\nprint(f\"\\nInterpretation:\")\nif auc_good &gt; 0.9:\n    print(\"  Good classifier: Excellent discrimination\")\nelif auc_good &gt; 0.8:\n    print(\"  Good classifier: Good discrimination\")\nelif auc_good &gt; 0.7:\n    print(\"  Good classifier: Acceptable discrimination\")\nelse:\n    print(\"  Good classifier: Poor discrimination\")\nCode Example (R) - ROC Curve Analysis:\nlibrary(ggplot2)\nlibrary(pROC)\nlibrary(patchwork)\n\nset.seed(42)\n\n# Simulate data\nn_samples &lt;- 500\ny_true &lt;- rbinom(n_samples, 1, 0.4)\n\n# Good classifier\ny_scores_good &lt;- ifelse(y_true == 1,\n                       rbeta(n_samples, 7, 3),\n                       rbeta(n_samples, 3, 7))\n\n# Poor classifier\ny_scores_poor &lt;- ifelse(y_true == 1,\n                       rbeta(n_samples, 5, 5),\n                       rbeta(n_samples, 5, 5))\n\n# Calculate ROC curves using pROC\nroc_good &lt;- roc(y_true, y_scores_good, ci = TRUE)\nroc_poor &lt;- roc(y_true, y_scores_poor, ci = TRUE)\n\n# Extract data for plotting\nroc_good_df &lt;- data.frame(\n  fpr = 1 - roc_good$specificities,\n  tpr = roc_good$sensitivities,\n  classifier = 'Good'\n)\n\nroc_poor_df &lt;- data.frame(\n  fpr = 1 - roc_poor$specificities,\n  tpr = roc_poor$sensitivities,\n  classifier = 'Poor'\n)\n\n# Find optimal threshold (Youden's index)\noptimal_idx &lt;- which.max(roc_good$sensitivities + roc_good$specificities - 1)\noptimal_point &lt;- data.frame(\n  fpr = 1 - roc_good$specificities[optimal_idx],\n  tpr = roc_good$sensitivities[optimal_idx],\n  threshold = roc_good$thresholds[optimal_idx]\n)\n\n# === PANEL A: Good ROC curve ===\np_a &lt;- ggplot(roc_good_df, aes(x = fpr, y = tpr)) +\n  # Diagonal reference line\n  geom_abline(intercept = 0, slope = 1, linetype = 'dashed', size = 1.5, alpha = 0.5) +\n\n  # ROC curve\n  geom_line(color = '#E74C3C', size = 2) +\n  geom_ribbon(aes(ymin = 0, ymax = tpr), fill = '#E74C3C', alpha = 0.2) +\n\n  # Optimal point\n  geom_point(data = optimal_point, aes(x = fpr, y = tpr),\n            color = 'blue', size = 5, shape = 19) +\n  annotate('text', x = optimal_point$fpr + 0.15, y = optimal_point$tpr - 0.12,\n          label = sprintf('Optimal\\nSensitivity: %.3f\\nSpecificity: %.3f',\n                         optimal_point$tpr, 1 - optimal_point$fpr),\n          size = 3, hjust = 0,\n          lineheight = 0.9) +\n\n  annotate('segment', x = optimal_point$fpr, y = optimal_point$tpr,\n          xend = optimal_point$fpr + 0.14, yend = optimal_point$tpr - 0.08,\n          arrow = arrow(length = unit(0.3, 'cm')), size = 1) +\n\n  # AUC annotation\n  annotate('text', x = 0.6, y = 0.25,\n          label = sprintf('AUC = %.3f\\n95%% CI: [%.3f, %.3f]',\n                         roc_good$auc, roc_good$ci[1], roc_good$ci[3]),\n          size = 4, fontface = 'bold',\n          hjust = 0, lineheight = 1.2) +\n\n  labs(x = 'False Positive Rate (1 - Specificity)',\n       y = 'True Positive Rate (Sensitivity)',\n       title = '✓ A. ROC Curve: Good Classifier\\n(AUC &gt;&gt; 0.5)') +\n\n  coord_fixed(ratio = 1, xlim = c(0, 1), ylim = c(0, 1)) +\n\n  theme_classic(base_size = 12) +\n  theme(\n    plot.title = element_text(face = 'bold', size = 13, hjust = 0.5, color = 'darkgreen'),\n    axis.title = element_text(face = 'bold', size = 12),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3),\n    plot.tag = element_text(size = 16, face = 'bold')\n  )\n\n# === PANEL B: Comparison ===\nroc_combined &lt;- rbind(roc_good_df, roc_poor_df)\n\np_b &lt;- ggplot(roc_combined, aes(x = fpr, y = tpr, color = classifier)) +\n  # Diagonal reference line\n  geom_abline(intercept = 0, slope = 1, linetype = 'dashed', size = 1.5, alpha = 0.5,\n             show.legend = FALSE) +\n\n  # ROC curves\n  geom_line(size = 2) +\n\n  scale_color_manual(values = c('Good' = '#E74C3C', 'Poor' = '#7F8C8D'),\n                    labels = c(sprintf('Good Classifier (AUC=%.3f)', roc_good$auc),\n                              sprintf('Poor Classifier (AUC=%.3f)', roc_poor$auc))) +\n\n  # Delta AUC annotation\n  annotate('text', x = 0.5, y = 0.2,\n          label = sprintf('ΔAUC = %.3f', roc_good$auc - roc_poor$auc),\n          size = 4.5, fontface = 'bold',\n          hjust = 0.5) +\n  annotate('rect', xmin = 0.35, xmax = 0.65, ymin = 0.15, ymax = 0.25,\n          fill = 'yellow', alpha = 0.3) +\n\n  labs(x = 'False Positive Rate (1 - Specificity)',\n       y = 'True Positive Rate (Sensitivity)',\n       title = 'B. ROC Comparison:\\nGood vs. Poor Classifier',\n       color = NULL) +\n\n  coord_fixed(ratio = 1, xlim = c(0, 1), ylim = c(0, 1)) +\n\n  theme_classic(base_size = 12) +\n  theme(\n    plot.title = element_text(face = 'bold', size = 13, hjust = 0.5),\n    axis.title = element_text(face = 'bold', size = 12),\n    legend.position = c(0.65, 0.15),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3),\n    plot.tag = element_text(size = 16, face = 'bold')\n  )\n\n# Combine plots\ncombined &lt;- p_a | p_b\ncombined &lt;- combined +\n  plot_annotation(tag_levels = 'A') &\n  theme(plot.tag = element_text(size = 16, face = 'bold'))\n\nggsave('roc_curve_analysis.png', combined, width = 14, height = 6, dpi = 300, bg = 'white')\n\n# Print summary\ncat(\"ROC Curve Analysis Summary:\\n\")\ncat(sprintf(\"\\nGood Classifier:\\n\"))\ncat(sprintf(\"  AUC: %.4f\\n\", roc_good$auc))\ncat(sprintf(\"  95%% CI: [%.4f, %.4f]\\n\", roc_good$ci[1], roc_good$ci[3]))\ncat(sprintf(\"  Optimal threshold: %.4f\\n\", optimal_point$threshold))\ncat(sprintf(\"  At optimal: Sensitivity=%.3f, Specificity=%.3f\\n\",\n           optimal_point$tpr, 1 - optimal_point$fpr))\n\ncat(sprintf(\"\\nPoor Classifier:\\n\"))\ncat(sprintf(\"  AUC: %.4f\\n\", roc_poor$auc))\ncat(sprintf(\"  95%% CI: [%.4f, %.4f]\\n\", roc_poor$ci[1], roc_poor$ci[3]))\n\ncat(sprintf(\"\\nInterpretation:\\n\"))\nif (roc_good$auc &gt; 0.9) {\n  cat(\"  Good classifier: Excellent discrimination\\n\")\n} else if (roc_good$auc &gt; 0.8) {\n  cat(\"  Good classifier: Good discrimination\\n\")\n} else if (roc_good$auc &gt; 0.7) {\n  cat(\"  Good classifier: Acceptable discrimination\\n\")\n} else {\n  cat(\"  Good classifier: Poor discrimination\\n\")\n}\n\n\n\nROC Curve Best Practices Checklist\nEssential elements:\n Diagonal reference line (random chance, AUC=0.5)\n AUC value with 95% confidence interval\n Both axes 0 to 1, equal aspect ratio (square plot)\n Optimal operating point marked (if applicable)\n Sample size stated (n positives, n negatives)\n\nInterpretation guide:\nAUC = 0.90-1.00: Excellent\nAUC = 0.80-0.90: Good\nAUC = 0.70-0.80: Fair\nAUC = 0.60-0.70: Poor\nAUC = 0.50-0.60: Fail (barely better than random)\n\nCommon mistakes to avoid:\n❌ No diagonal reference line\n❌ AUC reported without confidence interval\n❌ Non-square aspect ratio (distorts curve appearance)\n❌ Missing sample size\n❌ Comparing AUCs without statistical test\n❌ No indication of optimal threshold\n\nEnd of Chapter 7 Core Content\nSummary: Common Scientific Figure Types\n\n\n\n\n\n\n\n\n\nFigure Type\nBest For\nKey Elements\nCommon Pitfalls\n\n\n\n\nHeatmap\nMatrix data, patterns\nColormap choice, clustering, colorbar\nRainbow colormap, asymmetric diverging scale\n\n\nVolcano Plot\nDifferential analysis\nLog2FC, -log10(p), thresholds\nNo FC threshold, missing significance lines\n\n\nPCA Plot\nDimensionality reduction\nVariance explained, confidence ellipses\nNo variance reported, wrong color encoding\n\n\nSurvival Curve\nTime-to-event data\nStep function, CI bands, log-rank test\nSmooth curve, no CI, missing censored markers\n\n\nROC Curve\nClassifier performance\nDiagonal line, AUC+CI, optimal point\nNo reference line, AUC without CI",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 7: Common Figure Types Deep Dive</span>"
    ]
  },
  {
    "objectID": "Chapter 8.html",
    "href": "Chapter 8.html",
    "title": "Chapter 8: Specialized Field Visualizations",
    "section": "",
    "text": "8.1 Microscopy Images: Best Practices for Publication",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 8: Specialized Field Visualizations</span>"
    ]
  },
  {
    "objectID": "Chapter 8.html#microscopy-images-best-practices-for-publication",
    "href": "Chapter 8.html#microscopy-images-best-practices-for-publication",
    "title": "Chapter 8: Specialized Field Visualizations",
    "section": "",
    "text": "Unique Challenges in Microscopy Imaging\nUnlike other scientific figures, microscopy images are: - Raw data (not statistical summaries) - Subject to strict ethical guidelines (no manipulation allowed) - High-resolution (often &gt;10 MB per image) - Multi-channel (fluorescence, confocal, etc.)\nCritical ethical principle: &gt; Any adjustment (brightness, contrast) must be applied uniformly to all images in a comparison set. Selective editing is scientific misconduct.\n\n\n\nEssential Microscopy Figure Elements\nElement 1: Scale Bar\n✓ MANDATORY for all microscopy images\nSize: Should represent standard unit (e.g., 10 µm, 50 µm, 100 µm)\nPlacement: Bottom-left or bottom-right corner\nColor: White on dark images, black on light images\nWidth: Bold enough to be visible (2-3 pixels minimum)\n\n❌ NEVER submit microscopy without scale bars\n→ Reader cannot interpret size, magnification, or spatial relationships\nElement 2: Channel Labels\nFor multi-channel fluorescence:\n✓ Label each channel clearly\n✓ Use channel name (not just color): \"DAPI (nuclei)\" not just \"Blue\"\n✓ Include wavelength if relevant: \"GFP (488 nm)\"\n\nMerged images:\n✓ Show individual channels + merge\n✓ Label merge clearly: \"Merge\" or \"Overlay\"\nElement 3: Image Processing Documentation\nIn Methods section, MUST document:\n- Microscope type and model\n- Objective lens magnification and numerical aperture (NA)\n- Camera/detector specifications\n- Acquisition settings (exposure, gain, binning)\n- ALL post-processing applied (brightness, contrast, gamma)\n- Software used for processing\n\nIf images are cropped, state: \"Representative cropped regions shown\"\n\nCode Example (Python) - Adding Scale Bars to Microscopy Images:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Rectangle\nfrom matplotlib_scalebar.scalebar import ScaleBar\n\n# Simulate microscopy image (grayscale)\nnp.random.seed(42)\nimage = np.random.rand(512, 512) * 0.3  # Background noise\n\n# Add some \"cells\" (bright circular regions)\nfor _ in range(15):\n    x, y = np.random.randint(50, 462, 2)\n    r = np.random.randint(20, 40)\n    Y, X = np.ogrid[:512, :512]\n    mask = (X - x)**2 + (Y - y)**2 &lt;= r**2\n    image[mask] += np.random.rand() * 0.5 + 0.3\n\n# Clip to 0-1 range\nimage = np.clip(image, 0, 1)\n\n# Image metadata\npixel_size_um = 0.5  # 0.5 µm per pixel\nscale_bar_um = 50  # 50 µm scale bar\n\nfig, axes = plt.subplots(1, 3, figsize=(16, 5))\n\n# === PANEL A: BAD - No scale bar ===\nax1 = axes[0]\nax1.imshow(image, cmap='gray', interpolation='nearest')\nax1.axis('off')\nax1.set_title('❌ BAD: No Scale Bar\\n(Cannot determine size)',\n             fontsize=12, fontweight='bold', color='red', pad=10)\n\n# === PANEL B: GOOD - Manual scale bar ===\nax2 = axes[1]\nax2.imshow(image, cmap='gray', interpolation='nearest')\nax2.axis('off')\n\n# Calculate scale bar length in pixels\nscale_bar_pixels = scale_bar_um / pixel_size_um\n\n# Add scale bar as rectangle\nscale_bar_height = 5  # pixels\nscale_bar_x = 20  # pixels from left\nscale_bar_y = 512 - 30  # pixels from bottom\n\nrect = Rectangle((scale_bar_x, scale_bar_y), scale_bar_pixels, scale_bar_height,\n                linewidth=0, edgecolor='none', facecolor='white')\nax2.add_patch(rect)\n\n# Add scale bar label\nax2.text(scale_bar_x + scale_bar_pixels/2, scale_bar_y - 10,\n        f'{scale_bar_um} µm',\n        color='white', fontsize=10, fontweight='bold', ha='center', va='top')\n\nax2.set_title('✓ GOOD: Manual Scale Bar\\n(Clear size reference)',\n             fontsize=12, fontweight='bold', color='green', pad=10)\n\n# === PANEL C: BEST - Using matplotlib-scalebar library ===\nax3 = axes[2]\nax3.imshow(image, cmap='gray', interpolation='nearest')\nax3.axis('off')\n\n# Add scalebar using library (more professional)\nscalebar = ScaleBar(pixel_size_um, \"um\", length_fraction=0.2,\n                   location='lower left', box_alpha=0.5, color='white',\n                   font_properties={'size': 10, 'weight': 'bold'})\nax3.add_artist(scalebar)\n\nax3.set_title('✓ BEST: Professional Scale Bar\\n(Automated, consistent)',\n             fontsize=12, fontweight='bold', color='green', pad=10)\n\n# Add panel labels\nfor i, ax in enumerate(axes):\n    ax.text(0.02, 0.98, chr(65+i), transform=ax.transAxes,\n           fontsize=16, fontweight='bold', color='white', va='top',\n           bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))\n\nplt.tight_layout()\nplt.savefig('microscopy_scale_bars.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Microscopy scale bar examples created\")\nprint(f\"Image size: {image.shape[0]} × {image.shape[1]} pixels\")\nprint(f\"Pixel size: {pixel_size_um} µm/pixel\")\nprint(f\"Scale bar: {scale_bar_um} µm = {scale_bar_pixels} pixels\")\nCode Example (Python) - Multi-Channel Fluorescence Imaging:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Simulate 3-channel fluorescence image\nsize = 256\n\n# Channel 1: DAPI (nuclei, blue)\ndapi = np.zeros((size, size))\nfor _ in range(30):\n    x, y = np.random.randint(20, size-20, 2)\n    r = np.random.randint(8, 15)\n    Y, X = np.ogrid[:size, :size]\n    mask = (X - x)**2 + (Y - y)**2 &lt;= r**2\n    dapi[mask] = np.random.rand() * 0.8 + 0.2\n\n# Channel 2: GFP (cytoplasm, green)\ngfp = np.zeros((size, size))\nfor _ in range(25):\n    x, y = np.random.randint(15, size-15, 2)\n    r = np.random.randint(15, 25)\n    Y, X = np.ogrid[:size, :size]\n    mask = (X - x)**2 + (Y - y)**2 &lt;= r**2\n    gfp[mask] = np.random.rand() * 0.6 + 0.1\n\n# Channel 3: RFP (marker, red)\nrfp = np.zeros((size, size))\nfor _ in range(20):\n    x, y = np.random.randint(20, size-20, 2)\n    r = np.random.randint(5, 10)\n    Y, X = np.ogrid[:size, :size]\n    mask = (X - x)**2 + (Y - y)**2 &lt;= r**2\n    rfp[mask] = np.random.rand() * 0.9 + 0.1\n\n# Create RGB composite\nmerged = np.zeros((size, size, 3))\nmerged[:, :, 2] = dapi  # Blue channel\nmerged[:, :, 1] = gfp   # Green channel\nmerged[:, :, 0] = rfp   # Red channel\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\n# Individual channels\nchannel_data = [\n    (dapi, 'Blues', 'DAPI (Nuclei)', '#3498DB'),\n    (gfp, 'Greens', 'GFP (Cytoplasm)', '#27AE60'),\n    (rfp, 'Reds', 'RFP (Marker)', '#E74C3C')\n]\n\nfor i, (data, cmap, title, color) in enumerate(channel_data):\n    ax = axes[0, i]\n    ax.imshow(data, cmap=cmap, interpolation='nearest')\n    ax.axis('off')\n    ax.set_title(title, fontsize=12, fontweight='bold', color=color, pad=10)\n\n    # Add channel wavelength\n    wavelengths = ['405 nm', '488 nm', '561 nm']\n    ax.text(0.5, 0.02, wavelengths[i], transform=ax.transAxes,\n           fontsize=9, ha='center', color='white', fontweight='bold',\n           bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))\n\n    # Panel label\n    ax.text(0.02, 0.98, chr(65+i), transform=ax.transAxes,\n           fontsize=16, fontweight='bold', color='white', va='top',\n           bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))\n\n# Merged image\nax_merge = axes[1, 0]\nax_merge.imshow(merged, interpolation='nearest')\nax_merge.axis('off')\nax_merge.set_title('D. Merge (All Channels)', fontsize=12, fontweight='bold', pad=10)\nax_merge.text(0.02, 0.98, 'D', transform=ax_merge.transAxes,\n             fontsize=16, fontweight='bold', color='white', va='top',\n             bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))\n\n# Merge with only DAPI + GFP\nmerge_dg = np.zeros((size, size, 3))\nmerge_dg[:, :, 2] = dapi\nmerge_dg[:, :, 1] = gfp\nax_dg = axes[1, 1]\nax_dg.imshow(merge_dg, interpolation='nearest')\nax_dg.axis('off')\nax_dg.set_title('E. DAPI + GFP', fontsize=12, fontweight='bold', pad=10)\nax_dg.text(0.02, 0.98, 'E', transform=ax_dg.transAxes,\n          fontsize=16, fontweight='bold', color='white', va='top',\n          bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))\n\n# Quantification example\nax_quant = axes[1, 2]\ncategories = ['DAPI+', 'GFP+', 'RFP+', 'Colocalized']\ncounts = [30, 25, 20, 15]\ncolors_bar = ['#3498DB', '#27AE60', '#E74C3C', '#F39C12']\n\nbars = ax_quant.bar(range(len(categories)), counts, color=colors_bar,\n                    edgecolor='black', linewidth=1.5, width=0.6)\nax_quant.set_xticks(range(len(categories)))\nax_quant.set_xticklabels(categories, rotation=45, ha='right', fontsize=10)\nax_quant.set_ylabel('Cell Count', fontsize=11, fontweight='bold')\nax_quant.set_title('F. Quantification', fontsize=12, fontweight='bold', pad=10)\nax_quant.spines['top'].set_visible(False)\nax_quant.spines['right'].set_visible(False)\nax_quant.grid(axis='y', alpha=0.3)\n\n# Add counts on bars\nfor bar, count in zip(bars, counts):\n    height = bar.get_height()\n    ax_quant.text(bar.get_x() + bar.get_width()/2., height + 1,\n                 f'{count}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n\nax_quant.text(0.02, 0.98, 'F', transform=ax_quant.transAxes,\n             fontsize=16, fontweight='bold', va='top')\n\nplt.tight_layout()\nplt.savefig('fluorescence_multichannel.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Multi-channel fluorescence example created\")\n\n\n\nMicroscopy Figure Best Practices Checklist\nEssential elements (mandatory):\n Scale bar on ALL images (size + unit label)\n Consistent scale bars across comparison images\n Channel labels for fluorescence (name + wavelength)\n Panel labels (A, B, C...)\n Image acquisition settings in Methods\n\nImage processing (ethical requirements):\n All adjustments documented in Methods\n Brightness/contrast applied uniformly to all comparison images\n No selective editing (e.g., removing unwanted cells)\n Original unprocessed images available if requested\n Linear adjustments only (no gamma correction without justification)\n\nRepresentative images:\n State in caption: \"Representative images shown\"\n State how many images/fields were analyzed (n)\n Include quantification (if applicable)\n\nCommon mistakes to avoid:\n❌ Missing scale bars\n❌ Inconsistent scale bars (different sizes in comparison panels)\n❌ Unlabeled fluorescence channels\n❌ Selective brightness/contrast adjustments\n❌ No quantification (single image without statistics)\n❌ Aspect ratio distortion (stretched/compressed images)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 8: Specialized Field Visualizations</span>"
    ]
  },
  {
    "objectID": "Chapter 8.html#western-blots-and-gel-images",
    "href": "Chapter 8.html#western-blots-and-gel-images",
    "title": "Chapter 8: Specialized Field Visualizations",
    "section": "8.2 Western Blots and Gel Images",
    "text": "8.2 Western Blots and Gel Images\n\nSpecial Considerations for Gel/Blot Images\nWestern blots and gels are semi-quantitative data, NOT just images.\nStrict rules: 1. Show full lanes (no lane splicing without disclosure) 2. No background removal beyond uniform linear adjustments 3. Molecular weight markers must be visible 4. Loading controls required (e.g., β-actin, GAPDH)\n\n\n\nWestern Blot Figure Structure\nStandard layout:\nPanel A: Target protein blot\n- All lanes visible\n- Molecular weight marker labeled\n- Sample order clear\n\nPanel B: Loading control blot\n- Same samples, same order\n- Housekeeping protein (β-actin, GAPDH, tubulin)\n- Confirms equal loading\n\nPanel C: Quantification\n- Bar chart of normalized band intensities\n- Target / Loading control ratio\n- Error bars (from biological replicates)\n- Statistical comparisons\n\nCode Example (Python) - Simulated Western Blot Figure:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Rectangle\n\nnp.random.seed(42)\n\n# Simulate gel/blot images\ndef generate_blot_lane(target_level, loading_level=1.0, width=30, height=200):\n    \"\"\"Generate simulated Western blot lane\"\"\"\n    lane = np.zeros((height, width))\n\n    # Target protein band (variable intensity)\n    target_pos = 80  # Position from top\n    target_width = 25\n    for i in range(target_width):\n        y_start = max(0, target_pos - i)\n        y_end = min(height, target_pos + i)\n        intensity = target_level * np.exp(-i/5) + np.random.rand(1)[0] * 0.1\n        lane[y_start:y_end, :] = np.maximum(lane[y_start:y_end, :], intensity)\n\n    # Loading control band (consistent intensity)\n    loading_pos = 150\n    loading_width = 20\n    for i in range(loading_width):\n        y_start = max(0, loading_pos - i)\n        y_end = min(height, loading_pos + i)\n        intensity = loading_level * np.exp(-i/4) + np.random.rand(1)[0] * 0.05\n        lane[y_start:y_end, :] = np.maximum(lane[y_start:y_end, :], intensity)\n\n    return lane\n\n# Generate blot with 5 lanes\nn_lanes = 5\nlane_width = 30\nlane_spacing = 10\ntotal_width = n_lanes * lane_width + (n_lanes - 1) * lane_spacing\n\n# Target protein levels (control vs treatments)\ntarget_levels = [0.5, 0.5, 0.8, 1.2, 1.5]  # Relative to control\nlabels = ['Ctrl 1', 'Ctrl 2', 'Low', 'Med', 'High']\n\n# Create blot image\nblot_image = np.zeros((200, total_width))\nlane_positions = []\n\nfor i, target_level in enumerate(target_levels):\n    lane = generate_blot_lane(target_level, loading_level=1.0)\n    x_start = i * (lane_width + lane_spacing)\n    x_end = x_start + lane_width\n    blot_image[:, x_start:x_end] = lane\n    lane_positions.append((x_start, x_end))\n\n# Quantification data\nnormalized_intensities = np.array(target_levels)\nerrors = np.random.rand(n_lanes) * 0.15\n\n# Create figure\nfig = plt.figure(figsize=(14, 10))\ngs = fig.add_gridspec(3, 2, height_ratios=[1, 1, 1.2], hspace=0.3, wspace=0.3)\n\n# === PANEL A: Target protein blot ===\nax_target = fig.add_subplot(gs[0, :])\nax_target.imshow(blot_image, cmap='gray_r', aspect='auto', interpolation='nearest')\nax_target.axis('off')\nax_target.set_title('A. Target Protein (e.g., phospho-ERK)',\n                   fontsize=12, fontweight='bold', pad=10)\n\n# Add lane labels\nfor i, (x_start, x_end) in enumerate(lane_positions):\n    x_mid = (x_start + x_end) / 2\n    ax_target.text(x_mid, blot_image.shape[0] + 10, labels[i],\n                  ha='center', fontsize=9, fontweight='bold')\n\n# Add molecular weight marker\nax_target.text(-15, 80, '50 kDa', fontsize=8, ha='right', va='center')\nax_target.plot([-10, -5], [80, 80], 'k-', linewidth=2)\n\n# Panel label\nax_target.text(0.02, 0.98, 'A', transform=ax_target.transAxes,\n              fontsize=16, fontweight='bold', va='top')\n\n# === PANEL B: Loading control blot ===\n# Generate loading control image (consistent across lanes)\nloading_control = np.zeros((200, total_width))\nfor i in range(n_lanes):\n    lane = generate_blot_lane(0.3, loading_level=0.8)  # Consistent loading\n    x_start = i * (lane_width + lane_spacing)\n    x_end = x_start + lane_width\n    loading_control[:, x_start:x_end] = lane\n\nax_loading = fig.add_subplot(gs[1, :])\nax_loading.imshow(loading_control, cmap='gray_r', aspect='auto', interpolation='nearest')\nax_loading.axis('off')\nax_loading.set_title('B. Loading Control (β-actin)',\n                    fontsize=12, fontweight='bold', pad=10)\n\n# Add lane labels\nfor i, (x_start, x_end) in enumerate(lane_positions):\n    x_mid = (x_start + x_end) / 2\n    ax_loading.text(x_mid, loading_control.shape[0] + 10, labels[i],\n                   ha='center', fontsize=9, fontweight='bold')\n\n# Add molecular weight marker\nax_loading.text(-15, 150, '42 kDa', fontsize=8, ha='right', va='center')\nax_loading.plot([-10, -5], [150, 150], 'k-', linewidth=2)\n\nax_loading.text(0.02, 0.98, 'B', transform=ax_loading.transAxes,\n               fontsize=16, fontweight='bold', va='top')\n\n# === PANEL C: Quantification ===\nax_quant = fig.add_subplot(gs[2, 0])\n\ncategories = ['Control', 'Control', 'Low Dose', 'Med Dose', 'High Dose']\nx_pos = np.arange(len(categories))\ncolors_quant = ['#7F8C8D', '#7F8C8D', '#3498DB', '#3498DB', '#E74C3C']\n\nbars = ax_quant.bar(x_pos, normalized_intensities, yerr=errors,\n                   color=colors_quant, edgecolor='black', linewidth=1.5,\n                   capsize=8, width=0.6, error_kw={'linewidth': 2})\n\nax_quant.set_xticks(x_pos)\nax_quant.set_xticklabels(categories, rotation=45, ha='right', fontsize=10)\nax_quant.set_ylabel('Normalized Intensity\\n(Target / Loading Control)',\n                   fontsize=11, fontweight='bold')\nax_quant.set_title('C. Quantification (n=3 biological replicates)',\n                  fontsize=12, fontweight='bold')\nax_quant.set_ylim(0, 2.0)\nax_quant.grid(axis='y', alpha=0.3)\nax_quant.spines['top'].set_visible(False)\nax_quant.spines['right'].set_visible(False)\n\n# Add statistical comparisons\nax_quant.plot([0.5, 4], [1.8, 1.8], 'k-', linewidth=1.5)\nax_quant.text(2.25, 1.85, '**', ha='center', fontsize=14, fontweight='bold')\n\nax_quant.text(0.02, 0.98, 'C', transform=ax_quant.transAxes,\n             fontsize=16, fontweight='bold', va='top')\n\n# === PANEL D: Representative image note ===\nax_note = fig.add_subplot(gs[2, 1])\nax_note.axis('off')\n\nnote_text = \"\"\"\nD. Experimental Details\n\n• Representative blot from 3\n  independent experiments\n\n• Quantification based on 3\n  biological replicates\n\n• Statistical test: One-way ANOVA\n  with Dunnett's post-hoc\n\n• ** p &lt; 0.01 vs. Control\n\n• Blot image: Linear adjustments\n  only, applied uniformly\n\n• Full unprocessed blots available\n  in supplementary materials\n\"\"\"\n\nax_note.text(0.1, 0.9, note_text, transform=ax_note.transAxes,\n            fontsize=9, va='top', family='monospace',\n            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n\nax_note.text(0.02, 0.98, 'D', transform=ax_note.transAxes,\n            fontsize=16, fontweight='bold', va='top')\n\nplt.suptitle('Western Blot Analysis: Publication-Ready Format',\n            fontsize=14, fontweight='bold', y=0.98)\n\nplt.savefig('western_blot_figure.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Western blot figure created\")\nprint(\"Key components:\")\nprint(\"  - Target protein blot (Panel A)\")\nprint(\"  - Loading control blot (Panel B)\")\nprint(\"  - Quantification with statistics (Panel C)\")\nprint(\"  - Methods documentation (Panel D)\")\n\n\n\nWestern Blot Best Practices Checklist\nImage integrity (mandatory):\n Show FULL lanes (no splicing without clear indication)\n Molecular weight markers visible and labeled\n Loading control included (same sample order)\n All lanes from SAME gel/membrane (if comparing)\n Linear adjustments only, applied uniformly\n Original unprocessed images available\n\nQuantification (required for claims):\n Densitometry performed on multiple replicates (n≥3)\n Normalized to loading control\n Error bars shown (SEM or SD specified)\n Statistical test stated\n \"Representative image\" noted in caption\n\nCaption must include:\n Protein names and antibodies used\n Molecular weights\n Sample sizes and replicates\n How bands were quantified\n Statistical methods\n\nEthical violations (NEVER do):\n❌ Splice lanes from different gels without disclosure\n❌ Selectively adjust brightness/contrast for specific lanes\n❌ Remove background non-uniformly\n❌ Duplicate lanes\n❌ Clone/copy-paste bands",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 8: Specialized Field Visualizations</span>"
    ]
  },
  {
    "objectID": "Chapter 8.html#flow-cytometry-plots",
    "href": "Chapter 8.html#flow-cytometry-plots",
    "title": "Chapter 8: Specialized Field Visualizations",
    "section": "8.3 Flow Cytometry Plots",
    "text": "8.3 Flow Cytometry Plots\n\nStandard Flow Cytometry Display Formats\nCommon plot types: 1. Histogram: Single parameter distribution 2. Dot plot: Two-parameter comparison (most common) 3. Contour plot: Density representation 4. Overlay histogram: Compare multiple samples\n\n\n\nFlow Cytometry Figure Essentials\nElement 1: Gating Strategy\nShow the gating hierarchy:\n1. Forward scatter (FSC) vs. Side scatter (SSC) → Cell population\n2. Doublet discrimination → Single cells\n3. Viability gate → Live cells\n4. Marker-positive gates → Populations of interest\n\n✓ Show representative gates with percentages\nElement 2: Axes and Scales\nX/Y axes must show:\n- Parameter name (e.g., \"CD4-FITC\")\n- Scale type (linear vs. log)\n- Units if applicable\n\nMost fluorescence: Logarithmic scale\nScatter parameters: Linear scale\nElement 3: Quadrant/Gate Statistics\nEach gate/quadrant should show:\n- Percentage of parent population\n- Absolute count (if relevant)\n- Gate name/definition\n\nCode Example (Python) - Flow Cytometry Figure:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Rectangle, Polygon\n\nnp.random.seed(42)\n\n# Simulate flow cytometry data (2 populations)\nn_cells = 10000\n\n# Population 1: CD4+ cells (high CD4, low CD8)\ncd4_pos = np.random.lognormal(mean=3.5, sigma=0.5, size=4000)\ncd8_neg = np.random.lognormal(mean=1.5, sigma=0.5, size=4000)\n\n# Population 2: CD8+ cells (low CD4, high CD8)\ncd4_neg = np.random.lognormal(mean=1.5, sigma=0.5, size=3000)\ncd8_pos = np.random.lognormal(mean=3.5, sigma=0.5, size=3000)\n\n# Population 3: Double negative (low both)\ncd4_dn = np.random.lognormal(mean=1.5, sigma=0.5, size=2000)\ncd8_dn = np.random.lognormal(mean=1.5, sigma=0.5, size=2000)\n\n# Population 4: Double positive (high both) - rare\ncd4_dp = np.random.lognormal(mean=3.5, sigma=0.5, size=1000)\ncd8_dp = np.random.lognormal(mean=3.5, sigma=0.5, size=1000)\n\n# Combine all populations\ncd4_all = np.concatenate([cd4_pos, cd4_neg, cd4_dn, cd4_dp])\ncd8_all = np.concatenate([cd8_neg, cd8_pos, cd8_dn, cd8_dp])\n\n# Log transform for display\ncd4_log = np.log10(cd4_all)\ncd8_log = np.log10(cd8_all)\n\n# Define gates (in log space)\ncd4_threshold = 2.5  # 10^2.5\ncd8_threshold = 2.5\n\n# Calculate quadrant percentages\nq1 = np.sum((cd4_log &lt; cd4_threshold) & (cd8_log &gt; cd8_threshold)) / len(cd4_log) * 100  # CD4- CD8+\nq2 = np.sum((cd4_log &gt; cd4_threshold) & (cd8_log &gt; cd8_threshold)) / len(cd4_log) * 100  # CD4+ CD8+\nq3 = np.sum((cd4_log &lt; cd4_threshold) & (cd8_log &lt; cd8_threshold)) / len(cd4_log) * 100  # CD4- CD8-\nq4 = np.sum((cd4_log &gt; cd4_threshold) & (cd8_log &lt; cd8_threshold)) / len(cd4_log) * 100  # CD4+ CD8-\n\n# Create figure\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# === PANEL A: Dot plot (standard) ===\nax1 = axes[0, 0]\n\n# Plot cells as scatter\nax1.scatter(cd4_log, cd8_log, s=1, alpha=0.3, c='#3498DB', rasterized=True)\n\n# Add gates (cross-hairs)\nax1.axhline(cd8_threshold, color='red', linewidth=2, linestyle='--')\nax1.axvline(cd4_threshold, color='red', linewidth=2, linestyle='--')\n\n# Add quadrant percentages\nax1.text(1.5, 3.5, f'CD4⁻ CD8⁺\\n{q1:.1f}%', fontsize=10, fontweight='bold',\n        ha='center', va='center',\n        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\nax1.text(3.5, 3.5, f'CD4⁺ CD8⁺\\n{q2:.1f}%', fontsize=10, fontweight='bold',\n        ha='center', va='center',\n        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\nax1.text(1.5, 1.5, f'CD4⁻ CD8⁻\\n{q3:.1f}%', fontsize=10, fontweight='bold',\n        ha='center', va='center',\n        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\nax1.text(3.5, 1.5, f'CD4⁺ CD8⁻\\n{q4:.1f}%', fontsize=10, fontweight='bold',\n        ha='center', va='center',\n        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n\nax1.set_xlabel('CD4-FITC (log₁₀)', fontsize=11, fontweight='bold')\nax1.set_ylabel('CD8-PE (log₁₀)', fontsize=11, fontweight='bold')\nax1.set_title('A. Dot Plot with Quadrant Gates', fontsize=12, fontweight='bold')\nax1.set_xlim(0.5, 4.5)\nax1.set_ylim(0.5, 4.5)\nax1.grid(alpha=0.3)\n\n# Panel label\nax1.text(0.02, 0.98, 'A', transform=ax1.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\n# === PANEL B: Contour plot (density) ===\nax2 = axes[0, 1]\n\n# Create 2D histogram for contour\nfrom scipy.stats import gaussian_kde\n\n# Subsample for KDE (faster computation)\nsample_idx = np.random.choice(len(cd4_log), size=2000, replace=False)\ncd4_sample = cd4_log[sample_idx]\ncd8_sample = cd8_log[sample_idx]\n\n# Create grid\nx_grid = np.linspace(0.5, 4.5, 100)\ny_grid = np.linspace(0.5, 4.5, 100)\nX, Y = np.meshgrid(x_grid, y_grid)\npositions = np.vstack([X.ravel(), Y.ravel()])\n\n# Calculate density\nkernel = gaussian_kde([cd4_sample, cd8_sample])\nZ = kernel(positions).reshape(X.shape)\n\n# Plot contours\ncontours = ax2.contour(X, Y, Z, levels=8, colors='#3498DB', linewidths=1.5)\nax2.contourf(X, Y, Z, levels=8, cmap='Blues', alpha=0.6)\n\n# Add gates\nax2.axhline(cd8_threshold, color='red', linewidth=2, linestyle='--')\nax2.axvline(cd4_threshold, color='red', linewidth=2, linestyle='--')\n\n# Add quadrant percentages\nax2.text(3.5, 1.5, f'{q4:.1f}%', fontsize=11, fontweight='bold',\n        ha='center', va='center',\n        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n\nax2.set_xlabel('CD4-FITC (log₁₀)', fontsize=11, fontweight='bold')\nax2.set_ylabel('CD8-PE (log₁₀)', fontsize=11, fontweight='bold')\nax2.set_title('B. Contour Plot (Density)', fontsize=12, fontweight='bold')\nax2.set_xlim(0.5, 4.5)\nax2.set_ylim(0.5, 4.5)\n\nax2.text(0.02, 0.98, 'B', transform=ax2.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\n# === PANEL C: Histogram overlay (CD4 expression) ===\nax3 = axes[1, 0]\n\n# Separate populations\ncd4_pos_cells = cd4_log[cd4_log &gt; cd4_threshold]\ncd4_neg_cells = cd4_log[cd4_log &lt;= cd4_threshold]\n\nax3.hist(cd4_neg_cells, bins=50, alpha=0.6, color='#7F8C8D',\n        edgecolor='black', linewidth=0.5, label=f'CD4⁻ ({q3+q1:.1f}%)')\nax3.hist(cd4_pos_cells, bins=50, alpha=0.6, color='#E74C3C',\n        edgecolor='black', linewidth=0.5, label=f'CD4⁺ ({q4+q2:.1f}%)')\n\n# Add gate threshold\nax3.axvline(cd4_threshold, color='red', linewidth=2, linestyle='--')\n\nax3.set_xlabel('CD4-FITC (log₁₀)', fontsize=11, fontweight='bold')\nax3.set_ylabel('Cell Count', fontsize=11, fontweight='bold')\nax3.set_title('C. Histogram Overlay: CD4 Expression', fontsize=12, fontweight='bold')\nax3.legend(loc='upper right', frameon=True, fontsize=10)\nax3.grid(axis='y', alpha=0.3)\nax3.spines['top'].set_visible(False)\nax3.spines['right'].set_visible(False)\n\nax3.text(0.02, 0.98, 'C', transform=ax3.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\n# === PANEL D: Quantification bar chart ===\nax4 = axes[1, 1]\n\npopulations = ['CD4⁺\\nCD8⁻', 'CD4⁻\\nCD8⁺', 'CD4⁺\\nCD8⁺', 'CD4⁻\\nCD8⁻']\npercentages = [q4, q1, q2, q3]\ncolors_pop = ['#E74C3C', '#3498DB', '#9B59B6', '#7F8C8D']\n\nbars = ax4.bar(range(len(populations)), percentages, color=colors_pop,\n              edgecolor='black', linewidth=1.5, width=0.6)\n\n# Add percentage labels on bars\nfor bar, pct in zip(bars, percentages):\n    height = bar.get_height()\n    ax4.text(bar.get_x() + bar.get_width()/2., height + 1,\n            f'{pct:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n\nax4.set_xticks(range(len(populations)))\nax4.set_xticklabels(populations, fontsize=10, fontweight='bold')\nax4.set_ylabel('% of Total Cells', fontsize=11, fontweight='bold')\nax4.set_title('D. Population Frequencies', fontsize=12, fontweight='bold')\nax4.set_ylim(0, max(percentages) + 10)\nax4.grid(axis='y', alpha=0.3)\nax4.spines['top'].set_visible(False)\nax4.spines['right'].set_visible(False)\n\nax4.text(0.02, 0.98, 'D', transform=ax4.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\nplt.suptitle(f'Flow Cytometry Analysis (n = {len(cd4_log):,} cells)',\n            fontsize=14, fontweight='bold', y=0.98)\n\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.savefig('flow_cytometry_figure.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Flow cytometry figure created\")\nprint(f\"Total cells analyzed: {len(cd4_log):,}\")\nprint(f\"\\nPopulation frequencies:\")\nprint(f\"  CD4+ CD8- (Helper T cells): {q4:.2f}%\")\nprint(f\"  CD4- CD8+ (Cytotoxic T cells): {q1:.2f}%\")\nprint(f\"  CD4+ CD8+ (Double positive): {q2:.2f}%\")\nprint(f\"  CD4- CD8- (Double negative): {q3:.2f}%\")\n\n\n\nFlow Cytometry Best Practices Checklist\nPlot requirements:\n Axes labeled with marker name and fluorophore (e.g., \"CD4-FITC\")\n Scale type indicated (linear or logarithmic)\n Gates clearly visible (contrasting color, typically red)\n Population percentages shown in each gate/quadrant\n Total cell count stated (n = X cells)\n\nGating strategy:\n Show sequential gating steps (if applicable)\n Define gating criteria in Methods or caption\n Include negative/isotype controls (in supplement if not main figure)\n State how gates were determined (fluorescence minus one, isotype, etc.)\n\nCaption requirements:\n Antibody clones and fluorophores\n Gating strategy summary\n Number of cells analyzed\n Number of biological replicates\n Representative or pooled data (specify)\n\nCommon mistakes:\n❌ Unlabeled axes or missing fluorophore names\n❌ No scale indication (linear vs. log unclear)\n❌ Gates without percentages\n❌ No compensation information in Methods\n❌ Comparing plots with different scales",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 8: Specialized Field Visualizations</span>"
    ]
  },
  {
    "objectID": "Chapter 8.html#phylogenetic-trees",
    "href": "Chapter 8.html#phylogenetic-trees",
    "title": "Chapter 8: Specialized Field Visualizations",
    "section": "8.4 Phylogenetic Trees",
    "text": "8.4 Phylogenetic Trees\n\nTree Visualization Essentials\nCommon in: Evolutionary biology, microbiology, bioinformatics\nKey components:\n1. Branch lengths: Represent evolutionary distance\n2. Node labels: Bootstrap values (confidence)\n3. Tip labels: Species/strain/sequence names\n4. Scale bar: Units of substitution or time\n5. Root: Outgroup or midpoint\n\nCode Example (Python) - Phylogenetic Tree:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import FancyBboxPatch\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\nnp.random.seed(42)\n\n# Simulate sequence distance matrix (phylogenetic distances)\nspecies = ['Human', 'Chimp', 'Gorilla', 'Orangutan', 'Macaque',\n          'Mouse', 'Rat', 'Dog', 'Cat', 'Cow']\nn_species = len(species)\n\n# Create distance matrix (lower triangle)\ndistances = np.random.rand(n_species, n_species) * 0.5\ndistances = (distances + distances.T) / 2  # Make symmetric\nnp.fill_diagonal(distances, 0)\n\n# Adjust to reflect known phylogeny (primates closer to each other)\n# Primates (0-4): closer\ndistances[0:5, 0:5] *= 0.3\n# Rodents (5-6): closer\ndistances[5:7, 5:7] *= 0.3\n# Carnivores (7-9): closer\ndistances[7:9, 7:9] *= 0.3\n\n# Perform hierarchical clustering\nZ = linkage(distances[np.triu_indices(n_species, k=1)], method='average')\n\n# Create figure\nfig, axes = plt.subplots(1, 2, figsize=(14, 8))\n\n# === PANEL A: Standard dendrogram ===\nax1 = axes[0]\n\ndendro = dendrogram(Z, labels=species, orientation='right', ax=ax1,\n                   color_threshold=0.5, above_threshold_color='#3498DB')\n\nax1.set_xlabel('Evolutionary Distance (substitutions/site)', fontsize=11, fontweight='bold')\nax1.set_title('A. Phylogenetic Tree\\n(UPGMA clustering)',\n             fontsize=12, fontweight='bold')\nax1.grid(axis='x', alpha=0.3)\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# Add scale bar\nscale_bar_length = 0.1\nax1.plot([0, scale_bar_length], [-1, -1], 'k-', linewidth=3)\nax1.text(scale_bar_length/2, -1.5, '0.1 substitutions/site',\n        ha='center', fontsize=9, fontweight='bold')\n\n# Add bootstrap values (simulated) at major nodes\n# In real analysis, these come from resampling\nnode_positions = [(0.15, 3.5, 95), (0.12, 6.5, 88), (0.25, 7.5, 78)]\nfor x, y, boot in node_positions:\n    ax1.text(x, y, str(boot), fontsize=9, fontweight='bold',\n            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n\n# Highlight clades\n# Primates\nprimate_y = [i for i, sp in enumerate(dendro['ivl']) if sp in ['Human', 'Chimp', 'Gorilla', 'Orangutan', 'Macaque']]\nif primate_y:\n    y_min, y_max = min(primate_y), max(primate_y)\n    rect = FancyBboxPatch((-0.02, y_min-0.5), 0.02, y_max-y_min+1,\n                         boxstyle=\"round,pad=0.02\",\n                         edgecolor='#E74C3C', facecolor='none',\n                         linewidth=2, transform=ax1.transData)\n    ax1.add_patch(rect)\n    ax1.text(-0.04, (y_min+y_max)/2, 'Primates', rotation=90, va='center',\n            fontsize=9, fontweight='bold', color='#E74C3C')\n\nax1.text(0.02, 0.98, 'A', transform=ax1.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\n# === PANEL B: Circular tree (radial layout) ===\nax2 = axes[1]\nax2.set_aspect('equal')\nax2.axis('off')\n\n# Simplified circular tree representation\nn_leaves = len(species)\nangles = np.linspace(0, 2*np.pi, n_leaves, endpoint=False)\n\n# Plot leaf labels\nradius = 1.0\nfor i, (angle, sp) in enumerate(zip(angles, species)):\n    x = radius * np.cos(angle)\n    y = radius * np.sin(angle)\n\n    # Leaf node\n    ax2.plot(x, y, 'o', markersize=8, color='#3498DB')\n\n    # Label\n    angle_deg = np.degrees(angle)\n    if -90 &lt;= angle_deg &lt;= 90:\n        ha = 'left'\n        rotation = angle_deg\n        x_text = x * 1.15\n    else:\n        ha = 'right'\n        rotation = angle_deg + 180\n        x_text = x * 1.15\n\n    ax2.text(x_text, y * 1.15, sp, ha=ha, va='center',\n            rotation=rotation, fontsize=9, fontweight='bold')\n\n# Draw simplified branches (radial from center)\nfor i, angle in enumerate(angles):\n    x_inner = 0.3 * np.cos(angle)\n    y_inner = 0.3 * np.sin(angle)\n    x_outer = radius * np.cos(angle)\n    y_outer = radius * np.sin(angle)\n    ax2.plot([0, x_inner], [0, y_inner], 'k-', linewidth=1, alpha=0.5)\n    ax2.plot([x_inner, x_outer], [y_inner, y_outer], color='#3498DB', linewidth=2)\n\n# Central node\nax2.plot(0, 0, 'ko', markersize=10)\n\n# Title\nax2.set_title('B. Circular Phylogenetic Tree\\n(Alternative layout)',\n             fontsize=12, fontweight='bold')\nax2.set_xlim(-1.5, 1.5)\nax2.set_ylim(-1.5, 1.5)\n\nax2.text(0.02, 0.98, 'B', transform=ax2.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\nplt.suptitle('Phylogenetic Analysis: Tree Visualization',\n            fontsize=14, fontweight='bold', y=0.96)\n\nplt.tight_layout(rect=[0, 0, 1, 0.94])\nplt.savefig('phylogenetic_tree.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Phylogenetic tree figure created\")\nprint(f\"Species analyzed: {n_species}\")\nprint(\"Tree construction: UPGMA clustering method\")\n\n\n\nPhylogenetic Tree Best Practices\nEssential elements:\n Scale bar with units (substitutions/site, years, etc.)\n Branch lengths proportional to distance (unless cladogram)\n Bootstrap or posterior probability values at nodes\n Clear tip labels (species/strain names)\n Root indicated (outgroup or midpoint)\n Tree construction method stated in caption\n\nLayout choices:\n✓ Rectangular (standard): Best for detailed branch lengths\n✓ Circular/radial: Good for large trees, emphasizes relationships\n✓ Unrooted: When root position unknown\n\nCaption requirements:\n Alignment method (if sequences)\n Tree-building algorithm (NJ, ML, Bayesian, etc.)\n Bootstrap replicates (if applicable)\n Outgroup used for rooting\n Software used\n\nAvoid:\n❌ Unlabeled scale bars\n❌ No bootstrap values (can't assess confidence)\n❌ Inconsistent branch lengths without justification\n❌ Missing outgroup (unclear root)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 8: Specialized Field Visualizations</span>"
    ]
  },
  {
    "objectID": "Chapter 8.html#network-diagrams",
    "href": "Chapter 8.html#network-diagrams",
    "title": "Chapter 8: Specialized Field Visualizations",
    "section": "8.5 Network Diagrams",
    "text": "8.5 Network Diagrams\n\nWhen to Use Network Visualizations\nCommon in:\n\nProtein-protein interaction networks\nGene regulatory networks\nMetabolic pathways\nCo-occurrence networks\n\nKey components:\nNodes: Entities (genes, proteins, metabolites)\nEdges: Relationships (interactions, correlations)\nNode size: Often encodes degree or importance\nNode color: Often encodes category or expression\nEdge width: Often encodes interaction strength\n\nCode Example (Python) - Network Diagram:\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport networkx as nx\n\nnp.random.seed(42)\n\n# Create a gene regulatory network (simplified)\nG = nx.Graph()\n\n# Add nodes (genes)\ngenes = ['GENE_A', 'GENE_B', 'GENE_C', 'GENE_D', 'GENE_E',\n        'GENE_F', 'GENE_G', 'GENE_H', 'GENE_I', 'GENE_J']\n\n# Gene categories (functional groups)\ncategories = {\n    'GENE_A': 'Transcription Factor',\n    'GENE_B': 'Transcription Factor',\n    'GENE_C': 'Signaling',\n    'GENE_D': 'Signaling',\n    'GENE_E': 'Signaling',\n    'GENE_F': 'Metabolic',\n    'GENE_G': 'Metabolic',\n    'GENE_H': 'Structural',\n    'GENE_I': 'Structural',\n    'GENE_J': 'Receptor'\n}\n\n# Expression levels (fold change)\nexpression = {\n    'GENE_A': 2.5, 'GENE_B': 1.8, 'GENE_C': -1.5,\n    'GENE_D': 3.2, 'GENE_E': -2.1, 'GENE_F': 1.2,\n    'GENE_G': -1.8, 'GENE_H': 0.5, 'GENE_I': 2.8, 'GENE_J': 1.5\n}\n\n# Add nodes with attributes\nfor gene in genes:\n    G.add_node(gene, category=categories[gene], expression=expression[gene])\n\n# Add edges (interactions)\ninteractions = [\n    ('GENE_A', 'GENE_C', 0.9),  # (gene1, gene2, correlation)\n    ('GENE_A', 'GENE_D', 0.85),\n    ('GENE_B', 'GENE_C', 0.75),\n    ('GENE_B', 'GENE_E', 0.8),\n    ('GENE_C', 'GENE_F', 0.7),\n    ('GENE_D', 'GENE_G', 0.65),\n    ('GENE_E', 'GENE_H', 0.6),\n    ('GENE_F', 'GENE_I', 0.9),\n    ('GENE_G', 'GENE_J', 0.7),\n    ('GENE_H', 'GENE_I', 0.85),\n    ('GENE_I', 'GENE_J', 0.75),\n    ('GENE_A', 'GENE_B', 0.95)\n]\n\nfor gene1, gene2, weight in interactions:\n    G.add_edge(gene1, gene2, weight=weight)\n\n# Create figure\nfig, axes = plt.subplots(1, 2, figsize=(16, 7))\n\n# === PANEL A: Network colored by category ===\nax1 = axes[0]\n\n# Layout\npos = nx.spring_layout(G, k=0.5, iterations=50, seed=42)\n\n# Node colors by category\ncategory_colors = {\n    'Transcription Factor': '#E74C3C',\n    'Signaling': '#3498DB',\n    'Metabolic': '#27AE60',\n    'Structural': '#F39C12',\n    'Receptor': '#9B59B6'\n}\n\nnode_colors = [category_colors[categories[node]] for node in G.nodes()]\n\n# Node sizes by degree (number of connections)\nnode_sizes = [G.degree(node) * 300 for node in G.nodes()]\n\n# Edge widths by correlation\nedge_widths = [G[u][v]['weight'] * 3 for u, v in G.edges()]\n\n# Draw network\nnx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes,\n                      edgecolors='black', linewidths=2, ax=ax1)\nnx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.6, edge_color='gray', ax=ax1)\nnx.draw_networkx_labels(G, pos, font_size=8, font_weight='bold', ax=ax1)\n\nax1.set_title('A. Gene Regulatory Network\\n(Colored by functional category)',\n             fontsize=12, fontweight='bold')\nax1.axis('off')\n\n# Legend\nfrom matplotlib.patches import Patch\nlegend_elements = [Patch(facecolor=color, edgecolor='black', label=cat)\n                  for cat, color in category_colors.items()]\nax1.legend(handles=legend_elements, loc='upper left', frameon=True, fontsize=9,\n          title='Functional Category', title_fontsize=10)\n\nax1.text(0.02, 0.98, 'A', transform=ax1.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\n# === PANEL B: Network colored by expression ===\nax2 = axes[1]\n\n# Node colors by expression level\nexpr_values = [expression[node] for node in G.nodes()]\nnode_colors_expr = plt.cm.RdBu_r([(x + 3) / 6 for x in expr_values])  # Normalize to 0-1\n\n# Draw network\nnx.draw_networkx_nodes(G, pos, node_color=node_colors_expr, node_size=node_sizes,\n                      edgecolors='black', linewidths=2, ax=ax2)\nnx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.6, edge_color='gray', ax=ax2)\nnx.draw_networkx_labels(G, pos, font_size=8, font_weight='bold', ax=ax2)\n\nax2.set_title('B. Gene Regulatory Network\\n(Colored by fold change)',\n             fontsize=12, fontweight='bold')\nax2.axis('off')\n\n# Colorbar for expression\nfrom matplotlib.colorbar import ColorbarBase\nfrom matplotlib.colors import Normalize\nimport matplotlib.cm as cm\n\n# Create colorbar axis\ncbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\nnorm = Normalize(vmin=-3, vmax=3)\ncb = ColorbarBase(cbar_ax, cmap=cm.RdBu_r, norm=norm, orientation='vertical')\ncb.set_label('Log₂ Fold Change', fontsize=10, fontweight='bold')\n\nax2.text(0.02, 0.98, 'B', transform=ax2.transAxes,\n        fontsize=16, fontweight='bold', va='top')\n\nplt.suptitle(f'Network Analysis: {len(G.nodes())} genes, {len(G.edges())} interactions',\n            fontsize=14, fontweight='bold', y=0.95)\n\nplt.tight_layout(rect=[0, 0, 0.9, 0.93])\nplt.savefig('network_diagram.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.close()\n\nprint(\"✓ Network diagram created\")\nprint(f\"Nodes (genes): {len(G.nodes())}\")\nprint(f\"Edges (interactions): {len(G.edges())}\")\nprint(f\"Network density: {nx.density(G):.3f}\")\nprint(f\"Average clustering coefficient: {nx.average_clustering(G):.3f}\")\n\n\n\nNetwork Diagram Best Practices\nNode encoding:\n Size: Often represents degree, importance, or expression level\n Color: Category (discrete) or value (continuous)\n Shape: Secondary category (if needed)\n Label: Clear, non-overlapping\n\nEdge encoding:\n Width: Interaction strength, correlation, weight\n Color: Interaction type (activation, inhibition, etc.)\n Style: Solid vs. dashed for different evidence levels\n\nLayout considerations:\n✓ Force-directed (spring): Good for general networks\n✓ Hierarchical: Good for directed networks with clear levels\n✓ Circular: Good for highlighting cycles\n✓ Manual: When biological layout is known\n\nCaption requirements:\n Node and edge definitions\n Network statistics (nodes, edges, density)\n Layout algorithm used\n Data source and filtering criteria\n Software used\n\nAvoid:\n❌ Overlapping labels (use algorithms like adjustText)\n❌ Too many nodes (&gt;50 becomes cluttered; consider subnetwork)\n❌ Unlabeled encoding (what does node size mean?)\n❌ Hairball (too dense; filter by importance/threshold)\n\n\n\n8.6 Novel Plot Types: Providing Context\nPrinciple: Any non-standard plot type requires extra explanation to ensure reader understanding.\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Wedge, Circle\n\nnp.random.seed(42)\n\nfig = plt.figure(figsize=(16, 12))\n\n# Example: Circular plot (not commonly used in biology)\n# MUST provide sufficient context\n\n# Panel A: Novel plot WITHOUT explanation (confusing)\nax1 = plt.subplot(2, 2, 1, projection='polar')\ntheta = np.linspace(0, 2*np.pi, 24)\nr = 50 + 30*np.sin(3*theta) + np.random.randn(24)*5\n\nax1.plot(theta, r, 'o-', linewidth=2, markersize=8, color='#3498DB')\nax1.fill(theta, r, alpha=0.3, color='#3498DB')\nax1.set_theta_zero_location('N')\nax1.set_title('❌ BAD: No Explanation\\n(What am I looking at?)',\n              fontsize=13, fontweight='bold', color='red', pad=20)\n\n# Panel B: Same plot WITH clear explanation\nax2 = plt.subplot(2, 2, 2, projection='polar')\nax2.plot(theta, r, 'o-', linewidth=2.5, markersize=8, color='#27AE60')\nax2.fill(theta, r, alpha=0.3, color='#27AE60')\nax2.set_theta_zero_location('N')\nax2.set_theta_direction(-1)  # Clockwise\n\n# Add time labels\nhour_labels = [f'{h}:00' for h in range(0, 24, 3)]\nax2.set_xticks(np.linspace(0, 2*np.pi, 8, endpoint=False))\nax2.set_xticklabels(hour_labels, fontsize=10)\n\n# Add radial axis label\nax2.set_ylabel('Activity Level', fontsize=11, fontweight='bold', labelpad=30)\n\n# Add annotations\nax2.text(0, 85, 'Peak\\nActivity', ha='center', fontsize=10,\n        fontweight='bold', color='red',\n        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n\nax2.set_title('✓ GOOD: Clear Context\\n\"24-hour Circadian Activity Pattern\"',\n              fontsize=13, fontweight='bold', color='green', pad=20)\n\n# Panel C: Novel plot with legend/key explaining elements\nax3 = plt.subplot(2, 2, 3)\n\n# Example: Alluvial/Sankey-style plot\n# Simulate patient flow between disease states\nstates = ['Healthy', 'Stage I', 'Stage II', 'Stage III']\ntime_points = ['Baseline', 'Month 3', 'Month 6', 'Month 9']\n\n# Create flow diagram\nfrom matplotlib.sankey import Sankey\n\n# Simplified representation (actual Sankey would be more complex)\nax3.text(0.5, 0.95, 'Disease Progression Flow Diagram',\n        ha='center', va='top', transform=ax3.transAxes,\n        fontsize=12, fontweight='bold')\n\n# Add explanatory text boxes\nexplanations = [\n    \"Arrow width = Number of patients\",\n    \"Color = Disease severity\",\n    \"Left → Right = Time progression\",\n    \"Splits show state transitions\"\n]\n\ny_pos = 0.8\nfor exp in explanations:\n    ax3.text(0.05, y_pos, f'• {exp}', transform=ax3.transAxes,\n            fontsize=10, verticalalignment='top',\n            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n    y_pos -= 0.15\n\nax3.set_xlim(0, 1)\nax3.set_ylim(0, 1)\nax3.axis('off')\nax3.set_title('✓ GOOD: Novel Plot with Key\\n(All elements explained)',\n              fontsize=13, fontweight='bold', color='green', pad=20)\n\n# Panel D: Checklist for novel plots\nax4 = plt.subplot(2, 2, 4)\nax4.axis('off')\n\nchecklist_text = \"\"\"\n✓ CHECKLIST FOR NOVEL PLOT TYPES:\n\n Title clearly states what plot shows\n   Example: \"Circular Heatmap of Temporal Gene Expression\"\n\n All axes labeled with units\n   • Radial axis: What does distance mean?\n   • Angular axis: What does angle represent?\n\n Legend explains all visual encodings\n   • Line thickness → Sample size\n   • Color → Statistical significance\n   • Pattern → Experimental group\n\n Caption provides interpretation guide\n   \"In this polar plot, each point represents\n    hourly measurements over 24 hours. Radial\n    distance indicates activity level (AU).\"\n\n Reference to similar plot if published\n   \"Similar to circular genome plots (Zhang et al. 2020)\"\n\n Full methods in supplementary\n   • Software used\n   • Parameter settings\n   • Data processing steps\n\"\"\"\n\nax4.text(0.05, 0.95, checklist_text, transform=ax4.transAxes,\n        fontsize=10, verticalalignment='top', family='monospace',\n        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n\nax4.set_title('Novel Plot Checklist',\n              fontsize=13, fontweight='bold', pad=20)\n\nplt.tight_layout()\nplt.savefig('novel_plots_explanation.png', dpi=300,\n           bbox_inches='tight', facecolor='white')\nplt.close()\n\nEnd of Chapter 8: Specialized Field Visualizations\nSummary Table:\n\n\n\n\n\n\n\n\n\nFigure Type\nField\nKey Elements\nCommon Pitfalls\n\n\n\n\nMicroscopy\nAll biology\nScale bar, channel labels\nMissing scale bar, selective editing\n\n\nWestern Blot\nMolecular biology\nFull lanes, loading control, quantification\nLane splicing, no loading control\n\n\nFlow Cytometry\nImmunology\nGates with %, axes labeled, scale type\nUnlabeled axes, no gate percentages\n\n\nPhylogenetic Tree\nEvolution\nScale bar, bootstrap values, root\nNo scale bar, no confidence values\n\n\nNetwork Diagram\nSystems biology\nNode/edge encoding, layout, stats\nOverlapping labels, hairball, unlabeled encoding",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 8: Specialized Field Visualizations</span>"
    ]
  },
  {
    "objectID": "Chapter 9.html",
    "href": "Chapter 9.html",
    "title": "Chapter 9: Interactive and Dynamic Figures",
    "section": "",
    "text": "9.1 When to Use Interactive vs. Static Figures",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 9: Interactive and Dynamic Figures</span>"
    ]
  },
  {
    "objectID": "Chapter 9.html#when-to-use-interactive-vs.-static-figures",
    "href": "Chapter 9.html#when-to-use-interactive-vs.-static-figures",
    "title": "Chapter 9: Interactive and Dynamic Figures",
    "section": "",
    "text": "The Medium Determines the Format\nStatic figures (print journals, PDFs):\n✓ Use when:\n- Final publication format is print or PDF\n- Readers need to reference specific values easily\n- Figure must work in grayscale\n- No web infrastructure for hosting\n\nLimitations:\n- Single fixed view\n- Limited data density\n- No exploration by reader\nInteractive figures (web, presentations, supplements):\n✓ Use when:\n- Hosting on journal website or personal site\n- Large datasets with multiple views\n- Time-series animations helpful\n- 3D structures need rotation\n- Zoom/pan would aid understanding\n\nRequirements:\n- HTML5/JavaScript support\n- Web hosting\n- Fallback static version for accessibility\n\n\n\nHybrid Approach: Best of Both Worlds\nStandard practice for modern publications:\nMain manuscript: Static figures (PDF-compatible)\nSupplementary materials: Interactive versions online\n\nExample workflow:\n1. Create interactive figure with Plotly/Bokeh\n2. Export high-quality static snapshot for manuscript\n3. Host interactive version on journal website\n4. Link static → interactive in caption:\n   \"Interactive version available at [URL]\"",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 9: Interactive and Dynamic Figures</span>"
    ]
  },
  {
    "objectID": "Chapter 9.html#tools-for-interactive-visualizations",
    "href": "Chapter 9.html#tools-for-interactive-visualizations",
    "title": "Chapter 9: Interactive and Dynamic Figures",
    "section": "9.2 Tools for Interactive Visualizations",
    "text": "9.2 Tools for Interactive Visualizations\n\nPython: Plotly\nAdvantages:\n\nEasy syntax (similar to matplotlib)\nExports to HTML (standalone, no server needed)\nWorks in Jupyter notebooks\nExtensive chart types\n\nCode Example (Python) - Interactive Scatter Plot with Plotly:\nimport plotly.graph_objects as go\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(42)\n\n# Simulate gene expression data\nn_genes = 500\ngene_names = [f'Gene_{i+1}' for i in range(n_genes)]\n\n# Three experimental groups\ngroups = np.repeat(['Control', 'Treatment_A', 'Treatment_B'], n_genes // 3)\ngroups = np.append(groups, ['Control'] * (n_genes - len(groups)))\n\n# Expression levels\nexpression = np.random.lognormal(mean=5, sigma=2, size=n_genes)\nfold_change = np.where(groups == 'Control',\n                       np.random.normal(0, 0.5, n_genes),\n                       np.where(groups == 'Treatment_A',\n                               np.random.normal(1.5, 0.8, n_genes),\n                               np.random.normal(-1.2, 0.7, n_genes)))\n\np_values = np.random.beta(0.5, 5, n_genes)\n\n# Create DataFrame\ndf = pd.DataFrame({\n    'Gene': gene_names,\n    'Group': groups,\n    'Expression': expression,\n    'FoldChange': fold_change,\n    'PValue': p_values,\n    'Significant': p_values &lt; 0.05\n})\n\n# Create interactive scatter plot\nfig = go.Figure()\n\n# Add traces for each group\nfor group in df['Group'].unique():\n    df_group = df[df['Group'] == group]\n\n    colors_map = {'Control': '#7F8C8D', 'Treatment_A': '#3498DB', 'Treatment_B': '#E74C3C'}\n\n    fig.add_trace(go.Scatter(\n        x=df_group['FoldChange'],\n        y=-np.log10(df_group['PValue']),\n        mode='markers',\n        name=group,\n        marker=dict(\n            size=8,\n            color=colors_map[group],\n            opacity=0.7,\n            line=dict(width=0.5, color='black')\n        ),\n        text=df_group['Gene'],  # Hover text\n        hovertemplate='&lt;b&gt;%{text}&lt;/b&gt;&lt;br&gt;' +\n                     'Fold Change: %{x:.2f}&lt;br&gt;' +\n                     'P-value: %{customdata:.4f}&lt;br&gt;' +\n                     '&lt;extra&gt;&lt;/extra&gt;',\n        customdata=df_group['PValue']\n    ))\n\n# Add threshold lines\nfig.add_hline(y=-np.log10(0.05), line_dash=\"dash\", line_color=\"red\",\n             annotation_text=\"p = 0.05\", annotation_position=\"right\")\nfig.add_vline(x=1, line_dash=\"dash\", line_color=\"red\")\nfig.add_vline(x=-1, line_dash=\"dash\", line_color=\"red\")\n\n# Layout\nfig.update_layout(\n    title=dict(\n        text='Interactive Volcano Plot: Hover to Explore Genes',\n        font=dict(size=16, family='Arial', color='black')\n    ),\n    xaxis=dict(\n        title='Log₂ Fold Change',\n        titlefont=dict(size=14, family='Arial', color='black'),\n        showgrid=True,\n        gridcolor='lightgray'\n    ),\n    yaxis=dict(\n        title='-Log₁₀ (P-value)',\n        titlefont=dict(size=14, family='Arial', color='black'),\n        showgrid=True,\n        gridcolor='lightgray'\n    ),\n    hovermode='closest',\n    plot_bgcolor='white',\n    width=900,\n    height=700,\n    legend=dict(\n        x=0.02,\n        y=0.98,\n        bgcolor='rgba(255,255,255,0.8)',\n        bordercolor='black',\n        borderwidth=1\n    )\n)\n\n# Save as interactive HTML\nfig.write_html('interactive_volcano_plot.html')\n\n# Also export static image for manuscript\nfig.write_image('static_volcano_plot.png', width=900, height=700, scale=2)  # High DPI\n\nprint(\"✓ Interactive volcano plot created\")\nprint(\"  - HTML version: interactive_volcano_plot.html (open in browser)\")\nprint(\"  - Static PNG: static_volcano_plot.png (for manuscript)\")\n\n\n\nPython: Bokeh\nAdvantages:\n\nServer-side applications possible\nStreaming data support\nLinked plots (brushing and linking)\nMore control over interactivity\n\nCode Example (Python) - Interactive Heatmap with Bokeh:\nfrom bokeh.plotting import figure, output_file, save\nfrom bokeh.models import HoverTool, ColorBar, LinearColorMapper\nfrom bokeh.palettes import RdBu11\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(42)\n\n# Simulate gene expression matrix\nn_genes = 30\nn_samples = 12\n\ngenes = [f'Gene_{i+1}' for i in range(n_genes)]\nsamples = [f'Sample_{i+1}' for i in range(n_samples)]\n\n# Generate data with patterns\ndata = np.random.randn(n_genes, n_samples)\ndata[:10, :4] += 2  # Upregulated in first samples\ndata[10:20, 4:8] -= 2  # Downregulated in middle samples\n\n# Flatten for Bokeh (requires long format)\ndf_heatmap = pd.DataFrame({\n    'gene': np.repeat(genes, n_samples),\n    'sample': np.tile(samples, n_genes),\n    'expression': data.flatten()\n})\n\n# Create figure\noutput_file('interactive_heatmap.html')\n\n# Color mapper\nmapper = LinearColorMapper(palette=RdBu11[::-1], low=-3, high=3)\n\np = figure(\n    title=\"Interactive Gene Expression Heatmap (Hover for values)\",\n    x_range=samples,\n    y_range=genes[::-1],  # Reverse to have Gene_1 at top\n    x_axis_location=\"above\",\n    width=900,\n    height=700,\n    toolbar_location='right',\n    tools=\"pan,wheel_zoom,box_zoom,reset,save\"\n)\n\n# Create rectangles for heatmap\np.rect(x='sample', y='gene', width=1, height=1,\n      source=df_heatmap,\n      fill_color={'field': 'expression', 'transform': mapper},\n      line_color='white', line_width=0.5)\n\n# Add hover tool\nhover = HoverTool(tooltips=[\n    ('Gene', '@gene'),\n    ('Sample', '@sample'),\n    ('Expression', '@expression{0.00}')\n])\np.add_tools(hover)\n\n# Color bar\ncolor_bar = ColorBar(color_mapper=mapper, width=15, location=(0, 0),\n                    title='Expression (Z-score)')\np.add_layout(color_bar, 'right')\n\n# Styling\np.axis.axis_line_color = None\np.axis.major_tick_line_color = None\np.axis.major_label_text_font_size = \"8pt\"\np.axis.major_label_standoff = 0\np.xaxis.major_label_orientation = 0.785  # 45 degrees\n\nsave(p)\n\nprint(\"✓ Interactive heatmap created: interactive_heatmap.html\")\nprint(\"  Features: Hover tooltips, pan, zoom, reset\")\n\n\n\nR: Plotly\nCode Example (R) - Interactive 3D PCA Plot:\nlibrary(plotly)\n\nset.seed(42)\n\n# Simulate PCA data\nn_samples &lt;- 60\ngroup_size &lt;- 20\n\npc1 &lt;- c(rnorm(group_size, -2, 1), rnorm(group_size, 0, 1), rnorm(group_size, 2, 1))\npc2 &lt;- c(rnorm(group_size, 1, 1), rnorm(group_size, 0, 1), rnorm(group_size, -1, 1))\npc3 &lt;- c(rnorm(group_size, 0, 0.5), rnorm(group_size, 1, 0.5), rnorm(group_size, -0.5, 0.5))\n\ngroups &lt;- factor(rep(c('Control', 'Treatment A', 'Treatment B'), each = group_size))\nsample_names &lt;- paste0('Sample_', 1:n_samples)\n\n# Create 3D scatter plot\nfig &lt;- plot_ly(\n  x = ~pc1,\n  y = ~pc2,\n  z = ~pc3,\n  color = ~groups,\n  colors = c('Control' = '#7F8C8D', 'Treatment A' = '#3498DB', 'Treatment B' = '#E74C3C'),\n  type = 'scatter3d',\n  mode = 'markers',\n  marker = list(size = 8, line = list(color = 'black', width = 0.5)),\n  text = ~sample_names,\n  hovertemplate = paste('&lt;b&gt;%{text}&lt;/b&gt;&lt;br&gt;',\n                       'PC1: %{x:.2f}&lt;br&gt;',\n                       'PC2: %{y:.2f}&lt;br&gt;',\n                       'PC3: %{z:.2f}&lt;br&gt;',\n                       '&lt;extra&gt;&lt;/extra&gt;')\n) %&gt;%\n  layout(\n    title = list(text = 'Interactive 3D PCA Plot (Rotate to explore)',\n                font = list(size = 16, family = 'Arial')),\n    scene = list(\n      xaxis = list(title = 'PC1 (45.3% variance)', showgrid = TRUE),\n      yaxis = list(title = 'PC2 (18.7% variance)', showgrid = TRUE),\n      zaxis = list(title = 'PC3 (12.4% variance)', showgrid = TRUE),\n      camera = list(eye = list(x = 1.5, y = 1.5, z = 1.5))\n    ),\n    legend = list(x = 0.02, y = 0.98)\n  )\n\n# Save as HTML\nhtmlwidgets::saveWidget(fig, 'interactive_3d_pca.html', selfcontained = TRUE)\n\n# Export static snapshot\n# Note: Requires webshot and PhantomJS or chromote\n# install.packages(\"webshot\")\n# webshot::install_phantomjs()\n# webshot::webshot('interactive_3d_pca.html', 'static_3d_pca.png',\n#                 vwidth = 900, vheight = 700)\n\ncat(\"✓ Interactive 3D PCA plot created: interactive_3d_pca.html\\n\")\ncat(\"  Features: Rotate, zoom, pan, hover tooltips\\n\")",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 9: Interactive and Dynamic Figures</span>"
    ]
  },
  {
    "objectID": "Chapter 9.html#animation-for-time-series-data",
    "href": "Chapter 9.html#animation-for-time-series-data",
    "title": "Chapter 9: Interactive and Dynamic Figures",
    "section": "9.3 Animation for Time-Series Data",
    "text": "9.3 Animation for Time-Series Data\n\nWhen Animation is Appropriate\nGood use cases:\n✓ Temporal progression (time-lapse microscopy, disease spread)\n✓ Parameter sweeps (showing effect of varying one parameter)\n✓ Algorithmic processes (iterative optimization, simulation)\n✓ Spatial changes over time (geographic data)\n\nRequirements:\n- Clear temporal or sequential relationship\n- Animation adds insight (not just novelty)\n- Static alternatives available for print\nBad use cases:\n❌ Data that requires precise value reading\n❌ Complex comparisons (hard to track while moving)\n❌ Accessibility (some readers cannot view animations)\nCode Example (Python) - Animated Time-Series:\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport numpy as np\n\nnp.random.seed(42)\n\n# Simulate time-series data (e.g., cell count over time in different conditions)\ntime_points = np.arange(0, 50, 0.5)  # 0 to 50 hours\nn_conditions = 3\n\n# Generate growth curves\ndef growth_curve(time, growth_rate, initial_count=10):\n    return initial_count * np.exp(growth_rate * time / 10)\n\nconditions = ['Control', 'Treatment A', 'Treatment B']\ngrowth_rates = [0.5, 0.8, 0.3]  # Different growth rates\ncolors = ['#7F8C8D', '#3498DB', '#E74C3C']\n\n# Add noise\ndata = {}\nfor cond, rate in zip(conditions, growth_rates):\n    counts = growth_curve(time_points, rate)\n    counts += np.random.randn(len(time_points)) * counts * 0.1  # 10% noise\n    data[cond] = counts\n\n# Create figure\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Initialize lines\nlines = []\nfor cond, color in zip(conditions, colors):\n    line, = ax.plot([], [], 'o-', color=color, linewidth=3, markersize=6,\n                   label=cond, alpha=0.8)\n    lines.append(line)\n\n# Formatting\nax.set_xlim(0, 50)\nax.set_ylim(0, np.max([data[c] for c in conditions]) * 1.1)\nax.set_xlabel('Time (hours)', fontsize=12, fontweight='bold')\nax.set_ylabel('Cell Count (×10³)', fontsize=12, fontweight='bold')\nax.set_title('Animated Growth Curves: Bacterial Colony Growth',\n            fontsize=14, fontweight='bold')\nax.legend(loc='upper left', frameon=True, fontsize=11)\nax.grid(alpha=0.3)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n# Time annotation\ntime_text = ax.text(0.98, 0.02, '', transform=ax.transAxes,\n                   fontsize=14, fontweight='bold', ha='right', va='bottom',\n                   bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n\n# Animation function\ndef animate(frame):\n    # Update each line with data up to current frame\n    for line, cond in zip(lines, conditions):\n        line.set_data(time_points[:frame], data[cond][:frame])\n\n    # Update time text\n    time_text.set_text(f'Time: {time_points[frame-1]:.1f} h')\n\n    return lines + [time_text]\n\n# Create animation\nanim = animation.FuncAnimation(fig, animate, frames=len(time_points),\n                              interval=50, blit=True, repeat=True)\n\n# Save as GIF\nanim.save('animated_growth_curves.gif', writer='pillow', fps=20, dpi=150)\n\n# Save as MP4 (requires ffmpeg)\n# anim.save('animated_growth_curves.mp4', writer='ffmpeg', fps=20, dpi=150)\n\nplt.close()\n\nprint(\"✓ Animated growth curves created\")\nprint(\"  - GIF: animated_growth_curves.gif (for web/presentations)\")\nprint(\"  - Note: For manuscripts, include static final frame as well\")\n\nCode Example (R) - Animated Time-Series with gganimate:\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(gifski)  # For GIF rendering\n\nset.seed(42)\n\n# Simulate data\ntime_points &lt;- seq(0, 50, by = 0.5)\nconditions &lt;- c('Control', 'Treatment A', 'Treatment B')\ngrowth_rates &lt;- c(0.5, 0.8, 0.3)\n\n# Generate growth curves\ndata_list &lt;- lapply(1:length(conditions), function(i) {\n  cond &lt;- conditions[i]\n  rate &lt;- growth_rates[i]\n\n  counts &lt;- 10 * exp(rate * time_points / 10)\n  counts &lt;- counts + rnorm(length(counts), 0, counts * 0.1)\n\n  data.frame(\n    Time = time_points,\n    Condition = cond,\n    Count = counts\n  )\n})\n\ndata_anim &lt;- do.call(rbind, data_list)\n\n# Color map\ncolors &lt;- c('Control' = '#7F8C8D', 'Treatment A' = '#3498DB', 'Treatment B' = '#E74C3C')\n\n# Create animated plot\np &lt;- ggplot(data_anim, aes(x = Time, y = Count, color = Condition)) +\n  geom_line(size = 2, alpha = 0.8) +\n  geom_point(size = 3, alpha = 0.8) +\n\n  scale_color_manual(values = colors) +\n\n  labs(x = 'Time (hours)',\n       y = 'Cell Count (×10³)',\n       title = 'Bacterial Colony Growth',\n       subtitle = 'Time: {frame_along} hours') +\n\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(face = 'bold', size = 16, hjust = 0.5),\n    plot.subtitle = element_text(face = 'bold', size = 14, hjust = 0.5),\n    axis.title = element_text(face = 'bold', size = 12),\n    legend.position = c(0.15, 0.85),\n    legend.background = element_rect(fill = 'white', color = 'black', size = 0.5),\n    panel.grid.major = element_line(color = 'gray90', size = 0.3)\n  ) +\n\n  # Animation\n  transition_reveal(Time)\n\n# Render animation\nanim_output &lt;- animate(p, nframes = 200, fps = 20, width = 800, height = 600,\n                      renderer = gifski_renderer('animated_growth_curves.gif'))\n\ncat(\"✓ Animated growth curves created: animated_growth_curves.gif\\n\")\ncat(\"  Frames: 200, FPS: 20\\n\")",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 9: Interactive and Dynamic Figures</span>"
    ]
  },
  {
    "objectID": "Chapter 9.html#linked-plots-brushing-and-linking",
    "href": "Chapter 9.html#linked-plots-brushing-and-linking",
    "title": "Chapter 9: Interactive and Dynamic Figures",
    "section": "9.4 Linked Plots (Brushing and Linking)",
    "text": "9.4 Linked Plots (Brushing and Linking)\n\nInteractive Exploration of Multi-Dimensional Data\nConcept: Selecting data in one plot highlights corresponding points in other plots.\nUse cases: - Exploring PCA + expression data simultaneously - Linking genotype to phenotype visualizations - Quality control dashboards\nCode Example (Python) - Linked Scatter Plots with Bokeh:\nfrom bokeh.plotting import figure, output_file, save\nfrom bokeh.layouts import row\nfrom bokeh.models import ColumnDataSource\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(42)\n\n# Simulate data\nn_samples = 200\ngene_a = np.random.randn(n_samples) * 10 + 50\ngene_b = 0.8 * gene_a + np.random.randn(n_samples) * 5\ngene_c = -0.6 * gene_a + np.random.randn(n_samples) * 7 + 40\n\n# Sample groups\ngroups = np.random.choice(['Control', 'Treatment A', 'Treatment B'], n_samples)\n\n# Create DataFrame\ndf = pd.DataFrame({\n    'GeneA': gene_a,\n    'GeneB': gene_b,\n    'GeneC': gene_c,\n    'Group': groups,\n    'Sample': [f'S{i+1}' for i in range(n_samples)]\n})\n\n# Bokeh requires ColumnDataSource for linked brushing\nsource = ColumnDataSource(df)\n\n# Colors\ncolor_map = {'Control': '#7F8C8D', 'Treatment A': '#3498DB', 'Treatment B': '#E74C3C'}\ndf['color'] = df['Group'].map(color_map)\nsource.data['color'] = df['color']\n\noutput_file('linked_scatter_plots.html')\n\n# Plot 1: Gene A vs Gene B\np1 = figure(width=400, height=400, title=\"Gene A vs Gene B\",\n           tools=\"pan,wheel_zoom,box_select,lasso_select,reset\")\np1.circle('GeneA', 'GeneB', source=source, size=8, color='color',\n         alpha=0.6, selection_color='color', selection_alpha=1.0,\n         nonselection_alpha=0.1)\n\n# Plot 2: Gene A vs Gene C\np2 = figure(width=400, height=400, title=\"Gene A vs Gene C\",\n           tools=\"pan,wheel_zoom,box_select,lasso_select,reset\")\np2.circle('GeneA', 'GeneC', source=source, size=8, color='color',\n         alpha=0.6, selection_color='color', selection_alpha=1.0,\n         nonselection_alpha=0.1)\n\n# Plot 3: Gene B vs Gene C\np3 = figure(width=400, height=400, title=\"Gene B vs Gene C\",\n           tools=\"pan,wheel_zoom,box_select,lasso_select,reset\")\np3.circle('GeneB', 'GeneC', source=source, size=8, color='color',\n         alpha=0.6, selection_color='color', selection_alpha=1.0,\n         nonselection_alpha=0.1)\n\n# Layout\nlayout = row(p1, p2, p3)\n\nsave(layout)\n\nprint(\"✓ Linked scatter plots created: linked_scatter_plots.html\")\nprint(\"  Instructions: Use box/lasso select in one plot to highlight in others\")",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 9: Interactive and Dynamic Figures</span>"
    ]
  },
  {
    "objectID": "Chapter 9.html#interactive-figure-best-practices",
    "href": "Chapter 9.html#interactive-figure-best-practices",
    "title": "Chapter 9: Interactive and Dynamic Figures",
    "section": "9.5 Interactive Figure Best Practices",
    "text": "9.5 Interactive Figure Best Practices\n\nAccessibility and Fallbacks\nCritical principle: Interactive figures must have static alternatives.\nChecklist for interactive figures:\n Provide static version for print/PDF\n Include alt text describing figure content\n Ensure colorblind-safe palette (same as static rules)\n Test on multiple browsers\n Provide download option for underlying data\n State software/library versions in Methods\n\n\n\nCaption Requirements for Interactive Figures\nEnhanced caption for interactive version:\n\n\"Figure 3. Interactive volcano plot of differential gene expression.\n(Interactive version available at: https://doi.org/XX.XXXX/supplementary)\n\nInstructions:\n- Hover over points to view gene names and statistics\n- Click legend to show/hide groups\n- Drag to pan, scroll to zoom\n- Double-click to reset view\n\nStatic version shows final state. Full gene list available in Table S1.\"\n\n\n\nFile Size Considerations\nInteractive HTML files can be large:\nOptimization strategies:\n1. Downsample dense data (e.g., 10,000 points max for scatter)\n2. Use WebGL rendering for &gt;1000 points (Plotly: scatter plot_ly(..., type='scattergl'))\n3. Separate data from HTML (load JSON externally)\n4. Compress HTML files (gzip)\n5. Use CDN for libraries (don't embed full library in each file)\n\nTarget: &lt;10 MB per figure for reasonable load times\n\nEnd of Chapter 9: Interactive and Dynamic Figures\nSummary: Static vs. Interactive Decision Matrix\n\n\n\nFeature\nStatic (Print/PDF)\nInteractive (Web)\n\n\n\n\nUniversality\n✓ Works everywhere\nRequires browser\n\n\nPrecision\n✓ Exact value reading\nMay require hover\n\n\nAccessibility\n✓ Screen readers work well\nNeeds extra care\n\n\nData density\nLimited by page size\nCan show more with zoom\n\n\nExploration\nFixed view\nMultiple views/filters\n\n\nFile size\nSmall (&lt;10 MB)\nCan be large (&gt;50 MB)\n\n\nBest for\nPublications, reports\nSupplements, dashboards\n\n\n\nHybrid workflow (recommended): 1. Create interactive version first (full data) 2. Export static snapshot for manuscript 3. Host interactive version online 4. Link in caption: “Interactive version: [URL]”",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 9: Interactive and Dynamic Figures</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html",
    "href": "Chapter 10.html",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "",
    "text": "10.1 Diagnostic Framework: “My Figure Looks Wrong”",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#diagnostic-framework-my-figure-looks-wrong",
    "href": "Chapter 10.html#diagnostic-framework-my-figure-looks-wrong",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "",
    "text": "Systematic Troubleshooting Approach\nWhen your figure doesn’t look right, follow this diagnostic tree:\nSTEP 1: Identify the problem category\n├─ Technical issues (resolution, colors, file format)\n├─ Design issues (layout, spacing, readability)\n├─ Data representation issues (plot type, axes, scale)\n└─ Compliance issues (journal requirements, ethical standards)\n\nSTEP 2: Apply category-specific solutions (see sections below)\n\nSTEP 3: Verify fix doesn't create new problems\n\nSTEP 4: Document what worked for future reference",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#technical-issues",
    "href": "Chapter 10.html#technical-issues",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "10.2 Technical Issues",
    "text": "10.2 Technical Issues\n\nProblem 1: “My figure looks blurry,pixelated when zoomed”\nSymptoms:\n\nText appears fuzzy\nLines have jagged edges\nImage quality degrades when enlarged\n\nDiagnosis:\nfrom PIL import Image\nimg = Image.open('your_figure.png')\nprint(f\"Size: {img.size} pixels\")\nprint(f\"DPI: {img.info.get('dpi', 'Not set')}\")\n\n# Calculate effective DPI\nwidth_inches = 7  # Intended print width\ndpi_effective = img.size[0] / width_inches\nprint(f\"Effective DPI at {width_inches}\\\" width: {dpi_effective:.1f}\")\n\nSolutions:\n# Solution 1: Re-export at higher DPI\nimport matplotlib.pyplot as plt\n\n# ... your plotting code ...\n\n# Save at 300 DPI (publication standard)\nplt.savefig('figure_300dpi.png', dpi=300, bbox_inches='tight')\n\n# For microscopy/detailed images, use 600 DPI\nplt.savefig('figure_600dpi.png', dpi=600, bbox_inches='tight')\nCommon mistake: Upsampling after creation\n# ❌ WRONG: This doesn't add information\nfrom PIL import Image\nimg = Image.open('low_res.png')\nimg_upsampled = img.resize((img.width*2, img.height*2), Image.LANCZOS)\n# → Still blurry, just larger file\n\n# ✓ CORRECT: Create at target resolution from start\nfig, ax = plt.subplots(figsize=(7, 5), dpi=300)  # Set DPI at creation\n\n\n\nProblem 2: “Colors look different on screen vs print”\nCause: RGB (screen) vs CMYK (print) color space mismatch\nDiagnosis:\nfrom PIL import Image\nimg = Image.open('figure.png')\nprint(f\"Color mode: {img.mode}\")\n# RGB = screen colors, CMYK = print colors\nSolutions:\n# Preventive: Use print-safe RGB colors from the start\n# Avoid highly saturated colors that can't be printed\n\nPRINT_SAFE_PALETTE = {\n    'blue': '#0066CC',      # Instead of pure #0000FF\n    'red': '#CC0000',       # Instead of pure #FF0000\n    'green': '#009900',     # Instead of pure #00FF00\n    'orange': '#CC6600',\n    'purple': '#9933CC'\n}\n\n# Test colors in grayscale (simulate print preview)\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 4))\n\n# Original colors\ndata = np.random.rand(5, 5)\nim1 = axes[0].imshow(data, cmap='viridis')\naxes[0].set_title('Original (RGB)')\n\n# Grayscale preview (simulates black & white print)\nim2 = axes[1].imshow(data, cmap='gray')\naxes[1].set_title('Grayscale Preview')\n\nplt.tight_layout()\nplt.savefig('color_test.png', dpi=300)\nplt.close()\nJournal-specific fix:\n# Some journals require CMYK conversion\n# Do this ONLY if explicitly required\n\nfrom PIL import Image\n\n# Convert RGB to CMYK\nimg_rgb = Image.open('figure_rgb.png')\nimg_cmyk = img_rgb.convert('CMYK')\nimg_cmyk.save('figure_cmyk.tif')  # TIFF supports CMYK\n\nprint(\"⚠ Warning: Colors may shift during conversion\")\nprint(\"→ Preview before submission\")\n\n\n\nProblem 3: “File size too large for submission”\nDiagnosis:\nimport os\n\nfile_path = 'large_figure.png'\nsize_mb = os.path.getsize(file_path) / (1024 * 1024)\nprint(f\"Current file size: {size_mb:.2f} MB\")\n\n# Check journal limit (common limits: 5-20 MB per figure)\nlimit_mb = 10\nif size_mb &gt; limit_mb:\n    print(f\"❌ Exceeds {limit_mb} MB limit\")\nSolutions (in order of preference):\n# Solution 1: Optimize compression (lossless)\nfrom PIL import Image\n\nimg = Image.open('large_figure.png')\n\n# PNG optimization\nimg.save('optimized.png', optimize=True, compress_level=9)\n\n# Check new size\nnew_size = os.path.getsize('optimized.png') / (1024 * 1024)\nprint(f\"Optimized size: {new_size:.2f} MB ({(1-new_size/size_mb)*100:.1f}% reduction)\")\n\n# Solution 2: Reduce dimensions (if too large)\n# Only if figure dimensions exceed journal specifications\ntarget_width = 7  # inches\ncurrent_dpi = 300\nimg_resized = img.resize((int(target_width * current_dpi),\n                         int(target_width * current_dpi * img.height / img.width)),\n                        Image.LANCZOS)\nimg_resized.save('resized.png', optimize=True)\n\n# Solution 3: Use TIFF with LZW compression (lossless)\nimg.save('compressed.tif', compression='tiff_lzw')\n\n# Solution 4: Split into multiple panels (if complex)\n# Save panels separately, combine in manuscript text\n\n\nProblem 4: “Fonts look different after export”\nCause: Font embedding issues\nSolutions:\n# Matplotlib: Ensure fonts are embedded\nimport matplotlib.pyplot as plt\n\nplt.rcParams['pdf.fonttype'] = 42  # TrueType (embeds fonts)\nplt.rcParams['ps.fonttype'] = 42\n\n# Or rasterize text (converts to pixels, always works)\nplt.savefig('figure.pdf', dpi=300, bbox_inches='tight')  # Text as vectors\n\n# If font still missing, use rasterization\nplt.savefig('figure.png', dpi=300, bbox_inches='tight')  # Text as pixels\nR:\nlibrary(ggplot2)\n\n# Ensure fonts are embedded in PDF\nggsave('figure.pdf', plot,\n       width = 7, height = 5,\n       device = cairo_pdf,  # Uses Cairo for better font handling\n       dpi = 300)\n\n# Or save as PNG (rasterizes everything)\nggsave('figure.png', plot,\n       width = 7, height = 5,\n       dpi = 300)\nFallback: Use system fonts only\n# If custom fonts cause issues, stick to universals\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = ['Arial', 'Helvetica', 'DejaVu Sans']\n# System will use first available font",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#design-issues",
    "href": "Chapter 10.html#design-issues",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "10.3 Design Issues",
    "text": "10.3 Design Issues\n\nProblem 5: “Text is overlapping and illegible”\nCommon in: Scatter plots with many labels, crowded axes\nSolutions:\n# Solution 1: Use adjustText library (automatic label adjustment)\nfrom adjustText import adjust_text\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\nx = np.random.rand(30)\ny = np.random.rand(30)\nlabels = [f'Gene_{i}' for i in range(30)]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Without adjustment (overlapping)\nax1 = axes[0]\nax1.scatter(x, y, s=50, color='#3498DB', alpha=0.7)\nfor i, label in enumerate(labels):\n    ax1.text(x[i], y[i], label, fontsize=8)\nax1.set_title('❌ Without Adjustment\\n(Overlapping labels)', color='red', fontweight='bold')\n\n# With adjustment (clean)\nax2 = axes[1]\nax2.scatter(x, y, s=50, color='#3498DB', alpha=0.7)\ntexts = [ax2.text(x[i], y[i], label, fontsize=8) for i, label in enumerate(labels)]\nadjust_text(texts, arrowprops=dict(arrowstyle='-', color='gray', lw=0.5))\nax2.set_title('✓ With Adjustment\\n(Clear labels)', color='green', fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('label_overlap_fix.png', dpi=300, bbox_inches='tight')\nplt.close()\nR equivalent:\nlibrary(ggplot2)\nlibrary(ggrepel)  # Automatic label repelling\n\n# Without repelling (overlapping)\np1 &lt;- ggplot(data, aes(x = x, y = y)) +\n  geom_point(size = 3, color = '#3498DB', alpha = 0.7) +\n  geom_text(aes(label = label), size = 3) +  # Overlaps\n  labs(title = '❌ Without Repelling')\n\n# With repelling (clean)\np2 &lt;- ggplot(data, aes(x = x, y = y)) +\n  geom_point(size = 3, color = '#3498DB', alpha = 0.7) +\n  geom_text_repel(aes(label = label), size = 3,  # Automatic adjustment\n                  box.padding = 0.5, max.overlaps = 20) +\n  labs(title = '✓ With Repelling')\n\nlibrary(patchwork)\np1 | p2\nggsave('label_overlap_fix.png', width = 14, height = 6, dpi = 300)\nSolution 2: Selective labeling\n# Label only significant/important points\nsignificant_idx = [0, 5, 12, 20, 28]  # Indices of important points\n\nax.scatter(x, y, s=50, color='#3498DB', alpha=0.7)\nfor i in significant_idx:\n    ax.annotate(labels[i], (x[i], y[i]),\n               xytext=(5, 5), textcoords='offset points',\n               fontsize=9, fontweight='bold',\n               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n               arrowprops=dict(arrowstyle='-&gt;', lw=1))\n\n\n\nProblem 6: “Figure looks cluttered/too busy”\nSymptoms:\n\nHard to identify key message\nToo many colors/patterns\nDense gridlines overwhelm data\n\nSolutions:\n# Decluttering checklist:\n\n# 1. Remove unnecessary grid lines\nax.grid(False)  # Remove all grids\n# Or: Use subtle grid\nax.grid(axis='y', alpha=0.3, linewidth=0.5, color='gray')\n\n# 2. Remove top and right spines\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n# 3. Reduce color palette\n# ❌ BAD: Too many colors\ncolors = plt.cm.tab20(np.linspace(0, 1, 15))  # 15 different colors!\n\n# ✓ GOOD: 3-4 colors maximum\ncolors = ['#7F8C8D', '#3498DB', '#E74C3C']  # Gray, blue, red\n\n# 4. Increase white space\nplt.subplots_adjust(left=0.15, right=0.9, top=0.9, bottom=0.15)\n\n# 5. Use small multiples instead of overlaying everything\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))  # Split into 4 panels\n# Instead of cramming all data into one plot\n\n# 6. Remove redundant legends\n# If panel labels (A, B, C) are clear, legend may not be needed\nBefore/After Example:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\nx = np.linspace(0, 10, 100)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# CLUTTERED VERSION\nax1 = axes[0]\nfor i in range(10):\n    y = np.sin(x + i/2) + np.random.rand(100)*0.1\n    ax1.plot(x, y, linewidth=1, label=f'Series {i+1}')\nax1.grid(True, linewidth=1, alpha=0.7)  # Heavy grid\nax1.legend(loc='best', fontsize=8, ncol=2)\nax1.set_title('❌ Cluttered: Too Many Elements', color='red', fontweight='bold')\n\n# CLEAN VERSION\nax2 = axes[1]\n# Show only 3 key series\nfor i in [0, 4, 9]:\n    y = np.sin(x + i/2) + np.random.rand(100)*0.1\n    ax2.plot(x, y, linewidth=2.5, label=f'Series {i+1}', alpha=0.8)\n# Others in background (gray)\nfor i in [1, 2, 3, 5, 6, 7, 8]:\n    y = np.sin(x + i/2) + np.random.rand(100)*0.1\n    ax2.plot(x, y, color='#CCCCCC', linewidth=0.8, alpha=0.3)\nax2.grid(axis='y', alpha=0.3, linewidth=0.5)  # Subtle grid\nax2.legend(loc='upper right', frameon=True, fontsize=10)\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\nax2.set_title('✓ Clean: Focused Message', color='green', fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('declutter_fix.png', dpi=300, bbox_inches='tight')\nplt.close()\n\n\n\nProblem 7: “Panels are misaligned”\nCause: Inconsistent axis ranges, label sizes, or spacing\nSolutions:\n# Solution 1: Use consistent axis limits\nfig, axes = plt.subplots(2, 2, figsize=(10, 8))\n\n# Set same limits for all comparable plots\nxlim_range = (0, 10)\nylim_range = (0, 100)\n\nfor ax in axes.flat:\n    # ... plot data ...\n    ax.set_xlim(xlim_range)\n    ax.set_ylim(ylim_range)\n\n# Solution 2: Use GridSpec for precise control\nfrom matplotlib.gridspec import GridSpec\n\nfig = plt.figure(figsize=(12, 8))\ngs = GridSpec(2, 2, figure=fig,\n             width_ratios=[1, 1], height_ratios=[1, 1],\n             hspace=0.3, wspace=0.3)  # Consistent spacing\n\nax1 = fig.add_subplot(gs[0, 0])\nax2 = fig.add_subplot(gs[0, 1])\nax3 = fig.add_subplot(gs[1, 0])\nax4 = fig.add_subplot(gs[1, 1])\n\n# Solution 3: Match axis label sizes\nfor ax in [ax1, ax2, ax3, ax4]:\n    ax.set_xlabel('X Label', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Y Label', fontsize=11, fontweight='bold')\n    ax.tick_params(labelsize=9)\nR equivalent:\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Create plots with consistent limits\np1 &lt;- ggplot(data1, aes(x, y)) + geom_point() +\n  xlim(0, 10) + ylim(0, 100)\n\np2 &lt;- ggplot(data2, aes(x, y)) + geom_point() +\n  xlim(0, 10) + ylim(0, 100)  # Same limits\n\np3 &lt;- ggplot(data3, aes(x, y)) + geom_point() +\n  xlim(0, 10) + ylim(0, 100)\n\np4 &lt;- ggplot(data4, aes(x, y)) + geom_point() +\n  xlim(0, 10) + ylim(0, 100)\n\n# Combine with patchwork (auto-aligns)\n(p1 | p2) / (p3 | p4) +\n  plot_layout(heights = c(1, 1), widths = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#data-representation-issues",
    "href": "Chapter 10.html#data-representation-issues",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "10.4 Data Representation Issues",
    "text": "10.4 Data Representation Issues\n\nProblem 8: “My bar chart doesn’t show the difference clearly”\nDiagnosis: Likely truncated y-axis or wrong plot type\nSolutions:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndata = [98, 100, 102, 104]  # Small differences\ncategories = ['A', 'B', 'C', 'D']\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# WRONG: Truncated axis (exaggerates difference)\nax1 = axes[0]\nax1.bar(categories, data, color='#3498DB', edgecolor='black', linewidth=1.5)\nax1.set_ylim(95, 105)  # Truncated!\nax1.set_ylabel('Value')\nax1.set_title('❌ Misleading: Truncated Axis', color='red', fontweight='bold')\nax1.text(0.5, 0.5, 'Exaggerates\\ndifferences!', transform=ax1.transAxes,\n        ha='center', fontsize=12, color='red', fontweight='bold',\n        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n\n# CORRECT: Start at zero (shows true scale)\nax2 = axes[1]\nax2.bar(categories, data, color='#3498DB', edgecolor='black', linewidth=1.5)\nax2.set_ylim(0, 110)  # Starts at zero\nax2.set_ylabel('Value')\nax2.set_title('✓ Correct: Zero Baseline', color='green', fontweight='bold')\n\n# ALTERNATIVE: Dot plot with range (if differences are small but real)\nax3 = axes[2]\nax3.plot(categories, data, 'o', markersize=12, color='#3498DB')\nax3.set_ylim(95, 105)  # Can use truncated axis for dot plots\nax3.axhline(100, color='gray', linestyle='--', linewidth=1, alpha=0.5, label='Baseline')\nax3.set_ylabel('Value')\nax3.set_title('✓ Alternative: Dot Plot\\n(Truncation OK here)', color='green', fontweight='bold')\nax3.legend()\n\nplt.tight_layout()\nplt.savefig('bar_chart_fix.png', dpi=300, bbox_inches='tight')\nplt.close()\nKey rule:\nBar charts: ALWAYS start at zero\nDot plots/line plots: Truncation acceptable if clearly indicated\n\n\n\nProblem 9: “P-values overlap or are unreadable”\nCommon in: Plots with many statistical comparisons\nSolutions:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\ncategories = ['A', 'B', 'C', 'D', 'E']\nvalues = [25, 32, 28, 40, 35]\nerrors = [3, 4, 3, 5, 4]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# BAD: All comparisons shown (cluttered)\nax1 = axes[0]\nbars = ax1.bar(categories, values, yerr=errors, capsize=5,\n              color='#3498DB', edgecolor='black', linewidth=1.5)\nax1.set_ylabel('Response (AU)', fontsize=11, fontweight='bold')\nax1.set_ylim(0, 60)\n\n# Draw all pairwise comparisons (too many!)\ny_max = 50\nfor i in range(len(categories)-1):\n    y_max += 3\n    ax1.plot([i, i+1], [y_max, y_max], 'k-', linewidth=1.5)\n    ax1.text((i + i+1)/2, y_max + 0.5, '**', ha='center', fontsize=10)\n\nax1.set_title('❌ Cluttered: Too Many Comparisons', color='red', fontweight='bold')\n\n# GOOD: Show only key comparisons\nax2 = axes[1]\nbars = ax2.bar(categories, values, yerr=errors, capsize=5,\n              color='#3498DB', edgecolor='black', linewidth=1.5)\nax2.set_ylabel('Response (AU)', fontsize=11, fontweight='bold')\nax2.set_ylim(0, 55)\n\n# Show only comparisons vs. control (A) or most important\n# Comparison: D vs A\nax2.plot([0, 3], [48, 48], 'k-', linewidth=2)\nax2.text(1.5, 49, '** p&lt;0.01', ha='center', fontsize=11, fontweight='bold')\n\n# Comparison: E vs A\nax2.plot([0, 4], [52, 52], 'k-', linewidth=2)\nax2.text(2, 53, '* p&lt;0.05', ha='center', fontsize=11, fontweight='bold')\n\nax2.set_title('✓ Clean: Key Comparisons Only', color='green', fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('statistical_annotation_fix.png', dpi=300, bbox_inches='tight')\nplt.close()\n\n# Use letters instead of brackets (common in biology)\nax.bar(categories, values, ...)\n\n# Add letters above bars\nletters = ['a', 'ab', 'ab', 'c', 'bc']  # Different letters = significant difference\nfor i, (bar, letter) in enumerate(zip(bars, letters)):\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2., height + errors[i] + 1,\n           letter, ha='center', va='bottom', fontsize=12, fontweight='bold')\n\n# Caption: \"Bars with different letters are significantly different (p&lt;0.05, Tukey HSD)\"\n\n\n\nProblem 10: “Data points are too small or large”\nSolutions:\n# Guideline: Marker sizes for readability\nrecommended_sizes = {\n    'few_points': (10, 50),      # &lt;20 points: 50-150 in plt units\n    'moderate': (50, 100),       # 20-100 points: 30-80\n    'many': (100, 500),          # 100-500 points: 20-50\n    'dense': (500, 1000),        # &gt;500 points: 10-30 or use hexbin\n    'very_dense': (1000, 10000)  # &gt;1000 points: 5-15 or 2D density\n}\n\n# Adjust based on figure size\nfig_inches = 7\ndpi = 300\nfig_pixels = fig_inches * dpi\n\n# Rule of thumb: marker diameter should be 1-3% of figure dimension\nmarker_size_min = (0.01 * fig_pixels)**2  # matplotlib uses area, not diameter\nmarker_size_max = (0.03 * fig_pixels)**2\n\nprint(f\"Recommended marker size range: {marker_size_min:.0f} - {marker_size_max:.0f}\")\n\n# Example\nax.scatter(x, y, s=50, ...)  # s = area in points^2",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#compliance-issues",
    "href": "Chapter 10.html#compliance-issues",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "10.5 Compliance Issues",
    "text": "10.5 Compliance Issues\n\nProblem 11: “Journal rejected my figure for image manipulation”\nCommon violations: 1. Selective brightness/contrast adjustment 2. Lane splicing in Western blots without disclosure 3. Background removal 4. Duplicated/cloned elements\nPrevention:\n# Document ALL processing steps\n\"\"\"\nImage Processing Protocol (for Methods section):\n\n1. Microscopy images acquired with:\n   - Microscope: [Model]\n   - Objective: [Magnification, NA]\n   - Camera: [Model]\n   - Exposure: [milliseconds]\n   - Gain: [value]\n\n2. Post-acquisition processing:\n   - Software: ImageJ v1.53\n   - Brightness: +10% (applied uniformly to all images)\n   - Contrast: Linear adjustment (min=50, max=200, applied uniformly)\n   - No gamma adjustment\n   - No background subtraction\n   - No cloning or content-aware fill\n\n3. Cropping:\n   - Representative regions shown\n   - Original unprocessed images available upon request\n\n4. Figure assembly:\n   - Software: Adobe Illustrator CC 2024\n   - No modifications beyond cropping and labeling\n\"\"\"\n\n# Save original unprocessed images separately\n# Name: raw_image_01.tif, raw_image_02.tif, ...\n# Keep permanently for potential requests from journal/reviewers\n\n\n\nProblem 12: “Figure doesn’t meet journal specifications”\nSystematic check:\ndef validate_figure_specs(file_path, journal_specs):\n    \"\"\"\n    Validate figure against journal requirements\n\n    journal_specs = {\n        'max_width_inches': 7,\n        'min_dpi': 300,\n        'allowed_formats': ['TIFF', 'PNG', 'PDF'],\n        'max_file_size_mb': 10,\n        'color_mode': 'RGB'\n    }\n    \"\"\"\n    from PIL import Image\n    import os\n\n    img = Image.open(file_path)\n    file_size_mb = os.path.getsize(file_path) / (1024 * 1024)\n\n    issues = []\n\n    # Check format\n    if img.format not in journal_specs['allowed_formats']:\n        issues.append(f\"❌ Format {img.format} not allowed. Use: {journal_specs['allowed_formats']}\")\n\n    # Check DPI\n    dpi = img.info.get('dpi', (72, 72))[0]\n    if dpi &lt; journal_specs['min_dpi']:\n        issues.append(f\"❌ DPI {dpi} &lt; required {journal_specs['min_dpi']}\")\n\n    # Check dimensions\n    width_inches = img.size[0] / dpi\n    if width_inches &gt; journal_specs['max_width_inches']:\n        issues.append(f\"❌ Width {width_inches:.2f}\\\" &gt; max {journal_specs['max_width_inches']}\\\"\")\n\n    # Check file size\n    if file_size_mb &gt; journal_specs['max_file_size_mb']:\n        issues.append(f\"❌ File size {file_size_mb:.2f} MB &gt; max {journal_specs['max_file_size_mb']} MB\")\n\n    # Check color mode\n    if img.mode != journal_specs['color_mode']:\n        issues.append(f\"⚠ Color mode {img.mode}, required: {journal_specs['color_mode']}\")\n\n    if issues:\n        print(\"Issues found:\")\n        for issue in issues:\n            print(f\"  {issue}\")\n        return False\n    else:\n        print(\"✓ All specifications met\")\n        return True\n\n# Example usage\nnature_specs = {\n    'max_width_inches': 7.2,\n    'min_dpi': 300,\n    'allowed_formats': ['TIFF', 'PDF', 'EPS'],\n    'max_file_size_mb': 10,\n    'color_mode': 'RGB'\n}\n\nvalidate_figure_specs('my_figure.png', nature_specs)",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#quick-fix-cheat-sheet",
    "href": "Chapter 10.html#quick-fix-cheat-sheet",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "10.6 Quick Fix Cheat Sheet",
    "text": "10.6 Quick Fix Cheat Sheet\nOne-line fixes for common problems:\n# Problem: Text too small\nplt.rcParams['font.size'] = 11  # Increase base font size\n\n# Problem: Legend overlaps data\nax.legend(loc='upper left', bbox_to_anchor=(1.02, 1))  # Outside plot area\n\n# Problem: Margins too tight\nplt.tight_layout(pad=2.0)  # Increase padding\n\n# Problem: Axes labels cut off\nplt.savefig('figure.png', bbox_inches='tight')  # Auto-adjust bounds\n\n# Problem: Colorbar too wide\nplt.colorbar(fraction=0.046, pad=0.04)  # Standard narrow colorbar\n\n# Problem: Tick labels overlap\nax.tick_params(axis='x', rotation=45)  # Rotate 45°\n\n# Problem: Grid too prominent\nax.grid(alpha=0.3, linewidth=0.5)  # Subtle grid\n\n# Problem: Too much white space\nplt.subplots_adjust(left=0.1, right=0.95, top=0.95, bottom=0.1)\n\n# Problem: Inconsistent line widths\nax.plot(x, y, linewidth=2.5)  # Standard data line\nax.spines['left'].set_linewidth(1.5)  # Standard axis line\n\n# Problem: Can't see error bars\nax.errorbar(x, y, yerr=errors, capsize=6, capthick=2, linewidth=2)\n\nEnd of Chapter 10: Figure Troubleshooting Guide\nEmergency Checklist (use when deadline is tight):\n DPI ≥ 300 (check with print preview at 100%)\n File format correct for journal (usually TIFF/PNG)\n Color mode RGB (unless CMYK explicitly required)\n File size &lt; journal limit\n All text readable at intended print size\n Axes labeled with units\n Panel labels (A, B, C...) present\n Scale bars on all microscopy images\n Statistical annotations clear\n Color-blind safe palette used\n Figure works in grayscale\n Caption complete (methods, n, statistics)\n Consistent style across all manuscript figures",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-1-pre-design-planning",
    "href": "Chapter 10.html#section-1-pre-design-planning",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 1: PRE-DESIGN PLANNING",
    "text": "SECTION 1: PRE-DESIGN PLANNING\n\n1.1 Define Your Message\n One key finding per figure identified\n Target audience defined (specialists vs. general)\n Primary comparison clearly stated\n Figure type selected based on data structure\n\n\n1.2 Data Assessment\n Data type classified (continuous, categorical, temporal, spatial)\n Sample sizes documented (n for each group)\n Distribution assessed (normal, skewed, multimodal)\n Missing data identified and handling method determined\n Statistical tests planned\n\n\n1.3 Journal Requirements Research\n Submission guidelines read carefully\n Figure dimensions noted (single/double column width)\n Required DPI documented\n File format requirements noted\n File size limits recorded\n Color mode specified (RGB vs CMYK)\n Special requirements noted (e.g., separate panel files)",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-2-color-design",
    "href": "Chapter 10.html#section-2-color-design",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 2: COLOR DESIGN",
    "text": "SECTION 2: COLOR DESIGN\n\n2.1 Color Palette Selection\n Palette type matches data:\n   • Sequential (ordered, one direction): Viridis, Blues, YlOrRd\n   • Diverging (ordered, two directions): RdBu, PiYG, BrBG\n   • Categorical (unordered): Okabe-Ito, Set2, Dark2\n\n Colorblind-safe palette used (test with Color Oracle)\n Maximum 3-5 colors for categorical data\n Semantic consistency applied:\n   • Control always same color across figures\n   • Treatment A always same color across figures\n   • Statistical significance encoded consistently\n\n\n2.2 Color Accessibility\n Tested with colorblind simulator (Color Oracle, Coblis)\n Works in grayscale (print test performed)\n Redundant encoding added where critical (color + shape/line)\n Text contrast meets WCAG AA (4.5:1 minimum)\n No red-green combinations as sole distinguisher\n\n\n2.3 Color Scale Integrity\n Symmetric diverging scales (e.g., -3 to +3, center at 0)\n Colorbar included with units\n Missing data encoded distinctly (not from main palette)\n No rainbow colormap (jet, hsv) used\n Perceptually uniform colormap used for sequential data",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-3-typography-labels",
    "href": "Chapter 10.html#section-3-typography-labels",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 3: TYPOGRAPHY & LABELS",
    "text": "SECTION 3: TYPOGRAPHY & LABELS\n\n3.1 Font Specifications\n Font family consistent across all figures: Arial/Helvetica\n Font hierarchy implemented:\n   • Panel labels: 14-16pt, bold\n   • Titles: 12-13pt, bold\n   • Axis labels: 11pt, bold\n   • Tick labels: 9pt, regular\n   • Legend: 9pt, regular\n   • Annotations: 9-10pt, regular/italic\n\n\n3.2 Axis Labels\n All axes labeled with variable name and units: \"Variable (unit)\"\n Examples checked:\n   ✓ \"Temperature (°C)\" not \"Temperature\"\n   ✓ \"Time (hours)\" not \"Time\"\n   ✓ \"Expression (FPKM)\" not \"Expression\"\n   ✓ \"Fold Change (log₂)\" not \"Fold Change\"\n\n\n3.3 Statistical Annotations\n Notation consistent:\n   • * p &lt; 0.05\n   • ** p &lt; 0.01\n   • *** p &lt; 0.001\n   • n.s. p ≥ 0.05\n Statistical test stated in caption\n Exact p-values provided when critical\n Sample sizes (n) stated\n\n\n3.4 Text Readability\n No overlapping labels (adjustText or ggrepel used)\n All text readable at intended print size\n High contrast: black text on white background\n No text smaller than 6pt after reduction\n Bold used for emphasis (axis labels, panel labels)",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-4-plot-type-selection",
    "href": "Chapter 10.html#section-4-plot-type-selection",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 4: PLOT TYPE SELECTION",
    "text": "SECTION 4: PLOT TYPE SELECTION\n\n4.1 Comparing Groups\nData: Few groups (&lt;5), continuous variable\n Bar chart selected (if showing means/totals)\n Box plot selected (if showing distributions)\n Violin plot selected (if distributions complex/bimodal)\n Zero baseline used for bar charts\n Error bars included (SEM or SD specified)\n Individual data points overlaid (if n small)\n\n\n4.2 Distributions\nData: Distribution of continuous variable\n Histogram used (with appropriate bin width)\n Density plot used (for smooth estimate)\n Box/violin plot used (for compact view)\n Bin width justified (Sturges', Freedman-Diaconis, or manual)\n\n\n4.3 Relationships\nData: Two continuous variables\n Scatter plot used (always plot raw data)\n Regression line added if appropriate\n Correlation coefficient reported\n Hexbin or 2D density used if &gt;1000 points\n\n\n4.4 Time Series\nData: Variable measured over time\n Line graph used (implies continuity)\n Small multiples used if &gt;5 series\n Shaded error bands used (cleaner than error bars)\n Time axis starts at meaningful baseline\n\n\n4.5 What to AVOID\n NO pie charts (use bar chart instead)\n NO 3D effects on 2D data\n NO dual y-axes (unless absolutely justified)\n NO truncated bar charts (always start at zero)\n NO rainbow colormaps (jet, hsv)",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-5-layout-composition",
    "href": "Chapter 10.html#section-5-layout-composition",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 5: LAYOUT & COMPOSITION",
    "text": "SECTION 5: LAYOUT & COMPOSITION\n\n5.1 Panel Arrangement\n Layout strategy chosen:\n   • Equal weight: All panels equally important (2×2, 3×3)\n   • Dominant: Main panel (60-70%) + supporting (15-20%)\n   • Sequential: Left-to-right or top-to-bottom flow\n\n Gestalt principles applied:\n   • Proximity: Related panels close together\n   • Similarity: Same colors for same groups\n   • Closure: Boxes/borders for grouping\n\n\n5.2 Aspect Ratios\n Ratio matches data structure:\n   • Time series: 16:9 or 3:1 (wide)\n   • Comparisons: 4:3 or 3:2 (standard)\n   • Heatmaps: 1:1 or data-dependent (square)\n   • Trees: 1:2 (tall)\n\n\n5.3 White Space\n White space: 40-60% of figure area\n Margins adequate:\n   • Outer margin: 0.75-1 inch\n   • Between panels: 0.25-0.5 inch (related), 0.75-1 inch (separate)\n Not too cramped (&lt;30% white space)\n Not too sparse (&gt;70% white space)\n\n\n5.4 Panel Labels\n All panels labeled: A, B, C...\n Labels in consistent position (top-left or top-right)\n Labels bold, large (14-16pt)\n Labels easily visible (white on dark, black on light)",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-6-technical-specifications",
    "href": "Chapter 10.html#section-6-technical-specifications",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 6: TECHNICAL SPECIFICATIONS",
    "text": "SECTION 6: TECHNICAL SPECIFICATIONS\n\n6.1 Resolution\n DPI appropriate for content:\n   • Line art: 600-1000 DPI\n   • Photos/microscopy: 300-600 DPI\n   • Combination: 600 DPI\n Created at target resolution (not upsampled later)\n Effective DPI calculated: pixels / intended width (inches)\n\n\n6.2 File Format\n Format matches journal requirements:\n   • TIFF: Publication standard (lossless)\n   • PNG: Good alternative (lossless, smaller files)\n   • PDF: Vector graphics\n   • EPS: Legacy vector format\n NO JPEG used (lossy compression)\n Color mode correct: RGB (most common)\n\n\n6.3 Dimensions\n Width matches journal specifications:\n   • Single column: typically 3.5\" (89mm)\n   • Double column: typically 7\" (178mm)\n Height within limits (often ≤10\")\n Aspect ratio appropriate for data\n\n\n6.4 File Size\n File size &lt; journal limit (often 5-20 MB)\n Optimization applied if needed:\n   • PNG with compress_level=9\n   • TIFF with LZW compression\n   • Dimensions not larger than necessary\n Fallback: Split into multiple files if too large",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-7-field-specific-requirements",
    "href": "Chapter 10.html#section-7-field-specific-requirements",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 7: FIELD-SPECIFIC REQUIREMENTS",
    "text": "SECTION 7: FIELD-SPECIFIC REQUIREMENTS\n\n7.1 Microscopy Images\n Scale bar present on ALL images\n Scale bar sized appropriately (10 µm, 50 µm, 100 µm)\n Scale bar color contrasts with image (white on dark, black on light)\n Channel labels included for fluorescence:\n   • Channel name (e.g., \"DAPI\")\n   • Wavelength (e.g., \"405 nm\")\n   • Merge clearly labeled\n Image processing documented:\n   • Microscope model and settings\n   • All adjustments listed\n   • Uniform processing applied\n \"Representative images shown\" stated in caption\n Quantification included (n fields/images analyzed)\n\n\n7.2 Western Blots\n Full lanes visible (no splicing without disclosure)\n Molecular weight markers labeled\n Loading control included (β-actin, GAPDH, etc.)\n Loading control in SAME sample order\n Quantification bar chart included\n Normalized to loading control\n Error bars from biological replicates (n≥3)\n Statistical test stated\n \"Representative blot from X experiments\" in caption\n Original unprocessed images available\n\n\n7.3 Flow Cytometry\n Axes labeled: Marker name + fluorophore (e.g., \"CD4-FITC\")\n Scale type indicated (linear or logarithmic)\n Gates clearly visible (red lines typical)\n Population percentages shown\n Total cell count stated (n = X cells)\n Gating strategy defined in Methods or caption\n Compensation described in Methods\n\n\n7.4 Phylogenetic Trees\n Scale bar with units (substitutions/site, years)\n Bootstrap or posterior probability values at nodes\n Branch lengths proportional to distance\n Root indicated (outgroup stated)\n Tip labels clear\n Tree-building method stated in caption\n\n\n7.5 Network Diagrams\n Node encoding defined (size, color, shape)\n Edge encoding defined (width, color, style)\n Layout algorithm stated\n Network statistics reported (nodes, edges, density)\n Labels non-overlapping\n Not too dense (hairball avoided)",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-8-specialized-plot-types",
    "href": "Chapter 10.html#section-8-specialized-plot-types",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 8: SPECIALIZED PLOT TYPES",
    "text": "SECTION 8: SPECIALIZED PLOT TYPES\n\n8.1 Heatmaps\n Colormap matches data type:\n   • Sequential: Viridis, Plasma (one direction)\n   • Diverging: RdBu, PiYG (two directions from center)\n Symmetric diverging scale if applicable (-3 to +3, center at 0)\n Colorbar present with label and units\n Normalization stated (row Z-score, raw values, etc.)\n Clustering method stated if used\n Dendrogram shown if hierarchical clustering\n NO rainbow colormap\n\n\n8.2 Volcano Plots\n X-axis: Log₂ fold change\n Y-axis: -Log₁₀ p-value\n BOTH fold change AND p-value thresholds shown\n Threshold lines visible (typically |log₂FC| &gt; 1, p &lt; 0.05)\n Three color groups:\n   • Not significant (gray)\n   • Upregulated significant (red)\n   • Downregulated significant (blue)\n Gene counts per category in legend\n\n\n8.3 PCA Plots\n Variance explained in axis labels: \"PC1 (45.3% variance)\"\n Color/shape encodes biological variable\n 95% confidence ellipses shown for groups\n Scree plot included (shows variance by PC)\n Grid lines at x=0, y=0\n Legend with sample sizes\n\n\n8.4 Survival Curves (Kaplan-Meier)\n Y-axis: 0 to 1 (survival probability), starts at 1.0\n X-axis: Time, starts at 0\n Step function (not smooth curve)\n 95% confidence bands shown (shaded or dashed)\n Censored data marked (tick marks or + symbols)\n Log-rank test p-value reported\n Median survival times noted\n Number at risk table (or stated in caption)\n\n\n8.5 ROC Curves\n X-axis: False Positive Rate (1 - Specificity)\n Y-axis: True Positive Rate (Sensitivity)\n Diagonal reference line (y=x) shown\n AUC with 95% confidence interval reported\n Square aspect ratio (equal axes)\n Optimal operating point marked (if applicable)\n Sample size stated (n positives, n negatives)",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-9-captions",
    "href": "Chapter 10.html#section-9-captions",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 9: CAPTIONS",
    "text": "SECTION 9: CAPTIONS\n\n9.1 Caption Structure\n Format: [Figure #]. [One-sentence summary].\n   (A) [Panel A description]. (B) [Panel B description]. ...\n   [Error bar definition]. [Statistical methods]. [Abbreviations].\n\n Caption is self-contained (understandable without main text)\n All panels described (A, B, C...)\n Sample sizes stated for each group (n = X)\n Error bar type specified (SEM or SD)\n Statistical methods documented:\n   • Test used (t-test, ANOVA, etc.)\n   • Significance thresholds (*, **, ***)\n   • Post-hoc tests if applicable\n Abbreviations defined at first use\n Technical details included:\n   • Microscopy: scale bars, magnifications\n   • Blots: antibodies, molecular weights\n   • Flow: cell counts, gating strategy",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-10-cross-figure-consistency",
    "href": "Chapter 10.html#section-10-cross-figure-consistency",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 10: CROSS-FIGURE CONSISTENCY",
    "text": "SECTION 10: CROSS-FIGURE CONSISTENCY\n\n10.1 Manuscript-Wide Checks\n Font family identical across all figures\n Font sizes consistent (panel labels, axes, ticks)\n Color scheme consistent:\n   • Control always same color\n   • Treatment A always same color\n   • Treatment B always same color\n Line widths uniform (data: 2-3pt, axes: 1-1.5pt)\n Marker sizes uniform\n Panel label format consistent (position, size)\n Error bar style consistent (all SEM or all SD)\n Statistical notation consistent (*, **, ***)\n Grid styles consistent (if used)\n All figures export at same DPI (300 minimum)\n File formats consistent\n\n\n10.2 Style Guide Documentation\n Style guide created and saved:\n   • Font family and sizes\n   • Color palette (hex codes)\n   • Line widths\n   • Marker sizes\n   • Aspect ratios by plot type\n Template files created (Python rcParams, R themes)\n Version control for figures:\n   • File naming: figure1_v1_20250108.png\n   • Change log maintained\n   • Original high-res files saved separately",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-11-ethical-compliance",
    "href": "Chapter 10.html#section-11-ethical-compliance",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 11: ETHICAL COMPLIANCE",
    "text": "SECTION 11: ETHICAL COMPLIANCE\n\n11.1 Image Integrity\n NO selective brightness/contrast adjustments\n All adjustments applied uniformly to comparison images\n Linear adjustments only (no gamma without justification)\n NO background removal beyond uniform adjustments\n NO cloning or content-aware fill\n NO selective cropping to remove unwanted features\n Original unprocessed images saved and available\n All processing documented in Methods section\n\n\n11.2 Data Integrity\n NO data point removal without justification\n Outliers handled transparently (method stated)\n NO selective reporting (all replicates shown or summarized)\n NO p-hacking (multiple testing corrected)\n NO misleading truncation of axes (bar charts start at zero)\n NO manipulation of scales to exaggerate effects\n\n\n11.3 Documentation\n Methods section documents:\n   • Image acquisition settings\n   • Statistical tests and software\n   • Sample sizes and replicates\n   • Inclusion/exclusion criteria\n   • All image processing steps\n Raw data available (in supplement or upon request)\n Code available (if computational)",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-12-pre-submission-final-checks",
    "href": "Chapter 10.html#section-12-pre-submission-final-checks",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 12: PRE-SUBMISSION FINAL CHECKS",
    "text": "SECTION 12: PRE-SUBMISSION FINAL CHECKS\n\n12.1 Technical Quality\n Print test at 100% scale performed (readability check)\n DPI verified (≥300 for publication)\n File format correct for journal\n File size &lt; journal limit\n Color mode correct (RGB unless CMYK specified)\n All fonts embedded (if PDF/EPS)\n No compression artifacts (JPEG avoided)\n Files named per journal convention\n\n\n12.2 Visual Quality\n All text readable at intended size\n No overlapping labels\n Colors distinguish well\n Grid lines subtle (not overwhelming)\n White space balanced (40-60%)\n Panels aligned properly\n Consistent styling across all manuscript figures\n\n\n12.3 Content Completeness\n All axes labeled with units\n All panels labeled (A, B, C...)\n Scale bars on all microscopy images\n Molecular weight markers on all blots\n Statistical annotations clear\n Legends complete\n Captions self-contained\n Supplementary figures numbered separately\n\n\n12.4 Accessibility\n Colorblind-safe palette used\n Tested with colorblind simulator\n Works in grayscale\n Redundant encoding present (color + shape/line)\n Text contrast sufficient (WCAG AA)\n Alt text prepared (if online publication)\n\n\n12.5 Journal-Specific\n Dimensions match specifications\n Resolution meets requirements\n File format allowed\n File size within limits\n Special requirements met (e.g., separate panel files)\n Submission checklist completed",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-13-interactive-figures-if-applicable",
    "href": "Chapter 10.html#section-13-interactive-figures-if-applicable",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 13: INTERACTIVE FIGURES (if applicable)",
    "text": "SECTION 13: INTERACTIVE FIGURES (if applicable)\n\n13.1 Interactive Figure Requirements\n Static fallback version created (for print/PDF)\n Alt text provided (describes figure content)\n Colorblind-safe palette used (same as static)\n Tested on multiple browsers (Chrome, Firefox, Safari)\n Download option for underlying data provided\n Software/library versions documented in Methods\n File size optimized (&lt;10 MB target for web)\n\n\n13.2 Caption for Interactive\n Instructions included:\n   • How to interact (hover, click, drag)\n   • What features are available (zoom, pan, filter)\n   • URL to interactive version\n Static version described: \"Static version shows [state]\"\n Data availability noted (supplementary table, etc.)",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-14-troubleshooting-quick-fixes",
    "href": "Chapter 10.html#section-14-troubleshooting-quick-fixes",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 14: TROUBLESHOOTING QUICK FIXES",
    "text": "SECTION 14: TROUBLESHOOTING QUICK FIXES\n\n14.1 One-Line Fixes\n# Text too small\nplt.rcParams['font.size'] = 11\n\n# Legend overlaps data\nax.legend(loc='upper left', bbox_to_anchor=(1.02, 1))\n\n# Margins too tight\nplt.tight_layout(pad=2.0)\n\n# Axes labels cut off\nplt.savefig('figure.png', bbox_inches='tight')\n\n# Tick labels overlap\nax.tick_params(axis='x', rotation=45)\n\n# Grid too prominent\nax.grid(alpha=0.3, linewidth=0.5)\n\n# Inconsistent line widths\nax.plot(x, y, linewidth=2.5)  # Data lines\nax.spines['left'].set_linewidth(1.5)  # Axes\n\n# Error bars not visible\nax.errorbar(x, y, yerr=err, capsize=6, capthick=2, linewidth=2)\n\n\n14.2 Common Problems → Solutions\nBlurry figure → Re-export at 300+ DPI (don't upsample)\nColors look different in print → Use print-safe RGB palette\nFile too large → Optimize compression, reduce dimensions\nFonts missing → Embed fonts (fonttype=42) or use system fonts\nLabels overlapping → Use adjustText (Python) or ggrepel (R)\nFigure cluttered → Reduce elements, increase white space\nPanels misaligned → Use consistent limits and GridSpec\nBar chart misleading → Always start at zero\nP-values unreadable → Show only key comparisons or use letter notation\nJournal rejection → Document all processing, provide originals",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-15-manuscript-submission-checklist",
    "href": "Chapter 10.html#section-15-manuscript-submission-checklist",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 15: MANUSCRIPT SUBMISSION CHECKLIST",
    "text": "SECTION 15: MANUSCRIPT SUBMISSION CHECKLIST\n\n15.1 All Figures\n Figures numbered sequentially (Figure 1, 2, 3...)\n All figures cited in text in order\n All figure files in correct format\n All figure files named correctly (e.g., Figure1.tif)\n All figure captions in separate document (if required)\n Supplementary figures numbered separately (Figure S1, S2...)\n High-resolution originals saved separately\n Figure permissions obtained (if reusing published material)\n\n\n15.2 Cover Letter\n Figure creation software stated\n Statistical software stated\n Any special considerations mentioned (e.g., large file sizes)\n Confirmation of original data and no manipulation\n\n\n15.3 Methods Section\n Figure creation software and versions\n Statistical tests with software\n Image acquisition parameters\n Image processing steps\n Color encodings explained\n Any custom code deposited (GitHub, Zenodo)",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#section-16-post-submission",
    "href": "Chapter 10.html#section-16-post-submission",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "SECTION 16: POST-SUBMISSION",
    "text": "SECTION 16: POST-SUBMISSION\n\n16.1 Revision Response\n Original figure files saved (for comparison)\n Revised figures clearly marked (v2, v3, etc.)\n Change log maintained (what changed and why)\n Response letter documents figure changes\n Reviewer comments addressed systematically\n\n\n16.2 Data Archival\n Raw data deposited (journal repository or public database)\n Figure source code deposited (if computational)\n Original unprocessed images archived\n Processing scripts archived\n README file with metadata",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#emergency-deadline-checklist-30-min-review",
    "href": "Chapter 10.html#emergency-deadline-checklist-30-min-review",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "EMERGENCY DEADLINE CHECKLIST (30-min review)",
    "text": "EMERGENCY DEADLINE CHECKLIST (30-min review)\nIf you have 30 minutes before submission:\n DPI ≥ 300 (zoom to 100% and check readability)\n File format correct (TIFF or PNG, NOT JPEG)\n All axes labeled with units\n Panel labels present (A, B, C...)\n Scale bars on microscopy images\n Color-blind safe palette (test with Color Oracle)\n Works in grayscale (File → Print Preview)\n Caption complete (n, statistics, error bars defined)\n File size &lt; limit\n Consistent style across figures\n Statistical annotations clear\n Spelling checked (titles, labels, captions)",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  },
  {
    "objectID": "Chapter 10.html#resources-tools",
    "href": "Chapter 10.html#resources-tools",
    "title": "Chapter 10: Figure Troubleshooting Guide",
    "section": "RESOURCES & TOOLS",
    "text": "RESOURCES & TOOLS\n\nSoftware\nPython: matplotlib, seaborn, plotly\nR: ggplot2, patchwork, pheatmap\nColor tools: Color Oracle, Coblis, ColorBrewer\nImage processing: ImageJ/Fiji, Adobe Photoshop (with caution)\nVector graphics: Adobe Illustrator, Inkscape\n\n\nColor Palettes\nColorblind-safe:\n- Okabe-Ito (8 colors): Universal\n- Viridis family: Sequential, perceptually uniform\n- ColorBrewer: CVD-safe filter available\n\n\nReferences\n- Tufte, E. \"The Visual Display of Quantitative Information\"\n- Wilke, C. O. \"Fundamentals of Data Visualization\" (online)\n- Nature Methods \"Points of View\" series\n- Journal-specific figure guidelines\n\n\nOnline Validators\n- Color contrast: WebAIM Contrast Checker\n- Colorblind simulation: Color Oracle, Coblis\n- Image integrity: Check for duplications (manually or software)",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 10: Figure Troubleshooting Guide</span>"
    ]
  }
]